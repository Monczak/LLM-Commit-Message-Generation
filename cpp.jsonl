{"diff_id": 84, "repo": "apple/swift\n", "sha": "e8454ab8ab87afa92b999ef004477000ee60da41\n", "time": "2018-07-18T21:50:40Z\n", "diff": "mmm a / lib / Sema / TypeCheckDecl . cpp <nl> ppp b / lib / Sema / TypeCheckDecl . cpp <nl> static void finalizeType ( TypeChecker & TC , NominalTypeDecl * nominal ) { <nl> <nl> TC . validateDecl ( VD ) ; <nl> <nl> + TC . requestMemberLayout ( VD ) ; <nl> + <nl> / / The only thing left to do is synthesize storage for lazy variables . <nl> auto * prop = dyn_cast < VarDecl > ( D ) ; <nl> if ( ! prop ) <nl>\n", "msg": "[ Type checker ] Request member layout for a member of a finalized type .\n", "score": 1}
{"diff_id": 148, "repo": "bitcoin/bitcoin\n", "sha": "c2ccadc26a04358b11539097c1aadb8d11b85c21\n", "time": "2020-04-06T21:39:42Z\n", "diff": "mmm a / src / test / fuzz / prevector . cpp <nl> ppp b / src / test / fuzz / prevector . cpp <nl> void test_one_input ( const std : : vector < uint8_t > & buffer ) <nl> prevector_tester < 8 , int > test ; <nl> <nl> while ( prov . remaining_bytes ( ) ) { <nl> - switch ( prov . ConsumeIntegralInRange < int > ( 0 , 14 + 3 * ( test . size ( ) > 0 ) ) ) { <nl> + switch ( prov . ConsumeIntegralInRange < int > ( 0 , 13 + 3 * ( test . size ( ) > 0 ) ) ) { <nl> case 0 : <nl> test . insert ( prov . ConsumeIntegralInRange < size_t > ( 0 , test . size ( ) ) , prov . ConsumeIntegral < int > ( ) ) ; <nl> break ; <nl> void test_one_input ( const std : : vector < uint8_t > & buffer ) <nl> test . insert ( prov . ConsumeIntegralInRange < size_t > ( 0 , test . size ( ) ) , 1 + prov . ConsumeBool ( ) , prov . ConsumeIntegral < int > ( ) ) ; <nl> break ; <nl> case 3 : { <nl> - int del = std : : min < int > ( test . size ( ) , 1 + prov . ConsumeBool ( ) ) ; <nl> + int del = prov . ConsumeIntegralInRange < int > ( 0 , test . size ( ) ) ; <nl> int beg = prov . ConsumeIntegralInRange < int > ( 0 , test . size ( ) - del ) ; <nl> test . erase ( beg , beg + del ) ; <nl> break ; <nl> void test_one_input ( const std : : vector < uint8_t > & buffer ) <nl> test . insert_range ( prov . ConsumeIntegralInRange < size_t > ( 0 , test . size ( ) ) , values , values + num ) ; <nl> break ; <nl> } <nl> - case 6 : { <nl> - int del = std : : min < int > ( test . size ( ) , 1 + prov . ConsumeIntegralInRange < int > ( 0 , 3 ) ) ; <nl> - int beg = prov . ConsumeIntegralInRange < int > ( 0 , test . size ( ) - del ) ; <nl> - test . erase ( beg , beg + del ) ; <nl> - break ; <nl> - } <nl> case 7 : <nl> test . reserve ( prov . ConsumeIntegralInRange < size_t > ( 0 , 32767 ) ) ; <nl> break ; <nl> case 8 : <nl> test . shrink_to_fit ( ) ; <nl> break ; <nl> - case 17 : <nl> + case 14 : <nl> test . update ( prov . ConsumeIntegralInRange < size_t > ( 0 , test . size ( ) - 1 ) , prov . ConsumeIntegral < int > ( ) ) ; <nl> break ; <nl> case 9 : <nl> void test_one_input ( const std : : vector < uint8_t > & buffer ) <nl> case 13 : <nl> test . move ( ) ; <nl> break ; <nl> - case 14 : { <nl> + case 6 : { <nl> int num = 1 + prov . ConsumeIntegralInRange < int > ( 0 , 15 ) ; <nl> std : : vector < int > values ( num ) ; <nl> for ( auto & v : values ) { <nl>\n", "msg": "Merge and generalize case 3 and case 6\n"}
{"diff_id": 170, "msg": "Moved API Breaking Changes section of the documentation above the programmer ' s FAQ .\n", "msgGPT": "refactor API breaking changes section in documentation.", "METEOR Score": "33.88667755838267", "BLEU Score": "0.45949609387715834", "ROUGE-L Score": "0.49999999545000007", "score": 1, "repo": "ocornut/imgui\n", "sha": "abe45e9976eaf05028c9e1971d08f32bb7816d7c\n", "time": "2014-11-26T22:27:48Z\n", "diff": "mmm a / imgui . cpp <nl> ppp b / imgui . cpp <nl> <nl> - MISSION STATEMENT <nl> - END - USER GUIDE <nl> - PROGRAMMER GUIDE <nl> - - TROUBLESHOOTING & FREQUENTLY ASKED QUESTIONS <nl> - API BREAKING CHANGES <nl> + - TROUBLESHOOTING & FREQUENTLY ASKED QUESTIONS <nl> - ISSUES & TODO - LIST <nl> - CODE <nl> - SAMPLE CODE <nl> <nl> / / swap video buffer , etc . <nl> } <nl> <nl> + API BREAKING CHANGES <nl> + = = = = = = = = = = = = = = = = = = = = <nl> + <nl> + Occasionally introducing changes that are breaking the API . The breakage are generally minor and easy to fix . <nl> + Here is a change - log of API breaking changes , if you are using one of the functions listed , expect to have to fix some code . <nl> + <nl> + - 2014 / 11 / 26 ( 1 . 17 ) retired IMGUI_ONCE_UPON_A_FRAME helper macro in favor of ImGuiOnceUponAFrame type that works on all compilers . <nl> + - 2014 / 11 / 07 ( 1 . 15 ) renamed IsHovered ( ) to IsItemHovered ( ) <nl> + - 2014 / 10 / 02 ( 1 . 14 ) renamed IMGUI_INCLUDE_IMGUI_USER_CPP to IMGUI_INCLUDE_IMGUI_USER_INL and imgui_user . cpp to imgui_user . inl ( more IDE friendly ) <nl> + - 2014 / 09 / 25 ( 1 . 13 ) removed ' text_end ' parameter from IO . SetClipboardTextFn ( the string is now always zero - terminated for simplicity ) <nl> + - 2014 / 09 / 24 ( 1 . 12 ) renamed SetFontScale ( ) to SetWindowFontScale ( ) <nl> + - 2014 / 09 / 24 ( 1 . 12 ) moved IM_MALLOC / IM_REALLOC / IM_FREE preprocessor defines to IO . MemAllocFn / IO . MemReallocFn / IO . MemFreeFn <nl> + - 2014 / 08 / 30 ( 1 . 09 ) removed IO . FontHeight ( now computed automatically ) <nl> + - 2014 / 08 / 30 ( 1 . 09 ) moved IMGUI_FONT_TEX_UV_FOR_WHITE preprocessor define to IO . FontTexUvForWhite <nl> + - 2014 / 08 / 28 ( 1 . 09 ) changed the behavior of IO . PixelCenterOffset following various rendering fixes <nl> + <nl> TROUBLESHOOTING & FREQUENTLY ASKED QUESTIONS <nl> = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = <nl> <nl> <nl> - tip : you can create widgets without a Begin ( ) / End ( ) block , they will go in an implicit window called \" Debug \" <nl> - tip : read the ShowTestWindow ( ) code for more example of how to use ImGui ! <nl> <nl> - API BREAKING CHANGES <nl> - = = = = = = = = = = = = = = = = = = = = <nl> - <nl> - - 2014 / 11 / 07 ( 1 . 15 ) renamed IsHovered ( ) to IsItemHovered ( ) <nl> - - 2014 / 10 / 02 ( 1 . 14 ) renamed IMGUI_INCLUDE_IMGUI_USER_CPP to IMGUI_INCLUDE_IMGUI_USER_INL and imgui_user . cpp to imgui_user . inl ( more IDE friendly ) <nl> - - 2014 / 09 / 25 ( 1 . 13 ) removed ' text_end ' parameter from IO . SetClipboardTextFn ( the string is now always zero - terminated for simplicity ) <nl> - - 2014 / 09 / 24 ( 1 . 12 ) renamed SetFontScale ( ) to SetWindowFontScale ( ) <nl> - - 2014 / 09 / 24 ( 1 . 12 ) moved IM_MALLOC / IM_REALLOC / IM_FREE preprocessor defines to IO . MemAllocFn / IO . MemReallocFn / IO . MemFreeFn <nl> - - 2014 / 08 / 30 ( 1 . 09 ) removed IO . FontHeight ( now computed automatically ) <nl> - - 2014 / 08 / 30 ( 1 . 09 ) moved IMGUI_FONT_TEX_UV_FOR_WHITE preprocessor define to IO . FontTexUvForWhite <nl> - - 2014 / 08 / 28 ( 1 . 09 ) changed the behavior of IO . PixelCenterOffset following various rendering fixes <nl> - <nl> ISSUES & TODO - LIST <nl> = = = = = = = = = = = = = = = = = = <nl> <nl>\n"}
{"diff_id": 227, "repo": "MarlinFirmware/Marlin\n", "sha": "b2c1cd7eda5aaec3ec9ef5322e9502025ce2a2f2\n", "time": "2018-10-10T14:57:48Z\n", "diff": "mmm a / Marlin / src / module / tool_change . cpp <nl> ppp b / Marlin / src / module / tool_change . cpp <nl> void tool_change ( const uint8_t tmp_extruder , const float fr_mm_s / * = 0 . 0 * / , bool n <nl> if ( ! DEBUGGING ( DRYRUN ) & & thermalManager . targetTooColdToExtrude ( active_extruder ) ) { <nl> SERIAL_ERROR_START ( ) ; <nl> SERIAL_ERRORLNPGM ( MSG_HOTEND_TOO_COLD ) ; <nl> + active_extruder = tmp_extruder ; <nl> return ; <nl> } <nl> # endif <nl>\n", "msg": "Allow cold change of active extruder ( )\n"}
{"diff_id": 624, "repo": "xbmc/xbmc\n", "sha": "c03a4a7d1410fbdbbdd59581161c203f640a2108\n", "time": "2015-12-30T12:54:26Z\n", "diff": "mmm a / xbmc / cores / VideoPlayer / VideoRenderers / BaseRenderer . cpp <nl> ppp b / xbmc / cores / VideoPlayer / VideoRenderers / BaseRenderer . cpp <nl> void CBaseRenderer : : ManageDisplay ( ) <nl> else if ( stereo_view = = RENDER_STEREO_VIEW_RIGHT ) stereo_view = RENDER_STEREO_VIEW_LEFT ; <nl> } <nl> <nl> - switch ( stereo_mode ) <nl> + if ( m_format ! = RENDER_FMT_BYPASS ) <nl> { <nl> - case CONF_FLAGS_STEREO_MODE_TAB : <nl> - / / Those are flipped in y <nl> - if ( m_format = = RENDER_FMT_CVBREF | | m_format = = RENDER_FMT_MEDIACODEC ) <nl> - { <nl> - if ( stereo_view = = RENDER_STEREO_VIEW_LEFT ) <nl> - m_sourceRect . y1 + = m_sourceRect . y2 * 0 . 5f ; <nl> - else if ( stereo_view = = RENDER_STEREO_VIEW_RIGHT ) <nl> - m_sourceRect . y2 * = 0 . 5f ; <nl> - } <nl> - else <nl> - { <nl> - if ( stereo_view = = RENDER_STEREO_VIEW_LEFT ) <nl> - m_sourceRect . y2 * = 0 . 5f ; <nl> + switch ( stereo_mode ) <nl> + { <nl> + case CONF_FLAGS_STEREO_MODE_TAB : <nl> + / / Those are flipped in y <nl> + if ( m_format = = RENDER_FMT_CVBREF | | m_format = = RENDER_FMT_MEDIACODEC ) <nl> + { <nl> + if ( stereo_view = = RENDER_STEREO_VIEW_LEFT ) <nl> + m_sourceRect . y1 + = m_sourceRect . y2 * 0 . 5f ; <nl> + else if ( stereo_view = = RENDER_STEREO_VIEW_RIGHT ) <nl> + m_sourceRect . y2 * = 0 . 5f ; <nl> + } <nl> + else <nl> + { <nl> + if ( stereo_view = = RENDER_STEREO_VIEW_LEFT ) <nl> + m_sourceRect . y2 * = 0 . 5f ; <nl> + else if ( stereo_view = = RENDER_STEREO_VIEW_RIGHT ) <nl> + m_sourceRect . y1 + = m_sourceRect . y2 * 0 . 5f ; <nl> + } <nl> + break ; <nl> + <nl> + case CONF_FLAGS_STEREO_MODE_SBS : <nl> + if ( stereo_view = = RENDER_STEREO_VIEW_LEFT ) <nl> + m_sourceRect . x2 * = 0 . 5f ; <nl> else if ( stereo_view = = RENDER_STEREO_VIEW_RIGHT ) <nl> - m_sourceRect . y1 + = m_sourceRect . y2 * 0 . 5f ; <nl> - } <nl> - break ; <nl> - <nl> - case CONF_FLAGS_STEREO_MODE_SBS : <nl> - if ( stereo_view = = RENDER_STEREO_VIEW_LEFT ) <nl> - m_sourceRect . x2 * = 0 . 5f ; <nl> - else if ( stereo_view = = RENDER_STEREO_VIEW_RIGHT ) <nl> - m_sourceRect . x1 + = m_sourceRect . x2 * 0 . 5f ; <nl> - break ; <nl> + m_sourceRect . x1 + = m_sourceRect . x2 * 0 . 5f ; <nl> + break ; <nl> <nl> - default : <nl> - break ; <nl> + default : <nl> + break ; <nl> + } <nl> } <nl> <nl> CalcNormalDisplayRect ( m_viewRect . x1 , m_viewRect . y1 , m_viewRect . Width ( ) , m_viewRect . Height ( ) , GetAspectRatio ( ) * CDisplaySettings : : GetInstance ( ) . GetPixelRatio ( ) , CDisplaySettings : : GetInstance ( ) . GetZoomAmount ( ) , CDisplaySettings : : GetInstance ( ) . GetVerticalShift ( ) ) ; <nl>\n", "msg": "[ renderer ] Don ' t adjust 3d rectangles in bypass mode\n"}
{"diff_id": 634, "repo": "aseprite/aseprite\n", "sha": "ca6d038af3be57721d10ccf0ae993827084433bf\n", "time": "2018-11-28T15:05:17Z\n", "diff": "mmm a / src / app / script / app_object . cpp <nl> ppp b / src / app / script / app_object . cpp <nl> int App_set_activeLayer ( lua_State * L ) <nl> <nl> int App_set_activeFrame ( lua_State * L ) <nl> { <nl> - const doc : : frame_t frame = lua_tointeger ( L , 2 ) - 1 ; <nl> + const doc : : frame_t frame = get_frame_number_from_arg ( L , 2 ) ; <nl> # ifdef ENABLE_UI <nl> app : : Context * ctx = App : : instance ( ) - > context ( ) ; <nl> if ( auto uiCtx = dynamic_cast < UIContext * > ( ctx ) ) { <nl>\n", "msg": "lua : Add support to use app . activeFrame with a Frame object\n"}
{"diff_id": 679, "repo": "EOSIO/eos\n", "sha": "41a4c367b1dd2968083403aa9742ea4ef4878a6a\n", "time": "2017-11-23T02:50:50Z\n", "diff": "mmm a / programs / eosc / main . cpp <nl> ppp b / programs / eosc / main . cpp <nl> int main ( int argc , char * * argv ) { <nl> <nl> auto benchmark_transfer = benchmark - > add_subcommand ( \" transfer \" , localized ( \" executes random transfers among accounts \" ) ) ; <nl> uint64_t number_of_transfers = 0 ; <nl> + uint64_t expiration = 0 ; <nl> bool loop = false ; <nl> benchmark_transfer - > add_option ( \" accounts \" , number_of_accounts , localized ( \" the number of accounts in transfer among \" ) ) - > required ( ) ; <nl> benchmark_transfer - > add_option ( \" count \" , number_of_transfers , localized ( \" the number of transfers to execute \" ) ) - > required ( ) ; <nl> + benchmark_transfer - > add_option ( \" expiration \" , expiration , localized ( \" the number of seconds to expire \" ) ) - > required ( ) ; <nl> benchmark_transfer - > add_option ( \" loop \" , loop , localized ( \" whether or not to loop for ever \" ) ) ; <nl> add_standard_transaction_options ( benchmark_transfer ) ; <nl> benchmark_transfer - > set_callback ( [ & ] { <nl> int main ( int argc , char * * argv ) { <nl> transaction_emplace_message ( trx , config : : eos_contract_name , <nl> vector < types : : account_permission > { { sender , \" active \" } } , <nl> \" transfer \" , types : : transfer { sender , recipient , amount , memo } ) ; <nl> - trx . expiration = info . head_block_time + fc : : seconds ( 1800 ) ; <nl> + trx . expiration = info . head_block_time + fc : : seconds ( expiration ) ; <nl> transaction_set_reference_block ( trx , info . head_block_id ) ; <nl> sign_transaction ( trx ) ; <nl> batch . emplace_back ( trx ) ; <nl>\n", "msg": "Updated expiration in seconds for benchmark transfer command .\n", "score": 1}
{"diff_id": 932, "repo": "bitcoin/bitcoin\n", "sha": "bdd5b587fc7fd1b4dda479c4aad15c874b22e8f3\n", "time": "2014-07-14T11:58:57Z\n", "diff": "mmm a / src / init . cpp <nl> ppp b / src / init . cpp <nl> std : : string HelpMessage ( HelpMessageMode mode ) <nl> strUsage + = \" - par = < n > \" + strprintf ( _ ( \" Set the number of script verification threads ( % u to % d , 0 = auto , < 0 = leave that many cores free , default : % d ) \" ) , - ( int ) boost : : thread : : hardware_concurrency ( ) , MAX_SCRIPTCHECK_THREADS , DEFAULT_SCRIPTCHECK_THREADS ) + \" \\ n \" ; <nl> strUsage + = \" - pid = < file > \" + _ ( \" Specify pid file ( default : bitcoind . pid ) \" ) + \" \\ n \" ; <nl> strUsage + = \" - reindex \" + _ ( \" Rebuild block chain index from current blk000 ? ? . dat files \" ) + \" \" + _ ( \" on startup \" ) + \" \\ n \" ; <nl> + # if ! defined ( WIN32 ) <nl> + strUsage + = \" - sysperms \" + _ ( \" Create new files with system default permissions , instead of umask 077 ( only effective with disabled wallet functionality ) \" ) + \" \\ n \" ; <nl> + # endif <nl> strUsage + = \" - txindex \" + _ ( \" Maintain a full transaction index ( default : 0 ) \" ) + \" \\ n \" ; <nl> <nl> + <nl> strUsage + = \" \\ n \" + _ ( \" Connection options : \" ) + \" \\ n \" ; <nl> strUsage + = \" - addnode = < ip > \" + _ ( \" Add a node to connect to and attempt to keep the connection open \" ) + \" \\ n \" ; <nl> strUsage + = \" - banscore = < n > \" + _ ( \" Threshold for disconnecting misbehaving peers ( default : 100 ) \" ) + \" \\ n \" ; <nl> bool AppInit2 ( boost : : thread_group & threadGroup ) <nl> } <nl> # endif <nl> # ifndef WIN32 <nl> - umask ( 077 ) ; <nl> + <nl> + if ( GetBoolArg ( \" - sysperms \" , false ) ) { <nl> + # ifdef ENABLE_WALLET <nl> + if ( ! GetBoolArg ( \" - disablewallet \" , false ) ) <nl> + return InitError ( \" Error : - sysperms is not allowed in combination with enabled wallet functionality \" ) ; <nl> + # endif <nl> + } else { <nl> + umask ( 077 ) ; <nl> + } <nl> <nl> / / Clean shutdown on SIGTERM <nl> struct sigaction sa ; <nl>\n", "msg": "Add option to disable 077 umask ( create new files with system default umask )\n"}
{"diff_id": 997, "repo": "godotengine/godot\n", "sha": "99f93ea4406f14c6f6f9163d422c72598fa70dc9\n", "time": "2018-01-16T08:18:47Z\n", "diff": "mmm a / platform / android / export / export . cpp <nl> ppp b / platform / android / export / export . cpp <nl> class EditorExportAndroid : public EditorExportPlatform { <nl> return OK ; <nl> } <nl> <nl> + static Error ignore_apk_file ( void * p_userdata , const String & p_path , const Vector < uint8_t > & p_data , int p_file , int p_total ) { <nl> + return OK ; <nl> + } <nl> + <nl> void _fix_manifest ( const Ref < EditorExportPreset > & p_preset , Vector < uint8_t > & p_manifest , bool p_give_internet ) { <nl> <nl> / / Leaving the unused types commented because looking these constants up <nl> class EditorExportAndroid : public EditorExportPlatform { <nl> cl . push_back ( passwd ) ; <nl> } * / <nl> <nl> + APKExportData ed ; <nl> + ed . ep = & ep ; <nl> + ed . apk = unaligned_apk ; <nl> + err = export_project_files ( p_preset , ignore_apk_file , & ed , save_apk_so ) ; <nl> } else { <nl> / / all files <nl> <nl> class EditorExportAndroid : public EditorExportPlatform { <nl> <nl> err = export_project_files ( p_preset , save_apk_file , & ed , save_apk_so ) ; <nl> } <nl> + } <nl> <nl> - if ( ! err ) { <nl> - APKExportData ed ; <nl> - ed . ep = & ep ; <nl> - ed . apk = unaligned_apk ; <nl> - for ( int i = 0 ; i < sizeof ( launcher_icons ) / sizeof ( launcher_icons [ 0 ] ) ; + + i ) { <nl> - String icon_path = String ( p_preset - > get ( launcher_icons [ i ] . option_id ) ) . strip_edges ( ) ; <nl> - if ( icon_path ! = \" \" & & icon_path . ends_with ( \" . png \" ) & & FileAccess : : exists ( icon_path ) ) { <nl> - Vector < uint8_t > data = FileAccess : : get_file_as_array ( icon_path ) ; <nl> - store_in_apk ( & ed , launcher_icons [ i ] . export_path , data ) ; <nl> - } <nl> + if ( ! err ) { <nl> + APKExportData ed ; <nl> + ed . ep = & ep ; <nl> + ed . apk = unaligned_apk ; <nl> + for ( int i = 0 ; i < sizeof ( launcher_icons ) / sizeof ( launcher_icons [ 0 ] ) ; + + i ) { <nl> + String icon_path = String ( p_preset - > get ( launcher_icons [ i ] . option_id ) ) . strip_edges ( ) ; <nl> + if ( icon_path ! = \" \" & & icon_path . ends_with ( \" . png \" ) & & FileAccess : : exists ( icon_path ) ) { <nl> + Vector < uint8_t > data = FileAccess : : get_file_as_array ( icon_path ) ; <nl> + store_in_apk ( & ed , launcher_icons [ i ] . export_path , data ) ; <nl> } <nl> } <nl> } <nl>\n", "msg": "Make remote FS work with GDNative on Android\n"}
{"diff_id": 1118, "repo": "CRYTEK/CRYENGINE\n", "sha": "7e82904e25079629c601bd1e066946db1b93e55d\n", "time": "2016-11-23T15:20:02Z\n", "diff": "mmm a / Code / CryEngine / CryAISystem / Sequence / SequenceFlowNodes . cpp <nl> ppp b / Code / CryEngine / CryAISystem / Sequence / SequenceFlowNodes . cpp <nl> void CFlowNode_AISequenceBookmark : : ProcessEvent ( EFlowEvent event , SActivationInf <nl> { <nl> if ( IsPortActive ( pActInfo , InputPort_Set ) ) <nl> { <nl> - const SequenceId assignedSequenceId = GetAssignedSequenceId ( ) ; <nl> - assert ( assignedSequenceId ) ; <nl> - if ( ! assignedSequenceId ) <nl> - return ; <nl> - <nl> - GetAISystem ( ) - > GetSequenceManager ( ) - > SetBookmark ( assignedSequenceId , pActInfo - > myID ) ; <nl> - ActivateOutput ( pActInfo , OutputPort_Link , true ) ; <nl> + if ( const SequenceId assignedSequenceId = GetAssignedSequenceId ( ) ) <nl> + { <nl> + GetAISystem ( ) - > GetSequenceManager ( ) - > SetBookmark ( assignedSequenceId , pActInfo - > myID ) ; <nl> + ActivateOutput ( pActInfo , OutputPort_Link , true ) ; <nl> + } <nl> } <nl> } <nl> break ; <nl> void CFlowNode_AISequenceActionMoveAlongPath : : ProcessEvent ( EFlowEvent event , SAc <nl> case eFE_Activate : <nl> { <nl> m_actInfo = * pActInfo ; <nl> - const SequenceId assignedSequenceId = GetAssignedSequenceId ( ) ; <nl> - assert ( assignedSequenceId ) ; <nl> - if ( ! assignedSequenceId ) <nl> - return ; <nl> - <nl> - if ( IsPortActive ( pActInfo , InputPort_Start ) ) <nl> + if ( const SequenceId assignedSequenceId = GetAssignedSequenceId ( ) ) <nl> { <nl> - GetAISystem ( ) - > GetSequenceManager ( ) - > RequestActionStart ( assignedSequenceId , m_actInfo . myID ) ; <nl> + if ( IsPortActive ( pActInfo , InputPort_Start ) ) <nl> + { <nl> + GetAISystem ( ) - > GetSequenceManager ( ) - > RequestActionStart ( assignedSequenceId , m_actInfo . myID ) ; <nl> + } <nl> } <nl> } <nl> break ; <nl> void CFlowNode_AISequenceAction_Stance : : ProcessEvent ( EFlowEvent event , SActivati <nl> { <nl> m_actInfo = * pActInfo ; <nl> <nl> - const SequenceId assignedSequenceId = GetAssignedSequenceId ( ) ; <nl> - assert ( assignedSequenceId ) ; <nl> - if ( ! assignedSequenceId ) <nl> - return ; <nl> - <nl> - GetAISystem ( ) - > GetSequenceManager ( ) - > RequestActionStart ( assignedSequenceId , m_actInfo . myID ) ; <nl> + if ( const SequenceId assignedSequenceId = GetAssignedSequenceId ( ) ) <nl> + { <nl> + GetAISystem ( ) - > GetSequenceManager ( ) - > RequestActionStart ( assignedSequenceId , m_actInfo . myID ) ; <nl> + } <nl> } <nl> } <nl> } <nl>\n", "msg": "! B ( CE - 10899 ) ( AISystem ) Sequence nodes : changed the way how nodes react on invalid sequence IDs to prevent consequential errors from preceding errors ( Approved by samuelk )\n", "score": 1}
{"diff_id": 1359, "repo": "CRYTEK/CRYENGINE\n", "sha": "5ca877324650822fc29a1fcd847ca7788e8ba139\n", "time": "2018-01-03T16:21:02Z\n", "diff": "mmm a / Code / CryEngine / CryAudioSystem / ATLAudioObject . cpp <nl> ppp b / Code / CryEngine / CryAudioSystem / ATLAudioObject . cpp <nl> void CATLAudioObject : : Update ( <nl> m_propagationProcessor . GetPropagationData ( propagationData ) ; <nl> m_pImplData - > SetObstructionOcclusion ( propagationData . obstruction , propagationData . occlusion ) ; <nl> } <nl> + <nl> + UpdateControls ( deltaTime , distanceToListener , listenerPosition , listenerVelocity , listenerMoved ) ; <nl> + m_pImplData - > Update ( ) ; <nl> } <nl> <nl> / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / <nl>\n", "msg": "! XB ( Audio ) Fixed merge issue of CL 1631770\n"}
{"diff_id": 1361, "repo": "apple/swift\n", "sha": "6b446a0d38629d0611b00ecf3a27d749fb12b9b4\n", "time": "2017-09-23T05:02:59Z\n", "diff": "mmm a / lib / IRGen / IRGenDebugInfo . cpp <nl> ppp b / lib / IRGen / IRGenDebugInfo . cpp <nl> <nl> # include \" llvm / Config / config . h \" <nl> # include \" llvm / IR / DIBuilder . h \" <nl> # include \" llvm / IR / DebugInfo . h \" <nl> + # include \" llvm / IR / IntrinsicInst . h \" <nl> # include \" llvm / IR / Module . h \" <nl> # include \" llvm / Support / CommandLine . h \" <nl> # include \" llvm / Support / Debug . h \" <nl> void IRGenDebugInfoImpl : : emitDbgIntrinsic ( <nl> auto * BB = Builder . GetInsertBlock ( ) ; <nl> <nl> / / An alloca may only be described by exactly one dbg . declare . <nl> - if ( isa < llvm : : AllocaInst > ( Storage ) & & llvm : : FindAllocaDbgDeclare ( Storage ) ) <nl> + if ( isa < llvm : : AllocaInst > ( Storage ) & & ! llvm : : FindDbgAddrUses ( Storage ) . empty ( ) ) <nl> return ; <nl> <nl> / / A dbg . declare is only meaningful if there is a single alloca for <nl>\n", "msg": "master - next : Update IRGenDebugInfo . cpp for LLVM r313825\n"}
{"diff_id": 1382, "msg": "Adapted test of PathEnumerator to DepthFirstEnumerator .\n", "msgGPT": "replace path enumerator with depth first enumerator for full path enumeration.", "METEOR Score": "41.84119288795712", "BLEU Score": "0.533714768443692", "ROUGE-L Score": "0.4705882303114187", "score": 1, "repo": "arangodb/arangodb\n", "sha": "b348c20961a8ae9ab7ce8117f2df85ab3f532f94\n", "time": "2016-06-10T13:45:46Z\n", "diff": "mmm a / UnitTests / Basics / PathEnumeratorTest . cpp <nl> ppp b / UnitTests / Basics / PathEnumeratorTest . cpp <nl> BOOST_FIXTURE_TEST_SUITE ( PathEnumeratorTest , PathEnumeratorSetup ) <nl> <nl> BOOST_AUTO_TEST_CASE ( test_fullPathEnumerator ) { <nl> int startVertex = 1 ; <nl> - PathEnumerator < int , int , int > it ( integerEdgeEnumerator , integerVertexEnumerator , startVertex ) ; <nl> + DepthFirstEnumerator < int , int , int > it ( integerEdgeEnumerator , integerVertexEnumerator , startVertex ) ; <nl> EnumeratedPath < int , int > path ; <nl> for ( int k = 1 ; k < 4 ; k + + ) { <nl> path = it . next ( ) ; <nl>\n"}
{"diff_id": 1392, "repo": "apple/swift\n", "sha": "8c3f154258837606e3af658bac516bab0852d823\n", "time": "2020-06-11T23:02:17Z\n", "diff": "mmm a / lib / SIL / Parser / ParseSIL . cpp <nl> ppp b / lib / SIL / Parser / ParseSIL . cpp <nl> namespace { <nl> / / / A callback to be invoked every time a type was deserialized . <nl> std : : function < void ( Type ) > ParsedTypeCallback ; <nl> <nl> - bool performTypeLocChecking ( TypeLoc & T , bool IsSILType , <nl> + Type performTypeLocChecking ( TypeRepr * TyR , bool IsSILType , <nl> GenericEnvironment * GenericEnv = nullptr ) ; <nl> <nl> void convertRequirements ( SILFunction * F , ArrayRef < RequirementRepr > From , <nl> void SILParser : : convertRequirements ( SILFunction * F , <nl> IdentTypeReprLookup PerformLookup ( P ) ; <nl> / / Use parser lexical scopes to resolve references <nl> / / to the generic parameters . <nl> - auto ResolveToInterfaceType = [ & ] ( TypeLoc Ty ) - > Type { <nl> - Ty . getTypeRepr ( ) - > walk ( PerformLookup ) ; <nl> - performTypeLocChecking ( Ty , / * IsSIL * / false ) ; <nl> - assert ( Ty . getType ( ) ) ; <nl> - return Ty . getType ( ) - > mapTypeOutOfContext ( ) ; <nl> + auto ResolveToInterfaceType = [ & ] ( TypeRepr * Ty ) - > Type { <nl> + Ty - > walk ( PerformLookup ) ; <nl> + return performTypeLocChecking ( Ty , / * IsSIL * / false ) - > mapTypeOutOfContext ( ) ; <nl> } ; <nl> <nl> for ( auto & Req : From ) { <nl> if ( Req . getKind ( ) = = RequirementReprKind : : SameType ) { <nl> - auto FirstType = ResolveToInterfaceType ( Req . getFirstTypeLoc ( ) ) ; <nl> - auto SecondType = ResolveToInterfaceType ( Req . getSecondTypeLoc ( ) ) ; <nl> + auto FirstType = ResolveToInterfaceType ( Req . getFirstTypeRepr ( ) ) ; <nl> + auto SecondType = ResolveToInterfaceType ( Req . getSecondTypeRepr ( ) ) ; <nl> Requirement ConvertedRequirement ( RequirementKind : : SameType , FirstType , <nl> SecondType ) ; <nl> To . push_back ( ConvertedRequirement ) ; <nl> void SILParser : : convertRequirements ( SILFunction * F , <nl> } <nl> <nl> if ( Req . getKind ( ) = = RequirementReprKind : : TypeConstraint ) { <nl> - auto Subject = ResolveToInterfaceType ( Req . getSubjectLoc ( ) ) ; <nl> - auto Constraint = ResolveToInterfaceType ( Req . getConstraintLoc ( ) ) ; <nl> + auto Subject = ResolveToInterfaceType ( Req . getSubjectRepr ( ) ) ; <nl> + auto Constraint = ResolveToInterfaceType ( Req . getConstraintRepr ( ) ) ; <nl> Requirement ConvertedRequirement ( RequirementKind : : Conformance , Subject , <nl> Constraint ) ; <nl> To . push_back ( ConvertedRequirement ) ; <nl> void SILParser : : convertRequirements ( SILFunction * F , <nl> } <nl> <nl> if ( Req . getKind ( ) = = RequirementReprKind : : LayoutConstraint ) { <nl> - auto Subject = ResolveToInterfaceType ( Req . getSubjectLoc ( ) ) ; <nl> + auto Subject = ResolveToInterfaceType ( Req . getSubjectRepr ( ) ) ; <nl> Requirement ConvertedRequirement ( RequirementKind : : Layout , Subject , <nl> Req . getLayoutConstraint ( ) ) ; <nl> To . push_back ( ConvertedRequirement ) ; <nl> static bool parseDeclSILOptional ( bool * isTransparent , <nl> return false ; <nl> } <nl> <nl> - bool SILParser : : performTypeLocChecking ( TypeLoc & T , bool IsSILType , <nl> + Type SILParser : : performTypeLocChecking ( TypeRepr * T , bool IsSILType , <nl> GenericEnvironment * GenericEnv ) { <nl> if ( GenericEnv = = nullptr ) <nl> GenericEnv = ContextGenericEnv ; <nl> <nl> - return swift : : performTypeLocChecking ( P . Context , T , <nl> + TypeLoc loc ( T ) ; <nl> + ( void ) swift : : performTypeLocChecking ( P . Context , loc , <nl> / * isSILMode = * / true , IsSILType , <nl> GenericEnv , & P . SF ) ; <nl> + return loc . getType ( ) ; <nl> } <nl> <nl> / / / Find the top - level ValueDecl or Module given a name . <nl> static ValueDecl * lookupMember ( Parser & P , Type Ty , DeclBaseName Name , <nl> bool SILParser : : parseASTType ( CanType & result , GenericEnvironment * env ) { <nl> ParserResult < TypeRepr > parsedType = P . parseType ( ) ; <nl> if ( parsedType . isNull ( ) ) return true ; <nl> - TypeLoc loc = parsedType . get ( ) ; <nl> - if ( performTypeLocChecking ( loc , / * IsSILType = * / false , env ) ) <nl> + auto resolvedType = performTypeLocChecking ( parsedType . get ( ) , / * IsSILType = * / false , env ) ; <nl> + if ( resolvedType - > hasError ( ) ) <nl> return true ; <nl> <nl> if ( env ) <nl> - result = loc . getType ( ) - > mapTypeOutOfContext ( ) - > getCanonicalType ( ) ; <nl> + result = resolvedType - > mapTypeOutOfContext ( ) - > getCanonicalType ( ) ; <nl> else <nl> - result = loc . getType ( ) - > getCanonicalType ( ) ; <nl> + result = resolvedType - > getCanonicalType ( ) ; <nl> <nl> / / Invoke the callback on the parsed type . <nl> - ParsedTypeCallback ( loc . getType ( ) ) ; <nl> + ParsedTypeCallback ( resolvedType ) ; <nl> return false ; <nl> } <nl> <nl> bool SILParser : : parseSILType ( SILType & Result , <nl> ParsedGenericEnv = env ; <nl> <nl> / / Apply attributes to the type . <nl> - TypeLoc Ty = P . applyAttributeToType ( TyR . get ( ) , attrs , specifier , specifierLoc ) ; <nl> - <nl> - if ( performTypeLocChecking ( Ty , / * IsSILType = * / true , OuterGenericEnv ) ) <nl> + auto * attrRepr = P . applyAttributeToType ( TyR . get ( ) , attrs , specifier , specifierLoc ) ; <nl> + auto Ty = performTypeLocChecking ( attrRepr , / * IsSILType = * / true , OuterGenericEnv ) ; <nl> + if ( Ty - > hasError ( ) ) <nl> return true ; <nl> <nl> - Result = SILType : : getPrimitiveType ( Ty . getType ( ) - > getCanonicalType ( ) , <nl> + Result = SILType : : getPrimitiveType ( Ty - > getCanonicalType ( ) , <nl> category ) ; <nl> <nl> / / Invoke the callback on the parsed type . <nl> - ParsedTypeCallback ( Ty . getType ( ) ) ; <nl> + ParsedTypeCallback ( Ty ) ; <nl> <nl> return false ; <nl> } <nl> bool SILParser : : parseSILBBArgsAtBranch ( SmallVector < SILValue , 6 > & Args , <nl> / / / <nl> / / / FIXME : This is a hack to work around the lack of a DeclContext for <nl> / / / witness tables . <nl> - static void bindProtocolSelfInTypeRepr ( TypeLoc & TL , ProtocolDecl * proto ) { <nl> - if ( auto typeRepr = TL . getTypeRepr ( ) ) { <nl> - / / AST walker to update ' Self ' references . <nl> - class BindProtocolSelf : public ASTWalker { <nl> - ProtocolDecl * proto ; <nl> - GenericTypeParamDecl * selfParam ; <nl> - Identifier selfId ; <nl> - <nl> - public : <nl> - BindProtocolSelf ( ProtocolDecl * proto ) <nl> - : proto ( proto ) , <nl> - selfParam ( proto - > getProtocolSelfType ( ) - > getDecl ( ) ) , <nl> - selfId ( proto - > getASTContext ( ) . Id_Self ) { <nl> - } <nl> + static void bindProtocolSelfInTypeRepr ( TypeRepr * typeRepr , ProtocolDecl * proto ) { <nl> + assert ( typeRepr ) ; <nl> <nl> - virtual bool walkToTypeReprPre ( TypeRepr * T ) override { <nl> - if ( auto ident = dyn_cast < IdentTypeRepr > ( T ) ) { <nl> - auto firstComponent = ident - > getComponentRange ( ) . front ( ) ; <nl> - if ( firstComponent - > getNameRef ( ) . isSimpleName ( selfId ) ) <nl> - firstComponent - > setValue ( selfParam , proto ) ; <nl> - } <nl> + / / AST walker to update ' Self ' references . <nl> + class BindProtocolSelf : public ASTWalker { <nl> + ProtocolDecl * proto ; <nl> + GenericTypeParamDecl * selfParam ; <nl> + Identifier selfId ; <nl> <nl> - return true ; <nl> + public : <nl> + BindProtocolSelf ( ProtocolDecl * proto ) <nl> + : proto ( proto ) , <nl> + selfParam ( proto - > getProtocolSelfType ( ) - > getDecl ( ) ) , <nl> + selfId ( proto - > getASTContext ( ) . Id_Self ) { <nl> + } <nl> + <nl> + virtual bool walkToTypeReprPre ( TypeRepr * T ) override { <nl> + if ( auto ident = dyn_cast < IdentTypeRepr > ( T ) ) { <nl> + auto firstComponent = ident - > getComponentRange ( ) . front ( ) ; <nl> + if ( firstComponent - > getNameRef ( ) . isSimpleName ( selfId ) ) <nl> + firstComponent - > setValue ( selfParam , proto ) ; <nl> } <nl> - } ; <nl> <nl> - typeRepr - > walk ( BindProtocolSelf ( proto ) ) ; <nl> - } <nl> + return true ; <nl> + } <nl> + } ; <nl> + <nl> + typeRepr - > walk ( BindProtocolSelf ( proto ) ) ; <nl> } <nl> <nl> / / / Parse the substitution list for an apply instruction or <nl> bool SILParser : : parseSubstitutions ( SmallVectorImpl < ParsedSubstitution > & parsed , <nl> ParserResult < TypeRepr > TyR = P . parseType ( ) ; <nl> if ( TyR . isNull ( ) ) <nl> return true ; <nl> - TypeLoc Ty = TyR . get ( ) ; <nl> if ( defaultForProto ) <nl> - bindProtocolSelfInTypeRepr ( Ty , defaultForProto ) ; <nl> - if ( performTypeLocChecking ( Ty , / * IsSILType = * / false , GenericEnv ) ) <nl> + bindProtocolSelfInTypeRepr ( TyR . get ( ) , defaultForProto ) ; <nl> + <nl> + auto Ty = performTypeLocChecking ( TyR . get ( ) , / * IsSILType = * / false , GenericEnv ) ; <nl> + if ( Ty - > hasError ( ) ) <nl> return true ; <nl> - parsed . push_back ( { Loc , Ty . getType ( ) } ) ; <nl> + parsed . push_back ( { Loc , Ty } ) ; <nl> } while ( P . consumeIf ( tok : : comma ) ) ; <nl> <nl> / / Consume the closing ' > ' . <nl> bool SILParser : : parseSILDeclRef ( SILDeclRef & Member , bool FnTypeRequired ) { <nl> GenericsScope . reset ( ) ; <nl> if ( TyR . isNull ( ) ) <nl> return true ; <nl> - TypeLoc Ty = TyR . get ( ) ; <nl> <nl> / / The type can be polymorphic . <nl> GenericEnvironment * genericEnv = nullptr ; <nl> if ( auto fnType = dyn_cast < FunctionTypeRepr > ( TyR . get ( ) ) ) { <nl> if ( auto generics = fnType - > getGenericParams ( ) ) { <nl> - assert ( ! Ty . wasValidated ( ) & & Ty . getType ( ) . isNull ( ) ) ; <nl> - <nl> genericEnv = handleSILGenericParams ( generics , & P . SF ) ; <nl> fnType - > setGenericEnvironment ( genericEnv ) ; <nl> } <nl> if ( auto generics = fnType - > getPatternGenericParams ( ) ) { <nl> - assert ( ! Ty . wasValidated ( ) & & Ty . getType ( ) . isNull ( ) ) ; <nl> - <nl> genericEnv = handleSILGenericParams ( generics , & P . SF ) ; <nl> fnType - > setPatternGenericEnvironment ( genericEnv ) ; <nl> } <nl> } <nl> <nl> - if ( performTypeLocChecking ( Ty , / * IsSILType = * / false , genericEnv ) ) <nl> + auto Ty = performTypeLocChecking ( TyR . get ( ) , / * IsSILType = * / false , genericEnv ) ; <nl> + if ( Ty - > hasError ( ) ) <nl> return true ; <nl> <nl> / / Pick the ValueDecl that has the right type . <nl> ValueDecl * TheDecl = nullptr ; <nl> - auto declTy = Ty . getType ( ) - > getCanonicalType ( ) ; <nl> + auto declTy = Ty - > getCanonicalType ( ) ; <nl> for ( unsigned I = 0 , E = values . size ( ) ; I < E ; + + I ) { <nl> auto * decl = values [ I ] ; <nl> <nl> ProtocolConformanceRef SILParser : : parseProtocolConformanceHelper ( <nl> ParserResult < TypeRepr > TyR = P . parseType ( ) ; <nl> if ( TyR . isNull ( ) ) <nl> return ProtocolConformanceRef ( ) ; <nl> - TypeLoc Ty = TyR . get ( ) ; <nl> if ( defaultForProto ) { <nl> - bindProtocolSelfInTypeRepr ( Ty , defaultForProto ) ; <nl> + bindProtocolSelfInTypeRepr ( TyR . get ( ) , defaultForProto ) ; <nl> } <nl> <nl> - if ( performTypeLocChecking ( Ty , / * IsSILType = * / false , witnessEnv ) ) <nl> + auto ConformingTy = performTypeLocChecking ( TyR . get ( ) , / * IsSILType = * / false , witnessEnv ) ; <nl> + if ( ConformingTy - > hasError ( ) ) <nl> return ProtocolConformanceRef ( ) ; <nl> - auto ConformingTy = Ty . getType ( ) ; <nl> <nl> if ( P . parseToken ( tok : : colon , diag : : expected_sil_witness_colon ) ) <nl> return ProtocolConformanceRef ( ) ; <nl> static bool parseSILVTableEntry ( <nl> return true ; <nl> TypeLoc Ty = TyR . get ( ) ; <nl> if ( isDefaultWitnessTable ) <nl> - bindProtocolSelfInTypeRepr ( Ty , proto ) ; <nl> + bindProtocolSelfInTypeRepr ( TyR . get ( ) , proto ) ; <nl> if ( swift : : performTypeLocChecking ( P . Context , Ty , <nl> / * isSILMode = * / false , <nl> / * isSILType = * / false , <nl> static bool parseSILVTableEntry ( <nl> return true ; <nl> TypeLoc Ty = TyR . get ( ) ; <nl> if ( isDefaultWitnessTable ) <nl> - bindProtocolSelfInTypeRepr ( Ty , proto ) ; <nl> + bindProtocolSelfInTypeRepr ( TyR . get ( ) , proto ) ; <nl> if ( swift : : performTypeLocChecking ( P . Context , Ty , <nl> / * isSILMode = * / false , <nl> / * isSILType = * / false , <nl>\n", "msg": "[ NFC ] Wean SILParser off of TypeLocs\n"}
{"diff_id": 1558, "msg": "Adding layout handling to SparsePCReader .\n", "msgGPT": "fix initialization of m_pMBLayout in sparse pc reader.", "METEOR Score": "19.439164615834297", "BLEU Score": "0.4409030313374278", "ROUGE-L Score": "0.3999999950222222", "score": 1, "repo": "microsoft/CNTK\n", "sha": "ff39fb054c4a9ab41cac6137cec082dd07e23884\n", "time": "2015-11-05T21:57:52Z\n", "diff": "mmm a / DataReader / SparsePCReader / SparsePCReader . cpp <nl> ppp b / DataReader / SparsePCReader / SparsePCReader . cpp <nl> void SparsePCReader < ElemType > : : Init ( const ConfigParameters & readerConfig ) <nl> m_microBatchSize = readerConfig ( \" microbatchSize \" , \" 1 \" ) ; <nl> <nl> m_miniBatchSize = 0 ; <nl> + m_microBatchSize = readerConfig ( \" microbatchSize \" , \" 1 \" ) ; <nl> m_traceLevel = readerConfig ( \" traceLevel \" , \" 0 \" ) ; <nl> m_maxReadData = readerConfig ( \" maxReadData \" , \" 0 \" ) ; <nl> m_doGradientCheck = readerConfig ( \" gradientCheck \" , \" false \" ) ; <nl> bool SparsePCReader < ElemType > : : GetMinibatch ( std : : map < std : : wstring , Matrix < ElemTy <nl> return false ; <nl> } <nl> <nl> + m_pMBLayout - > Init ( m_miniBatchSize / m_microBatchSize , m_microBatchSize , false ) ; <nl> + <nl> Matrix < ElemType > * labels = nullptr ; <nl> auto labelEntry = matrices . find ( m_labelName ) ; <nl> bool useLabels = false ; <nl>\n"}
{"diff_id": 2189, "repo": "ocornut/imgui\n", "sha": "aea3fe41b9a3dea659b92f50215be2b6b104bb68\n", "time": "2017-11-30T22:15:55Z\n", "diff": "mmm a / imgui_draw . cpp <nl> ppp b / imgui_draw . cpp <nl> void ImGui : : StyleColorsDark ( ImGuiStyle * dst ) <nl> colors [ ImGuiCol_HeaderHovered ] = ImVec4 ( 0 . 26f , 0 . 59f , 0 . 98f , 0 . 80f ) ; <nl> colors [ ImGuiCol_HeaderActive ] = ImVec4 ( 0 . 26f , 0 . 59f , 0 . 98f , 1 . 00f ) ; <nl> colors [ ImGuiCol_Separator ] = colors [ ImGuiCol_Border ] ; / / ImVec4 ( 0 . 61f , 0 . 61f , 0 . 61f , 1 . 00f ) ; <nl> - colors [ ImGuiCol_SeparatorHovered ] = ImVec4 ( 0 . 26f , 0 . 59f , 0 . 98f , 0 . 78f ) ; <nl> - colors [ ImGuiCol_SeparatorActive ] = ImVec4 ( 0 . 26f , 0 . 59f , 0 . 98f , 1 . 00f ) ; <nl> + colors [ ImGuiCol_SeparatorHovered ] = ImVec4 ( 0 . 10f , 0 . 40f , 0 . 75f , 0 . 78f ) ; <nl> + colors [ ImGuiCol_SeparatorActive ] = ImVec4 ( 0 . 10f , 0 . 40f , 0 . 75f , 1 . 00f ) ; <nl> colors [ ImGuiCol_ResizeGrip ] = ImVec4 ( 0 . 26f , 0 . 59f , 0 . 98f , 0 . 25f ) ; <nl> colors [ ImGuiCol_ResizeGripHovered ] = ImVec4 ( 0 . 26f , 0 . 59f , 0 . 98f , 0 . 67f ) ; <nl> colors [ ImGuiCol_ResizeGripActive ] = ImVec4 ( 0 . 26f , 0 . 59f , 0 . 98f , 0 . 95f ) ; <nl> void ImGui : : StyleColorsLight ( ImGuiStyle * dst ) <nl> / / colors [ ImGuiCol_TextActive ] = ImVec4 ( 1 . 00f , 1 . 00f , 0 . 00f , 1 . 00f ) ; <nl> colors [ ImGuiCol_WindowBg ] = ImVec4 ( 0 . 94f , 0 . 94f , 0 . 94f , 1 . 00f ) ; <nl> colors [ ImGuiCol_ChildBg ] = ImVec4 ( 0 . 00f , 0 . 00f , 0 . 00f , 0 . 00f ) ; <nl> - colors [ ImGuiCol_PopupBg ] = ImVec4 ( 1 . 00f , 1 . 00f , 1 . 00f , 0 . 94f ) ; <nl> + colors [ ImGuiCol_PopupBg ] = ImVec4 ( 1 . 00f , 1 . 00f , 1 . 00f , 0 . 98f ) ; <nl> colors [ ImGuiCol_Border ] = ImVec4 ( 0 . 00f , 0 . 00f , 0 . 00f , 0 . 30f ) ; <nl> colors [ ImGuiCol_BorderShadow ] = ImVec4 ( 0 . 00f , 0 . 00f , 0 . 00f , 0 . 00f ) ; <nl> colors [ ImGuiCol_FrameBg ] = ImVec4 ( 1 . 00f , 1 . 00f , 1 . 00f , 1 . 00f ) ; <nl> void ImGui : : StyleColorsLight ( ImGuiStyle * dst ) <nl> colors [ ImGuiCol_HeaderHovered ] = ImVec4 ( 0 . 26f , 0 . 59f , 0 . 98f , 0 . 80f ) ; <nl> colors [ ImGuiCol_HeaderActive ] = ImVec4 ( 0 . 26f , 0 . 59f , 0 . 98f , 1 . 00f ) ; <nl> colors [ ImGuiCol_Separator ] = ImVec4 ( 0 . 39f , 0 . 39f , 0 . 39f , 1 . 00f ) ; <nl> - colors [ ImGuiCol_SeparatorHovered ] = ImVec4 ( 0 . 26f , 0 . 59f , 0 . 98f , 0 . 78f ) ; <nl> - colors [ ImGuiCol_SeparatorActive ] = ImVec4 ( 0 . 26f , 0 . 59f , 0 . 98f , 1 . 00f ) ; <nl> + colors [ ImGuiCol_SeparatorHovered ] = ImVec4 ( 0 . 14f , 0 . 44f , 0 . 80f , 0 . 78f ) ; <nl> + colors [ ImGuiCol_SeparatorActive ] = ImVec4 ( 0 . 14f , 0 . 44f , 0 . 80f , 1 . 00f ) ; <nl> colors [ ImGuiCol_ResizeGrip ] = ImVec4 ( 0 . 80f , 0 . 80f , 0 . 80f , 0 . 56f ) ; <nl> colors [ ImGuiCol_ResizeGripHovered ] = ImVec4 ( 0 . 26f , 0 . 59f , 0 . 98f , 0 . 67f ) ; <nl> colors [ ImGuiCol_ResizeGripActive ] = ImVec4 ( 0 . 26f , 0 . 59f , 0 . 98f , 0 . 95f ) ; <nl>\n", "msg": "Style : Tweaks Dark and Light styles . ( )\n"}
{"diff_id": 2274, "repo": "sqlitebrowser/sqlitebrowser\n", "sha": "7541a8205024368d9f0bdab311e5c6de6e3f8aac\n", "time": "2019-09-22T21:16:04Z\n", "diff": "mmm a / src / FilterTableHeader . cpp <nl> ppp b / src / FilterTableHeader . cpp <nl> FilterTableHeader : : FilterTableHeader ( QTableView * parent ) : <nl> / / Make sure to not automatically resize the columns according to the contents <nl> setSectionResizeMode ( QHeaderView : : Interactive ) ; <nl> <nl> + / / Highlight column headers of selected cells to emulate spreadsheet behaviour <nl> + setHighlightSections ( true ) ; <nl> + <nl> / / Do some connects : Basically just resize and reposition the input widgets whenever anything changes <nl> connect ( this , & FilterTableHeader : : sectionResized , this , & FilterTableHeader : : adjustPositions ) ; <nl> connect ( parent - > horizontalScrollBar ( ) , & QScrollBar : : valueChanged , this , & FilterTableHeader : : adjustPositions ) ; <nl>\n", "msg": "Highlight column headers to emulate spreadsheet behaviour\n", "score": 1}
{"diff_id": 2297, "repo": "bitcoin/bitcoin\n", "sha": "312ff01ee533fab68348283200eb57e9956fdb34\n", "time": "2018-08-01T22:16:41Z\n", "diff": "mmm a / src / init . cpp <nl> ppp b / src / init . cpp <nl> void SetupServerArgs ( ) <nl> # endif <nl> gArgs . AddArg ( \" - prune = < n > \" , strprintf ( \" Reduce storage requirements by enabling pruning ( deleting ) of old blocks . This allows the pruneblockchain RPC to be called to delete specific blocks , and enables automatic pruning of old blocks if a target size in MiB is provided . This mode is incompatible with - txindex and - rescan . \" <nl> \" Warning : Reverting this setting requires re - downloading the entire blockchain . \" <nl> - \" ( default : 0 = disable pruning blocks , 1 = allow manual pruning via RPC , > % u = automatically prune block files to stay under the specified target size in MiB ) \" , MIN_DISK_SPACE_FOR_BLOCK_FILES / 1024 / 1024 ) , false , OptionsCategory : : OPTIONS ) ; <nl> + \" ( default : 0 = disable pruning blocks , 1 = allow manual pruning via RPC , > = % u = automatically prune block files to stay under the specified target size in MiB ) \" , MIN_DISK_SPACE_FOR_BLOCK_FILES / 1024 / 1024 ) , false , OptionsCategory : : OPTIONS ) ; <nl> gArgs . AddArg ( \" - reindex \" , \" Rebuild chain state and block index from the blk * . dat files on disk \" , false , OptionsCategory : : OPTIONS ) ; <nl> gArgs . AddArg ( \" - reindex - chainstate \" , \" Rebuild chain state from the currently indexed blocks \" , false , OptionsCategory : : OPTIONS ) ; <nl> # ifndef WIN32 <nl>\n", "msg": "- prune option - help output aligned with code\n"}
{"diff_id": 2427, "repo": "xbmc/xbmc\n", "sha": "0bbfe03c92d1405bf6af12408b08b1008435b796\n", "time": "2011-07-16T23:36:02Z\n", "diff": "mmm a / xbmc / music / MusicDatabase . cpp <nl> ppp b / xbmc / music / MusicDatabase . cpp <nl> bool CMusicDatabase : : GetAlbumsByWhere ( const CStdString & baseDir , const CStdStrin <nl> int idAlbum = m_pDS - > fv ( \" idAlbum \" ) . get_asInt ( ) ; <nl> strDir . Format ( \" % s % ld / \" , baseDir . c_str ( ) , idAlbum ) ; <nl> CFileItemPtr pItem ( new CFileItem ( strDir , GetAlbumFromDataset ( m_pDS . get ( ) ) ) ) ; <nl> + pItem - > SetIconImage ( \" DefaultAlbumCover . png \" ) ; <nl> items . Add ( pItem ) ; <nl> m_pDS - > next ( ) ; <nl> } <nl>\n", "msg": "added : set Music Album fallback icon to \" DefaultAlbumCover . png \"\n"}
{"diff_id": 2472, "msg": "! B ( Renderer ) Fixed malformed texture - name\n", "msgGPT": "change shadow map cached texture name format for better readability.", "METEOR Score": "15.721135809893605", "BLEU Score": "0.31149345393025346", "ROUGE-L Score": "0.19999999500000015", "score": 1, "repo": "CRYTEK/CRYENGINE\n", "sha": "2fdb8d78ab2263e1573627b284abdf66be5ee6a2\n", "time": "2019-01-29T10:02:03Z\n", "diff": "mmm a / Code / CryEngine / RenderDll / XRenderD3D9 / GraphicsPipeline / ShadowMap . cpp <nl> ppp b / Code / CryEngine / RenderDll / XRenderD3D9 / GraphicsPipeline / ShadowMap . cpp <nl> void CShadowMapStage : : ReAllocateResources ( const SShadowConfig shadowConfig ) <nl> if ( ! pTx ) <nl> { <nl> char szName [ 64 ] ; <nl> - cry_sprintf ( szName , \" % CachedShadowMap_ % d \" , i ) ; <nl> + cry_sprintf ( szName , \" $ ShadowMapCached_ % d \" , i ) ; <nl> <nl> pTx = CTexture : : GetOrCreateDepthStencil ( szName , nResolutions [ i ] , nResolutions [ i ] , Clr_FarPlane , eTT_2D , FT_DONT_STREAM , texFormat ) ; <nl> } <nl>\n"}
{"diff_id": 2663, "repo": "MarlinFirmware/Marlin\n", "sha": "71ac6f9d42ca4b39eda86b725c3daece1ec40b46\n", "time": "2017-03-09T22:49:57Z\n", "diff": "mmm a / Marlin / Marlin_main . cpp <nl> ppp b / Marlin / Marlin_main . cpp <nl> inline void gcode_G92 ( ) { <nl> current_position [ i ] = code_value_axis_units ( i ) ; <nl> if ( i ! = E_AXIS ) didXYZ = true ; <nl> # else <nl> - float p = current_position [ i ] , <nl> - v = code_value_axis_units ( i ) ; <nl> + # if DISABLED ( NO_WORKSPACE_OFFSETS ) <nl> + float p = current_position [ i ] ; <nl> + # endif <nl> + float v = code_value_axis_units ( i ) ; <nl> <nl> current_position [ i ] = v ; <nl> <nl>\n", "msg": "prevent warning with define of NO_WORKSPACE_OFFSETS\n"}
{"diff_id": 2737, "repo": "apple/swift\n", "sha": "d6d26758573914950aa6a5ae6c24bfe1ada687f2\n", "time": "2018-04-19T20:16:36Z\n", "diff": "mmm a / lib / Sema / TypeCheckDecl . cpp <nl> ppp b / lib / Sema / TypeCheckDecl . cpp <nl> static void inferDynamic ( ASTContext & ctx , ValueDecl * D ) { <nl> if ( D - > isFinal ( ) & & ! isNSManaged ) <nl> return ; <nl> <nl> - / / Variables declared with ' let ' cannot be ' dynamic ' . <nl> - if ( auto VD = dyn_cast < VarDecl > ( D ) ) { <nl> - auto staticSpelling = VD - > getParentPatternBinding ( ) - > getStaticSpelling ( ) ; <nl> - <nl> - / / The presence of ' static ' blocks the inference of ' dynamic ' . <nl> - if ( staticSpelling = = StaticSpellingKind : : KeywordStatic ) <nl> - return ; <nl> - <nl> - if ( VD - > isLet ( ) & & ! isNSManaged ) <nl> - return ; <nl> - } <nl> - <nl> / / Accessors should not infer ' dynamic ' on their own ; they can get it from <nl> / / their storage decls . <nl> - if ( auto FD = dyn_cast < FuncDecl > ( D ) ) { <nl> - if ( isa < AccessorDecl > ( FD ) ) <nl> - return ; <nl> - <nl> - auto staticSpelling = FD - > getStaticSpelling ( ) ; <nl> - <nl> - / / The presence of ' static ' bocks the inference of ' dynamic ' . <nl> - if ( staticSpelling = = StaticSpellingKind : : KeywordStatic ) <nl> - return ; <nl> - } <nl> + if ( isa < AccessorDecl > ( D ) ) <nl> + return ; <nl> <nl> - / / The presence of ' final ' on a class prevents ' dynamic ' . <nl> + / / Only classes can use ' dynamic ' . <nl> auto classDecl = D - > getDeclContext ( ) - > getAsClassOrClassExtensionContext ( ) ; <nl> - if ( ! classDecl ) return ; <nl> - if ( ! isNSManaged & & classDecl - > isFinal ( ) & & <nl> - ! classDecl - > requiresStoredPropertyInits ( ) ) <nl> + if ( ! classDecl ) <nl> return ; <nl> <nl> / / Add the ' dynamic ' attribute . <nl> void TypeChecker : : validateDecl ( ValueDecl * D ) { <nl> } <nl> } <nl> <nl> - / / Infer ' dynamic ' before touching accessors . <nl> - inferDynamic ( Context , VD ) ; <nl> - <nl> / / If this variable is a class member , mark it final if the <nl> / / class is final , or if it was declared with ' let ' . <nl> auto staticSpelling = <nl> VD - > getParentPatternBinding ( ) - > getStaticSpelling ( ) ; <nl> inferFinalAndDiagnoseIfNeeded ( * this , VD , staticSpelling ) ; <nl> <nl> - if ( VD - > isLet ( ) & & <nl> - VD - > getDeclContext ( ) - > getAsClassOrClassExtensionContext ( ) ) { <nl> + if ( VD - > isLet ( ) & & isa < ClassDecl > ( nominalDecl ) ) { <nl> makeFinal ( Context , VD ) ; <nl> <nl> if ( VD - > getFormalAccess ( ) = = AccessLevel : : Open ) { <nl> void TypeChecker : : validateDecl ( ValueDecl * D ) { <nl> fixItAccess ( inFlightDiag , D , AccessLevel : : Public ) ; <nl> } <nl> } <nl> + <nl> + / / Infer ' dynamic ' after ' final ' but before touching accessors . <nl> + inferDynamic ( Context , VD ) ; <nl> } <nl> <nl> / / Perform accessor - related validation . <nl> void TypeChecker : : validateDecl ( ValueDecl * D ) { <nl> errorConvention ) ) ) <nl> isObjC = None ; <nl> markAsObjC ( * this , FD , isObjC , errorConvention ) ; <nl> + <nl> + inferFinalAndDiagnoseIfNeeded ( * this , FD , FD - > getStaticSpelling ( ) ) ; <nl> + inferDynamic ( Context , FD ) ; <nl> } <nl> <nl> / / If the function is exported to C , it must be representable in ( Obj - ) C . <nl> void TypeChecker : : validateDecl ( ValueDecl * D ) { <nl> } <nl> } <nl> <nl> - inferDynamic ( Context , FD ) ; <nl> - <nl> - / / If this is a class member , mark it final if the class is final . <nl> - inferFinalAndDiagnoseIfNeeded ( * this , FD , FD - > getStaticSpelling ( ) ) ; <nl> - <nl> checkDeclAttributes ( FD ) ; <nl> <nl> break ; <nl>\n", "msg": "Simplify inferDynamic by assuming ' final ' has already been inferred\n"}
{"diff_id": 2909, "repo": "yuzu-emu/yuzu\n", "sha": "834d3fe336b066776c53b43b5682699622911acc\n", "time": "2019-03-17T08:02:48Z\n", "diff": "mmm a / src / input_common / sdl / sdl_impl . cpp <nl> ppp b / src / input_common / sdl / sdl_impl . cpp <nl> SDLState : : SDLState ( ) { <nl> if ( start_thread ) { <nl> poll_thread = std : : thread ( [ & ] { <nl> using namespace std : : chrono_literals ; <nl> - SDL_Event event ; <nl> while ( initialized ) { <nl> SDL_PumpEvents ( ) ; <nl> std : : this_thread : : sleep_for ( std : : chrono : : duration ( 10ms ) ) ; <nl>\n", "msg": "input_common / sdl_impl : Remove unused variable in SDLState constructor\n"}
{"diff_id": 3002, "repo": "apple/swift\n", "sha": "58ec58881972fa1c924601ea9b1b0f073aef63e5\n", "time": "2013-12-15T00:58:25Z\n", "diff": "mmm a / lib / Driver / Driver . cpp <nl> ppp b / lib / Driver / Driver . cpp <nl> Driver : : OutputMode Driver : : getOutputMode ( const ArgList & Args ) const { <nl> bool ShouldLink = false ; <nl> types : : ID CompileOutputType = types : : TY_INVALID ; <nl> <nl> - Arg * OutputModeArg ; <nl> - if ( ( OutputModeArg = Args . getLastArg ( options : : OPT_c ) ) ) { <nl> + const Arg * const OutputModeArg = Args . getLastArg ( options : : OPT_modes_Group ) ; <nl> + if ( ! OutputModeArg | | <nl> + OutputModeArg - > getOption ( ) . matches ( options : : OPT_emit_executable ) ) { <nl> + / / Default to producing a linked executable . As a result , the compile <nl> + / / action should produce an object file suitable for linking . <nl> + ShouldLink = true ; <nl> + CompileOutputType = types : : TY_Object ; <nl> + } else if ( OutputModeArg - > getOption ( ) . matches ( options : : OPT_c ) ) { <nl> / / The user has requested an object file . <nl> CompileOutputType = types : : TY_Object ; <nl> - } else if ( ( OutputModeArg = Args . getLastArg ( options : : OPT_S ) ) ) { <nl> + } else if ( OutputModeArg - > getOption ( ) . matches ( options : : OPT_S ) ) { <nl> / / The user has requested an assembly file . <nl> CompileOutputType = types : : TY_Assembly ; <nl> - } else if ( ( OutputModeArg = Args . getLastArg ( options : : OPT_emit_sil ) ) ) { <nl> + } else if ( OutputModeArg - > getOption ( ) . matches ( options : : OPT_emit_sil ) ) { <nl> / / The user has requested a SIL file . <nl> CompileOutputType = types : : TY_SIL ; <nl> - } else if ( ( OutputModeArg = Args . getLastArg ( options : : OPT_emit_silgen ) ) ) { <nl> + } else if ( OutputModeArg - > getOption ( ) . matches ( options : : OPT_emit_silgen ) ) { <nl> / / The user has requested a raw SIL file . <nl> CompileOutputType = types : : TY_RawSIL ; <nl> - } else if ( ( OutputModeArg = Args . getLastArg ( options : : OPT_parse ) ) | | <nl> - ( OutputModeArg = Args . getLastArg ( options : : OPT_dump_parse ) ) | | <nl> - ( OutputModeArg = Args . getLastArg ( options : : OPT_dump_ast ) ) | | <nl> - ( OutputModeArg = Args . getLastArg ( options : : OPT_print_ast ) ) ) { <nl> + } else if ( OutputModeArg - > getOption ( ) . matches ( options : : OPT_parse ) | | <nl> + OutputModeArg - > getOption ( ) . matches ( options : : OPT_dump_parse ) | | <nl> + OutputModeArg - > getOption ( ) . matches ( options : : OPT_dump_ast ) | | <nl> + OutputModeArg - > getOption ( ) . matches ( options : : OPT_print_ast ) | | <nl> + OutputModeArg - > getOption ( ) . matches ( options : : OPT_i ) | | <nl> + OutputModeArg - > getOption ( ) . matches ( options : : OPT_repl ) ) { <nl> / / These modes don ' t have any output . <nl> CompileOutputType = types : : TY_Nothing ; <nl> - } else if ( ( OutputModeArg = Args . getLastArg ( options : : OPT_emit_executable ) ) ) { <nl> - / / The user asked for a linked executable . As a result , the compile action <nl> - / / should produce an object file suitable for linking . <nl> - ShouldLink = true ; <nl> - CompileOutputType = types : : TY_Object ; <nl> } else { <nl> - / / Default to producing a linked executable . As a result , the compile <nl> - / / action should produce an object file suitable for linking . <nl> - ShouldLink = true ; <nl> - CompileOutputType = types : : TY_Object ; <nl> + llvm_unreachable ( \" Unknown output mode option ! \" ) ; <nl> } <nl> <nl> return OutputMode ( CompileOutputType , ShouldLink ) ; <nl>\n", "msg": "[ driver ] Adjusted the implementation of Driver : : getOutputMode ( ) so that it uses Option : : matches ( ) instead of a series of ArgList : : getLastArg ( ) calls .\n"}
{"diff_id": 3149, "repo": "opencv/opencv\n", "sha": "5a3e7d041f99384b5d029feceb256530ac37f6cf\n", "time": "2011-05-30T06:54:59Z\n", "diff": "mmm a / modules / features2d / src / blobdetector . cpp <nl> ppp b / modules / features2d / src / blobdetector . cpp <nl> void SimpleBlobDetector : : detectImpl ( const cv : : Mat & image , std : : vector < cv : : KeyPoi <nl> KeyPoint kpt ( sumPoint , ( float ) params . defaultKeypointSize ) ; <nl> keypoints . push_back ( kpt ) ; <nl> } <nl> + <nl> + # ifdef DEBUG_BLOB_DETECTOR <nl> + namedWindow ( \" keypoints \" , CV_WINDOW_NORMAL ) ; <nl> + Mat outImg = image . clone ( ) ; <nl> + for ( size_t i = 0 ; i < keypoints . size ( ) ; i + + ) <nl> + { <nl> + circle ( outImg , keypoints [ i ] . pt , 2 , Scalar ( 255 , 0 , 255 ) , - 1 ) ; <nl> + } <nl> + / / drawKeypoints ( image , keypoints , outImg ) ; <nl> + imshow ( \" keypoints \" , outImg ) ; <nl> + waitKey ( ) ; <nl> + # endif <nl> } <nl>\n", "msg": "Added drawing of a new image for debugging of the SimpleBlobDetector class .\n", "score": 1}
{"diff_id": 3169, "repo": "godotengine/godot\n", "sha": "6ffe1fff2df61a0b6648eea673bd693ea60c85ef\n", "time": "2015-12-04T18:29:27Z\n", "diff": "mmm a / tools / editor / io_plugins / editor_font_import_plugin . cpp <nl> ppp b / tools / editor / io_plugins / editor_font_import_plugin . cpp <nl> class EditorFontImportDialog : public ConfirmationDialog { <nl> return ; <nl> } <nl> <nl> + if ( dest - > get_line_edit ( ) - > get_text ( ) . get_file ( ) = = \" . fnt \" ) { <nl> + dest - > get_line_edit ( ) - > set_text ( dest - > get_line_edit ( ) - > get_text ( ) . get_base_dir ( ) + \" / \" + source - > get_line_edit ( ) - > get_text ( ) . get_file ( ) . basename ( ) + \" . fnt \" ) ; <nl> + } <nl> + <nl> Ref < ResourceImportMetadata > rimd = get_rimd ( ) ; <nl> <nl> if ( rimd . is_null ( ) ) { <nl>\n", "msg": "Set default destination filename of imported font to be input font filename\n", "score": 1}
{"diff_id": 3229, "repo": "xbmc/xbmc\n", "sha": "3b200c7a080c0cfe33604aa88bd2d35b3c20ee85\n", "time": "2010-06-20T01:39:33Z\n", "diff": "mmm a / xbmc / lib / libPython / xbmcmodule / GUIPythonWindow . cpp <nl> ppp b / xbmc / lib / libPython / xbmcmodule / GUIPythonWindow . cpp <nl> bool CGUIPythonWindow : : OnAction ( const CAction & action ) <nl> PyXBMCAction * inf = new PyXBMCAction ; <nl> inf - > pObject = Action_FromAction ( action ) ; <nl> inf - > pCallbackWindow = pCallbackWindow ; <nl> + Py_INCREF ( pCallbackWindow ) ; <nl> <nl> / / aquire lock ? <nl> PyXBMC_AddPendingCall ( Py_XBMC_Event_OnAction , inf ) ; <nl> bool CGUIPythonWindow : : OnMessage ( CGUIMessage & message ) <nl> { <nl> / / create a new call and set it in the python queue <nl> inf - > pCallbackWindow = pCallbackWindow ; <nl> + Py_INCREF ( pCallbackWindow ) ; <nl> <nl> / / aquire lock ? <nl> PyXBMC_AddPendingCall ( Py_XBMC_Event_OnControl , inf ) ; <nl> int Py_XBMC_Event_OnControl ( void * arg ) <nl> if ( ret ) { <nl> Py_DECREF ( ret ) ; <nl> } <nl> + Py_DECREF ( action - > pCallbackWindow ) ; <nl> delete action ; <nl> } <nl> return 0 ; <nl> int Py_XBMC_Event_OnAction ( void * arg ) <nl> CLog : : Log ( LOGERROR , \" Exception in python script ' s onAction \" ) ; <nl> PyErr_Print ( ) ; <nl> } <nl> + Py_DECREF ( action - > pCallbackWindow ) ; <nl> delete action ; <nl> } <nl> return 0 ; <nl>\n", "msg": "fixed : callback window for python pending calls , must not be deleted before the pending call has executed\n"}
{"diff_id": 3431, "repo": "EOSIO/eos\n", "sha": "6bbf48407a3d3842531498e95432f4f8539fb31e\n", "time": "2018-04-03T12:50:53Z\n", "diff": "mmm a / contracts / test_api / test_transaction . cpp <nl> ppp b / contracts / test_api / test_transaction . cpp <nl> void test_transaction : : send_action_empty ( ) { <nl> * / <nl> void test_transaction : : send_action_large ( ) { <nl> using namespace eosio ; <nl> - char large_message [ 8 * 1024 ] ; <nl> + static char large_message [ 8 * 1024 ] ; <nl> test_action_action < N ( testapi ) , WASM_TEST_ACTION ( \" test_action \" , \" read_action_normal \" ) > test_action ; <nl> copy_data ( large_message , 8 * 1024 , test_action . data ) ; <nl> action act ( vector < permission_level > { { N ( testapi ) , N ( active ) } } , test_action ) ; <nl> void test_transaction : : test_transaction_size ( ) { <nl> eosio_assert ( trans_size = = transaction_size ( ) , \" transaction size does not match \" ) ; <nl> } <nl> <nl> - void test_transaction : : send_transaction ( uint64_t receiver , uint64_t code , uint64_t action ) { <nl> + void test_transaction : : send_transaction ( uint64_t receiver , uint64_t , uint64_t ) { <nl> using namespace eosio ; <nl> dummy_action payload = { DUMMY_ACTION_DEFAULT_A , DUMMY_ACTION_DEFAULT_B , DUMMY_ACTION_DEFAULT_C } ; <nl> <nl> void test_transaction : : send_transaction ( uint64_t receiver , uint64_t code , uint64 <nl> trx . send ( 0 , receiver ) ; <nl> } <nl> <nl> - void test_transaction : : send_action_sender ( uint64_t receiver , uint64_t code , uint64_t action ) { <nl> + void test_transaction : : send_action_sender ( uint64_t receiver , uint64_t , uint64_t ) { <nl> using namespace eosio ; <nl> account_name cur_send ; <nl> read_action_data ( & cur_send , sizeof ( account_name ) ) ; <nl> void test_transaction : : send_action_sender ( uint64_t receiver , uint64_t code , uint <nl> trx . send ( 0 , receiver ) ; <nl> } <nl> <nl> - void test_transaction : : send_transaction_empty ( uint64_t receiver , uint64_t code , uint64_t action ) { <nl> + void test_transaction : : send_transaction_empty ( uint64_t receiver , uint64_t , uint64_t ) { <nl> using namespace eosio ; <nl> auto trx = transaction ( ) ; <nl> trx . send ( 0 , receiver ) ; <nl> void test_transaction : : send_transaction_empty ( uint64_t receiver , uint64_t code , <nl> / * * <nl> * cause failure due to a large transaction size <nl> * / <nl> - void test_transaction : : send_transaction_large ( uint64_t receiver , uint64_t code , uint64_t action ) { <nl> + void test_transaction : : send_transaction_large ( uint64_t receiver , uint64_t , uint64_t ) { <nl> using namespace eosio ; <nl> auto trx = transaction ( ) ; <nl> for ( int i = 0 ; i < 32 ; i + + ) { <nl> void test_transaction : : send_transaction_large ( uint64_t receiver , uint64_t code , <nl> eosio_assert ( false , \" send_transaction_large ( ) should ' ve thrown an error \" ) ; <nl> } <nl> <nl> - void test_transaction : : send_transaction_expiring_late ( uint64_t receiver , uint64_t code , uint64_t action ) { <nl> + void test_transaction : : send_transaction_expiring_late ( uint64_t receiver , uint64_t , uint64_t ) { <nl> using namespace eosio ; <nl> account_name cur_send ; <nl> read_action_data ( & cur_send , sizeof ( account_name ) ) ; <nl> void test_transaction : : deferred_print ( ) { <nl> eosio : : print ( \" deferred executed \\ n \" ) ; <nl> } <nl> <nl> - void test_transaction : : send_deferred_transaction ( uint64_t receiver , uint64_t code , uint64_t action ) { <nl> + void test_transaction : : send_deferred_transaction ( uint64_t receiver , uint64_t , uint64_t ) { <nl> using namespace eosio ; <nl> auto trx = transaction ( ) ; <nl> test_action_action < N ( testapi ) , WASM_TEST_ACTION ( \" test_transaction \" , \" deferred_print \" ) > test_action ; <nl> void test_transaction : : read_inline_action ( ) { <nl> eosio_assert ( res ! = - 1 , \" get_action error \" ) ; <nl> <nl> action tmp ; <nl> - datastream < char * > ds ( buffer , res ) ; <nl> + datastream < char * > ds ( buffer , ( size_t ) res ) ; <nl> ds > > tmp . account ; <nl> ds > > tmp . name ; <nl> ds > > tmp . authorization ; <nl> void test_transaction : : read_inline_cf_action ( ) { <nl> eosio_assert ( res ! = - 1 , \" get_action error \" ) ; <nl> <nl> action tmp ; <nl> - datastream < char * > ds ( buffer , res ) ; <nl> + datastream < char * > ds ( buffer , ( size_t ) res ) ; <nl> ds > > tmp . account ; <nl> ds > > tmp . name ; <nl> ds > > tmp . authorization ; <nl>\n", "msg": "move large stack allocation to heap to avoid stack overflow , silence warnings EOSIO / eos\n", "score": 1}
{"diff_id": 3519, "repo": "yuzu-emu/yuzu\n", "sha": "e90fa1ac54cd7ffdec78a16b2ccaa5a078f3cfc4\n", "time": "2018-12-05T08:41:33Z\n", "diff": "mmm a / src / yuzu / configuration / config . cpp <nl> ppp b / src / yuzu / configuration / config . cpp <nl> const std : : array < int , Settings : : NativeKeyboard : : NumKeyboardMods > Config : : default <nl> <nl> void Config : : ReadPlayerValues ( ) { <nl> for ( std : : size_t p = 0 ; p < Settings : : values . players . size ( ) ; + + p ) { <nl> - Settings : : values . players [ p ] . connected = <nl> - qt_config - > value ( QString ( \" player_ % 1_connected \" ) . arg ( p ) , false ) . toBool ( ) ; <nl> + auto & player = Settings : : values . players [ p ] ; <nl> <nl> - Settings : : values . players [ p ] . type = static_cast < Settings : : ControllerType > ( <nl> + player . connected = qt_config - > value ( QString ( \" player_ % 1_connected \" ) . arg ( p ) , false ) . toBool ( ) ; <nl> + <nl> + player . type = static_cast < Settings : : ControllerType > ( <nl> qt_config <nl> - > value ( QString ( \" player_ % 1_type \" ) . arg ( p ) , <nl> static_cast < u8 > ( Settings : : ControllerType : : DualJoycon ) ) <nl> . toUInt ( ) ) ; <nl> <nl> - Settings : : values . players [ p ] . body_color_left = <nl> - qt_config <nl> - - > value ( QString ( \" player_ % 1_body_color_left \" ) . arg ( p ) , <nl> - Settings : : JOYCON_BODY_NEON_BLUE ) <nl> - . toUInt ( ) ; <nl> - Settings : : values . players [ p ] . body_color_right = <nl> - qt_config <nl> - - > value ( QString ( \" player_ % 1_body_color_right \" ) . arg ( p ) , <nl> - Settings : : JOYCON_BODY_NEON_RED ) <nl> - . toUInt ( ) ; <nl> - Settings : : values . players [ p ] . button_color_left = <nl> - qt_config <nl> - - > value ( QString ( \" player_ % 1_button_color_left \" ) . arg ( p ) , <nl> - Settings : : JOYCON_BUTTONS_NEON_BLUE ) <nl> - . toUInt ( ) ; <nl> - Settings : : values . players [ p ] . button_color_right = <nl> - qt_config <nl> - - > value ( QString ( \" player_ % 1_button_color_right \" ) . arg ( p ) , <nl> - Settings : : JOYCON_BUTTONS_NEON_RED ) <nl> - . toUInt ( ) ; <nl> + player . body_color_left = qt_config <nl> + - > value ( QString ( \" player_ % 1_body_color_left \" ) . arg ( p ) , <nl> + Settings : : JOYCON_BODY_NEON_BLUE ) <nl> + . toUInt ( ) ; <nl> + player . body_color_right = qt_config <nl> + - > value ( QString ( \" player_ % 1_body_color_right \" ) . arg ( p ) , <nl> + Settings : : JOYCON_BODY_NEON_RED ) <nl> + . toUInt ( ) ; <nl> + player . button_color_left = qt_config <nl> + - > value ( QString ( \" player_ % 1_button_color_left \" ) . arg ( p ) , <nl> + Settings : : JOYCON_BUTTONS_NEON_BLUE ) <nl> + . toUInt ( ) ; <nl> + player . button_color_right = qt_config <nl> + - > value ( QString ( \" player_ % 1_button_color_right \" ) . arg ( p ) , <nl> + Settings : : JOYCON_BUTTONS_NEON_RED ) <nl> + . toUInt ( ) ; <nl> <nl> for ( int i = 0 ; i < Settings : : NativeButton : : NumButtons ; + + i ) { <nl> std : : string default_param = InputCommon : : GenerateKeyboardParam ( default_buttons [ i ] ) ; <nl> - Settings : : values . players [ p ] . buttons [ i ] = <nl> + player . buttons [ i ] = <nl> qt_config <nl> - > value ( QString ( \" player_ % 1_ \" ) . arg ( p ) + Settings : : NativeButton : : mapping [ i ] , <nl> QString : : fromStdString ( default_param ) ) <nl> . toString ( ) <nl> . toStdString ( ) ; <nl> - if ( Settings : : values . players [ p ] . buttons [ i ] . empty ( ) ) <nl> - Settings : : values . players [ p ] . buttons [ i ] = default_param ; <nl> + if ( player . buttons [ i ] . empty ( ) ) <nl> + player . buttons [ i ] = default_param ; <nl> } <nl> <nl> for ( int i = 0 ; i < Settings : : NativeAnalog : : NumAnalogs ; + + i ) { <nl> std : : string default_param = InputCommon : : GenerateAnalogParamFromKeys ( <nl> default_analogs [ i ] [ 0 ] , default_analogs [ i ] [ 1 ] , default_analogs [ i ] [ 2 ] , <nl> default_analogs [ i ] [ 3 ] , default_analogs [ i ] [ 4 ] , 0 . 5f ) ; <nl> - Settings : : values . players [ p ] . analogs [ i ] = <nl> + player . analogs [ i ] = <nl> qt_config <nl> - > value ( QString ( \" player_ % 1_ \" ) . arg ( p ) + Settings : : NativeAnalog : : mapping [ i ] , <nl> QString : : fromStdString ( default_param ) ) <nl> . toString ( ) <nl> . toStdString ( ) ; <nl> - if ( Settings : : values . players [ p ] . analogs [ i ] . empty ( ) ) <nl> - Settings : : values . players [ p ] . analogs [ i ] = default_param ; <nl> + if ( player . analogs [ i ] . empty ( ) ) <nl> + player . analogs [ i ] = default_param ; <nl> } <nl> } <nl> <nl> void Config : : ReadValues ( ) { <nl> } <nl> <nl> void Config : : SavePlayerValues ( ) { <nl> - for ( int p = 0 ; p < Settings : : values . players . size ( ) ; + + p ) { <nl> - qt_config - > setValue ( QString ( \" player_ % 1_connected \" ) . arg ( p ) , <nl> - Settings : : values . players [ p ] . connected ) ; <nl> - qt_config - > setValue ( QString ( \" player_ % 1_type \" ) . arg ( p ) , <nl> - static_cast < u8 > ( Settings : : values . players [ p ] . type ) ) ; <nl> - <nl> - qt_config - > setValue ( QString ( \" player_ % 1_body_color_left \" ) . arg ( p ) , <nl> - Settings : : values . players [ p ] . body_color_left ) ; <nl> - qt_config - > setValue ( QString ( \" player_ % 1_body_color_right \" ) . arg ( p ) , <nl> - Settings : : values . players [ p ] . body_color_right ) ; <nl> + for ( std : : size_t p = 0 ; p < Settings : : values . players . size ( ) ; + + p ) { <nl> + const auto & player = Settings : : values . players [ p ] ; <nl> + <nl> + qt_config - > setValue ( QString ( \" player_ % 1_connected \" ) . arg ( p ) , player . connected ) ; <nl> + qt_config - > setValue ( QString ( \" player_ % 1_type \" ) . arg ( p ) , static_cast < u8 > ( player . type ) ) ; <nl> + <nl> + qt_config - > setValue ( QString ( \" player_ % 1_body_color_left \" ) . arg ( p ) , player . body_color_left ) ; <nl> + qt_config - > setValue ( QString ( \" player_ % 1_body_color_right \" ) . arg ( p ) , player . body_color_right ) ; <nl> qt_config - > setValue ( QString ( \" player_ % 1_button_color_left \" ) . arg ( p ) , <nl> - Settings : : values . players [ p ] . button_color_left ) ; <nl> + player . button_color_left ) ; <nl> qt_config - > setValue ( QString ( \" player_ % 1_button_color_right \" ) . arg ( p ) , <nl> - Settings : : values . players [ p ] . button_color_right ) ; <nl> + player . button_color_right ) ; <nl> <nl> for ( int i = 0 ; i < Settings : : NativeButton : : NumButtons ; + + i ) { <nl> qt_config - > setValue ( QString ( \" player_ % 1_ \" ) . arg ( p ) + <nl> QString : : fromStdString ( Settings : : NativeButton : : mapping [ i ] ) , <nl> - QString : : fromStdString ( Settings : : values . players [ p ] . buttons [ i ] ) ) ; <nl> + QString : : fromStdString ( player . buttons [ i ] ) ) ; <nl> } <nl> for ( int i = 0 ; i < Settings : : NativeAnalog : : NumAnalogs ; + + i ) { <nl> qt_config - > setValue ( QString ( \" player_ % 1_ \" ) . arg ( p ) + <nl> QString : : fromStdString ( Settings : : NativeAnalog : : mapping [ i ] ) , <nl> - QString : : fromStdString ( Settings : : values . players [ p ] . analogs [ i ] ) ) ; <nl> + QString : : fromStdString ( player . analogs [ i ] ) ) ; <nl> } <nl> } <nl> } <nl>\n", "msg": "configuration / config : Use an intermediary variable for accessing players\n"}
{"diff_id": 3745, "repo": "apple/swift\n", "sha": "8d257c256fed0339c8497a2f49d9000a35858345\n", "time": "2018-06-28T04:16:32Z\n", "diff": "mmm a / lib / FrontendTool / FrontendTool . cpp <nl> ppp b / lib / FrontendTool / FrontendTool . cpp <nl> static bool validateTBDIfNeeded ( CompilerInvocation & Invocation , <nl> switch ( mode ) { <nl> case FrontendOptions : : TBDValidationMode : : Default : <nl> # ifndef NDEBUG <nl> - / / When a debug compiler is targeting an apple platform , we do some <nl> - / / validation by default . <nl> - if ( Invocation . getLangOptions ( ) . Target . getVendor ( ) = = llvm : : Triple : : Apple ) { <nl> - mode = FrontendOptions : : TBDValidationMode : : MissingFromTBD ; <nl> - break ; <nl> - } <nl> - # endif <nl> + / / With a debug compiler , we do some validation by default . <nl> + mode = FrontendOptions : : TBDValidationMode : : MissingFromTBD ; <nl> + break ; <nl> + # else <nl> / / Otherwise , the default is to do nothing . <nl> LLVM_FALLTHROUGH ; <nl> + # endif <nl> case FrontendOptions : : TBDValidationMode : : None : <nl> return false ; <nl> case FrontendOptions : : TBDValidationMode : : All : <nl>\n", "msg": "[ TBD ] Validate TBDs in debug compilers for all platforms .\n"}
{"diff_id": 3892, "repo": "opencv/opencv\n", "sha": "72063bf13610b8d262c00d57a52aadc188af5c7b\n", "time": "2015-01-13T09:53:13Z\n", "diff": "old mode 100644 <nl> new mode 100755 <nl> index c829830e724 . . 68a6395dea6 <nl> mmm a / samples / gpu / driver_api_multi . cpp <nl> ppp b / samples / gpu / driver_api_multi . cpp <nl> <nl> # endif <nl> <nl> # include < iostream > <nl> - # include \" cvconfig . h \" <nl> # include \" opencv2 / core / core . hpp \" <nl> # include \" opencv2 / gpu / gpu . hpp \" <nl> <nl> - # if ! defined ( HAVE_CUDA ) | | ! defined ( HAVE_TBB ) | | defined ( __arm__ ) <nl> - <nl> + # if defined ( __arm__ ) <nl> int main ( ) <nl> { <nl> - # if ! defined ( HAVE_CUDA ) <nl> - std : : cout < < \" CUDA support is required ( CMake key ' WITH_CUDA ' must be true ) . \\ n \" ; <nl> - # endif <nl> - <nl> - # if ! defined ( HAVE_TBB ) <nl> - std : : cout < < \" TBB support is required ( CMake key ' WITH_TBB ' must be true ) . \\ n \" ; <nl> - # endif <nl> - <nl> - # if defined ( __arm__ ) <nl> std : : cout < < \" Unsupported for ARM CUDA library . \" < < std : : endl ; <nl> - # endif <nl> - <nl> return 0 ; <nl> } <nl> - <nl> # else <nl> <nl> # include < cuda . h > <nl> # include < cuda_runtime . h > <nl> - # include \" opencv2 / core / internal . hpp \" / / For TBB wrappers <nl> <nl> using namespace std ; <nl> using namespace cv ; <nl> using namespace cv : : gpu ; <nl> <nl> - struct Worker { void operator ( ) ( int device_id ) const ; } ; <nl> - void destroyContexts ( ) ; <nl> - <nl> # define safeCall ( expr ) safeCall_ ( expr , # expr , __FILE__ , __LINE__ ) <nl> inline void safeCall_ ( int code , const char * expr , const char * file , int line ) <nl> { <nl> if ( code ! = CUDA_SUCCESS ) <nl> { <nl> std : : cout < < \" CUDA driver API error : code \" < < code < < \" , expr \" < < expr <nl> - < < \" , file \" < < file < < \" , line \" < < line < < endl ; <nl> - destroyContexts ( ) ; <nl> + < < \" , file \" < < file < < \" , line \" < < line < < endl ; <nl> exit ( - 1 ) ; <nl> } <nl> } <nl> <nl> - / / Each GPU is associated with its own context <nl> - CUcontext contexts [ 2 ] ; <nl> + struct Worker : public ParallelLoopBody <nl> + { <nl> + Worker ( int num_devices ) <nl> + { <nl> + count = num_devices ; <nl> + contexts = new contexts CUcontext [ num_devices ] ; <nl> + for ( int device_id = 0 ; i < num_devices ; device_id + + ) <nl> + { <nl> + CUdevice device ; <nl> + safeCall ( cuDeviceGet ( & device , device_id ) ) ; <nl> + safeCall ( cuCtxCreate ( & contexts [ device_id ] , 0 , device ) ) ; <nl> + } <nl> + } <nl> + <nl> + virtual void operator ( ) ( const Range & range ) const <nl> + { <nl> + for ( int device_id = range . start ; device_id ! = range . end ; + + device_id ) <nl> + { <nl> + / / Set the proper context <nl> + safeCall ( cuCtxPushCurrent ( contexts [ device_id ] ) ) ; <nl> + <nl> + Mat src ( 1000 , 1000 , CV_32F ) ; <nl> + Mat dst ; <nl> + <nl> + RNG rng ( 0 ) ; <nl> + rng . fill ( src , RNG : : UNIFORM , 0 , 1 ) ; <nl> + <nl> + / / CPU works <nl> + transpose ( src , dst ) ; <nl> + <nl> + / / GPU works <nl> + GpuMat d_src ( src ) ; <nl> + GpuMat d_dst ; <nl> + transpose ( d_src , d_dst ) ; <nl> + <nl> + / / Check results <nl> + bool passed = norm ( dst - Mat ( d_dst ) , NORM_INF ) < 1e - 3 ; <nl> + std : : cout < < \" GPU # \" < < device_id < < \" ( \" < < DeviceInfo ( ) . name ( ) < < \" ) : \" <nl> + < < ( passed ? \" passed \" : \" FAILED \" ) < < endl ; <nl> + <nl> + / / Deallocate data here , otherwise deallocation will be performed <nl> + / / after context is extracted from the stack <nl> + d_src . release ( ) ; <nl> + d_dst . release ( ) ; <nl> + <nl> + CUcontext prev_context ; <nl> + safeCall ( cuCtxPopCurrent ( & prev_context ) ) ; <nl> + } <nl> + } <nl> + <nl> + ~ Worker ( ) <nl> + { <nl> + if ( ( contexts ! = NULL ) & & count ! = 0 ) <nl> + { <nl> + for ( int device_id = 0 ; i < num_devices ; device_id + + ) <nl> + { <nl> + safeCall ( cuCtxDestroy ( contexts [ device_id ] ) ) ; <nl> + } <nl> + <nl> + delete [ ] contexts ; <nl> + } <nl> + } <nl> + <nl> + CUcontext * contexts ; <nl> + int count ; <nl> + } ; <nl> <nl> int main ( ) <nl> { <nl> int main ( ) <nl> / / Init CUDA Driver API <nl> safeCall ( cuInit ( 0 ) ) ; <nl> <nl> - / / Create context for GPU # 0 <nl> - CUdevice device ; <nl> - safeCall ( cuDeviceGet ( & device , 0 ) ) ; <nl> - safeCall ( cuCtxCreate ( & contexts [ 0 ] , 0 , device ) ) ; <nl> - <nl> - CUcontext prev_context ; <nl> - safeCall ( cuCtxPopCurrent ( & prev_context ) ) ; <nl> - <nl> - / / Create context for GPU # 1 <nl> - safeCall ( cuDeviceGet ( & device , 1 ) ) ; <nl> - safeCall ( cuCtxCreate ( & contexts [ 1 ] , 0 , device ) ) ; <nl> - <nl> - safeCall ( cuCtxPopCurrent ( & prev_context ) ) ; <nl> + / / Execute calculation <nl> + parallel_for_ ( cv : : Range ( 0 , num_devices , Worker ( num_devices ) ) ; <nl> <nl> - / / Execute calculation in two threads using two GPUs <nl> - int devices [ ] = { 0 , 1 } ; <nl> - parallel_do ( devices , devices + 2 , Worker ( ) ) ; <nl> - <nl> - destroyContexts ( ) ; <nl> return 0 ; <nl> } <nl> <nl> - <nl> - void Worker : : operator ( ) ( int device_id ) const <nl> - { <nl> - / / Set the proper context <nl> - safeCall ( cuCtxPushCurrent ( contexts [ device_id ] ) ) ; <nl> - <nl> - Mat src ( 1000 , 1000 , CV_32F ) ; <nl> - Mat dst ; <nl> - <nl> - RNG rng ( 0 ) ; <nl> - rng . fill ( src , RNG : : UNIFORM , 0 , 1 ) ; <nl> - <nl> - / / CPU works <nl> - transpose ( src , dst ) ; <nl> - <nl> - / / GPU works <nl> - GpuMat d_src ( src ) ; <nl> - GpuMat d_dst ; <nl> - transpose ( d_src , d_dst ) ; <nl> - <nl> - / / Check results <nl> - bool passed = norm ( dst - Mat ( d_dst ) , NORM_INF ) < 1e - 3 ; <nl> - std : : cout < < \" GPU # \" < < device_id < < \" ( \" < < DeviceInfo ( ) . name ( ) < < \" ) : \" <nl> - < < ( passed ? \" passed \" : \" FAILED \" ) < < endl ; <nl> - <nl> - / / Deallocate data here , otherwise deallocation will be performed <nl> - / / after context is extracted from the stack <nl> - d_src . release ( ) ; <nl> - d_dst . release ( ) ; <nl> - <nl> - CUcontext prev_context ; <nl> - safeCall ( cuCtxPopCurrent ( & prev_context ) ) ; <nl> - } <nl> - <nl> - <nl> - void destroyContexts ( ) <nl> - { <nl> - safeCall ( cuCtxDestroy ( contexts [ 0 ] ) ) ; <nl> - safeCall ( cuCtxDestroy ( contexts [ 1 ] ) ) ; <nl> - } <nl> - <nl> # endif <nl>\n", "msg": "parallel_do replaced with parallel_for_ in driver_gpu_multi sample .\n"}
{"diff_id": 3948, "msg": "set horizontal scrollmode of result widgets to per pixel\n", "msgGPT": "added horizontal scroll mode to the data table and query result table.", "METEOR Score": "16.62958838566196", "BLEU Score": "0.4489839449730402", "ROUGE-L Score": "0.1999999950500001", "score": 1, "repo": "sqlitebrowser/sqlitebrowser\n", "sha": "1f760aac1417c39f7366850a79576c4ce7eddb5e\n", "time": "2012-04-17T14:37:21Z\n", "diff": "mmm a / src / mainwindow . cpp <nl> ppp b / src / mainwindow . cpp <nl> void MainWindow : : setupUi ( ) <nl> dataTable - > setRowCount ( 0 ) ; <nl> dataTable - > setColumnCount ( 0 ) ; <nl> dataTable - > setSelectionMode ( QTableWidget : : SingleSelection ) ; <nl> + dataTable - > setHorizontalScrollMode ( QAbstractItemView : : ScrollPerPixel ) ; <nl> <nl> vboxLayout2 - > addWidget ( dataTable ) ; <nl> <nl> void MainWindow : : setupUi ( ) <nl> queryResultTableView - > setSelectionMode ( QTreeView : : NoSelection ) ; <nl> queryResultTableView - > setModel ( queryResultListModel ) ; <nl> queryResultTableView - > setEditTriggers ( QAbstractItemView : : NoEditTriggers ) ; <nl> + queryResultTableView - > setHorizontalScrollMode ( QAbstractItemView : : ScrollPerPixel ) ; <nl> <nl> vboxLayout3 - > addWidget ( queryResultTableView ) ; <nl> <nl>\n"}
{"diff_id": 3978, "repo": "xbmc/xbmc\n", "sha": "b3db4e710a019f268cd97b6afcb742e8e00d91de\n", "time": "2015-06-30T09:41:05Z\n", "diff": "mmm a / xbmc / pvr / channels / PVRChannelGroup . cpp <nl> ppp b / xbmc / pvr / channels / PVRChannelGroup . cpp <nl> CPVRChannelGroup : : CPVRChannelGroup ( const PVR_CHANNEL_GROUP & group ) : <nl> OnInit ( ) ; <nl> } <nl> <nl> + CPVRChannelGroup : : CPVRChannelGroup ( const CPVRChannelGroup & group ) : <nl> + m_strGroupName ( group . m_strGroupName ) <nl> + { <nl> + m_bRadio = group . m_bRadio ; <nl> + m_iGroupType = group . m_iGroupType ; <nl> + m_iGroupId = group . m_iGroupId ; <nl> + m_bLoaded = group . m_bLoaded ; <nl> + m_bChanged = group . m_bChanged ; <nl> + m_bUsingBackendChannelOrder = group . m_bUsingBackendChannelOrder ; <nl> + m_bUsingBackendChannelNumbers = group . m_bUsingBackendChannelNumbers ; <nl> + m_iLastWatched = group . m_iLastWatched ; <nl> + m_bHidden = group . m_bHidden ; <nl> + m_bSelectedGroup = group . m_bSelectedGroup ; <nl> + m_bPreventSortAndRenumber = group . m_bPreventSortAndRenumber ; <nl> + m_members = group . m_members ; <nl> + m_sortedMembers = group . m_sortedMembers ; <nl> + m_iPosition = group . m_iPosition ; <nl> + OnInit ( ) ; <nl> + } <nl> + <nl> CPVRChannelGroup : : ~ CPVRChannelGroup ( void ) <nl> { <nl> CSettings : : Get ( ) . UnregisterCallback ( this ) ; <nl> std : : pair < int , int > CPVRChannelGroup : : PathIdToStorageId ( uint64_t storageId ) <nl> return std : : make_pair ( storageId > > 32 , storageId & 0xFFFFFFFF ) ; <nl> } <nl> <nl> - CPVRChannelGroup : : CPVRChannelGroup ( const CPVRChannelGroup & group ) : <nl> - m_strGroupName ( group . m_strGroupName ) <nl> - { <nl> - m_bRadio = group . m_bRadio ; <nl> - m_iGroupType = group . m_iGroupType ; <nl> - m_iGroupId = group . m_iGroupId ; <nl> - m_bLoaded = group . m_bLoaded ; <nl> - m_bChanged = group . m_bChanged ; <nl> - m_bUsingBackendChannelOrder = group . m_bUsingBackendChannelOrder ; <nl> - m_bUsingBackendChannelNumbers = group . m_bUsingBackendChannelNumbers ; <nl> - m_iLastWatched = group . m_iLastWatched ; <nl> - m_bHidden = group . m_bHidden ; <nl> - m_bSelectedGroup = group . m_bSelectedGroup ; <nl> - m_bPreventSortAndRenumber = group . m_bPreventSortAndRenumber ; <nl> - m_members = group . m_members ; <nl> - m_sortedMembers = group . m_sortedMembers ; <nl> - m_iPosition = group . m_iPosition ; <nl> - OnInit ( ) ; <nl> - } <nl> - <nl> void CPVRChannelGroup : : OnInit ( void ) <nl> { <nl> CSettings : : Get ( ) . RegisterCallback ( this , { <nl>\n", "msg": "[ cosmetics ] sort ctor in CPVRChannelGroup\n"}
{"diff_id": 4054, "msg": "Add copyright notice to fix lint failure\n", "msgGPT": "add proper copyright information to the file.", "METEOR Score": "18.151260504201677", "BLEU Score": "0.4166860451596924", "ROUGE-L Score": "0.4285714235714286", "score": 1, "repo": "mongodb/mongo\n", "sha": "0078f9cb5084e049f06a58fafa6dc6330cc2c076\n", "time": "2012-11-14T06:02:04Z\n", "diff": "mmm a / src / mongo / util / descriptive_stats_test . cpp <nl> ppp b / src / mongo / util / descriptive_stats_test . cpp <nl> <nl> + / * * <nl> + * Copyright ( C ) 2012 10gen Inc . <nl> + * <nl> + * This program is free software : you can redistribute it and / or modify <nl> + * it under the terms of the GNU Affero General Public License , version 3 , <nl> + * as published by the Free Software Foundation . <nl> + * <nl> + * This program is distributed in the hope that it will be useful , <nl> + * but WITHOUT ANY WARRANTY ; without even the implied warranty of <nl> + * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE . See the <nl> + * GNU Affero General Public License for more details . <nl> + * <nl> + * You should have received a copy of the GNU Affero General Public License <nl> + * along with this program . If not , see < http : / / www . gnu . org / licenses / > . <nl> + * / <nl> + <nl> / * * <nl> * Tests for mongo / util / descriptive_stats . h <nl> * / <nl>\n"}
{"diff_id": 4082, "repo": "godotengine/godot\n", "sha": "ec18b97f5cdc3fcf67cb2625d289cb061958b2b6\n", "time": "2016-07-03T14:34:23Z\n", "diff": "mmm a / scene / gui / text_edit . cpp <nl> ppp b / scene / gui / text_edit . cpp <nl> void TextEdit : : _update_completion_candidates ( ) { <nl> int ci_match = 0 ; <nl> Vector < float > sim_cache ; <nl> for ( int i = 0 ; i < completion_strings . size ( ) ; i + + ) { <nl> + if ( s = = completion_strings [ i ] ) { <nl> + / / A perfect match , stop completion <nl> + _cancel_completion ( ) ; <nl> + return ; <nl> + } <nl> if ( s . is_subsequence_ofi ( completion_strings [ i ] ) ) { <nl> / / don ' t remove duplicates if no input is provided <nl> if ( s ! = \" \" & & completion_options . find ( completion_strings [ i ] ) ! = - 1 ) { <nl>\n", "msg": "Stop completion when the match is perfect\n", "score": 1}
{"diff_id": 4103, "repo": "simdjson/simdjson\n", "sha": "af18d5ed81c617c89efa85c7444c97b6f0b316d5\n", "time": "2020-07-20T22:56:39Z\n", "diff": "mmm a / benchmark / bench_parse_call . cpp <nl> ppp b / benchmark / bench_parse_call . cpp <nl> const char * GSOC_JSON = SIMDJSON_BENCHMARK_DATA_DIR \" gsoc - 2018 . json \" ; <nl> <nl> <nl> <nl> + static void unicode_validate_twitter ( State & state ) { <nl> + dom : : parser parser ; <nl> + padded_string docdata ; <nl> + auto error = padded_string : : load ( TWITTER_JSON ) . get ( docdata ) ; <nl> + if ( error ) { <nl> + cerr < < \" could not parse twitter . json \" < < error < < endl ; <nl> + return ; <nl> + } <nl> + / / we do not want mem . alloc . in the loop . <nl> + error = parser . allocate ( docdata . size ( ) ) ; <nl> + if ( error ) { <nl> + cout < < error < < endl ; <nl> + return ; <nl> + } <nl> + size_t bytes = 0 ; <nl> + for ( UNUSED auto _ : state ) { <nl> + bool is_ok = simdjson : : validate_utf8 ( docdata . data ( ) , docdata . size ( ) ) ; <nl> + bytes + = docdata . size ( ) ; <nl> + benchmark : : DoNotOptimize ( is_ok ) ; <nl> + } <nl> + / / Gigabyte : https : / / en . wikipedia . org / wiki / Gigabyte <nl> + state . counters [ \" Gigabytes \" ] = benchmark : : Counter ( <nl> + double ( bytes ) , benchmark : : Counter : : kIsRate , <nl> + benchmark : : Counter : : OneK : : kIs1000 ) ; / / For GiB : kIs1024 <nl> + state . counters [ \" docs \" ] = Counter ( double ( state . iterations ( ) ) , benchmark : : Counter : : kIsRate ) ; <nl> + } <nl> + BENCHMARK ( unicode_validate_twitter ) - > Repetitions ( 10 ) - > ComputeStatistics ( \" max \" , [ ] ( const std : : vector < double > & v ) - > double { <nl> + return * ( std : : max_element ( std : : begin ( v ) , std : : end ( v ) ) ) ; <nl> + } ) - > DisplayAggregatesOnly ( true ) ; <nl> + <nl> static void parse_twitter ( State & state ) { <nl> dom : : parser parser ; <nl> padded_string docdata ; <nl> static void parse_twitter ( State & state ) { <nl> for ( UNUSED auto _ : state ) { <nl> dom : : element doc ; <nl> bytes + = docdata . size ( ) ; <nl> - ; <nl> if ( ( error = parser . parse ( docdata ) . get ( doc ) ) ) { <nl> cerr < < \" could not parse twitter . json \" < < error < < endl ; <nl> return ; <nl>\n", "msg": "This adds a validation benchmark ( )\n"}
{"diff_id": 4117, "repo": "apple/swift\n", "sha": "ee0599b892e8b941bee3a3c58151fd531f465a1a\n", "time": "2015-09-25T21:11:10Z\n", "diff": "mmm a / lib / SILPasses / LoadStoreOpts . cpp <nl> ppp b / lib / SILPasses / LoadStoreOpts . cpp <nl> using namespace swift ; <nl> static llvm : : cl : : opt < bool > DisableGDSE ( \" sil - disable - loadstore - dse \" , <nl> llvm : : cl : : init ( false ) , llvm : : cl : : Hidden ) ; <nl> <nl> + STATISTIC ( NumSameValueStores , \" Number of same value stores removed \" ) ; <nl> STATISTIC ( NumDeadStores , \" Number of dead stores removed \" ) ; <nl> STATISTIC ( NumDupLoads , \" Number of dup loads removed \" ) ; <nl> STATISTIC ( NumForwardedLoads , \" Number of loads forwarded \" ) ; <nl> bool LSBBForwarder : : tryToEliminateDeadStores ( LSContext & Ctx , StoreInst * SI , <nl> / / If we are storing a value that is available in the load list then we <nl> / / know that no one clobbered that address and the current store is <nl> / / redundant and we can remove it . <nl> + / / <nl> + / / e . g . <nl> + / / % 0 = load % A <nl> + / / . . . nothing happens in middle and the % A contains the value of % 0 . <nl> + / / store % 0 to % A < mmm - no need to do this store . <nl> if ( auto * LdSrc = dyn_cast < LoadInst > ( SI - > getSrc ( ) ) ) { <nl> / / Check that the loaded value is live and that the destination address <nl> / / is the same as the loaded address . <nl> bool LSBBForwarder : : tryToEliminateDeadStores ( LSContext & Ctx , StoreInst * SI , <nl> / / do . <nl> if ( Iter ! = Loads . end ( ) & & LdSrcOp = = SI - > getDest ( ) ) { <nl> deleteUntrackedInstruction ( Ctx , SI , StoreMap ) ; <nl> - NumDeadStores + + ; <nl> + NumSameValueStores + + ; <nl> return true ; <nl> } <nl> } <nl>\n", "msg": "separate number of dead stores with number of same - value stores in LoadStoreOpts . cpp\n"}
{"diff_id": 4183, "msg": "[ doc ] Improve help for getpeerinfo connection_type field .\n", "msgGPT": "add additional information to the getpeerinfo RPC method output regarding the stability of the \"connection_type\" field.", "METEOR Score": "19.285729485389545", "BLEU Score": "0.2986089829070018", "ROUGE-L Score": "0.1739130387145559", "score": 1, "repo": "bitcoin/bitcoin\n", "sha": "3069b56a456d98fca7c4a4ccd329581bd1f0b853\n", "time": "2020-10-09T23:08:02Z\n", "diff": "mmm a / src / rpc / net . cpp <nl> ppp b / src / rpc / net . cpp <nl> static RPCHelpMan getpeerinfo ( ) <nl> { RPCResult : : Type : : BOOL , \" inbound \" , \" Inbound ( true ) or Outbound ( false ) \" } , <nl> { RPCResult : : Type : : BOOL , \" addnode \" , \" Whether connection was due to addnode / - connect or if it was an automatic / inbound connection \\ n \" <nl> \" ( DEPRECATED , returned only if the config option - deprecatedrpc = getpeerinfo_addnode is passed ) \" } , <nl> - { RPCResult : : Type : : STR , \" connection_type \" , \" Type of connection : \\ n \" + Join ( CONNECTION_TYPE_DOC , \" , \\ n \" ) + \" . \" } , <nl> + { RPCResult : : Type : : STR , \" connection_type \" , \" Type of connection : \\ n \" + Join ( CONNECTION_TYPE_DOC , \" , \\ n \" ) + \" . \\ n \" <nl> + \" Please note this output is unlikely to be stable in upcoming releases as we iterate to \\ n \" <nl> + \" best capture connection behaviors . \" } , <nl> { RPCResult : : Type : : NUM , \" startingheight \" , \" The starting height ( block ) of the peer \" } , <nl> { RPCResult : : Type : : NUM , \" banscore \" , \" The ban score ( DEPRECATED , returned only if config option - deprecatedrpc = banscore is passed ) \" } , <nl> { RPCResult : : Type : : NUM , \" synced_headers \" , \" The last header we have in common with this peer \" } , <nl>\n"}
{"diff_id": 4287, "repo": "x64dbg/x64dbg\n", "sha": "b1578540a8b531a87d471224f1ca22a8281c6481\n", "time": "2016-09-08T11:01:40Z\n", "diff": "mmm a / src / gui / Src / Gui / MainWindow . cpp <nl> ppp b / src / gui / Src / Gui / MainWindow . cpp <nl> MainWindow : : MainWindow ( QWidget * parent ) <nl> makeCommandAction ( ui - > actioneStepInto , \" eStepInto \" ) ; <nl> makeCommandAction ( ui - > actioneRun , \" eRun \" ) ; <nl> makeCommandAction ( ui - > actioneRtr , \" eRtr \" ) ; <nl> - makeCommandAction ( ui - > actionRtu , \" rtu \" ) ; <nl> + makeCommandAction ( ui - > actionRtu , \" TraceIntoConditional ! mod . party ( cip ) \" ) ; <nl> connect ( ui - > actionTicnd , SIGNAL ( triggered ( ) ) , this , SLOT ( execTicnd ( ) ) ) ; <nl> connect ( ui - > actionTocnd , SIGNAL ( triggered ( ) ) , this , SLOT ( execTocnd ( ) ) ) ; <nl> connect ( ui - > actionTRBit , SIGNAL ( triggered ( ) ) , this , SLOT ( execTRBit ( ) ) ) ; <nl>\n", "msg": "GUI : conditional tracing instead of rtu in run to user code\n", "score": 1}
{"diff_id": 4442, "msg": "Add precedencegroup and operator decls to SourceLookupCache\n", "msgGPT": "rename the ` decl map` class to ` value decl map` and add template aliases for ` operator map` and ` value decl map` in the ` source lookup cache` class.", "METEOR Score": "32.255557204797896", "BLEU Score": "0.2799318570746585", "ROUGE-L Score": "0.2962962918518519", "score": 1, "repo": "apple/swift\n", "sha": "6c3362fb55affe123a1f7254c7a39fc8c554a9bc\n", "time": "2020-03-27T16:44:55Z\n", "diff": "mmm a / lib / AST / Module . cpp <nl> ppp b / lib / AST / Module . cpp <nl> SourceFile : : ~ SourceFile ( ) = default ; <nl> class swift : : SourceLookupCache { <nl> / / / A lookup map for value decls . When declarations are added they are added <nl> / / / under all variants of the name they can be found under . <nl> - class DeclMap { <nl> - llvm : : DenseMap < DeclName , TinyPtrVector < ValueDecl * > > Members ; <nl> + class ValueDeclMap { <nl> + llvm : : DenseMap < DeclName , TinyPtrVector < ValueDecl * > > Members ; <nl> <nl> public : <nl> void add ( ValueDecl * VD ) { <nl> class swift : : SourceLookupCache { <nl> } <nl> } ; <nl> <nl> - DeclMap TopLevelValues ; <nl> - DeclMap ClassMembers ; <nl> + ValueDeclMap TopLevelValues ; <nl> + ValueDeclMap ClassMembers ; <nl> bool MemberCachePopulated = false ; <nl> <nl> + template < typename T > <nl> + using OperatorMap = llvm : : DenseMap < Identifier , TinyPtrVector < T * > > ; <nl> + OperatorMap < OperatorDecl > Operators ; <nl> + OperatorMap < PrecedenceGroupDecl > PrecedenceGroups ; <nl> + <nl> template < typename Range > <nl> void addToUnqualifiedLookupCache ( Range decls , bool onlyOperators ) ; <nl> template < typename Range > <nl> class swift : : SourceLookupCache { <nl> <nl> void lookupValue ( DeclName Name , NLKind LookupKind , <nl> SmallVectorImpl < ValueDecl * > & Result ) ; <nl> - <nl> + <nl> + / / / Retrieves all the operator decls . The order of the results is not <nl> + / / / guaranteed to be meaningful . <nl> + void getOperatorDecls ( SmallVectorImpl < OperatorDecl * > & results ) ; <nl> + <nl> + / / / Retrieves all the precedence groups . The order of the results is not <nl> + / / / guaranteed to be meaningful . <nl> + void getPrecedenceGroups ( SmallVectorImpl < PrecedenceGroupDecl * > & results ) ; <nl> + <nl> + / / / Look up an operator declaration . <nl> + / / / <nl> + / / / \\ param name The operator name ( \" + \" , \" > > \" , etc . ) <nl> + / / / \\ param fixity The fixity of the operator ( infix , prefix or postfix ) . <nl> + void lookupOperator ( Identifier name , OperatorFixity fixity , <nl> + TinyPtrVector < OperatorDecl * > & results ) ; <nl> + <nl> + / / / Look up a precedence group . <nl> + / / / <nl> + / / / \\ param name The operator name ( \" + \" , \" > > \" , etc . ) <nl> + void lookupPrecedenceGroup ( Identifier name , <nl> + TinyPtrVector < PrecedenceGroupDecl * > & results ) ; <nl> + <nl> void lookupVisibleDecls ( AccessPathTy AccessPath , <nl> VisibleDeclConsumer & Consumer , <nl> NLKind LookupKind ) ; <nl> void SourceLookupCache : : addToUnqualifiedLookupCache ( Range decls , <nl> if ( ! ED - > hasUnparsedMembers ( ) | | ED - > maybeHasOperatorDeclarations ( ) ) <nl> addToUnqualifiedLookupCache ( ED - > getMembers ( ) , true ) ; <nl> } <nl> + <nl> + if ( auto * OD = dyn_cast < OperatorDecl > ( D ) ) <nl> + Operators [ OD - > getName ( ) ] . push_back ( OD ) ; <nl> + <nl> + if ( auto * PG = dyn_cast < PrecedenceGroupDecl > ( D ) ) <nl> + PrecedenceGroups [ PG - > getName ( ) ] . push_back ( PG ) ; <nl> } <nl> } <nl> <nl> void SourceLookupCache : : lookupValue ( DeclName Name , NLKind LookupKind , <nl> Result . push_back ( Elt ) ; <nl> } <nl> <nl> + void SourceLookupCache : : getPrecedenceGroups ( <nl> + SmallVectorImpl < PrecedenceGroupDecl * > & results ) { <nl> + for ( auto & groups : PrecedenceGroups ) <nl> + results . append ( groups . second . begin ( ) , groups . second . end ( ) ) ; <nl> + } <nl> + <nl> + void SourceLookupCache : : getOperatorDecls ( <nl> + SmallVectorImpl < OperatorDecl * > & results ) { <nl> + for ( auto & ops : Operators ) <nl> + results . append ( ops . second . begin ( ) , ops . second . end ( ) ) ; <nl> + } <nl> + <nl> + void SourceLookupCache : : lookupOperator ( Identifier name , OperatorFixity fixity , <nl> + TinyPtrVector < OperatorDecl * > & results ) { <nl> + auto ops = Operators . find ( name ) ; <nl> + if ( ops = = Operators . end ( ) ) <nl> + return ; <nl> + <nl> + for ( auto * op : ops - > second ) <nl> + if ( op - > getFixity ( ) = = fixity ) <nl> + results . push_back ( op ) ; <nl> + } <nl> + <nl> + void SourceLookupCache : : lookupPrecedenceGroup ( <nl> + Identifier name , TinyPtrVector < PrecedenceGroupDecl * > & results ) { <nl> + auto groups = PrecedenceGroups . find ( name ) ; <nl> + if ( groups = = PrecedenceGroups . end ( ) ) <nl> + return ; <nl> + <nl> + for ( auto * group : groups - > second ) <nl> + results . push_back ( group ) ; <nl> + } <nl> + <nl> void SourceLookupCache : : lookupVisibleDecls ( AccessPathTy AccessPath , <nl> VisibleDeclConsumer & Consumer , <nl> NLKind LookupKind ) { <nl>\n"}
{"diff_id": 4475, "repo": "xbmc/xbmc\n", "sha": "4d3b243811e4273676ac11039682a2cdcebe3761\n", "time": "2016-09-28T15:31:56Z\n", "diff": "mmm a / xbmc / video / dialogs / GUIDialogVideoInfo . cpp <nl> ppp b / xbmc / video / dialogs / GUIDialogVideoInfo . cpp <nl> void CGUIDialogVideoInfo : : OnGetArt ( ) <nl> / / which is probably the IMDb thumb . These could be wrong , so allow the user <nl> / / to delete the incorrect thumb <nl> CFileItemPtr item ( new CFileItem ( \" thumb : / / None \" , false ) ) ; <nl> - item - > SetIconImage ( \" DefaultVideo . png \" ) ; <nl> + item - > SetIconImage ( \" DefaultPicture . png \" ) ; <nl> item - > SetLabel ( g_localizeStrings . Get ( 13515 ) ) ; <nl> items . Add ( item ) ; <nl> } <nl> void CGUIDialogVideoInfo : : OnGetFanart ( ) <nl> else <nl> { <nl> CFileItemPtr itemNone ( new CFileItem ( \" fanart : / / None \" , false ) ) ; <nl> - itemNone - > SetIconImage ( \" DefaultVideo . png \" ) ; <nl> + itemNone - > SetIconImage ( \" DefaultPicture . png \" ) ; <nl> itemNone - > SetLabel ( g_localizeStrings . Get ( 20439 ) ) ; <nl> items . Add ( itemNone ) ; <nl> } <nl> void CGUIDialogVideoInfo : : ShowFor ( const CFileItem & item ) <nl> ADDON : : ScraperPtr info ; <nl> window - > OnItemInfo ( item , info ) ; <nl> } <nl> - } <nl> \\ No newline at end of file <nl> + } <nl>\n", "msg": "[ gui ] use correct fallback icon for \" no art \" entry in art selection\n"}
{"diff_id": 4496, "msg": "added : Allow the use of our ValidatePath ( ) function in Python\n", "msgGPT": "added a new function `validate path` to the `PYXBMC` namespace for validating and fixing slash problems in file paths.", "METEOR Score": "35.74315834857994", "BLEU Score": "0.31559398130255767", "ROUGE-L Score": "0.18181817693296617", "score": 1, "repo": "xbmc/xbmc\n", "sha": "69f92a1b6c5a8b7fc3b66e21514d1bcccfb67c15\n", "time": "2010-02-22T07:53:22Z\n", "diff": "mmm a / xbmc / lib / libPython / xbmcmodule / xbmcmodule . cpp <nl> ppp b / xbmc / lib / libPython / xbmcmodule / xbmcmodule . cpp <nl> namespace PYXBMC <nl> \" \\ n \" <nl> \" path : string or unicode - Path to format \\ n \" <nl> \" \\ n \" <nl> - \" * Note , Only useful if you are coding for both Linux and the Xbox . \\ n \" <nl> + \" * Note , Only useful if you are coding for both Linux and Windows / Xbox . \\ n \" <nl> \" e . g . Converts ' special : / / masterprofile / script_data ' - > ' / home / user / XBMC / UserData / script_data ' \\ n \" <nl> \" on Linux . Would return ' special : / / masterprofile / script_data ' on the Xbox . \\ n \" <nl> \" \\ n \" <nl> namespace PYXBMC <nl> return Py_BuildValue ( ( char * ) \" s \" , strPath . c_str ( ) ) ; <nl> } <nl> <nl> + / / validatePath function <nl> + PyDoc_STRVAR ( validatePath__doc__ , <nl> + \" validatePath ( path ) - - Returns the validated path . \\ n \" <nl> + \" \\ n \" <nl> + \" path : string or unicode - Path to format \\ n \" <nl> + \" \\ n \" <nl> + \" * Note , Only useful if you are coding for both Linux and Windows / Xbox for fixing slash problems . \\ n \" <nl> + \" e . g . Corrects ' Z : / / something ' - > ' Z : \\ \\ something ' \\ n \" <nl> + \" \\ n \" <nl> + \" example : \\ n \" <nl> + \" - fpath = xbmc . validatePath ( somepath ) \\ n \" ) ; <nl> + <nl> + PyObject * XBMC_ValidatePath ( PyObject * self , PyObject * args ) <nl> + { <nl> + PyObject * pObjectText ; <nl> + if ( ! PyArg_ParseTuple ( args , ( char * ) \" O \" , & pObjectText ) ) return NULL ; <nl> + <nl> + CStdString strText ; <nl> + if ( ! PyXBMCGetUnicodeString ( strText , pObjectText , 1 ) ) return NULL ; <nl> + <nl> + return Py_BuildValue ( ( char * ) \" s \" , CUtil : : ValidatePath ( strText ) . c_str ( ) ) ; <nl> + } <nl> + <nl> / / getRegion function <nl> PyDoc_STRVAR ( getRegion__doc__ , <nl> \" getRegion ( id ) - - Returns your regions setting as a string for the specified id . \\ n \" <nl>\n"}
{"diff_id": 4538, "repo": "telegramdesktop/tdesktop\n", "sha": "fae0bccc9cc5eaf912ca63f4b0e1aea9ee30bde5\n", "time": "2018-07-31T19:53:37Z\n", "diff": "mmm a / Telegram / SourceFiles / platform / win / notifications_manager_win . cpp <nl> ppp b / Telegram / SourceFiles / platform / win / notifications_manager_win . cpp <nl> namespace { <nl> bool QuietHoursEnabled = false ; <nl> DWORD QuietHoursValue = 0 ; <nl> <nl> + bool useQuietHoursRegistryEntry ( ) { <nl> + / / Taken from QSysInfo . <nl> + OSVERSIONINFO result = { sizeof ( OSVERSIONINFO ) , 0 , 0 , 0 , 0 , { ' \\ 0 ' } } ; <nl> + if ( const auto library = GetModuleHandle ( L \" ntdll . dll \" ) ) { <nl> + using RtlGetVersionFunction = NTSTATUS ( NTAPI * ) ( LPOSVERSIONINFO ) ; <nl> + const auto RtlGetVersion = reinterpret_cast < RtlGetVersionFunction > ( <nl> + GetProcAddress ( library , \" RtlGetVersion \" ) ) ; <nl> + if ( RtlGetVersion ) { <nl> + RtlGetVersion ( & result ) ; <nl> + } <nl> + } <nl> + / / At build 17134 ( Redstone 4 ) the \" Quiet hours \" was replaced <nl> + / / by \" Focus assist \" and it looks like it doesn ' t use registry . <nl> + return ( result . dwMajorVersion = = 10 <nl> + & & result . dwMinorVersion = = 0 <nl> + & & result . dwBuildNumber < 17134 ) ; <nl> + } <nl> + <nl> / / Thanks https : / / stackoverflow . com / questions / 35600128 / get - windows - quiet - hours - from - win32 - or - c - sharp - api <nl> void queryQuietHours ( ) { <nl> - if ( QSysInfo : : windowsVersion ( ) < QSysInfo : : WV_WINDOWS10 ) { <nl> + if ( ! useQuietHoursRegistryEntry ( ) ) { <nl> / / There are quiet hours in Windows starting from Windows 8 . 1 <nl> / / But there were several reports about the notifications being shut <nl> / / down according to the registry while no quiet hours were enabled . <nl>\n", "msg": "Don ' t use registry quiet hours entry any more .\n"}
{"diff_id": 4598, "repo": "apple/swift\n", "sha": "713a2ab747db51513700fe79a88354eccc81ae4a\n", "time": "2019-04-17T21:34:45Z\n", "diff": "mmm a / lib / AST / ASTDumper . cpp <nl> ppp b / lib / AST / ASTDumper . cpp <nl> class PrintExpr : public ExprVisitor < PrintExpr > { <nl> printCommon ( E , \" keypath_expr \" ) ; <nl> if ( E - > isObjC ( ) ) <nl> OS < < \" objc \" ; <nl> + <nl> + OS < < ' \\ n ' ; <nl> + Indent + = 2 ; <nl> + OS . indent ( Indent ) ; <nl> + PrintWithColorRAII ( OS , ParenthesisColor ) < < ' ( ' ; <nl> + PrintWithColorRAII ( OS , ExprColor ) < < \" components \" ; <nl> + OS . indent ( Indent + 2 ) ; <nl> for ( unsigned i : indices ( E - > getComponents ( ) ) ) { <nl> auto & component = E - > getComponents ( ) [ i ] ; <nl> OS < < ' \\ n ' ; <nl> OS . indent ( Indent + 2 ) ; <nl> - OS < < \" ( component = \" ; <nl> + PrintWithColorRAII ( OS , ParenthesisColor ) < < ' ( ' ; <nl> switch ( component . getKind ( ) ) { <nl> case KeyPathExpr : : Component : : Kind : : Invalid : <nl> - OS < < \" invalid \" ; <nl> + PrintWithColorRAII ( OS , ASTNodeColor ) < < \" invalid \" ; <nl> break ; <nl> <nl> case KeyPathExpr : : Component : : Kind : : OptionalChain : <nl> - OS < < \" optional_chain \" ; <nl> + PrintWithColorRAII ( OS , ASTNodeColor ) < < \" optional_chain \" ; <nl> break ; <nl> <nl> case KeyPathExpr : : Component : : Kind : : OptionalForce : <nl> - OS < < \" optional_force \" ; <nl> + PrintWithColorRAII ( OS , ASTNodeColor ) < < \" optional_force \" ; <nl> break ; <nl> <nl> case KeyPathExpr : : Component : : Kind : : OptionalWrap : <nl> - OS < < \" optional_wrap \" ; <nl> + PrintWithColorRAII ( OS , ASTNodeColor ) < < \" optional_wrap \" ; <nl> break ; <nl> <nl> case KeyPathExpr : : Component : : Kind : : Property : <nl> - OS < < \" property \" ; <nl> + PrintWithColorRAII ( OS , ASTNodeColor ) < < \" property \" ; <nl> + PrintWithColorRAII ( OS , DeclColor ) < < \" decl = \" ; <nl> printDeclRef ( component . getDeclRef ( ) ) ; <nl> - OS < < \" \" ; <nl> break ; <nl> <nl> case KeyPathExpr : : Component : : Kind : : Subscript : <nl> - OS < < \" subscript \" ; <nl> + PrintWithColorRAII ( OS , ASTNodeColor ) < < \" subscript \" ; <nl> + PrintWithColorRAII ( OS , DeclColor ) < < \" decl = ' \" ; <nl> printDeclRef ( component . getDeclRef ( ) ) ; <nl> - OS < < ' \\ n ' ; <nl> - Indent + = 2 ; <nl> - printRec ( component . getIndexExpr ( ) ) ; <nl> - Indent - = 2 ; <nl> - OS . indent ( Indent + 4 ) ; <nl> + PrintWithColorRAII ( OS , DeclColor ) < < \" ' \" ; <nl> break ; <nl> <nl> case KeyPathExpr : : Component : : Kind : : UnresolvedProperty : <nl> - OS < < \" unresolved_property \" ; <nl> - component . getUnresolvedDeclName ( ) . print ( OS ) ; <nl> - OS < < \" \" ; <nl> + PrintWithColorRAII ( OS , ASTNodeColor ) < < \" unresolved_property \" ; <nl> + PrintWithColorRAII ( OS , IdentifierColor ) <nl> + < < \" decl_name = ' \" < < component . getUnresolvedDeclName ( ) < < \" ' \" ; <nl> break ; <nl> <nl> case KeyPathExpr : : Component : : Kind : : UnresolvedSubscript : <nl> - OS < < \" unresolved_subscript \" ; <nl> - OS < < ' \\ n ' ; <nl> - Indent + = 2 ; <nl> - printRec ( component . getIndexExpr ( ) ) ; <nl> - Indent - = 2 ; <nl> - OS . indent ( Indent + 4 ) ; <nl> + PrintWithColorRAII ( OS , ASTNodeColor ) < < \" unresolved_subscript \" ; <nl> + printArgumentLabels ( component . getSubscriptLabels ( ) ) ; <nl> break ; <nl> case KeyPathExpr : : Component : : Kind : : Identity : <nl> - OS < < \" identity \" ; <nl> - OS < < ' \\ n ' ; <nl> + PrintWithColorRAII ( OS , ASTNodeColor ) < < \" identity \" ; <nl> break ; <nl> + <nl> case KeyPathExpr : : Component : : Kind : : TupleElement : <nl> - OS < < \" tuple_element \" ; <nl> - OS < < \" # \" < < component . getTupleIndex ( ) ; <nl> - OS < < \" \" ; <nl> + PrintWithColorRAII ( OS , ASTNodeColor ) < < \" tuple_element \" ; <nl> + PrintWithColorRAII ( OS , DiscriminatorColor ) <nl> + < < \" # \" < < component . getTupleIndex ( ) ; <nl> break ; <nl> } <nl> - OS < < \" type = \" ; <nl> - GetTypeOfKeyPathComponent ( E , i ) . print ( OS ) ; <nl> + PrintWithColorRAII ( OS , TypeColor ) <nl> + < < \" type = ' \" < < GetTypeOfKeyPathComponent ( E , i ) < < \" ' \" ; <nl> + if ( auto indexExpr = component . getIndexExpr ( ) ) { <nl> + OS < < ' \\ n ' ; <nl> + Indent + = 2 ; <nl> + printRec ( indexExpr ) ; <nl> + Indent - = 2 ; <nl> + } <nl> PrintWithColorRAII ( OS , ParenthesisColor ) < < ' ) ' ; <nl> } <nl> + <nl> + PrintWithColorRAII ( OS , ParenthesisColor ) < < ' ) ' ; <nl> + Indent - = 2 ; <nl> + <nl> if ( auto stringLiteral = E - > getObjCStringLiteralExpr ( ) ) { <nl> OS < < ' \\ n ' ; <nl> - printRec ( stringLiteral ) ; <nl> + printRecLabeled ( stringLiteral , \" objc_string_literal \" ) ; <nl> } <nl> if ( ! E - > isObjC ( ) ) { <nl> - OS < < \" \\ n \" ; <nl> if ( auto root = E - > getParsedRoot ( ) ) { <nl> - printRec ( root ) ; <nl> - } else { <nl> - OS . indent ( Indent + 2 ) < < \" < < null > > \" ; <nl> + OS < < \" \\ n \" ; <nl> + printRecLabeled ( root , \" parsed_root \" ) ; <nl> } <nl> - OS < < \" \\ n \" ; <nl> if ( auto path = E - > getParsedPath ( ) ) { <nl> - printRec ( path ) ; <nl> - } else { <nl> - OS . indent ( Indent + 2 ) < < \" < < null > > \" ; <nl> + OS < < \" \\ n \" ; <nl> + printRecLabeled ( path , \" parsed_path \" ) ; <nl> } <nl> } <nl> PrintWithColorRAII ( OS , ParenthesisColor ) < < ' ) ' ; <nl>\n", "msg": "Reformat and colorize KeyPathExpr AST dumps\n"}
{"diff_id": 4759, "msg": "SERVER - 8819 Framework for testing round trip and test roundtrip of DBRef and DBPointer\n", "msgGPT": "refactor db ref test class for better readability and maintainability.", "METEOR Score": "38.97926131290843", "BLEU Score": "0.2549646849673374", "ROUGE-L Score": "0.23999999520000007", "score": 1, "repo": "mongodb/mongo\n", "sha": "211191443212b35e71a41ea4a5c669f4de3c5a2e\n", "time": "2013-03-11T21:00:52Z\n", "diff": "mmm a / src / mongo / dbtests / jstests . cpp <nl> ppp b / src / mongo / dbtests / jstests . cpp <nl> namespace JSTests { <nl> } <nl> } ; <nl> <nl> - class DBRefTest { <nl> - public : <nl> - DBRefTest ( ) { <nl> - _a = \" unittest . dbref . a \" ; <nl> - _b = \" unittest . dbref . b \" ; <nl> - reset ( ) ; <nl> - } <nl> - ~ DBRefTest ( ) { <nl> - / / reset ( ) ; <nl> - } <nl> + namespace RoundTripTests { <nl> <nl> - void run ( ) { <nl> + / / Inherit from this class to test round tripping of JSON objects <nl> + class TestRoundTrip { <nl> + public : <nl> + virtual ~ TestRoundTrip ( ) { } <nl> + void run ( ) { <nl> <nl> - client . insert ( _a , BSON ( \" a \" < < \" 17 \" ) ) ; <nl> + / / Insert in Javascript - > Find using DBDirectClient <nl> <nl> - { <nl> - BSONObj fromA = client . findOne ( _a , BSONObj ( ) ) ; <nl> - verify ( fromA . valid ( ) ) ; <nl> - / / cout < < \" Froma : \" < < fromA < < endl ; <nl> + / / Drop the collection <nl> + client . dropCollection ( \" unittest . testroundtrip \" ) ; <nl> + <nl> + / / Insert in Javascript <nl> + stringstream jsInsert ; <nl> + jsInsert < < \" db . testroundtrip . insert ( \" < < jsonIn ( ) < < \" ) \" ; <nl> + ASSERT_TRUE ( client . eval ( \" unittest \" , jsInsert . str ( ) ) ) ; <nl> + <nl> + / / Find using DBDirectClient <nl> + BSONObj excludeIdProjection = BSON ( \" _id \" < < 0 ) ; <nl> + BSONObj directFind = client . findOne ( \" unittest . testroundtrip \" , <nl> + \" \" , <nl> + & excludeIdProjection ) ; <nl> + bsonEquals ( bson ( ) , directFind ) ; <nl> + <nl> + <nl> + / / Insert using DBDirectClient - > Find in Javascript <nl> + <nl> + / / Drop the collection <nl> + client . dropCollection ( \" unittest . testroundtrip \" ) ; <nl> + <nl> + / / Insert using DBDirectClient <nl> + client . insert ( \" unittest . testroundtrip \" , bson ( ) ) ; <nl> + <nl> + / / Find in Javascript <nl> + stringstream jsFind ; <nl> + jsFind < < \" dbref = db . testroundtrip . findOne ( { } , { _id : 0 } ) \\ n \" <nl> + < < \" assert . eq ( dbref , \" < < jsonOut ( ) < < \" ) \" ; <nl> + ASSERT_TRUE ( client . eval ( \" unittest \" , jsFind . str ( ) ) ) ; <nl> + } <nl> + protected : <nl> + <nl> + / / Methods that must be defined by child classes <nl> + virtual BSONObj bson ( ) const = 0 ; <nl> + virtual string json ( ) const = 0 ; <nl> + <nl> + / / This can be overriden if a different meaning of equality besides woCompare is needed <nl> + virtual void bsonEquals ( const BSONObj & expected , const BSONObj & actual ) { <nl> + if ( expected . woCompare ( actual ) ) { <nl> + out ( ) < < \" want : \" < < expected . jsonString ( ) < < \" size : \" < < expected . objsize ( ) < < endl ; <nl> + out ( ) < < \" got : \" < < actual . jsonString ( ) < < \" size : \" < < actual . objsize ( ) < < endl ; <nl> + out ( ) < < expected . hexDump ( ) < < endl ; <nl> + out ( ) < < actual . hexDump ( ) < < endl ; <nl> + } <nl> + ASSERT ( ! expected . woCompare ( actual ) ) ; <nl> + } <nl> + <nl> + / / This can be overriden if the JSON representation is altered on the round trip <nl> + virtual string jsonIn ( ) const { <nl> + return json ( ) ; <nl> + } <nl> + virtual string jsonOut ( ) const { <nl> + return json ( ) ; <nl> + } <nl> + } ; <nl> + <nl> + class DBRefTest : public TestRoundTrip { <nl> + virtual BSONObj bson ( ) const { <nl> BSONObjBuilder b ; <nl> - b . append ( \" b \" , 18 ) ; <nl> - b . appendDBRef ( \" c \" , \" dbref . a \" , fromA [ \" _id \" ] . __oid ( ) ) ; <nl> - client . insert ( _b , b . obj ( ) ) ; <nl> + OID o ; <nl> + memset ( & o , 0 , 12 ) ; <nl> + BSONObjBuilder subBuilder ( b . subobjStart ( \" a \" ) ) ; <nl> + subBuilder . append ( \" $ ref \" , \" ns \" ) ; <nl> + subBuilder . append ( \" $ id \" , o ) ; <nl> + subBuilder . done ( ) ; <nl> + return b . obj ( ) ; <nl> + } <nl> + virtual string json ( ) const { <nl> + return \" { \\ \" a \\ \" : DBRef ( \\ \" ns \\ \" , ObjectId ( \\ \" 000000000000000000000000 \\ \" ) ) } \" ; <nl> } <nl> <nl> - ASSERT ( client . eval ( \" unittest \" , \" x = db . dbref . b . findOne ( ) ; assert . eq ( 17 , x . c . fetch ( ) . a , ' ref working ' ) ; \" ) ) ; <nl> + / / A \" fetch \" function is added to the DBRef object when it is inserted using the <nl> + / / constructor , so we need to compare the fields individually <nl> + virtual void bsonEquals ( const BSONObj & expected , const BSONObj & actual ) { <nl> + ASSERT_EQUALS ( expected [ \" a \" ] . type ( ) , actual [ \" a \" ] . type ( ) ) ; <nl> + ASSERT_EQUALS ( expected [ \" a \" ] [ \" $ id \" ] . OID ( ) , actual [ \" a \" ] [ \" $ id \" ] . OID ( ) ) ; <nl> + ASSERT_EQUALS ( expected [ \" a \" ] [ \" $ ref \" ] . String ( ) , actual [ \" a \" ] [ \" $ ref \" ] . String ( ) ) ; <nl> + } <nl> + } ; <nl> <nl> - / / BSON DBRef < = > JS DBPointer <nl> - ASSERT ( client . eval ( \" unittest \" , \" x = db . dbref . b . findOne ( ) ; db . dbref . b . drop ( ) ; x . c = new DBPointer ( x . c . ns , x . c . id ) ; db . dbref . b . insert ( x ) ; \" ) ) ; <nl> - ASSERT_EQUALS ( DBRef , client . findOne ( \" unittest . dbref . b \" , \" \" ) [ \" c \" ] . type ( ) ) ; <nl> + class DBPointerTest : public TestRoundTrip { <nl> + virtual BSONObj bson ( ) const { <nl> + BSONObjBuilder b ; <nl> + OID o ; <nl> + memset ( & o , 0 , 12 ) ; <nl> + b . appendDBRef ( \" a \" , \" ns \" , o ) ; <nl> + return b . obj ( ) ; <nl> + } <nl> + virtual string json ( ) const { <nl> + return \" { \\ \" a \\ \" : DBPointer ( \\ \" ns \\ \" , ObjectId ( \\ \" 000000000000000000000000 \\ \" ) ) } \" ; <nl> + } <nl> + } ; <nl> <nl> - / / BSON Object < = > JS DBRef <nl> - ASSERT ( client . eval ( \" unittest \" , \" x = db . dbref . b . findOne ( ) ; db . dbref . b . drop ( ) ; x . c = new DBRef ( x . c . ns , x . c . id ) ; db . dbref . b . insert ( x ) ; \" ) ) ; <nl> - ASSERT_EQUALS ( Object , client . findOne ( \" unittest . dbref . b \" , \" \" ) [ \" c \" ] . type ( ) ) ; <nl> - ASSERT_EQUALS ( string ( \" dbref . a \" ) , client . findOne ( \" unittest . dbref . b \" , \" \" ) [ \" c \" ] . embeddedObject ( ) . getStringField ( \" $ ref \" ) ) ; <nl> - } <nl> + class InformalDBRefTest : public TestRoundTrip { <nl> + virtual BSONObj bson ( ) const { <nl> + BSONObjBuilder b ; <nl> + OID o ; <nl> + memset ( & o , 0 , 12 ) ; <nl> + BSONObjBuilder subBuilder ( b . subobjStart ( \" a \" ) ) ; <nl> + subBuilder . append ( \" $ ref \" , \" ns \" ) ; <nl> + subBuilder . append ( \" $ id \" , o ) ; <nl> + subBuilder . done ( ) ; <nl> + return b . obj ( ) ; <nl> + } <nl> <nl> - void reset ( ) { <nl> - client . dropCollection ( _a ) ; <nl> - client . dropCollection ( _b ) ; <nl> - } <nl> + / / Don ' t need to return anything because we are overriding both jsonOut and jsonIn <nl> + virtual string json ( ) const { return \" \" ; } <nl> <nl> - const char * _a ; <nl> - const char * _b ; <nl> - } ; <nl> + / / Need to override these because the JSON doesn ' t actually round trip . <nl> + / / An object with \" $ ref \" and \" $ id \" fields is handled specially and different on the way out . <nl> + virtual string jsonOut ( ) const { <nl> + return \" { \\ \" a \\ \" : DBRef ( \\ \" ns \\ \" , ObjectId ( \\ \" 000000000000000000000000 \\ \" ) ) } \" ; <nl> + } <nl> + virtual string jsonIn ( ) const { <nl> + stringstream ss ; <nl> + ss < < \" { \\ \" a \\ \" : { \\ \" $ ref \\ \" : \\ \" ns \\ \" , \" < < <nl> + \" \\ \" $ id \\ \" : ObjectId ( \\ \" 000000000000000000000000 \\ \" ) } } \" ; <nl> + return ss . str ( ) ; <nl> + } <nl> + } ; <nl> <nl> - class InformalDBRef { <nl> - public : <nl> - void run ( ) { <nl> - client . insert ( ns ( ) , BSON ( \" i \" < < 1 ) ) ; <nl> - BSONObj obj = client . findOne ( ns ( ) , BSONObj ( ) ) ; <nl> - client . remove ( ns ( ) , BSONObj ( ) ) ; <nl> - client . insert ( ns ( ) , BSON ( \" r \" < < BSON ( \" $ ref \" < < \" jstests . informaldbref \" < < \" $ id \" < < obj [ \" _id \" ] . __oid ( ) < < \" foo \" < < \" bar \" ) ) ) ; <nl> - obj = client . findOne ( ns ( ) , BSONObj ( ) ) ; <nl> - ASSERT_EQUALS ( \" bar \" , obj [ \" r \" ] . embeddedObject ( ) [ \" foo \" ] . str ( ) ) ; <nl> - <nl> - ASSERT ( client . eval ( \" unittest \" , \" x = db . jstests . informaldbref . findOne ( ) ; y = { r : x . r } ; db . jstests . informaldbref . drop ( ) ; y . r [ \\ \" a \\ \" ] = \\ \" b \\ \" ; db . jstests . informaldbref . save ( y ) ; \" ) ) ; <nl> - obj = client . findOne ( ns ( ) , BSONObj ( ) ) ; <nl> - ASSERT_EQUALS ( \" bar \" , obj [ \" r \" ] . embeddedObject ( ) [ \" foo \" ] . str ( ) ) ; <nl> - ASSERT_EQUALS ( \" b \" , obj [ \" r \" ] . embeddedObject ( ) [ \" a \" ] . str ( ) ) ; <nl> - } <nl> - private : <nl> - static const char * ns ( ) { return \" unittest . jstests . informaldbref \" ; } <nl> - } ; <nl> + class InformalDBRefExtraFieldTest : public TestRoundTrip { <nl> + virtual BSONObj bson ( ) const { <nl> + BSONObjBuilder b ; <nl> + OID o ; <nl> + memset ( & o , 0 , 12 ) ; <nl> + BSONObjBuilder subBuilder ( b . subobjStart ( \" a \" ) ) ; <nl> + subBuilder . append ( \" $ ref \" , \" ns \" ) ; <nl> + subBuilder . append ( \" $ id \" , o ) ; <nl> + subBuilder . append ( \" otherfield \" , \" value \" ) ; <nl> + subBuilder . done ( ) ; <nl> + return b . obj ( ) ; <nl> + } <nl> + <nl> + / / Don ' t need to return anything because we are overriding both jsonOut and jsonIn <nl> + virtual string json ( ) const { return \" \" ; } <nl> + <nl> + / / Need to override these because the JSON doesn ' t actually round trip . <nl> + / / An object with \" $ ref \" and \" $ id \" fields is handled specially and different on the way out . <nl> + virtual string jsonOut ( ) const { <nl> + return \" { \\ \" a \\ \" : DBRef ( \\ \" ns \\ \" , ObjectId ( \\ \" 000000000000000000000000 \\ \" ) ) } \" ; <nl> + } <nl> + virtual string jsonIn ( ) const { <nl> + stringstream ss ; <nl> + ss < < \" { \\ \" a \\ \" : { \\ \" $ ref \\ \" : \\ \" ns \\ \" , \" < < <nl> + \" \\ \" $ id \\ \" : ObjectId ( \\ \" 000000000000000000000000 \\ \" ) , \" < < <nl> + \" \\ \" otherfield \\ \" : \\ \" value \\ \" } } \" ; <nl> + return ss . str ( ) ; <nl> + } <nl> + } ; <nl> + <nl> + } / / namespace RoundTripTests <nl> <nl> class BinDataType { <nl> public : <nl> namespace JSTests { <nl> <nl> add < WeirdObjects > ( ) ; <nl> add < CodeTests > ( ) ; <nl> - add < DBRefTest > ( ) ; <nl> - add < InformalDBRef > ( ) ; <nl> add < BinDataType > ( ) ; <nl> <nl> add < VarTests > ( ) ; <nl> namespace JSTests { <nl> <nl> add < ScopeOut > ( ) ; <nl> add < InvalidStoredJS > ( ) ; <nl> + <nl> + add < RoundTripTests : : DBRefTest > ( ) ; <nl> + add < RoundTripTests : : DBPointerTest > ( ) ; <nl> + add < RoundTripTests : : InformalDBRefTest > ( ) ; <nl> + add < RoundTripTests : : InformalDBRefExtraFieldTest > ( ) ; <nl> } <nl> } myall ; <nl> <nl>\n"}
{"diff_id": 4859, "repo": "apple/foundationdb\n", "sha": "6235d087a6f28ce46d25c7e016ddd96a12acb379\n", "time": "2020-11-16T20:46:21Z\n", "diff": "mmm a / fdbserver / DataDistributionTracker . actor . cpp <nl> ppp b / fdbserver / DataDistributionTracker . actor . cpp <nl> struct DataDistributionTracker { <nl> / / be accessed <nl> bool const & trackerCancelled ; <nl> <nl> + / / This class extracts the trackerCancelled reference from a DataDistributionTracker object <nl> + / / Because some actors spawned by the dataDistributionTracker outlive the DataDistributionTracker <nl> + / / object , we must guard against memory errors by using a GetTracker functor to access <nl> + / / the DataDistributionTracker object . <nl> + class SafeAccessor { <nl> + bool const & trackerCancelled ; <nl> + DataDistributionTracker & tracker ; <nl> + <nl> + public : <nl> + SafeAccessor ( DataDistributionTracker * tracker ) <nl> + : trackerCancelled ( tracker - > trackerCancelled ) , tracker ( * tracker ) { <nl> + ASSERT ( ! trackerCancelled ) ; <nl> + } <nl> + <nl> + DataDistributionTracker * operator ( ) ( ) { <nl> + if ( trackerCancelled ) { <nl> + throw dd_tracker_cancelled ( ) ; <nl> + } <nl> + return & tracker ; <nl> + } <nl> + } ; <nl> + <nl> DataDistributionTracker ( Database cx , UID distributorId , Promise < Void > const & readyToStart , <nl> PromiseStream < RelocateShard > const & output , <nl> Reference < ShardsAffectedByTeamFailure > shardsAffectedByTeamFailure , <nl> int64_t getMaxShardSize ( double dbSizeEstimate ) { <nl> ( int64_t ) SERVER_KNOBS - > MAX_SHARD_BYTES ) ; <nl> } <nl> <nl> - / / This class extracts the trackerCancelled reference from a DataDistributionTracker object <nl> - / / Because some actors spawned by the dataDistributionTracker outlive the DataDistributionTracker <nl> - / / object , we must guard against memory errors by using a GetTracker functor to access <nl> - / / the DataDistributionTracker object . <nl> - / / <nl> - / / Ideally this would be implemented with a lambda instead , but the actor compiler does not do <nl> - / / type deduction . <nl> - class GetTracker { <nl> - bool const & trackerCancelled ; <nl> - DataDistributionTracker & tracker ; <nl> - <nl> - public : <nl> - GetTracker ( DataDistributionTracker * tracker ) : trackerCancelled ( tracker - > trackerCancelled ) , tracker ( * tracker ) { <nl> - ASSERT ( ! trackerCancelled ) ; <nl> - } <nl> - <nl> - DataDistributionTracker * operator ( ) ( ) { <nl> - if ( trackerCancelled ) { <nl> - throw dd_tracker_cancelled ( ) ; <nl> - } <nl> - return & tracker ; <nl> - } <nl> - } ; <nl> - <nl> - ACTOR Future < Void > trackShardBytes ( <nl> - DataDistributionTracker * self , <nl> - KeyRange keys , <nl> - Reference < AsyncVar < Optional < ShardMetrics > > > shardSize ) <nl> - { <nl> - state GetTracker getSelf ( self ) ; <nl> + ACTOR Future < Void > trackShardBytes ( DataDistributionTracker : : SafeAccessor self , KeyRange keys , <nl> + Reference < AsyncVar < Optional < ShardMetrics > > > shardSize ) { <nl> state BandwidthStatus bandwidthStatus = shardSize - > get ( ) . present ( ) ? getBandwidthStatus ( shardSize - > get ( ) . get ( ) . metrics ) : BandwidthStatusNormal ; <nl> state double lastLowBandwidthStartTime = shardSize - > get ( ) . present ( ) ? shardSize - > get ( ) . get ( ) . lastLowBandwidthStartTime : now ( ) ; <nl> state int shardCount = shardSize - > get ( ) . present ( ) ? shardSize - > get ( ) . get ( ) . shardCount : 1 ; <nl> ACTOR Future < Void > trackShardBytes ( <nl> bounds . permittedError . iosPerKSecond = bounds . permittedError . infinity ; <nl> <nl> loop { <nl> - Transaction tr ( getSelf ( ) - > cx ) ; <nl> + Transaction tr ( self ( ) - > cx ) ; <nl> / / metrics . second is the number of key - ranges ( i . e . , shards ) in the ' keys ' key - range <nl> std : : pair < Optional < StorageMetrics > , int > metrics = wait ( tr . waitStorageMetrics ( keys , bounds . min , bounds . max , bounds . permittedError , CLIENT_KNOBS - > STORAGE_METRICS_SHARD_LIMIT , shardCount ) ) ; <nl> if ( metrics . first . present ( ) ) { <nl> ACTOR Future < Void > trackShardBytes ( <nl> . detail ( \" TrackerID \" , trackerID ) ; * / <nl> <nl> if ( shardSize - > get ( ) . present ( ) ) { <nl> - getSelf ( ) - > dbSizeEstimate - > set ( getSelf ( ) - > dbSizeEstimate - > get ( ) + metrics . first . get ( ) . bytes - <nl> - shardSize - > get ( ) . get ( ) . metrics . bytes ) ; <nl> + self ( ) - > dbSizeEstimate - > set ( self ( ) - > dbSizeEstimate - > get ( ) + metrics . first . get ( ) . bytes - <nl> + shardSize - > get ( ) . get ( ) . metrics . bytes ) ; <nl> if ( keys . begin > = systemKeys . begin ) { <nl> - getSelf ( ) - > systemSizeEstimate + = <nl> + self ( ) - > systemSizeEstimate + = <nl> metrics . first . get ( ) . bytes - shardSize - > get ( ) . get ( ) . metrics . bytes ; <nl> } <nl> } <nl> ACTOR Future < Void > trackShardBytes ( <nl> } catch ( Error & e ) { <nl> if ( e . code ( ) ! = error_code_actor_cancelled & & e . code ( ) ! = error_code_broken_promise & & <nl> e . code ( ) ! = error_code_dd_tracker_cancelled ) { <nl> - getSelf ( ) - > output . sendError ( e ) ; / / Propagate failure to dataDistributionTracker <nl> + self ( ) - > output . sendError ( e ) ; / / Propagate failure to dataDistributionTracker <nl> } <nl> throw e ; <nl> } <nl> ACTOR Future < Void > shardEvaluator ( <nl> return Void ( ) ; <nl> } <nl> <nl> - ACTOR Future < Void > shardTracker ( DataDistributionTracker * self , KeyRange keys , <nl> + ACTOR Future < Void > shardTracker ( DataDistributionTracker : : SafeAccessor self , KeyRange keys , <nl> Reference < AsyncVar < Optional < ShardMetrics > > > shardSize ) { <nl> - state GetTracker getSelf ( self ) ; <nl> - wait ( yieldedFuture ( self - > readyToStart . getFuture ( ) ) ) ; <nl> + wait ( yieldedFuture ( self ( ) - > readyToStart . getFuture ( ) ) ) ; <nl> <nl> if ( ! shardSize - > get ( ) . present ( ) ) <nl> wait ( shardSize - > onChange ( ) ) ; <nl> <nl> - if ( ! getSelf ( ) - > maxShardSize - > get ( ) . present ( ) ) wait ( yieldedFuture ( getSelf ( ) - > maxShardSize - > onChange ( ) ) ) ; <nl> + if ( ! self ( ) - > maxShardSize - > get ( ) . present ( ) ) wait ( yieldedFuture ( self ( ) - > maxShardSize - > onChange ( ) ) ) ; <nl> <nl> / / Since maxShardSize will become present for all shards at once , avoid slow tasks with a short delay <nl> wait ( delay ( 0 , TaskPriority : : DataDistribution ) ) ; <nl> ACTOR Future < Void > shardTracker ( DataDistributionTracker * self , KeyRange keys , <nl> / / Survives multiple calls to shardEvaluator and keeps merges from happening too quickly . <nl> state Reference < HasBeenTrueFor > wantsToMerge ( new HasBeenTrueFor ( shardSize - > get ( ) ) ) ; <nl> <nl> - / * TraceEvent ( \" ShardTracker \" , getSelf ( ) - > distributorId ) <nl> + / * TraceEvent ( \" ShardTracker \" , self ( ) - > distributorId ) <nl> . detail ( \" Begin \" , keys . begin ) <nl> . detail ( \" End \" , keys . end ) <nl> . detail ( \" TrackerID \" , trackerID ) <nl> - . detail ( \" MaxBytes \" , getSelf ( ) - > maxShardSize - > get ( ) . get ( ) ) <nl> + . detail ( \" MaxBytes \" , self ( ) - > maxShardSize - > get ( ) . get ( ) ) <nl> . detail ( \" ShardSize \" , shardSize - > get ( ) . get ( ) . bytes ) <nl> . detail ( \" BytesPerKSec \" , shardSize - > get ( ) . get ( ) . bytesPerKSecond ) ; * / <nl> <nl> try { <nl> loop { <nl> / / Use the current known size to check for ( and start ) splits and merges . <nl> - wait ( shardEvaluator ( getSelf ( ) , keys , shardSize , wantsToMerge ) ) ; <nl> + wait ( shardEvaluator ( self ( ) , keys , shardSize , wantsToMerge ) ) ; <nl> <nl> / / We could have a lot of actors being released from the previous wait at the same time . Immediately calling <nl> / / delay ( 0 ) mitigates the resulting SlowTask <nl> ACTOR Future < Void > shardTracker ( DataDistributionTracker * self , KeyRange keys , <nl> / / If e is broken_promise then self may have already been deleted <nl> if ( e . code ( ) ! = error_code_actor_cancelled & & e . code ( ) ! = error_code_broken_promise & & <nl> e . code ( ) ! = error_code_dd_tracker_cancelled ) { <nl> - getSelf ( ) - > output . sendError ( e ) ; / / Propagate failure to dataDistributionTracker <nl> + self ( ) - > output . sendError ( e ) ; / / Propagate failure to dataDistributionTracker <nl> } <nl> throw e ; <nl> } <nl> void restartShardTrackers ( DataDistributionTracker * self , KeyRangeRef keys , Optio <nl> <nl> ShardTrackedData data ; <nl> data . stats = shardSize ; <nl> - data . trackShard = shardTracker ( self , ranges [ i ] , shardSize ) ; <nl> - data . trackBytes = trackShardBytes ( self , ranges [ i ] , shardSize ) ; <nl> + data . trackShard = shardTracker ( DataDistributionTracker : : SafeAccessor ( self ) , ranges [ i ] , shardSize ) ; <nl> + data . trackBytes = trackShardBytes ( DataDistributionTracker : : SafeAccessor ( self ) , ranges [ i ] , shardSize ) ; <nl> self - > shards . insert ( ranges [ i ] , data ) ; <nl> } <nl> } <nl>\n", "msg": "Prevent shardTracker or trackShardBytes from accidentally unsafely accessing DataDistributionTracker\n"}
{"diff_id": 4883, "repo": "xbmc/xbmc\n", "sha": "a3ba58c09e7b4292bc7ef079971de953281df34b\n", "time": "2011-08-02T04:25:32Z\n", "diff": "mmm a / xbmc / GUIInfoManager . cpp <nl> ppp b / xbmc / GUIInfoManager . cpp <nl> infomap fanart_labels [ ] = { { \" color1 \" , FANART_COLOR1 } , <nl> infomap skin_labels [ ] = { { \" currenttheme \" , SKIN_THEME } , <nl> { \" currentcolourtheme \" , SKIN_COLOUR_THEME } } ; <nl> <nl> + infomap window_bools [ ] = { { \" ismedia \" , WINDOW_IS_MEDIA } , <nl> + { \" isactive \" , WINDOW_IS_ACTIVE } , <nl> + { \" istopmost \" , WINDOW_IS_TOPMOST } , <nl> + { \" isvisible \" , WINDOW_IS_VISIBLE } , <nl> + { \" previous \" , WINDOW_PREVIOUS } , <nl> + { \" next \" , WINDOW_NEXT } } ; <nl> + <nl> + infomap control_labels [ ] = { { \" hasfocus \" , CONTROL_HAS_FOCUS } , <nl> + { \" isvisible \" , CONTROL_IS_VISIBLE } , <nl> + { \" isenabled \" , CONTROL_IS_ENABLED } , <nl> + { \" getlabel \" , CONTROL_GET_LABEL } } ; <nl> + <nl> void CGUIInfoManager : : SplitInfoString ( const CStdString & infoString , vector < pair < CStdString , CStdString > > & info ) <nl> { <nl> / / our string is of the form : <nl> int CGUIInfoManager : : TranslateSingleString ( const CStdString & strCondition ) <nl> else if ( property = = \" hastheme \" ) <nl> return AddMultiInfo ( GUIInfo ( SKIN_HAS_THEME , ConditionalStringParameter ( info [ 1 ] . second ) ) ) ; <nl> } <nl> + else if ( category = = \" window \" ) <nl> + { <nl> + if ( property = = \" property \" ) <nl> + { / / TODO : this doesn ' t support foo . xml <nl> + int winID = 0 ; <nl> + if ( ! info [ 0 ] . second . IsEmpty ( ) ) <nl> + winID = CButtonTranslator : : TranslateWindow ( info [ 0 ] . second ) ; <nl> + if ( winID ! = WINDOW_INVALID ) <nl> + return AddMultiInfo ( GUIInfo ( WINDOW_PROPERTY , winID , ConditionalStringParameter ( info [ 1 ] . second ) ) ) ; <nl> + } <nl> + for ( size_t i = 0 ; i < sizeof ( window_bools ) / sizeof ( infomap ) ; i + + ) <nl> + { <nl> + if ( property = = window_bools [ i ] . str ) <nl> + { / / TODO : The parameter for these should really be on the first not the second property <nl> + if ( info [ 1 ] . second . Find ( \" xml \" ) > = 0 ) <nl> + return AddMultiInfo ( GUIInfo ( window_bools [ i ] . val , 0 , ConditionalStringParameter ( info [ 1 ] . second ) ) ) ; <nl> + int winID = CButtonTranslator : : TranslateWindow ( info [ 1 ] . second ) ; <nl> + if ( winID ! = WINDOW_INVALID ) <nl> + return AddMultiInfo ( GUIInfo ( window_bools [ i ] . val , winID , 0 ) ) ; <nl> + return 0 ; <nl> + } <nl> + } <nl> + } <nl> + else if ( category = = \" control \" ) <nl> + { <nl> + for ( size_t i = 0 ; i < sizeof ( control_labels ) / sizeof ( infomap ) ; i + + ) <nl> + { <nl> + if ( property = = control_labels [ i ] . str ) <nl> + { / / TODO : The parameter for these should really be on the first not the second property <nl> + int controlID = atoi ( info [ 1 ] . second . c_str ( ) ) ; <nl> + if ( controlID ) <nl> + return AddMultiInfo ( GUIInfo ( control_labels [ i ] . val , controlID , 0 ) ) ; <nl> + return 0 ; <nl> + } <nl> + } <nl> + } <nl> + else if ( category = = \" controlgroup \" & & property = = \" hasfocus \" ) <nl> + { <nl> + int groupID = atoi ( info [ 0 ] . second . c_str ( ) ) ; <nl> + if ( groupID ) <nl> + return AddMultiInfo ( GUIInfo ( CONTROL_GROUP_HAS_FOCUS , groupID , atoi ( info [ 1 ] . second . c_str ( ) ) ) ) ; <nl> + } <nl> } <nl> else if ( info . size ( ) = = 3 ) <nl> { <nl> int CGUIInfoManager : : TranslateSingleString ( const CStdString & strCondition ) <nl> else if ( strTest . Equals ( \" playlist . isrepeat \" ) ) ret = PLAYLIST_ISREPEAT ; <nl> else if ( strTest . Equals ( \" playlist . isrepeatone \" ) ) ret = PLAYLIST_ISREPEATONE ; <nl> } <nl> - else if ( strCategory . Left ( 6 ) . Equals ( \" window \" ) ) <nl> - { <nl> - CStdString info = strTest . Mid ( strCategory . GetLength ( ) + 1 ) ; <nl> - / / special case for window . xml parameter , fails above <nl> - if ( info . Left ( 5 ) . Equals ( \" xml ) . \" ) ) <nl> - info = info . Mid ( 5 , info . GetLength ( ) + 1 ) ; <nl> - if ( info . Left ( 9 ) . Equals ( \" property ( \" ) ) <nl> - { <nl> - int winID = 0 ; <nl> - if ( strTest . Left ( 7 ) . Equals ( \" window ( \" ) ) <nl> - { <nl> - CStdString window ( strTest . Mid ( 7 , strTest . Find ( \" ) \" , 7 ) - 7 ) . ToLower ( ) ) ; <nl> - winID = CButtonTranslator : : TranslateWindow ( window ) ; <nl> - } <nl> - if ( winID ! = WINDOW_INVALID ) <nl> - { <nl> - int compareString = ConditionalStringParameter ( info . Mid ( 9 , info . GetLength ( ) - 10 ) ) ; <nl> - return AddMultiInfo ( GUIInfo ( WINDOW_PROPERTY , winID , compareString ) ) ; <nl> - } <nl> - } <nl> - else if ( info . Left ( 9 ) . Equals ( \" isactive ( \" ) ) <nl> - { <nl> - CStdString window ( strTest . Mid ( 16 , strTest . GetLength ( ) - 17 ) . ToLower ( ) ) ; <nl> - if ( window . Find ( \" xml \" ) > = 0 ) <nl> - return AddMultiInfo ( GUIInfo ( WINDOW_IS_ACTIVE , 0 , ConditionalStringParameter ( window ) ) ) ; <nl> - int winID = CButtonTranslator : : TranslateWindow ( window ) ; <nl> - if ( winID ! = WINDOW_INVALID ) <nl> - return AddMultiInfo ( GUIInfo ( WINDOW_IS_ACTIVE , winID , 0 ) ) ; <nl> - } <nl> - else if ( info . Left ( 7 ) . Equals ( \" ismedia \" ) ) return WINDOW_IS_MEDIA ; <nl> - else if ( info . Left ( 10 ) . Equals ( \" istopmost ( \" ) ) <nl> - { <nl> - CStdString window ( strTest . Mid ( 17 , strTest . GetLength ( ) - 18 ) . ToLower ( ) ) ; <nl> - if ( window . Find ( \" xml \" ) > = 0 ) <nl> - return AddMultiInfo ( GUIInfo ( WINDOW_IS_TOPMOST , 0 , ConditionalStringParameter ( window ) ) ) ; <nl> - int winID = CButtonTranslator : : TranslateWindow ( window ) ; <nl> - if ( winID ! = WINDOW_INVALID ) <nl> - return AddMultiInfo ( GUIInfo ( WINDOW_IS_TOPMOST , winID , 0 ) ) ; <nl> - } <nl> - else if ( info . Left ( 10 ) . Equals ( \" isvisible ( \" ) ) <nl> - { <nl> - CStdString window ( strTest . Mid ( 17 , strTest . GetLength ( ) - 18 ) . ToLower ( ) ) ; <nl> - if ( window . Find ( \" xml \" ) > = 0 ) <nl> - return AddMultiInfo ( GUIInfo ( WINDOW_IS_VISIBLE , 0 , ConditionalStringParameter ( window ) ) ) ; <nl> - int winID = CButtonTranslator : : TranslateWindow ( window ) ; <nl> - if ( winID ! = WINDOW_INVALID ) <nl> - return AddMultiInfo ( GUIInfo ( WINDOW_IS_VISIBLE , winID , 0 ) ) ; <nl> - } <nl> - else if ( info . Left ( 9 ) . Equals ( \" previous ( \" ) ) <nl> - { <nl> - CStdString window ( strTest . Mid ( 16 , strTest . GetLength ( ) - 17 ) . ToLower ( ) ) ; <nl> - if ( window . Find ( \" xml \" ) > = 0 ) <nl> - return AddMultiInfo ( GUIInfo ( WINDOW_PREVIOUS , 0 , ConditionalStringParameter ( window ) ) ) ; <nl> - int winID = CButtonTranslator : : TranslateWindow ( window ) ; <nl> - if ( winID ! = WINDOW_INVALID ) <nl> - return AddMultiInfo ( GUIInfo ( WINDOW_PREVIOUS , winID , 0 ) ) ; <nl> - } <nl> - else if ( info . Left ( 5 ) . Equals ( \" next ( \" ) ) <nl> - { <nl> - CStdString window ( strTest . Mid ( 12 , strTest . GetLength ( ) - 13 ) . ToLower ( ) ) ; <nl> - if ( window . Find ( \" xml \" ) > = 0 ) <nl> - return AddMultiInfo ( GUIInfo ( WINDOW_NEXT , 0 , ConditionalStringParameter ( window ) ) ) ; <nl> - int winID = CButtonTranslator : : TranslateWindow ( window ) ; <nl> - if ( winID ! = WINDOW_INVALID ) <nl> - return AddMultiInfo ( GUIInfo ( WINDOW_NEXT , winID , 0 ) ) ; <nl> - } <nl> - } <nl> - else if ( strTest . Left ( 17 ) . Equals ( \" control . hasfocus ( \" ) ) <nl> - { <nl> - int controlID = atoi ( strTest . Mid ( 17 , strTest . GetLength ( ) - 18 ) . c_str ( ) ) ; <nl> - if ( controlID ) <nl> - return AddMultiInfo ( GUIInfo ( CONTROL_HAS_FOCUS , controlID , 0 ) ) ; <nl> - } <nl> - else if ( strTest . Left ( 18 ) . Equals ( \" control . isvisible ( \" ) ) <nl> - { <nl> - int controlID = atoi ( strTest . Mid ( 18 , strTest . GetLength ( ) - 19 ) . c_str ( ) ) ; <nl> - if ( controlID ) <nl> - return AddMultiInfo ( GUIInfo ( CONTROL_IS_VISIBLE , controlID , 0 ) ) ; <nl> - } <nl> - else if ( strTest . Left ( 18 ) . Equals ( \" control . isenabled ( \" ) ) <nl> - { <nl> - int controlID = atoi ( strTest . Mid ( 18 , strTest . GetLength ( ) - 19 ) . c_str ( ) ) ; <nl> - if ( controlID ) <nl> - return AddMultiInfo ( GUIInfo ( CONTROL_IS_ENABLED , controlID , 0 ) ) ; <nl> - } <nl> - else if ( strTest . Left ( 17 ) . Equals ( \" control . getlabel ( \" ) ) <nl> - { <nl> - int controlID = atoi ( strTest . Mid ( 17 , strTest . GetLength ( ) - 18 ) . c_str ( ) ) ; <nl> - if ( controlID ) <nl> - return AddMultiInfo ( GUIInfo ( CONTROL_GET_LABEL , controlID , 0 ) ) ; <nl> - } <nl> - else if ( strTest . Left ( 13 ) . Equals ( \" controlgroup ( \" ) ) <nl> - { <nl> - int groupID = atoi ( strTest . Mid ( 13 ) . c_str ( ) ) ; <nl> - int controlID = 0 ; <nl> - int controlPos = strTest . Find ( \" . hasfocus ( \" ) ; <nl> - if ( controlPos > 0 ) <nl> - controlID = atoi ( strTest . Mid ( controlPos + 10 ) . c_str ( ) ) ; <nl> - if ( groupID ) <nl> - { <nl> - return AddMultiInfo ( GUIInfo ( CONTROL_GROUP_HAS_FOCUS , groupID , controlID ) ) ; <nl> - } <nl> - } <nl> <nl> return ret ; <nl> } <nl>\n", "msg": "move window . * and control * to the info parser\n"}
{"diff_id": 4905, "repo": "ClickHouse/ClickHouse\n", "sha": "d14a12151e8af82daaa3dfca593f3b8262827162\n", "time": "2016-02-11T01:48:34Z\n", "diff": "mmm a / dbms / src / Storages / StorageReplicatedMergeTree . cpp <nl> ppp b / dbms / src / Storages / StorageReplicatedMergeTree . cpp <nl> namespace ErrorCodes <nl> <nl> <nl> const auto ERROR_SLEEP_MS = 1000 ; <nl> - <nl> - / / / Если ждём какого - то события с помощью watch - а , то просыпаться на всякий случай вхолостую раз в указанное время . <nl> - const auto WAIT_FOR_NEW_LOGS_SLEEP_MS = 60 * 1000 ; <nl> - const auto WAIT_FOR_ALTER_SLEEP_MS = 300 * 1000 ; <nl> - const auto WAIT_FOR_REPLICA_QUEUE_MS = 10 * 1000 ; <nl> - <nl> const auto MERGE_SELECTING_SLEEP_MS = 5 * 1000 ; <nl> <nl> / * * Добавляемым блокам данных присваиваются некоторые номера - целые числа . <nl> void StorageReplicatedMergeTree : : queueUpdatingThread ( ) <nl> try <nl> { <nl> pullLogsToQueue ( queue_updating_event ) ; <nl> - queue_updating_event - > tryWait ( WAIT_FOR_NEW_LOGS_SLEEP_MS ) ; <nl> + queue_updating_event - > wait ( ) ; <nl> } <nl> catch ( const zkutil : : KeeperException & e ) <nl> { <nl> void StorageReplicatedMergeTree : : alterThread ( ) <nl> / / / Важно , что уничтожается parts и merge_blocker перед wait - ом . <nl> } <nl> <nl> - alter_thread_event - > tryWait ( WAIT_FOR_ALTER_SLEEP_MS ) ; <nl> + alter_thread_event - > wait ( ) ; <nl> } <nl> catch ( . . . ) <nl> { <nl> void StorageReplicatedMergeTree : : alter ( const AlterCommands & params , <nl> if ( stat . version ! = replica_columns_version ) <nl> continue ; <nl> <nl> - alter_query_event - > tryWait ( WAIT_FOR_ALTER_SLEEP_MS ) ; <nl> + alter_query_event - > wait ( ) ; <nl> } <nl> <nl> if ( shutdown_called ) <nl> void StorageReplicatedMergeTree : : waitForReplicaToProcessLogEntry ( const String & <nl> if ( ! log_pointer . empty ( ) & & parse < UInt64 > ( log_pointer ) > log_index ) <nl> break ; <nl> <nl> - event - > tryWait ( WAIT_FOR_REPLICA_QUEUE_MS ) ; <nl> + event - > wait ( ) ; <nl> } <nl> } <nl> else if ( 0 = = entry . znode_name . compare ( 0 , strlen ( \" queue - \" ) , \" queue - \" ) ) <nl> void StorageReplicatedMergeTree : : waitForReplicaToProcessLogEntry ( const String & <nl> if ( ! log_pointer . empty ( ) & & parse < UInt64 > ( log_pointer ) > log_index ) <nl> break ; <nl> <nl> - event - > tryWait ( WAIT_FOR_REPLICA_QUEUE_MS ) ; <nl> + event - > wait ( ) ; <nl> } <nl> } <nl> } <nl>\n", "msg": "Fixed error with leak of watches [ # METR - 19975 ] .\n"}
{"diff_id": 5010, "repo": "apple/swift\n", "sha": "940ecda379ed8954065cfcab5952d7049b14a589\n", "time": "2017-11-17T18:59:48Z\n", "diff": "mmm a / lib / AST / Type . cpp <nl> ppp b / lib / AST / Type . cpp <nl> static Type getMemberForBaseType ( LookupConformanceFn lookupConformances , <nl> <nl> if ( ! conformance ) return failed ( ) ; <nl> if ( ! conformance - > isConcrete ( ) ) return failed ( ) ; <nl> - assert ( conformance - > getConditionalRequirements ( ) . empty ( ) & & <nl> - \" unhandled conditional requirements \" ) ; <nl> <nl> / / Retrieve the type witness . <nl> auto witness = <nl>\n", "msg": "[ AST ] Remove another bogus assertion .\n"}
{"diff_id": 5032, "repo": "apple/swift\n", "sha": "8972f3680706f8e0940744eaf7589683eeb726cf\n", "time": "2018-08-22T04:51:53Z\n", "diff": "mmm a / lib / IRGen / GenMeta . cpp <nl> ppp b / lib / IRGen / GenMeta . cpp <nl> void IRGenModule : : addFieldTypes ( ArrayRef < CanType > fieldTypes ) { <nl> IRGen . addFieldTypes ( fieldTypes , this ) ; <nl> } <nl> <nl> + static void emitInitializeFieldOffsetVector ( IRGenFunction & IGF , <nl> + SILType T , <nl> + llvm : : Value * metadata , <nl> + bool isVWTMutable , <nl> + MetadataDependencyCollector * collector ) { <nl> + auto * target = T . getNominalOrBoundGenericNominal ( ) ; <nl> + llvm : : Value * fieldVector <nl> + = emitAddressOfFieldOffsetVector ( IGF , metadata , target ) <nl> + . getAddress ( ) ; <nl> + <nl> + / / Collect the stored properties of the type . <nl> + llvm : : SmallVector < VarDecl * , 4 > storedProperties ; <nl> + for ( auto prop : target - > getStoredProperties ( ) ) { <nl> + storedProperties . push_back ( prop ) ; <nl> + } <nl> + <nl> + / / Fill out an array with the field type metadata records . <nl> + Address fields = IGF . createAlloca ( <nl> + llvm : : ArrayType : : get ( IGF . IGM . Int8PtrPtrTy , <nl> + storedProperties . size ( ) ) , <nl> + IGF . IGM . getPointerAlignment ( ) , \" classFields \" ) ; <nl> + IGF . Builder . CreateLifetimeStart ( fields , <nl> + IGF . IGM . getPointerSize ( ) * storedProperties . size ( ) ) ; <nl> + fields = IGF . Builder . CreateStructGEP ( fields , 0 , Size ( 0 ) ) ; <nl> + <nl> + unsigned index = 0 ; <nl> + for ( auto prop : storedProperties ) { <nl> + auto propTy = T . getFieldType ( prop , IGF . getSILModule ( ) ) ; <nl> + llvm : : Value * metadata = emitTypeLayoutRef ( IGF , propTy , collector ) ; <nl> + Address field = IGF . Builder . CreateConstArrayGEP ( fields , index , <nl> + IGF . IGM . getPointerSize ( ) ) ; <nl> + IGF . Builder . CreateStore ( metadata , field ) ; <nl> + + + index ; <nl> + } <nl> + <nl> + / / Ask the runtime to lay out the struct or class . <nl> + auto numFields = IGF . IGM . getSize ( Size ( storedProperties . size ( ) ) ) ; <nl> + <nl> + if ( auto * classDecl = dyn_cast < ClassDecl > ( target ) ) { <nl> + / / Compute class layout flags . <nl> + ClassLayoutFlags flags = ClassLayoutFlags : : Swift5Algorithm ; <nl> + if ( ! doesClassMetadataRequireRelocation ( IGF . IGM , classDecl ) ) <nl> + flags | = ClassLayoutFlags : : HasStaticVTable ; <nl> + <nl> + / / Get the superclass metadata , if the class has one . <nl> + llvm : : Value * superclassMetadata ; <nl> + if ( auto superclassType = classDecl - > getSuperclass ( ) ) { <nl> + superclassType = classDecl - > mapTypeIntoContext ( superclassType ) ; <nl> + <nl> + auto request = DynamicMetadataRequest : : getNonBlocking ( <nl> + MetadataState : : NonTransitiveComplete , collector ) ; <nl> + <nl> + superclassMetadata = <nl> + emitClassHeapMetadataRef ( IGF , superclassType - > getCanonicalType ( ) , <nl> + MetadataValueType : : TypeMetadata , <nl> + request , <nl> + / * allowUninit * / false ) ; <nl> + } else { <nl> + superclassMetadata = <nl> + llvm : : ConstantPointerNull : : get ( IGF . IGM . TypeMetadataPtrTy ) ; <nl> + } <nl> + <nl> + / / Call swift_initClassMetadata ( ) . <nl> + IGF . Builder . CreateCall ( IGF . IGM . getInitClassMetadataFn ( ) , <nl> + { metadata , superclassMetadata , <nl> + IGF . IGM . getSize ( Size ( uintptr_t ( flags ) ) ) , <nl> + numFields , fields . getAddress ( ) , fieldVector } ) ; <nl> + } else { <nl> + assert ( isa < StructDecl > ( target ) ) ; <nl> + <nl> + / / Compute struct layout flags . <nl> + StructLayoutFlags flags = StructLayoutFlags : : Swift5Algorithm ; <nl> + if ( isVWTMutable ) <nl> + flags | = StructLayoutFlags : : IsVWTMutable ; <nl> + <nl> + / / Call swift_initStructMetadata ( ) . <nl> + IGF . Builder . CreateCall ( IGF . IGM . getInitStructMetadataFn ( ) , <nl> + { metadata , IGF . IGM . getSize ( Size ( uintptr_t ( flags ) ) ) , <nl> + numFields , fields . getAddress ( ) , fieldVector } ) ; <nl> + } <nl> + <nl> + IGF . Builder . CreateLifetimeEnd ( fields , <nl> + IGF . IGM . getPointerSize ( ) * storedProperties . size ( ) ) ; <nl> + } <nl> + <nl> + static void emitInitializeMetadata ( IRGenFunction & IGF , <nl> + NominalTypeDecl * nominalDecl , <nl> + llvm : : Value * metadata , <nl> + bool isVWTMutable , <nl> + MetadataDependencyCollector * collector ) { <nl> + auto loweredTy = <nl> + IGF . IGM . getLoweredType ( nominalDecl - > getDeclaredTypeInContext ( ) ) ; <nl> + <nl> + if ( isa < StructDecl > ( nominalDecl ) ) { <nl> + auto & fixedTI = IGF . IGM . getTypeInfo ( loweredTy ) ; <nl> + if ( isa < FixedTypeInfo > ( fixedTI ) ) return ; <nl> + <nl> + emitInitializeFieldOffsetVector ( IGF , loweredTy , metadata , isVWTMutable , <nl> + collector ) ; <nl> + } else { <nl> + assert ( isa < EnumDecl > ( nominalDecl ) ) ; <nl> + auto & strategy = getEnumImplStrategy ( IGF . IGM , loweredTy ) ; <nl> + strategy . initializeMetadata ( IGF , metadata , isVWTMutable , loweredTy , <nl> + collector ) ; <nl> + } <nl> + } <nl> + <nl> + static void emitInitializeClassMetadata ( IRGenFunction & IGF , <nl> + ClassDecl * classDecl , <nl> + const ClassLayout & fieldLayout , <nl> + llvm : : Value * metadata , <nl> + MetadataDependencyCollector * collector ) { <nl> + auto & IGM = IGF . IGM ; <nl> + <nl> + assert ( doesClassMetadataRequireInitialization ( IGM , classDecl ) ) ; <nl> + <nl> + auto loweredTy = <nl> + IGM . getLoweredType ( classDecl - > getDeclaredTypeInContext ( ) ) ; <nl> + <nl> + / / Set the superclass , fill out the field offset vector , and copy vtable <nl> + / / entries , generic requirements and field offsets from superclasses . <nl> + emitInitializeFieldOffsetVector ( IGF , loweredTy , <nl> + metadata , / * VWT is mutable * / false , <nl> + collector ) ; <nl> + <nl> + / / Realizing the class with the ObjC runtime will copy back to the <nl> + / / field offset globals for us ; but if ObjC interop is disabled , we <nl> + / / have to do that ourselves , assuming we didn ' t just emit them all <nl> + / / correctly in the first place . <nl> + if ( ! IGM . ObjCInterop ) { <nl> + for ( auto prop : classDecl - > getStoredProperties ( ) ) { <nl> + auto fieldInfo = fieldLayout . getFieldAccessAndElement ( prop ) ; <nl> + if ( fieldInfo . first = = FieldAccess : : NonConstantDirect ) { <nl> + Address offsetA = IGM . getAddrOfFieldOffset ( prop , ForDefinition ) ; <nl> + <nl> + / / We can ' t use emitClassFieldOffset ( ) here because that creates <nl> + / / an invariant load , which could be hoisted above the point <nl> + / / where the metadata becomes fully initialized <nl> + auto slot = <nl> + emitAddressOfClassFieldOffset ( IGF , metadata , classDecl , prop ) ; <nl> + auto offsetVal = IGF . emitInvariantLoad ( slot ) ; <nl> + IGF . Builder . CreateStore ( offsetVal , offsetA ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + if ( ! doesClassMetadataRequireRelocation ( IGM , classDecl ) ) <nl> + return ; <nl> + <nl> + / / Update vtable entries for method overrides . The runtime copies in <nl> + / / the vtable from the superclass for us ; we have to install method <nl> + / / overrides ourselves . <nl> + auto * vtable = IGM . getSILModule ( ) . lookUpVTable ( classDecl ) ; <nl> + for ( auto & entry : vtable - > getEntries ( ) ) { <nl> + if ( entry . TheKind ! = SILVTable : : Entry : : Kind : : Override ) <nl> + continue ; <nl> + <nl> + auto fn = entry . Method ; <nl> + <nl> + auto * classDecl = cast < ClassDecl > ( fn . getDecl ( ) - > getDeclContext ( ) ) ; <nl> + auto & layout = IGM . getClassMetadataLayout ( classDecl ) ; <nl> + <nl> + auto offset = layout . getMethodInfo ( IGF , fn ) . getOffset ( ) ; <nl> + <nl> + auto slot = IGF . emitAddressAtOffset ( metadata , offset , <nl> + IGM . Int8PtrTy , <nl> + IGM . getPointerAlignment ( ) ) ; <nl> + <nl> + auto * implFn = IGM . getAddrOfSILFunction ( entry . Implementation , <nl> + NotForDefinition ) ; <nl> + auto * value = IGF . Builder . CreateBitCast ( implFn , IGM . Int8PtrTy ) ; <nl> + IGF . Builder . CreateStore ( value , slot ) ; <nl> + } <nl> + } <nl> + <nl> + static MetadataKind getMetadataKind ( NominalTypeDecl * nominalDecl ) { <nl> + if ( isa < StructDecl > ( nominalDecl ) ) <nl> + return MetadataKind : : Struct ; <nl> + <nl> + assert ( isa < EnumDecl > ( nominalDecl ) ) ; <nl> + return ( nominalDecl - > isOptionalDecl ( ) <nl> + ? MetadataKind : : Optional <nl> + : MetadataKind : : Enum ) ; <nl> + } <nl> + <nl> / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / <nl> / * * Metadata Emission * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / <nl> / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / <nl> namespace { <nl> GenericMetadataPatternFlags getPatternFlags ( ) { <nl> auto flags = super : : getPatternFlags ( ) ; <nl> <nl> - flags . value_setMetadataKind ( asImpl ( ) . getMetadataKind ( ) ) ; <nl> + flags . value_setMetadataKind ( getMetadataKind ( Target ) ) ; <nl> <nl> assert ( ! asImpl ( ) . hasImmediateMembersPattern ( ) ) ; <nl> <nl> namespace { <nl> auto table = asImpl ( ) . emitValueWitnessTable ( ) ; <nl> B . addRelativeAddress ( table ) ; <nl> } <nl> - } ; <nl> - } / / end anonymous namespace <nl> - <nl> - static void emitInitializeFieldOffsetVector ( IRGenFunction & IGF , <nl> - SILType T , <nl> - llvm : : Value * metadata , <nl> - bool isVWTMutable , <nl> - MetadataDependencyCollector * collector ) { <nl> - auto * target = T . getNominalOrBoundGenericNominal ( ) ; <nl> - llvm : : Value * fieldVector <nl> - = emitAddressOfFieldOffsetVector ( IGF , metadata , target ) <nl> - . getAddress ( ) ; <nl> <nl> - / / Collect the stored properties of the type . <nl> - llvm : : SmallVector < VarDecl * , 4 > storedProperties ; <nl> - for ( auto prop : target - > getStoredProperties ( ) ) { <nl> - storedProperties . push_back ( prop ) ; <nl> - } <nl> - <nl> - / / Fill out an array with the field type metadata records . <nl> - Address fields = IGF . createAlloca ( <nl> - llvm : : ArrayType : : get ( IGF . IGM . Int8PtrPtrTy , <nl> - storedProperties . size ( ) ) , <nl> - IGF . IGM . getPointerAlignment ( ) , \" classFields \" ) ; <nl> - IGF . Builder . CreateLifetimeStart ( fields , <nl> - IGF . IGM . getPointerSize ( ) * storedProperties . size ( ) ) ; <nl> - fields = IGF . Builder . CreateStructGEP ( fields , 0 , Size ( 0 ) ) ; <nl> - <nl> - unsigned index = 0 ; <nl> - for ( auto prop : storedProperties ) { <nl> - auto propTy = T . getFieldType ( prop , IGF . getSILModule ( ) ) ; <nl> - llvm : : Value * metadata = emitTypeLayoutRef ( IGF , propTy , collector ) ; <nl> - Address field = IGF . Builder . CreateConstArrayGEP ( fields , index , <nl> - IGF . IGM . getPointerSize ( ) ) ; <nl> - IGF . Builder . CreateStore ( metadata , field ) ; <nl> - + + index ; <nl> - } <nl> - <nl> - / / Ask the runtime to lay out the struct or class . <nl> - auto numFields = IGF . IGM . getSize ( Size ( storedProperties . size ( ) ) ) ; <nl> - <nl> - if ( auto * classDecl = dyn_cast < ClassDecl > ( target ) ) { <nl> - / / Compute class layout flags . <nl> - ClassLayoutFlags flags = ClassLayoutFlags : : Swift5Algorithm ; <nl> - if ( ! doesClassMetadataRequireRelocation ( IGF . IGM , classDecl ) ) <nl> - flags | = ClassLayoutFlags : : HasStaticVTable ; <nl> - <nl> - / / Get the superclass metadata , if the class has one . <nl> - llvm : : Value * superclassMetadata ; <nl> - if ( auto superclassType = classDecl - > getSuperclass ( ) ) { <nl> - superclassType = classDecl - > mapTypeIntoContext ( superclassType ) ; <nl> - <nl> - auto request = DynamicMetadataRequest : : getNonBlocking ( <nl> - MetadataState : : NonTransitiveComplete , collector ) ; <nl> - <nl> - superclassMetadata = <nl> - emitClassHeapMetadataRef ( IGF , superclassType - > getCanonicalType ( ) , <nl> - MetadataValueType : : TypeMetadata , <nl> - request , <nl> - / * allowUninit * / false ) ; <nl> - } else { <nl> - superclassMetadata = <nl> - llvm : : ConstantPointerNull : : get ( IGF . IGM . TypeMetadataPtrTy ) ; <nl> + void emitInitializeMetadata ( IRGenFunction & IGF , <nl> + llvm : : Value * metadata , <nl> + bool isVWTMutable , <nl> + MetadataDependencyCollector * collector ) { <nl> + : : emitInitializeMetadata ( IGF , Target , metadata , isVWTMutable , collector ) ; <nl> } <nl> - <nl> - / / Call swift_initClassMetadata ( ) . <nl> - IGF . Builder . CreateCall ( IGF . IGM . getInitClassMetadataFn ( ) , <nl> - { metadata , superclassMetadata , <nl> - IGF . IGM . getSize ( Size ( uintptr_t ( flags ) ) ) , <nl> - numFields , fields . getAddress ( ) , fieldVector } ) ; <nl> - } else { <nl> - assert ( isa < StructDecl > ( target ) ) ; <nl> - <nl> - / / Compute struct layout flags . <nl> - StructLayoutFlags flags = StructLayoutFlags : : Swift5Algorithm ; <nl> - if ( isVWTMutable ) <nl> - flags | = StructLayoutFlags : : IsVWTMutable ; <nl> - <nl> - / / Call swift_initStructMetadata ( ) . <nl> - IGF . Builder . CreateCall ( IGF . IGM . getInitStructMetadataFn ( ) , <nl> - { metadata , IGF . IGM . getSize ( Size ( uintptr_t ( flags ) ) ) , <nl> - numFields , fields . getAddress ( ) , fieldVector } ) ; <nl> - } <nl> - <nl> - IGF . Builder . CreateLifetimeEnd ( fields , <nl> - IGF . IGM . getPointerSize ( ) * storedProperties . size ( ) ) ; <nl> - } <nl> + } ; <nl> + } / / end anonymous namespace <nl> <nl> / / / Create an access function for the given type which triggers the <nl> / / / in - place initialization path . <nl> createInPlaceInitializationMetadataAccessFunction ( IRGenModule & IGM , <nl> <nl> / / Classes <nl> <nl> + / / / Emit the base - offset variable for the class . <nl> + static void emitClassMetadataBaseOffset ( IRGenModule & IGM , <nl> + ClassDecl * classDecl ) { <nl> + / / Otherwise , we know the offset at compile time , even if our <nl> + / / clients do not , so just emit a constant . <nl> + auto & layout = IGM . getClassMetadataLayout ( classDecl ) ; <nl> + <nl> + / / Only classes defined in resilient modules , or those that have <nl> + / / a resilient superclass need this . <nl> + if ( ! layout . hasResilientSuperclass ( ) & & <nl> + ! IGM . isResilient ( classDecl , ResilienceExpansion : : Minimal ) ) { <nl> + return ; <nl> + } <nl> + <nl> + auto * offsetAddr = <nl> + IGM . getAddrOfClassMetadataBounds ( classDecl , ForDefinition ) ; <nl> + auto * offsetVar = cast < llvm : : GlobalVariable > ( offsetAddr ) ; <nl> + <nl> + if ( layout . hasResilientSuperclass ( ) ) { <nl> + / / If the superclass is resilient to us , we have to compute and <nl> + / / initialize the global when we initialize the metadata . <nl> + auto init = llvm : : ConstantAggregateZero : : get ( offsetVar - > getValueType ( ) ) ; <nl> + <nl> + offsetVar - > setInitializer ( init ) ; <nl> + offsetVar - > setConstant ( false ) ; <nl> + return ; <nl> + } <nl> + <nl> + auto immediateMembersOffset = layout . getStartOfImmediateMembers ( ) ; <nl> + auto size = layout . getSize ( ) ; <nl> + auto negativeSizeInWords = size . AddressPoint / IGM . getPointerSize ( ) ; <nl> + auto positiveSizeInWords = size . getOffsetToEnd ( ) / IGM . getPointerSize ( ) ; <nl> + <nl> + auto initTy = cast < llvm : : StructType > ( offsetVar - > getValueType ( ) ) ; <nl> + auto * init = llvm : : ConstantStruct : : get ( initTy , { <nl> + llvm : : ConstantInt : : get ( IGM . SizeTy , immediateMembersOffset . getValue ( ) ) , <nl> + llvm : : ConstantInt : : get ( IGM . Int32Ty , negativeSizeInWords ) , <nl> + llvm : : ConstantInt : : get ( IGM . Int32Ty , positiveSizeInWords ) <nl> + } ) ; <nl> + <nl> + offsetVar - > setInitializer ( init ) ; <nl> + offsetVar - > setConstant ( true ) ; <nl> + } <nl> + <nl> + static Optional < llvm : : Constant * > <nl> + getAddrOfDestructorFunction ( IRGenModule & IGM , ClassDecl * classDecl ) { <nl> + auto dtorRef = SILDeclRef ( classDecl - > getDestructor ( ) , <nl> + SILDeclRef : : Kind : : Deallocator ) ; <nl> + SILFunction * dtorFunc = IGM . getSILModule ( ) . lookUpFunction ( dtorRef ) ; <nl> + if ( ! dtorFunc ) return llvm : : None ; <nl> + return IGM . getAddrOfSILFunction ( dtorFunc , NotForDefinition ) ; <nl> + } <nl> + <nl> static void emitFieldOffsetGlobals ( IRGenModule & IGM , <nl> ClassDecl * classDecl , <nl> const ClassLayout & classLayout ) { <nl> static void emitFieldOffsetGlobals ( IRGenModule & IGM , <nl> } <nl> } <nl> <nl> + static ClassFlags getClassFlags ( ClassDecl * classDecl ) { <nl> + auto flags = ClassFlags ( ) ; <nl> + <nl> + # if ! SWIFT_DARWIN_ENABLE_STABLE_ABI_BIT <nl> + / / FIXME : Remove this after enabling stable ABI . <nl> + / / This bit is NOT conditioned on UseDarwinPreStableABIBit . <nl> + flags | = ClassFlags : : IsSwiftPreStableABI ; <nl> + # endif <nl> + <nl> + / / Set a flag if the class uses Swift refcounting . <nl> + auto type = classDecl - > getDeclaredType ( ) - > getCanonicalType ( ) ; <nl> + if ( type - > getReferenceCounting ( ) = = ReferenceCounting : : Native ) { <nl> + flags | = ClassFlags : : UsesSwiftRefcounting ; <nl> + } <nl> + <nl> + / / Set a flag if the class has a custom ObjC name . <nl> + DeclAttributes attrs = classDecl - > getAttrs ( ) ; <nl> + if ( auto objc = attrs . getAttribute < ObjCAttr > ( ) ) { <nl> + if ( objc - > getName ( ) ) <nl> + flags | = ClassFlags : : HasCustomObjCName ; <nl> + } <nl> + if ( attrs . hasAttribute < ObjCRuntimeNameAttr > ( ) ) <nl> + flags | = ClassFlags : : HasCustomObjCName ; <nl> + <nl> + return flags ; <nl> + } <nl> + <nl> namespace { <nl> / / / Utility class for building member metadata for classes where the <nl> / / / entire hierarchy is in the current resilience domain , and all stored <nl> namespace { <nl> B . addBitCast ( IGM . getDeletedMethodErrorFn ( ) , IGM . FunctionPtrTy ) ; <nl> } <nl> <nl> - void emitInitializeMethodOverrides ( IRGenFunction & IGF , <nl> - llvm : : Value * metadata ) { <nl> - / / Emitted statically by the above . <nl> - } <nl> - <nl> void addGenericArgument ( ClassDecl * forClass ) { <nl> llvm_unreachable ( \" Fixed class metadata cannot have generic parameters \" ) ; <nl> } <nl> namespace { <nl> B . addBitCast ( IGM . getDeletedMethodErrorFn ( ) , IGM . FunctionPtrTy ) ; <nl> } <nl> <nl> - void emitInitializeMethodOverrides ( IRGenFunction & IGF , <nl> - llvm : : Value * metadata ) { <nl> - / / Emitted statically by the above . <nl> - } <nl> - <nl> void addGenericArgument ( ClassDecl * forClass ) { <nl> / / Filled in at runtime . <nl> B . addNullPointer ( IGM . TypeMetadataPtrTy ) ; <nl> namespace { <nl> / / / ancestry . The total size of the class metadata is not known at compile <nl> / / / time , and requires relocation . <nl> class ResilientClassMemberBuilder { <nl> - IRGenModule & IGM ; <nl> - SILVTable * VTable ; <nl> - <nl> public : <nl> ResilientClassMemberBuilder ( IRGenModule & IGM , <nl> ConstantStructBuilder & builder , <nl> - SILVTable * vtable ) <nl> - : IGM ( IGM ) , VTable ( vtable ) { } <nl> + SILVTable * vtable ) { } <nl> <nl> void addFieldOffset ( VarDecl * var ) { } <nl> <nl> namespace { <nl> <nl> void addMethod ( SILDeclRef fn ) { } <nl> <nl> - / / Update vtable entries for method overrides . The runtime copies in <nl> - / / the vtable from the superclass for us ; we have to install method <nl> - / / overrides ourselves . <nl> - void emitInitializeMethodOverrides ( IRGenFunction & IGF , <nl> - llvm : : Value * metadata ) { <nl> - for ( auto & entry : VTable - > getEntries ( ) ) { <nl> - if ( entry . TheKind ! = SILVTable : : Entry : : Kind : : Override ) <nl> - continue ; <nl> - <nl> - auto fn = entry . Method ; <nl> - <nl> - auto * classDecl = cast < ClassDecl > ( fn . getDecl ( ) - > getDeclContext ( ) ) ; <nl> - auto & layout = IGM . getClassMetadataLayout ( classDecl ) ; <nl> - <nl> - auto offset = layout . getMethodInfo ( IGF , fn ) . getOffset ( ) ; <nl> - <nl> - auto slot = IGF . emitAddressAtOffset ( metadata , offset , <nl> - IGM . Int8PtrTy , <nl> - IGM . getPointerAlignment ( ) ) ; <nl> - <nl> - auto * implFn = IGM . getAddrOfSILFunction ( entry . Implementation , <nl> - NotForDefinition ) ; <nl> - auto * value = IGF . Builder . CreateBitCast ( implFn , IGM . Int8PtrTy ) ; <nl> - IGF . Builder . CreateStore ( value , slot ) ; <nl> - } <nl> - } <nl> - <nl> void addGenericArgument ( ClassDecl * forClass ) { } <nl> <nl> void addGenericWitnessTable ( ClassDecl * forClass ) { } <nl> namespace { <nl> IGM . getSILModule ( ) . lookUpVTable ( theClass ) ) { } <nl> <nl> public : <nl> + void addClassFlags ( ) { <nl> + B . addInt32 ( ( uint32_t ) getClassFlags ( Target ) ) ; <nl> + } <nl> + <nl> void noteResilientSuperclass ( ) { } <nl> <nl> void noteStartOfImmediateMembers ( ClassDecl * theClass ) { <nl> if ( theClass = = Target ) { <nl> - emitClassMetadataBaseOffset ( ) ; <nl> - } <nl> - } <nl> - <nl> - / / / Emit the base - offset variable for the class . <nl> - void emitClassMetadataBaseOffset ( ) { <nl> - / / Only classes defined in resilient modules , or those that have <nl> - / / a resilient superclass need this . <nl> - if ( ! MetadataLayout . hasResilientSuperclass ( ) & & <nl> - ! IGM . isResilient ( Target , ResilienceExpansion : : Minimal ) ) { <nl> - return ; <nl> + emitClassMetadataBaseOffset ( IGM , theClass ) ; <nl> } <nl> - <nl> - auto * offsetAddr = <nl> - IGM . getAddrOfClassMetadataBounds ( Target , ForDefinition ) ; <nl> - auto * offsetVar = cast < llvm : : GlobalVariable > ( offsetAddr ) ; <nl> - <nl> - if ( MetadataLayout . hasResilientSuperclass ( ) ) { <nl> - / / If the superclass is resilient to us , we have to compute and <nl> - / / initialize the global when we initialize the metadata . <nl> - auto init = llvm : : ConstantAggregateZero : : get ( offsetVar - > getValueType ( ) ) ; <nl> - <nl> - offsetVar - > setInitializer ( init ) ; <nl> - offsetVar - > setConstant ( false ) ; <nl> - return ; <nl> - } <nl> - <nl> - / / Otherwise , we know the offset at compile time , even if our <nl> - / / clients do not , so just emit a constant . <nl> - auto & layout = IGM . getClassMetadataLayout ( Target ) ; <nl> - <nl> - auto immediateMembersOffset = layout . getStartOfImmediateMembers ( ) ; <nl> - auto size = layout . getSize ( ) ; <nl> - auto negativeSizeInWords = size . AddressPoint / IGM . getPointerSize ( ) ; <nl> - auto positiveSizeInWords = size . getOffsetToEnd ( ) / IGM . getPointerSize ( ) ; <nl> - <nl> - auto initTy = cast < llvm : : StructType > ( offsetVar - > getValueType ( ) ) ; <nl> - auto * init = llvm : : ConstantStruct : : get ( initTy , { <nl> - llvm : : ConstantInt : : get ( IGM . SizeTy , immediateMembersOffset . getValue ( ) ) , <nl> - llvm : : ConstantInt : : get ( IGM . Int32Ty , negativeSizeInWords ) , <nl> - llvm : : ConstantInt : : get ( IGM . Int32Ty , positiveSizeInWords ) <nl> - } ) ; <nl> - <nl> - offsetVar - > setInitializer ( init ) ; <nl> - offsetVar - > setConstant ( true ) ; <nl> } <nl> <nl> / / / The ' metadata flags ' field in a class is actually a pointer to <nl> namespace { <nl> } <nl> <nl> void addDestructorFunction ( ) { <nl> - if ( auto ptr = getAddrOfDestructorFunction ( ) ) { <nl> + if ( auto ptr = getAddrOfDestructorFunction ( IGM , Target ) ) { <nl> B . add ( * ptr ) ; <nl> } else { <nl> / / In case the optimizer removed the function . See comment in <nl> namespace { <nl> } <nl> } <nl> <nl> - Optional < llvm : : Constant * > getAddrOfDestructorFunction ( ) { <nl> - auto dtorRef = SILDeclRef ( Target - > getDestructor ( ) , <nl> - SILDeclRef : : Kind : : Deallocator ) ; <nl> - SILFunction * dtorFunc = IGM . getSILModule ( ) . lookUpFunction ( dtorRef ) ; <nl> - if ( ! dtorFunc ) return llvm : : None ; <nl> - return IGM . getAddrOfSILFunction ( dtorFunc , NotForDefinition ) ; <nl> - } <nl> - <nl> - void addNominalTypeDescriptor ( ) { <nl> - auto descriptor = asImpl ( ) . emitNominalTypeDescriptor ( ) ; <nl> - B . add ( descriptor ) ; <nl> - } <nl> - <nl> - llvm : : Constant * emitNominalTypeDescriptor ( ) { <nl> - return ClassContextDescriptorBuilder ( IGM , Target , RequireMetadata ) . emit ( ) ; <nl> - } <nl> - <nl> void addIVarDestroyer ( ) { <nl> - auto dtorFunc = getAddrOfIVarDestroyer ( ) ; <nl> + auto dtorFunc = IGM . getAddrOfIVarInitDestroy ( Target , <nl> + / * isDestroyer = * / true , <nl> + / * isForeign = * / false , <nl> + NotForDefinition ) ; <nl> if ( dtorFunc ) { <nl> B . add ( * dtorFunc ) ; <nl> } else { <nl> namespace { <nl> } <nl> } <nl> <nl> - Optional < llvm : : Function * > getAddrOfIVarDestroyer ( ) { <nl> - return IGM . getAddrOfIVarInitDestroy ( Target , <nl> - / * isDestroyer = * / true , <nl> - / * isForeign = * / false , <nl> - NotForDefinition ) ; <nl> + llvm : : Constant * emitNominalTypeDescriptor ( ) { <nl> + return ClassContextDescriptorBuilder ( IGM , Target , RequireMetadata ) . emit ( ) ; <nl> } <nl> <nl> - void addClassFlags ( ) { <nl> - auto flags = ClassFlags ( ) ; <nl> - <nl> - # if ! SWIFT_DARWIN_ENABLE_STABLE_ABI_BIT <nl> - / / FIXME : Remove this after enabling stable ABI . <nl> - / / This bit is NOT conditioned on UseDarwinPreStableABIBit . <nl> - flags | = ClassFlags : : IsSwiftPreStableABI ; <nl> - # endif <nl> - <nl> - / / Set a flag if the class uses Swift refcounting . <nl> - auto type = Target - > getDeclaredType ( ) - > getCanonicalType ( ) ; <nl> - if ( type - > getReferenceCounting ( ) = = ReferenceCounting : : Native ) { <nl> - flags | = ClassFlags : : UsesSwiftRefcounting ; <nl> - } <nl> - <nl> - / / Set a flag if the class has a custom ObjC name . <nl> - DeclAttributes attrs = Target - > getAttrs ( ) ; <nl> - if ( auto objc = attrs . getAttribute < ObjCAttr > ( ) ) { <nl> - if ( objc - > getName ( ) ) <nl> - flags | = ClassFlags : : HasCustomObjCName ; <nl> - } <nl> - if ( attrs . hasAttribute < ObjCRuntimeNameAttr > ( ) ) <nl> - flags | = ClassFlags : : HasCustomObjCName ; <nl> + void addNominalTypeDescriptor ( ) { <nl> + B . add ( emitNominalTypeDescriptor ( ) ) ; <nl> + } <nl> <nl> - B . addInt32 ( ( uint32_t ) flags ) ; <nl> + bool canBeConstant ( ) { <nl> + / / TODO : the metadata global can actually be constant in a very <nl> + / / special case : it ' s not a pattern , ObjC interoperation isn ' t <nl> + / / required , there are no class fields , and there is nothing that <nl> + / / needs to be runtime - adjusted . <nl> + return false ; <nl> } <nl> <nl> void addInstanceAddressPoint ( ) { <nl> namespace { <nl> Members . addGenericWitnessTable ( forClass ) ; <nl> } <nl> <nl> - protected : <nl> - llvm : : Value * emitFinishInitializationOfClassMetadata ( IRGenFunction & IGF , <nl> - llvm : : Value * metadata , <nl> - MetadataDependencyCollector * collector ) { <nl> - assert ( doesClassMetadataRequireInitialization ( IGF . IGM , Target ) ) ; <nl> - <nl> - / / Set the superclass , fill out the field offset vector , and copy vtable <nl> - / / entries , generic requirements and field offsets from superclasses . <nl> - auto classTy = Target - > getDeclaredTypeInContext ( ) - > getCanonicalType ( ) ; <nl> - auto loweredClassTy = IGF . IGM . getLoweredType ( classTy ) ; <nl> - emitInitializeFieldOffsetVector ( IGF , loweredClassTy , <nl> - metadata , / * VWT is mutable * / false , <nl> - collector ) ; <nl> - <nl> - / / Realizing the class with the ObjC runtime will copy back to the <nl> - / / field offset globals for us ; but if ObjC interop is disabled , we <nl> - / / have to do that ourselves , assuming we didn ' t just emit them all <nl> - / / correctly in the first place . <nl> - if ( ! IGF . IGM . ObjCInterop ) <nl> - emitInitializeFieldOffsets ( IGF , metadata ) ; <nl> - <nl> - emitInitializeMethodOverrides ( IGF , metadata ) ; <nl> - <nl> - return metadata ; <nl> - } <nl> - <nl> - / / Update vtable entries for method overrides . The runtime copies in <nl> - / / the vtable from the superclass for us ; we have to install method <nl> - / / overrides ourselves . <nl> - void emitInitializeMethodOverrides ( IRGenFunction & IGF , <nl> - llvm : : Value * metadata ) { <nl> - Members . emitInitializeMethodOverrides ( IGF , metadata ) ; <nl> - } <nl> - <nl> - / / The Objective - C runtime will copy field offsets from the field offset <nl> - / / vector into field offset globals for us , if present . If there ' s no <nl> - / / Objective - C runtime , we have to do this ourselves . <nl> - void emitInitializeFieldOffsets ( IRGenFunction & IGF , <nl> - llvm : : Value * metadata ) { <nl> - for ( auto prop : Target - > getStoredProperties ( ) ) { <nl> - auto fieldInfo = FieldLayout . getFieldAccessAndElement ( prop ) ; <nl> - if ( fieldInfo . first = = FieldAccess : : NonConstantDirect ) { <nl> - Address offsetA = IGF . IGM . getAddrOfFieldOffset ( prop , ForDefinition ) ; <nl> - <nl> - / / We can ' t use emitClassFieldOffset ( ) here because that creates <nl> - / / an invariant load , which could be hoisted above the point <nl> - / / where the metadata becomes fully initialized <nl> - auto slot = <nl> - emitAddressOfClassFieldOffset ( IGF , metadata , Target , prop ) ; <nl> - auto offsetVal = IGF . emitInvariantLoad ( slot ) ; <nl> - IGF . Builder . CreateStore ( offsetVal , offsetA ) ; <nl> - } <nl> - } <nl> - } <nl> } ; <nl> <nl> / / / Base class for layout of non - generic class metadata . <nl> namespace { <nl> <nl> using super : : IGM ; <nl> using super : : Target ; <nl> + using super : : FieldLayout ; <nl> using super : : B ; <nl> - using super : : emitFinishInitializationOfClassMetadata ; <nl> <nl> Size AddressPoint ; <nl> <nl> namespace { <nl> IGM , Target , <nl> [ & ] ( IRGenFunction & IGF , llvm : : Value * metadata , <nl> MetadataDependencyCollector * collector ) { <nl> - emitFinishInitializationOfClassMetadata ( IGF , metadata , collector ) ; <nl> + emitInitializeClassMetadata ( IGF , Target , FieldLayout , metadata , <nl> + collector ) ; <nl> } ) ; <nl> <nl> / / If the class has resilient ancestry we also need a relocation <nl> namespace { <nl> addIVarDestroyer ( ) ; <nl> <nl> / / ClassFlags Flags ; <nl> - addClassFlags ( ) ; <nl> + B . addInt32 ( ( uint32_t ) getClassFlags ( Target ) ) ; <nl> <nl> / / uint16_t ClassRODataOffset ; <nl> if ( IGM . ObjCInterop ) <nl> namespace { <nl> <nl> void emitInstantiationDefinitions ( ) { <nl> / / Emit the base - offset variable . <nl> - emitClassMetadataBaseOffset ( ) ; <nl> + emitClassMetadataBaseOffset ( IGM , Target ) ; <nl> <nl> super : : emitInstantiationDefinitions ( ) ; <nl> } <nl> <nl> void addDestructorFunction ( ) { <nl> - auto function = getAddrOfDestructorFunction ( ) ; <nl> + auto function = getAddrOfDestructorFunction ( IGM , Target ) ; <nl> B . addRelativeAddressOrNull ( function ? * function : nullptr ) ; <nl> } <nl> <nl> void addIVarDestroyer ( ) { <nl> - auto function = getAddrOfIVarDestroyer ( ) ; <nl> + auto function = IGM . getAddrOfIVarInitDestroy ( Target , <nl> + / * isDestroyer = * / true , <nl> + / * isForeign = * / false , <nl> + NotForDefinition ) ; <nl> B . addRelativeAddressOrNull ( function ? * function : nullptr ) ; <nl> } <nl> <nl> namespace { <nl> bool isVWTMutable , <nl> MetadataDependencyCollector * collector ) { <nl> assert ( ! HasDependentVWT & & \" class should never have dependent VWT \" ) ; <nl> - <nl> - / / We can assume that this never relocates the metadata because <nl> - / / it should have been allocated properly for the class . <nl> - ( void ) emitFinishInitializationOfClassMetadata ( IGF , metadata , collector ) ; <nl> + emitInitializeClassMetadata ( IGF , Target , FieldLayout , metadata , collector ) ; <nl> } <nl> } ; <nl> } / / end anonymous namespace <nl> namespace { <nl> emitMetadataCompletionFunction ( IGM , Target , <nl> [ & ] ( IRGenFunction & IGF , llvm : : Value * metadata , <nl> MetadataDependencyCollector * collector ) { <nl> - asImpl ( ) . emitInitializeMetadata ( IGF , metadata , / * vwt mutable * / true , <nl> - collector ) ; <nl> + emitInitializeMetadata ( IGF , Target , metadata , / * vwt mutable * / true , <nl> + collector ) ; <nl> } ) ; <nl> } <nl> } ; <nl> namespace { <nl> return IGM . getLoweredType ( Target - > getDeclaredTypeInContext ( ) ) ; <nl> } <nl> <nl> - MetadataKind getMetadataKind ( ) { <nl> - return MetadataKind : : Struct ; <nl> - } <nl> - <nl> void addMetadataFlags ( ) { <nl> - B . addInt ( IGM . MetadataKindTy , unsigned ( getMetadataKind ( ) ) ) ; <nl> + B . addInt ( IGM . MetadataKindTy , unsigned ( getMetadataKind ( Target ) ) ) ; <nl> } <nl> <nl> llvm : : Constant * emitNominalTypeDescriptor ( ) { <nl> namespace { <nl> void addGenericWitnessTable ( ) { <nl> llvm_unreachable ( \" Concrete type metadata cannot have generic requirements \" ) ; <nl> } <nl> - <nl> - void emitInitializeMetadata ( IRGenFunction & IGF , <nl> - llvm : : Value * metadata , <nl> - bool isVWTMutable , <nl> - MetadataDependencyCollector * collector ) { <nl> - auto loweredTy = getLoweredType ( ) ; <nl> - auto & fixedTI = IGM . getTypeInfo ( loweredTy ) ; <nl> - if ( isa < FixedTypeInfo > ( fixedTI ) ) return ; <nl> - <nl> - emitInitializeFieldOffsetVector ( IGF , loweredTy , metadata , isVWTMutable , <nl> - collector ) ; <nl> - } <nl> } ; <nl> <nl> class StructMetadataBuilder : <nl> void IRGenerator : : noteUseOfAnyParentTypeMetadata ( NominalTypeDecl * type ) { <nl> <nl> / / Enums <nl> <nl> + static Optional < Size > getConstantPayloadSize ( IRGenModule & IGM , <nl> + EnumDecl * enumDecl ) { <nl> + auto enumTy = enumDecl - > getDeclaredTypeInContext ( ) - > getCanonicalType ( ) ; <nl> + auto & enumTI = IGM . getTypeInfoForUnlowered ( enumTy ) ; <nl> + if ( ! enumTI . isFixedSize ( ResilienceExpansion : : Maximal ) ) { <nl> + return None ; <nl> + } <nl> + <nl> + assert ( ! enumTI . isFixedSize ( ResilienceExpansion : : Minimal ) & & <nl> + \" non - generic , non - resilient enums don ' t need payload size in metadata \" ) ; <nl> + auto & strategy = getEnumImplStrategy ( IGM , enumTy ) ; <nl> + return Size ( strategy . getPayloadSizeForMetadata ( ) ) ; <nl> + } <nl> + <nl> namespace { <nl> <nl> template < class Impl > <nl> namespace { <nl> public : <nl> void noteStartOfTypeSpecificMembers ( ) { } <nl> <nl> - MetadataKind getMetadataKind ( ) { <nl> - return Target - > isOptionalDecl ( ) ? MetadataKind : : Optional <nl> - : MetadataKind : : Enum ; <nl> - } <nl> - <nl> void addMetadataFlags ( ) { <nl> - auto kind = getMetadataKind ( ) ; <nl> - B . addInt ( IGM . MetadataKindTy , unsigned ( kind ) ) ; <nl> + B . addInt ( IGM . MetadataKindTy , unsigned ( getMetadataKind ( Target ) ) ) ; <nl> } <nl> <nl> llvm : : Constant * emitValueWitnessTable ( ) { <nl> namespace { <nl> void addGenericWitnessTable ( ) { <nl> llvm_unreachable ( \" Concrete type metadata cannot have generic requirements \" ) ; <nl> } <nl> - <nl> - Optional < Size > getConstantPayloadSize ( ) { <nl> - auto enumTy = Target - > getDeclaredTypeInContext ( ) - > getCanonicalType ( ) ; <nl> - auto & enumTI = IGM . getTypeInfoForUnlowered ( enumTy ) ; <nl> - if ( ! enumTI . isFixedSize ( ResilienceExpansion : : Maximal ) ) { <nl> - return None ; <nl> - } <nl> - <nl> - assert ( ! enumTI . isFixedSize ( ResilienceExpansion : : Minimal ) & & <nl> - \" non - generic , non - resilient enums don ' t need payload size in metadata \" ) ; <nl> - auto & strategy = getEnumImplStrategy ( IGM , enumTy ) ; <nl> - return Size ( strategy . getPayloadSizeForMetadata ( ) ) ; <nl> - } <nl> - <nl> - void emitInitializeMetadata ( IRGenFunction & IGF , <nl> - llvm : : Value * metadata , <nl> - bool isVWTMutable , <nl> - MetadataDependencyCollector * collector ) { <nl> - / / Nominal types are always preserved through SIL lowering . <nl> - auto enumTy = getLoweredType ( ) ; <nl> - <nl> - auto & strategy = getEnumImplStrategy ( IGF . IGM , enumTy ) ; <nl> - strategy . initializeMetadata ( IGF , metadata , isVWTMutable , enumTy , <nl> - collector ) ; <nl> - } <nl> } ; <nl> <nl> class EnumMetadataBuilder <nl> namespace { <nl> : EnumMetadataBuilderBase ( IGM , theEnum , B ) { } <nl> <nl> void addPayloadSize ( ) { <nl> - auto payloadSize = getConstantPayloadSize ( ) ; <nl> + auto payloadSize = getConstantPayloadSize ( IGM , Target ) ; <nl> if ( ! payloadSize ) { <nl> B . addInt ( IGM . IntPtrTy , 0 ) ; <nl> HasUnfilledPayloadSize = true ; <nl> namespace { <nl> / / This is so small that we just do it inline instead of bothering <nl> / / with a pattern . <nl> if ( layout . hasPayloadSizeOffset ( ) ) { <nl> - if ( auto size = getConstantPayloadSize ( ) ) { <nl> + if ( auto size = getConstantPayloadSize ( IGM , Target ) ) { <nl> auto offset = layout . getPayloadSizeOffset ( ) ; <nl> auto slot = IGF . emitAddressAtOffset ( metadata , offset , IGM . SizeTy , <nl> IGM . getPointerAlignment ( ) ) ; <nl>\n", "msg": "IRGen : Make some metadata builder methods into top level static functions\n"}
{"diff_id": 5150, "repo": "xbmc/xbmc\n", "sha": "c2bd593649ed2493e3502ba15e62c62b1bdbe73f\n", "time": "2016-06-19T06:26:12Z\n", "diff": "mmm a / xbmc / addons / GUIDialogAddonSettings . cpp <nl> ppp b / xbmc / addons / GUIDialogAddonSettings . cpp <nl> void CGUIDialogAddonSettings : : CreateControls ( ) <nl> int iAdd = i ; <nl> if ( entryVec . size ( ) > i ) <nl> iAdd = atoi ( entryVec [ i ] . c_str ( ) ) ; <nl> - if ( ! lvalues . empty ( ) ) <nl> + std : : string replace ; <nl> + if ( std : : all_of ( valuesVec [ i ] . begin ( ) , valuesVec [ i ] . end ( ) , : : isdigit ) ) <nl> { <nl> - std : : string replace = g_localizeStrings . GetAddonString ( m_addon - > ID ( ) , atoi ( valuesVec [ i ] . c_str ( ) ) ) ; <nl> + replace = g_localizeStrings . GetAddonString ( m_addon - > ID ( ) , atoi ( valuesVec [ i ] . c_str ( ) ) ) ; <nl> if ( replace . empty ( ) ) <nl> replace = g_localizeStrings . Get ( atoi ( valuesVec [ i ] . c_str ( ) ) ) ; <nl> - ( ( CGUISpinControlEx * ) pControl ) - > AddLabel ( replace , iAdd ) ; <nl> + if ( replace . empty ( ) ) <nl> + replace = valuesVec [ i ] ; <nl> } <nl> else <nl> - ( ( CGUISpinControlEx * ) pControl ) - > AddLabel ( valuesVec [ i ] , iAdd ) ; <nl> + replace = valuesVec [ i ] ; <nl> + ( ( CGUISpinControlEx * ) pControl ) - > AddLabel ( replace , iAdd ) ; <nl> } <nl> if ( type = = \" labelenum \" ) <nl> { / / need to run through all our settings and find the one that matches <nl>\n", "msg": "[ addons ] Preserve strings which are not string ids in enum lvalues\n"}
{"diff_id": 5208, "repo": "facebook/folly\n", "sha": "7f696fbd87e7bf22936930611a413e29c95f6df7\n", "time": "2018-03-17T18:34:18Z\n", "diff": "mmm a / folly / experimental / coro / tests / CoroTest . cpp <nl> ppp b / folly / experimental / coro / tests / CoroTest . cpp <nl> <nl> * limitations under the License . <nl> * / <nl> <nl> + # include < folly / Portability . h > <nl> + <nl> # if FOLLY_HAS_COROUTINES <nl> <nl> # include < folly / executors / ManualExecutor . h > <nl>\n", "msg": "Include Portability . h before using FOLLY_HAS_COROUTINES\n"}
{"diff_id": 5271, "repo": "taichi-dev/taichi\n", "sha": "a354c0a850a332d3208ade3f30d62f9b51de4b74\n", "time": "2019-07-26T22:21:06Z\n", "diff": "mmm a / src / taichi_llvm_context . cpp <nl> ppp b / src / taichi_llvm_context . cpp <nl> TLANG_NAMESPACE_BEGIN <nl> static llvm : : ExitOnError exit_on_err ; <nl> <nl> TaichiLLVMContext : : TaichiLLVMContext ( ) { <nl> - return ; <nl> llvm : : InitializeNativeTarget ( ) ; <nl> llvm : : InitializeNativeTargetAsmPrinter ( ) ; <nl> llvm : : InitializeNativeTargetAsmParser ( ) ; <nl>\n", "msg": "reenable llvm after fixing glibc ABI version issue on Ubuntu\n"}
{"diff_id": 5391, "repo": "ocornut/imgui\n", "sha": "2c7ba21417dbc82e277e223e556e5a29a0674798\n", "time": "2017-11-07T10:37:38Z\n", "diff": "mmm a / imgui . cpp <nl> ppp b / imgui . cpp <nl> static ImVec2 CalcSizeAutoFit ( ImGuiWindow * window ) <nl> if ( size_auto_fit_after_constraint . x < window - > SizeContents . x & & ! ( flags & ImGuiWindowFlags_NoScrollbar ) & & ( flags & ImGuiWindowFlags_HorizontalScrollbar ) ) <nl> size_auto_fit . y + = style . ScrollbarSize ; <nl> if ( size_auto_fit_after_constraint . y < window - > SizeContents . y & & ! ( flags & ImGuiWindowFlags_NoScrollbar ) ) <nl> - size_auto_fit . x + = style . ScrollbarSize * 2 . 0f ; <nl> + size_auto_fit . x + = style . ScrollbarSize ; <nl> size_auto_fit . y = ImMax ( size_auto_fit . y - style . ItemSpacing . y , 0 . 0f ) ; <nl> } <nl> return size_auto_fit ; <nl>\n", "msg": "Fixed auto - resize allocating too much space for scrollbar when SizeContents is bigger than maximum window size ( fixes c0547d358d746699f8d46a4996e49fdac8c55748 ) ( )\n"}
{"diff_id": 5400, "repo": "opencv/opencv\n", "sha": "d046602ea4e2f8a9b08bd632073816d32fef9ab9\n", "time": "2016-03-29T19:35:27Z\n", "diff": "mmm a / modules / ml / src / svm . cpp <nl> ppp b / modules / ml / src / svm . cpp <nl> class SVMImpl : public SVM <nl> < < \" alpha \" < < \" [ : \" ; <nl> fs . writeRaw ( \" d \" , ( const uchar * ) & df_alpha [ df . ofs ] , sv_count * sizeof ( df_alpha [ 0 ] ) ) ; <nl> fs < < \" ] \" ; <nl> - if ( class_count > 2 ) <nl> + if ( class_count > = 2 ) <nl> { <nl> fs < < \" index \" < < \" [ : \" ; <nl> fs . writeRaw ( \" i \" , ( const uchar * ) & df_index [ df . ofs ] , sv_count * sizeof ( df_index [ 0 ] ) ) ; <nl> class SVMImpl : public SVM <nl> df_index . resize ( ofs + sv_count ) ; <nl> df_alpha . resize ( ofs + sv_count ) ; <nl> dfi [ \" alpha \" ] . readRaw ( \" d \" , ( uchar * ) & df_alpha [ ofs ] , sv_count * sizeof ( df_alpha [ 0 ] ) ) ; <nl> - if ( class_count > 2 ) <nl> + if ( class_count > = 2 ) <nl> dfi [ \" index \" ] . readRaw ( \" i \" , ( uchar * ) & df_index [ ofs ] , sv_count * sizeof ( df_index [ 0 ] ) ) ; <nl> decision_func . push_back ( df ) ; <nl> } <nl> - if ( class_count < = 2 ) <nl> + if ( class_count < 2 ) <nl> setRangeVector ( df_index , sv_total ) ; <nl> if ( ( int ) fn [ \" optimize_linear \" ] ! = 0 ) <nl> optimize_linear_svm ( ) ; <nl>\n", "msg": "Enforced DecisionFunction vector indexes to be saved on SVM save / load methods\n"}
{"diff_id": 5424, "repo": "sqlitebrowser/sqlitebrowser\n", "sha": "9594115ef3b50cb9fc26bc3830c43fd4f9f14f61\n", "time": "2019-07-06T21:05:57Z\n", "diff": "mmm a / src / RowLoader . cpp <nl> ppp b / src / RowLoader . cpp <nl> void RowLoader : : process ( Task & t ) <nl> sqlite3_finalize ( stmt ) ; <nl> } <nl> <nl> - if ( row ! = t . row_begin ) <nl> - emit fetched ( t . token , t . row_begin , row ) ; <nl> + emit fetched ( t . token , t . row_begin , row ) ; <nl> } <nl>\n", "msg": "Send the fetched signal in RowLoader even when no rows where fetched\n"}
{"diff_id": 5434, "repo": "mongodb/mongo\n", "sha": "510c4a6fc3eff8569c5d45e611037a9f412cfe8d\n", "time": "2011-06-10T18:36:41Z\n", "diff": "mmm a / db / repl / rs_config . cpp <nl> ppp b / db / repl / rs_config . cpp <nl> namespace mongo { <nl> / * TODO : use of string exceptions may be problematic for reconfig case ! * / <nl> throw \" _id must be numeric \" ; <nl> } <nl> - string s ; <nl> try { <nl> - s = mobj [ \" host \" ] . String ( ) ; <nl> + string s = mobj [ \" host \" ] . String ( ) ; <nl> m . h = HostAndPort ( s ) ; <nl> + if ( ! m . h . hasPort ( ) ) { <nl> + m . h . setPort ( m . h . port ( ) ) ; <nl> + } <nl> } <nl> catch ( . . . ) { <nl> throw string ( \" bad or missing host field ? \" ) + mobj . toString ( ) ; <nl>\n", "msg": "always set port when for rs config\n"}
{"diff_id": 5436, "repo": "mongodb/mongo\n", "sha": "d8fbead145525c2c79c798cc4b9b129b93c71083\n", "time": "2009-11-03T17:17:56Z\n", "diff": "mmm a / db / mr . cpp <nl> ppp b / db / mr . cpp <nl> namespace mongo { <nl> if ( values . size ( ) ) <nl> db . insert ( fulloutput , reduceValues ( values , s . get ( ) , reduceFunction ) ) ; <nl> <nl> + for ( set < ServerAndQuery > : : iterator i = servers . begin ( ) ; i ! = servers . end ( ) ; i + + ) { <nl> + ScopedDbConnection conn ( i - > _server ) ; <nl> + conn - > dropCollection ( dbname + \" . \" + shardedOutputCollection ) ; <nl> + } <nl> <nl> return 1 ; <nl> } <nl>\n", "msg": "delete temp shard collections on shards SHARDING - 37\n"}
{"diff_id": 5445, "repo": "mongodb/mongo\n", "sha": "18132e81cb12c2b5b90bd556a4f16e233a74e0c9\n", "time": "2010-07-27T16:48:11Z\n", "diff": "mmm a / s / d_state . cpp <nl> ppp b / s / d_state . cpp <nl> namespace mongo { <nl> BSONObj d = cursor - > next ( ) ; <nl> <nl> if ( min . isEmpty ( ) ) { <nl> - min = d [ \" min \" ] . Obj ( ) ; <nl> - max = d [ \" max \" ] . Obj ( ) ; <nl> + min = d [ \" min \" ] . Obj ( ) . getOwned ( ) ; <nl> + max = d [ \" max \" ] . Obj ( ) . getOwned ( ) ; <nl> continue ; <nl> } <nl> <nl> if ( max = = d [ \" min \" ] . Obj ( ) ) { <nl> - max = d [ \" max \" ] . Obj ( ) ; <nl> + max = d [ \" max \" ] . Obj ( ) . getOwned ( ) ; <nl> continue ; <nl> } <nl> <nl> p - > gotRange ( min . getOwned ( ) , max . getOwned ( ) ) ; <nl> - min = d [ \" min \" ] . Obj ( ) ; <nl> - max = d [ \" max \" ] . Obj ( ) ; <nl> + min = d [ \" min \" ] . Obj ( ) . getOwned ( ) ; <nl> + max = d [ \" max \" ] . Obj ( ) . getOwned ( ) ; <nl> } <nl> assert ( ! min . isEmpty ( ) ) ; <nl> p - > gotRange ( min . getOwned ( ) , max . getOwned ( ) ) ; <nl>\n", "msg": "getOwned ( ) on all cursor objects\n"}
{"diff_id": 5697, "repo": "apple/swift\n", "sha": "72f0cc2ab48cbf5903b94ff41d9fca1f1fc5e1e2\n", "time": "2014-12-05T16:52:23Z\n", "diff": "mmm a / lib / SILPasses / PassManager . cpp <nl> ppp b / lib / SILPasses / PassManager . cpp <nl> llvm : : cl : : opt < std : : string > <nl> SILPrintOnlyFun ( \" sil - print - only - function \" , llvm : : cl : : init ( \" \" ) , <nl> llvm : : cl : : desc ( \" Only print out the sil for this function \" ) ) ; <nl> <nl> + llvm : : cl : : opt < std : : string > <nl> + SILPrintBefore ( \" sil - print - before \" , llvm : : cl : : init ( \" \" ) , llvm : : cl : : desc ( <nl> + \" Print out the sil before passes which contain this string \" ) ) ; <nl> + <nl> + llvm : : cl : : opt < std : : string > <nl> + SILPrintAfter ( \" sil - print - after \" , llvm : : cl : : init ( \" \" ) , llvm : : cl : : desc ( <nl> + \" Print out the sil after passes which contain this string \" ) ) ; <nl> + <nl> + llvm : : cl : : opt < std : : string > <nl> + SILPrintAround ( \" sil - print - around \" , llvm : : cl : : init ( \" \" ) , llvm : : cl : : desc ( <nl> + \" Print out the sil before and after passes which contain this string \" ) ) ; <nl> + <nl> + static bool doPrintBefore ( SILTransform * T , SILFunction * F ) { <nl> + if ( ! SILPrintOnlyFun . empty ( ) & & ( ! F | | F - > getName ( ) ! = SILPrintOnlyFun ) ) <nl> + return false ; <nl> + <nl> + if ( ! SILPrintBefore . empty ( ) & & <nl> + T - > getName ( ) . find ( SILPrintBefore ) ! = StringRef : : npos ) <nl> + return true ; <nl> + <nl> + if ( ! SILPrintAround . empty ( ) & & <nl> + T - > getName ( ) . find ( SILPrintAround ) ! = StringRef : : npos ) <nl> + return true ; <nl> + <nl> + return false ; <nl> + } <nl> + <nl> + static bool doPrintAfter ( SILTransform * T , SILFunction * F , bool Default ) { <nl> + if ( ! SILPrintOnlyFun . empty ( ) & & ( ! F | | F - > getName ( ) ! = SILPrintOnlyFun ) ) <nl> + return false ; <nl> + <nl> + if ( ! SILPrintAfter . empty ( ) & & <nl> + T - > getName ( ) . find ( SILPrintAfter ) ! = StringRef : : npos ) <nl> + return true ; <nl> + <nl> + if ( ! SILPrintAround . empty ( ) & & <nl> + T - > getName ( ) . find ( SILPrintAround ) ! = StringRef : : npos ) <nl> + return true ; <nl> + <nl> + return Default ; <nl> + } <nl> + <nl> bool SILPassManager : : <nl> runFunctionPasses ( llvm : : ArrayRef < SILFunctionTransform * > FuncTransforms ) { <nl> CompleteFunctions * CompleteFuncs = getAnalysis < CompleteFunctions > ( ) ; <nl> runFunctionPasses ( llvm : : ArrayRef < SILFunctionTransform * > FuncTransforms ) { <nl> llvm : : dbgs ( ) < < \" # \" < < NumPassesRun < < \" Pass : \" < < SFT - > getName ( ) <nl> < < \" , Function : \" < < F . getName ( ) < < \" \\ n \" ; <nl> <nl> + if ( doPrintBefore ( SFT , & F ) ) { <nl> + llvm : : dbgs ( ) < < \" * * * SIL function before \" < < SFT - > getName ( ) < < \" ( \" <nl> + < < NumOptimizationIterations < < \" ) * * * \\ n \" ; <nl> + F . dump ( ) ; <nl> + } <nl> + <nl> llvm : : sys : : TimeValue StartTime = llvm : : sys : : TimeValue : : now ( ) ; <nl> SFT - > run ( ) ; <nl> <nl> runFunctionPasses ( llvm : : ArrayRef < SILFunctionTransform * > FuncTransforms ) { <nl> } <nl> <nl> / / If this pass invalidated anything , print and verify . <nl> - if ( CompleteFuncs - > hasChanged ( ) ) { <nl> - if ( Options . PrintAll ) { <nl> - if ( SILPrintOnlyFun . empty ( ) | | F . getName ( ) . str ( ) = = SILPrintOnlyFun ) { <nl> - llvm : : dbgs ( ) < < \" * * * SIL function after \" < < SFT - > getName ( ) < < \" ( \" <nl> - < < NumOptimizationIterations < < \" ) * * * \\ n \" ; <nl> - F . dump ( ) ; <nl> - } <nl> - } <nl> - if ( Options . VerifyAll ) { <nl> - F . verify ( ) ; <nl> - } <nl> + if ( doPrintAfter ( SFT , & F , <nl> + CompleteFuncs - > hasChanged ( ) & & Options . PrintAll ) ) { <nl> + llvm : : dbgs ( ) < < \" * * * SIL function after \" < < SFT - > getName ( ) < < \" ( \" <nl> + < < NumOptimizationIterations < < \" ) * * * \\ n \" ; <nl> + F . dump ( ) ; <nl> + } <nl> + if ( CompleteFuncs - > hasChanged ( ) & & Options . VerifyAll ) { <nl> + F . verify ( ) ; <nl> } <nl> } <nl> } <nl> void SILPassManager : : runOneIteration ( ) { <nl> llvm : : dbgs ( ) < < \" # \" < < NumPassesRun < < \" Pass : \" < < SMT - > getName ( ) <nl> < < \" ( module pass ) \\ n \" ; <nl> <nl> + if ( doPrintBefore ( SMT , nullptr ) ) { <nl> + llvm : : dbgs ( ) < < \" * * * SIL module before \" < < SMT - > getName ( ) < < \" ( \" <nl> + < < NumOptimizationIterations < < \" ) * * * \\ n \" ; <nl> + Mod - > dump ( ) ; <nl> + } <nl> + <nl> llvm : : sys : : TimeValue StartTime = llvm : : sys : : TimeValue : : now ( ) ; <nl> SMT - > run ( ) ; <nl> + + NumPassesRun ; <nl> void SILPassManager : : runOneIteration ( ) { <nl> } <nl> <nl> / / If this pass invalidated anything , print and verify . <nl> - if ( CompleteFuncs - > hasChanged ( ) ) { <nl> - if ( Options . PrintAll & & SILPrintOnlyFun . empty ( ) ) { <nl> - llvm : : dbgs ( ) < < \" * * * SIL module after \" < < SMT - > getName ( ) < < \" ( \" <nl> - < < NumOptimizationIterations < < \" ) * * * \\ n \" ; <nl> - Mod - > dump ( ) ; <nl> - } <nl> - if ( Options . VerifyAll ) { <nl> - Mod - > verify ( ) ; <nl> - } <nl> + if ( doPrintAfter ( SMT , nullptr , <nl> + CompleteFuncs - > hasChanged ( ) & & Options . PrintAll ) ) { <nl> + llvm : : dbgs ( ) < < \" * * * SIL module after \" < < SMT - > getName ( ) < < \" ( \" <nl> + < < NumOptimizationIterations < < \" ) * * * \\ n \" ; <nl> + Mod - > dump ( ) ; <nl> + } <nl> + if ( CompleteFuncs - > hasChanged ( ) & & Options . VerifyAll ) { <nl> + Mod - > verify ( ) ; <nl> } <nl> <nl> continue ; <nl>\n", "msg": "Add more options to dump the SIL during optimizations .\n", "score": 1}
{"diff_id": 5709, "repo": "facebook/folly\n", "sha": "135cff30a54b77523ff404a269a960ad981ff8df\n", "time": "2020-01-28T01:26:08Z\n", "diff": "mmm a / folly / synchronization / test / BarrierTest . cpp <nl> ppp b / folly / synchronization / test / BarrierTest . cpp <nl> <nl> <nl> # include < folly / portability / GTest . h > <nl> <nl> - using namespace folly ; <nl> using namespace folly : : test ; <nl> <nl> class BarrierTest : public testing : : Test { } ; <nl>\n", "msg": "Remove dead includes in folly / synchronization\n"}
{"diff_id": 5898, "repo": "facebook/hhvm\n", "sha": "b0e049145f442fb8b87a3146d957ffbbbe276d46\n", "time": "2017-07-12T20:35:46Z\n", "diff": "mmm a / hphp / runtime / ext / json / JSON_parser . cpp <nl> ppp b / hphp / runtime / ext / json / JSON_parser . cpp <nl> struct json_parser { <nl> size_t bufSize = length < = RuntimeOption : : EvalSimpleJsonMaxLength ? <nl> SimpleParser : : BufferBytesForLength ( length ) : <nl> sb_cap * 2 ; <nl> - if ( tl_buffer . raw ) delete [ ] tl_buffer . raw ; <nl> - tl_buffer . raw = new char [ bufSize ] ; <nl> + if ( tl_buffer . raw ) { <nl> + free ( tl_buffer . raw ) ; <nl> + tl_buffer . raw = nullptr ; <nl> + } <nl> + if ( ! MM ( ) . preAllocOOM ( bufSize ) ) { <nl> + tl_buffer . raw = ( char * ) malloc ( bufSize ) ; <nl> + if ( ! tl_buffer . raw ) MM ( ) . forceOOM ( ) ; <nl> + } <nl> + check_non_safepoint_surprise ( ) ; <nl> + always_assert ( tl_buffer . raw ) ; <nl> sb_buf . setBuf ( tl_buffer . raw , sb_cap ) ; <nl> sb_key . setBuf ( tl_buffer . raw + sb_cap , sb_cap ) ; <nl> } else { <nl> struct json_parser { <nl> } <nl> void flushSb ( ) { <nl> if ( tl_buffer . raw ) { <nl> - delete [ ] tl_buffer . raw ; <nl> + free ( tl_buffer . raw ) ; <nl> tl_buffer . raw = nullptr ; <nl> } <nl> sb_cap = 0 ; <nl>\n", "msg": "Throw OOM instead of nullptr deref on huge JSON\n"}
{"diff_id": 5971, "msg": "Added unit tests for the svm_multiclass_linear with sparse priors\n", "msgGPT": "added missing include statements and implemented a new test function for prior_sparse.", "METEOR Score": "14.882546721321843", "BLEU Score": "0.31670241552322603", "ROUGE-L Score": "0.19047618557823143", "score": 1, "repo": "davisking/dlib\n", "sha": "d7f207f2f7e7e29f8807a09ec0b2809eeb24c1f5\n", "time": "2014-05-23T22:35:49Z\n", "diff": "mmm a / dlib / test / svm_multiclass_linear . cpp <nl> ppp b / dlib / test / svm_multiclass_linear . cpp <nl> <nl> # include < dlib / data_io . h > <nl> # include \" create_iris_datafile . h \" <nl> # include < vector > <nl> + # include < map > <nl> # include < sstream > <nl> <nl> namespace <nl> namespace <nl> DLIB_TEST ( ( unsigned int ) sum ( diag ( res ) ) = = samples . size ( ) ) ; <nl> } <nl> <nl> + void test_prior_sparse ( ) <nl> + { <nl> + print_spinner ( ) ; <nl> + typedef std : : map < unsigned long , double > sample_type ; <nl> + typedef sparse_linear_kernel < sample_type > kernel_type ; <nl> + <nl> + std : : vector < sample_type > samples ; <nl> + std : : vector < int > labels ; <nl> + <nl> + for ( int i = 0 ; i < 4 ; + + i ) <nl> + { <nl> + if ( i = = 2 ) <nl> + + + i ; <nl> + for ( int iter = 0 ; iter < 5 ; + + iter ) <nl> + { <nl> + sample_type samp ; <nl> + samp [ i ] = 1 ; <nl> + samples . push_back ( samp ) ; <nl> + labels . push_back ( i ) ; <nl> + } <nl> + } <nl> + <nl> + <nl> + svm_multiclass_linear_trainer < kernel_type , int > trainer ; <nl> + <nl> + multiclass_linear_decision_function < kernel_type , int > df = trainer . train ( samples , labels ) ; <nl> + <nl> + / / cout < < \" test : \\ n \" < < test_multiclass_decision_function ( df , samples , labels ) < < endl ; <nl> + / / cout < < df . weights < < endl ; <nl> + / / cout < < df . b < < endl ; <nl> + <nl> + std : : vector < sample_type > samples2 ; <nl> + std : : vector < int > labels2 ; <nl> + int i = 2 ; <nl> + for ( int iter = 0 ; iter < 5 ; + + iter ) <nl> + { <nl> + sample_type samp ; <nl> + samp [ i ] = 1 ; <nl> + samp [ i + 10 ] = 1 ; <nl> + samples2 . push_back ( samp ) ; <nl> + labels2 . push_back ( i ) ; <nl> + samples . push_back ( samp ) ; <nl> + labels . push_back ( i ) ; <nl> + } <nl> + <nl> + trainer . set_prior ( df ) ; <nl> + trainer . set_c ( 0 . 1 ) ; <nl> + df = trainer . train ( samples2 , labels2 ) ; <nl> + <nl> + matrix < double > res = test_multiclass_decision_function ( df , samples , labels ) ; <nl> + dlog < < LINFO < < \" test : \\ n \" < < res ; <nl> + dlog < < LINFO < < df . weights ; <nl> + dlog < < LINFO < < df . b ; <nl> + DLIB_TEST ( ( unsigned int ) sum ( diag ( res ) ) = = samples . size ( ) ) ; <nl> + } <nl> + <nl> template < typename sample_type > <nl> void run_test ( ) <nl> { <nl> namespace <nl> run_test < std : : vector < std : : pair < unsigned long , double > > > ( ) ; <nl> <nl> test_prior ( ) ; <nl> + test_prior_sparse ( ) ; <nl> } <nl> } ; <nl> <nl>\n"}
{"diff_id": 6306, "repo": "MarlinFirmware/Marlin\n", "sha": "6730408ec10b5dafbdc356c3b4d02f910d85b1d6\n", "time": "2016-04-03T23:27:29Z\n", "diff": "mmm a / Marlin / ultralcd . cpp <nl> ppp b / Marlin / ultralcd . cpp <nl> static void lcd_main_menu ( ) { <nl> END_MENU ( ) ; <nl> } <nl> <nl> - # if ENABLED ( SDSUPPORT ) & & ENABLED ( MENU_ADDAUTOSTART ) <nl> - static void lcd_autostart_sd ( ) { <nl> - card . autostart_index = 0 ; <nl> - card . setroot ( ) ; <nl> - card . checkautostart ( true ) ; <nl> - } <nl> - # endif <nl> <nl> / * * <nl> * Set the home offset based on the current_position <nl> void lcd_cooldown ( ) { <nl> lcd_return_to_status ( ) ; <nl> } <nl> <nl> + # if ENABLED ( SDSUPPORT ) & & ENABLED ( MENU_ADDAUTOSTART ) <nl> + <nl> + static void lcd_autostart_sd ( ) { <nl> + card . autostart_index = 0 ; <nl> + card . setroot ( ) ; <nl> + card . checkautostart ( true ) ; <nl> + } <nl> + <nl> + # endif <nl> / * * <nl> * <nl> * \" Prepare \" submenu <nl>\n", "msg": "Move lcd_autostart_sd to its logical place\n"}
{"diff_id": 6312, "repo": "apple/foundationdb\n", "sha": "1df3d8f0c71226150a88b265dfcb66364f0a046c\n", "time": "2019-05-13T21:15:22Z\n", "diff": "mmm a / flow / Platform . cpp <nl> ppp b / flow / Platform . cpp <nl> void setMemoryQuota ( size_t limit ) { <nl> } <nl> if ( ! AssignProcessToJobObject ( job , GetCurrentProcess ( ) ) ) <nl> TraceEvent ( SevWarn , \" FailedToSetMemoryLimit \" ) . GetLastError ( ) ; <nl> - # elif defined ( __linux__ ) <nl> + # elif defined ( __linux__ ) & & ! defined ( USE_ASAN ) <nl> struct rlimit rlim ; <nl> if ( getrlimit ( RLIMIT_AS , & rlim ) ) { <nl> TraceEvent ( SevError , \" GetMemoryLimit \" ) . GetLastError ( ) ; <nl>\n", "msg": "disable rlimit when ASAN is used\n"}
{"diff_id": 6385, "repo": "xbmc/xbmc\n", "sha": "76fa470de7a8629f5f79b2a57db6a1d388c9eac5\n", "time": "2010-07-02T15:58:33Z\n", "diff": "mmm a / xbmc / cores / dvdplayer / DVDCodecs / Video / CrystalHD . cpp <nl> ppp b / xbmc / cores / dvdplayer / DVDCodecs / Video / CrystalHD . cpp <nl> void CMPCOutputThread : : CopyOutAsNV12 ( CPictureBuffer * pBuffer , BCM : : BC_DTS_PROC_O <nl> } <nl> } <nl> <nl> - # if 0 <nl> + # if _WIN32 <nl> / / Taken from Xine Project ( color . c ) <nl> / / Copyright ( C ) 2000 - 2003 the xine project <nl> / / GNU General Public License version 2 of the License , <nl>\n", "msg": "[ chd ] use c routines for yuy2 to yv12 convert under win platform\n", "score": 1}
{"diff_id": 6449, "repo": "MarlinFirmware/Marlin\n", "sha": "786d1afb72f6374bdef5fd8fcc591d7a0df22499\n", "time": "2016-09-13T08:33:00Z\n", "diff": "mmm a / Marlin / Marlin_main . cpp <nl> ppp b / Marlin / Marlin_main . cpp <nl> void unknown_command_error ( ) { <nl> <nl> # endif / / HOST_KEEPALIVE_FEATURE <nl> <nl> + bool position_is_reachable ( float target [ XYZ ] ) { <nl> + float dx = RAW_X_POSITION ( target [ X_AXIS ] ) , <nl> + dy = RAW_Y_POSITION ( target [ Y_AXIS ] ) ; <nl> + <nl> + # if ENABLED ( DELTA ) <nl> + return HYPOT2 ( dx , dy ) < = sq ( DELTA_PRINTABLE_RADIUS ) ; <nl> + # else <nl> + float dz = RAW_Z_POSITION ( target [ Z_AXIS ] ) ; <nl> + return dx > = X_MIN_POS - 0 . 0001 & & dx < = X_MAX_POS + 0 . 0001 <nl> + & & dy > = Y_MIN_POS - 0 . 0001 & & dy < = Y_MAX_POS + 0 . 0001 <nl> + & & dz > = Z_MIN_POS - 0 . 0001 & & dz < = Z_MAX_POS + 0 . 0001 ; <nl> + # endif <nl> + } <nl> + <nl> / * * <nl> * G0 , G1 : Coordinated movement of X Y Z E axes <nl> * / <nl> inline void gcode_G4 ( ) { <nl> / * * <nl> * Move the Z probe ( or just the nozzle ) to the safe homing point <nl> * / <nl> - float cpx = Z_SAFE_HOMING_X_POINT , cpy = Z_SAFE_HOMING_Y_POINT ; <nl> + destination [ X_AXIS ] = LOGICAL_X_POSITION ( Z_SAFE_HOMING_X_POINT ) ; <nl> + destination [ Y_AXIS ] = LOGICAL_Y_POSITION ( Z_SAFE_HOMING_Y_POINT ) ; <nl> + destination [ Z_AXIS ] = current_position [ Z_AXIS ] ; / / Z is already at the right height <nl> + <nl> # if HAS_BED_PROBE <nl> - cpx - = X_PROBE_OFFSET_FROM_EXTRUDER ; <nl> - cpy - = Y_PROBE_OFFSET_FROM_EXTRUDER ; <nl> + destination [ X_AXIS ] - = X_PROBE_OFFSET_FROM_EXTRUDER ; <nl> + destination [ Y_AXIS ] - = Y_PROBE_OFFSET_FROM_EXTRUDER ; <nl> # endif <nl> <nl> # if ENABLED ( DEBUG_LEVELING_FEATURE ) <nl> - if ( DEBUGGING ( LEVELING ) ) { <nl> - SERIAL_ECHOPAIR ( \" Z_SAFE_HOMING X : \" , cpx ) ; <nl> - SERIAL_ECHOLNPAIR ( \" Y : \" , cpy ) ; <nl> - } <nl> + if ( DEBUGGING ( LEVELING ) ) DEBUG_POS ( \" Z_SAFE_HOMING \" , destination ) ; <nl> # endif <nl> <nl> - if ( cpx > = X_MIN_POS & & cpx < = X_MAX_POS & & cpy > = Y_MIN_POS & & cpy < = Y_MAX_POS ) { <nl> - do_blocking_move_to_xy ( LOGICAL_X_POSITION ( destination [ X_AXIS ] ) , LOGICAL_Y_POSITION ( destination [ Y_AXIS ] ) ) ; <nl> + if ( position_is_reachable ( destination ) ) { <nl> + do_blocking_move_to_xy ( destination [ X_AXIS ] , destination [ Y_AXIS ] ) ; <nl> HOMEAXIS ( Z ) ; <nl> } <nl> else { <nl>\n", "msg": "Add position_is_reachable , use in home_z_safely\n"}
{"diff_id": 6547, "repo": "openalpr/openalpr\n", "sha": "0490bf9127ec7f3586481cfb11bada36acf77855\n", "time": "2015-07-08T11:06:46Z\n", "diff": "mmm a / src / bindings / csharp / openalpr - net / openalpr - net . cpp <nl> ppp b / src / bindings / csharp / openalpr - net / openalpr - net . cpp <nl> using namespace msclr : : interop ; <nl> using namespace System : : Collections : : Generic ; <nl> using namespace System : : Runtime : : InteropServices ; <nl> using namespace System : : Drawing ; <nl> + using namespace System : : Drawing : : Imaging ; <nl> + using namespace System : : IO ; <nl> using namespace alpr ; <nl> <nl> namespace openalprnet { <nl> namespace openalprnet { <nl> private ref class AlprHelper sealed <nl> { <nl> public : <nl> + <nl> static std : : vector < char > ToVector ( array < char > ^ src ) <nl> { <nl> std : : vector < char > result ( src - > Length ) ; <nl> namespace openalprnet { <nl> return result ; <nl> } <nl> <nl> + static cv : : Mat BitmapToMat ( Bitmap ^ bitmap ) <nl> + { <nl> + int channels = 0 ; <nl> + <nl> + switch ( bitmap - > PixelFormat ) <nl> + { <nl> + case PixelFormat : : Format8bppIndexed : <nl> + case PixelFormat : : Format1bppIndexed : <nl> + channels = 1 ; <nl> + break ; <nl> + case PixelFormat : : Format24bppRgb : <nl> + channels = 3 ; <nl> + break ; <nl> + case PixelFormat : : Format32bppRgb : <nl> + case PixelFormat : : Format32bppArgb : <nl> + case PixelFormat : : Format32bppPArgb : <nl> + channels = 4 ; <nl> + break ; <nl> + default : <nl> + throw gcnew NotImplementedException ( ) ; <nl> + } <nl> + <nl> + BitmapData ^ bitmapData = bitmap - > LockBits ( <nl> + System : : Drawing : : Rectangle ( 0 , 0 , bitmap - > Width , bitmap - > Height ) , <nl> + ImageLockMode : : ReadOnly , <nl> + bitmap - > PixelFormat <nl> + ) ; <nl> + <nl> + cv : : Mat dstMat ( cv : : Size ( bitmap - > Width , bitmap - > Height ) , CV_8UC ( channels ) , reinterpret_cast < char * > ( bitmapData - > Scan0 . ToPointer ( ) ) ) ; <nl> + <nl> + bitmap - > UnlockBits ( bitmapData ) ; <nl> + <nl> + return dstMat ; <nl> + } <nl> + <nl> + static Bitmap ^ MatToBitmap ( cv : : Mat mat ) <nl> + { <nl> + const int width = mat . size ( ) . width ; <nl> + const int height = mat . size ( ) . height ; <nl> + const int channels = mat . channels ( ) ; <nl> + const int totalSize = mat . total ( ) ; <nl> + void * data = reinterpret_cast < void * > ( mat . data ) ; <nl> + Bitmap ^ bitmap ; <nl> + <nl> + if ( channels = = 1 ) <nl> + { <nl> + bitmap = gcnew Bitmap ( width , height , PixelFormat : : Format8bppIndexed ) ; <nl> + <nl> + ColorPalette ^ palette = bitmap - > Palette ; <nl> + for ( int i = 0 ; i < 256 ; i + + ) <nl> + { <nl> + palette - > Entries [ i ] = Color : : FromArgb ( i , i , i ) ; <nl> + } <nl> + <nl> + bitmap - > Palette = palette ; <nl> + } <nl> + else <nl> + { <nl> + bitmap = gcnew Bitmap ( width , height , PixelFormat : : Format24bppRgb ) ; <nl> + } <nl> + <nl> + System : : Drawing : : Imaging : : BitmapData ^ bitmapData = bitmap - > LockBits ( <nl> + System : : Drawing : : Rectangle ( 0 , 0 , bitmap - > Width , bitmap - > Height ) , <nl> + System : : Drawing : : Imaging : : ImageLockMode : : ReadWrite , <nl> + bitmap - > PixelFormat <nl> + ) ; <nl> + <nl> + : : memcpy ( bitmapData - > Scan0 . ToPointer ( ) , data , totalSize ) ; <nl> + <nl> + bitmap - > UnlockBits ( bitmapData ) ; <nl> + <nl> + return bitmap ; <nl> + } <nl> + <nl> + static MemoryStream ^ BitmapToMemoryStream ( Bitmap ^ bitmap , ImageFormat ^ imageFormat ) <nl> + { <nl> + MemoryStream ^ ms = gcnew System : : IO : : MemoryStream ( ) ; <nl> + bitmap - > Save ( ms , imageFormat ) ; <nl> + return ms ; <nl> + } <nl> + <nl> + static std : : vector < char > MemoryStreamToVector ( MemoryStream ^ ms ) <nl> + { <nl> + unsigned char * byteArray = ToCharPtr ( ms - > ToArray ( ) ) ; <nl> + std : : vector < char > result ( byteArray , byteArray + ms - > Length ) ; <nl> + return result ; <nl> + } <nl> + <nl> static std : : vector < AlprRegionOfInterest > ToVector ( List < System : : Drawing : : Rectangle > ^ src ) <nl> { <nl> std : : vector < AlprRegionOfInterest > result ; <nl> namespace openalprnet { <nl> } <nl> return std : : string ( ) ; <nl> } <nl> + <nl> + static System : : Drawing : : Rectangle ToRectangle ( cv : : Rect rect ) <nl> + { <nl> + return System : : Drawing : : Rectangle ( rect . x , rect . y , rect . width , rect . height ) ; <nl> + } <nl> + <nl> } ; <nl> <nl> public enum class AlprDetectorTypeNet : int { <nl>\n", "msg": "Add marshalling support for Bitmap , Rectangle and MemoryStream .\n"}
{"diff_id": 6584, "repo": "mongodb/mongo\n", "sha": "024506e7770c69c72374e6ded1a0aa78b05a8c6e\n", "time": "2010-01-20T22:01:58Z\n", "diff": "mmm a / db / db . cpp <nl> ppp b / db / db . cpp <nl> namespace mongo { <nl> break ; <nl> } <nl> <nl> + if ( inShutdown ( ) ) { <nl> + log ( ) < < \" got request after shutdown ( ) \" < < endl ; <nl> + break ; <nl> + } <nl> + <nl> lastError . startRequest ( m , le ) ; <nl> <nl> DbResponse dbresponse ; <nl>\n", "msg": "checking inShutdown ( ) when recv a message\n"}
{"diff_id": 6610, "repo": "mongodb/mongo\n", "sha": "c1901441f0e9c73d5457d3169145fb55a65c7307\n", "time": "2014-08-26T12:20:27Z\n", "diff": "mmm a / src / mongo / db / pipeline / document_source_cursor . cpp <nl> ppp b / src / mongo / db / pipeline / document_source_cursor . cpp <nl> namespace mongo { <nl> return false ; <nl> } <nl> <nl> - namespace { <nl> - Document extractInfo ( ptr < const TypeExplain > info ) { <nl> - MutableDocument out ; <nl> - <nl> - if ( info - > isClausesSet ( ) ) { <nl> - vector < Value > clauses ; <nl> - for ( size_t i = 0 ; i < info - > sizeClauses ( ) ; i + + ) { <nl> - clauses . push_back ( Value ( extractInfo ( info - > getClausesAt ( i ) ) ) ) ; <nl> - } <nl> - out [ TypeExplain : : clauses ( ) ] = Value : : consume ( clauses ) ; <nl> - } <nl> - <nl> - if ( info - > isCursorSet ( ) ) <nl> - out [ TypeExplain : : cursor ( ) ] = Value ( info - > getCursor ( ) ) ; <nl> - <nl> - if ( info - > isIsMultiKeySet ( ) ) <nl> - out [ TypeExplain : : isMultiKey ( ) ] = Value ( info - > getIsMultiKey ( ) ) ; <nl> - <nl> - if ( info - > isScanAndOrderSet ( ) ) <nl> - out [ TypeExplain : : scanAndOrder ( ) ] = Value ( info - > getScanAndOrder ( ) ) ; <nl> - <nl> - # if 0 / / Disabled pending SERVER - 12015 since until then no aggs will be index only . <nl> - if ( info - > isIndexOnlySet ( ) ) <nl> - out [ TypeExplain : : indexOnly ( ) ] = Value ( info - > getIndexOnly ( ) ) ; <nl> - # endif <nl> - <nl> - if ( info - > isIndexBoundsSet ( ) ) <nl> - out [ TypeExplain : : indexBounds ( ) ] = Value ( info - > getIndexBounds ( ) ) ; <nl> - <nl> - if ( info - > isAllPlansSet ( ) ) { <nl> - vector < Value > allPlans ; <nl> - for ( size_t i = 0 ; i < info - > sizeAllPlans ( ) ; i + + ) { <nl> - allPlans . push_back ( Value ( extractInfo ( info - > getAllPlansAt ( i ) ) ) ) ; <nl> - } <nl> - out [ TypeExplain : : allPlans ( ) ] = Value : : consume ( allPlans ) ; <nl> - } <nl> - <nl> - return out . freeze ( ) ; <nl> - } <nl> - } / / namespace <nl> - <nl> Value DocumentSourceCursor : : serialize ( bool explain ) const { <nl> / / we never parse a documentSourceCursor , so we only serialize for explain <nl> if ( ! explain ) <nl> return Value ( ) ; <nl> <nl> + / / Get planner - level explain info from the underlying PlanExecutor . <nl> + BSONObjBuilder explainBuilder ; <nl> Status explainStatus ( ErrorCodes : : InternalError , \" \" ) ; <nl> - scoped_ptr < TypeExplain > plan ; <nl> { <nl> Lock : : DBRead lk ( pExpCtx - > opCtx - > lockState ( ) , _ns ) ; <nl> Client : : Context ctx ( pExpCtx - > opCtx , _ns , / * doVersion = * / false ) ; <nl> <nl> - massert ( 17392 , \" No _exec . Were we disposed before explained ? \" , <nl> - _exec ) ; <nl> + massert ( 17392 , \" No _exec . Were we disposed before explained ? \" , _exec ) ; <nl> <nl> _exec - > restoreState ( pExpCtx - > opCtx ) ; <nl> - <nl> - TypeExplain * explainRaw ; <nl> - explainStatus = Explain : : legacyExplain ( _exec . get ( ) , & explainRaw ) ; <nl> - if ( explainStatus . isOK ( ) ) <nl> - plan . reset ( explainRaw ) ; <nl> - <nl> + explainStatus = Explain : : explainStages ( _exec . get ( ) , Explain : : QUERY_PLANNER , <nl> + & explainBuilder ) ; <nl> _exec - > saveState ( ) ; <nl> } <nl> <nl> namespace { <nl> if ( ! _projection . isEmpty ( ) ) <nl> out [ \" fields \" ] = Value ( _projection ) ; <nl> <nl> + / / Add explain results from the query system into the agg explain output . <nl> if ( explainStatus . isOK ( ) ) { <nl> - out [ \" plan \" ] = Value ( extractInfo ( plan ) ) ; <nl> - } else { <nl> + BSONObj explainObj = explainBuilder . obj ( ) ; <nl> + invariant ( explainObj . hasField ( \" queryPlanner \" ) ) ; <nl> + out [ \" queryPlanner \" ] = Value ( explainObj [ \" queryPlanner \" ] ) ; <nl> + } <nl> + else { <nl> out [ \" planError \" ] = Value ( explainStatus . toString ( ) ) ; <nl> } <nl> <nl>\n", "msg": "SERVER - 14743 agg explain uses explain 2 . 0 format\n"}
{"diff_id": 6723, "repo": "google/flatbuffers\n", "sha": "db0fcdd906422be064ca9bf543b95b6de0f61e6b\n", "time": "2018-11-02T15:54:43Z\n", "diff": "mmm a / src / idl_gen_js . cpp <nl> ppp b / src / idl_gen_js . cpp <nl> class JsGenerator : public BaseGenerator { <nl> const auto basename = <nl> flatbuffers : : StripPath ( flatbuffers : : StripExtension ( file ) ) ; <nl> if ( basename ! = file_name_ ) { <nl> - const auto file_name = basename + kGeneratedFileNamePostfix ; <nl> - code + = GenPrefixedImport ( file , file_name ) ; <nl> + code + = GenPrefixedImport ( file , basename ) ; <nl> } <nl> } <nl> } <nl> class JsGenerator : public BaseGenerator { <nl> return \" NS \" + std : : to_string ( HashFnv1a < uint64_t > ( file . c_str ( ) ) ) ; <nl> } <nl> <nl> - static std : : string GenPrefixedImport ( const std : : string & full_file_name , <nl> - const std : : string & base_file_name ) { <nl> + std : : string GenPrefixedImport ( const std : : string & full_file_name , <nl> + const std : : string & base_name ) { <nl> + / / Either keep the include path as it was <nl> + / / or use only the base_name + kGeneratedFileNamePostfix <nl> + std : : string path ; <nl> + if ( parser_ . opts . keep_include_path ) { <nl> + auto it = parser_ . included_files_ . find ( full_file_name ) ; <nl> + FLATBUFFERS_ASSERT ( it ! = parser_ . included_files_ . end ( ) ) ; <nl> + path = <nl> + flatbuffers : : StripExtension ( it - > second ) + kGeneratedFileNamePostfix ; <nl> + } else { <nl> + path = base_name + kGeneratedFileNamePostfix ; <nl> + } <nl> + <nl> + / / Add the include prefix and make the path always relative <nl> + path = flatbuffers : : ConCatPathFileName ( parser_ . opts . include_prefix , path ) ; <nl> + path = std : : string ( \" . \" ) + kPathSeparator + path ; <nl> + <nl> return \" import * as \" + GenFileNamespacePrefix ( full_file_name ) + <nl> - \" from \\ \" . / \" + base_file_name + \" \\ \" ; \\ n \" ; <nl> + \" from \\ \" \" + path + \" \\ \" ; \\ n \" ; <nl> } <nl> <nl> / / Adds a source - dependent prefix , for of import * statements . <nl>\n", "msg": "- - keep - prefix for JS generator ( )\n"}
{"diff_id": 6840, "repo": "apple/swift\n", "sha": "b9c1785421214cb6e8a753da9b7430b21b8ef1f1\n", "time": "2014-03-01T22:36:27Z\n", "diff": "mmm a / lib / Sema / CSApply . cpp <nl> ppp b / lib / Sema / CSApply . cpp <nl> Expr * ExprRewriter : : coerceToType ( Expr * expr , Type toType , <nl> fromType = expr - > getType ( ) ; <nl> } <nl> <nl> + / / Coercion of a SuperRefExpr . Refine the type of the ' super ' reference <nl> + / / instead of inserting a derived - to - base conversion . <nl> + if ( auto superRef = dyn_cast < SuperRefExpr > ( expr ) ) { <nl> + assert ( tc . isSubtypeOf ( fromType , toType , dc ) & & <nl> + \" coercing super expr to non - supertype ? ! \" ) ; <nl> + superRef - > setType ( toType ) ; <nl> + return expr ; <nl> + } <nl> + <nl> / / Coercion from subclass to superclass . <nl> return new ( tc . Context ) DerivedToBaseExpr ( expr , toType ) ; <nl> } <nl> Expr * ExprRewriter : : coerceToType ( Expr * expr , Type toType , <nl> return expr ; <nl> } <nl> <nl> + / / Coercion of a SuperRefExpr . Refine the type of the ' super ' reference <nl> + / / instead of inserting a derived - to - base conversion . <nl> + if ( auto superRef = dyn_cast < SuperRefExpr > ( expr ) ) { <nl> + assert ( tc . isSubtypeOf ( fromType , toType , dc ) & & <nl> + \" coercing super expr to non - supertype ? ! \" ) ; <nl> + superRef - > setType ( toType ) ; <nl> + return expr ; <nl> + } <nl> + <nl> / / Coercion from subclass to superclass . <nl> expr = new ( tc . Context ) DerivedToBaseExpr ( expr , toType ) ; <nl> return expr ; <nl>\n", "msg": "Revert r14559 ; we still need to cannibalize SuperRefExprs for DI .\n"}
{"diff_id": 7422, "repo": "qbittorrent/qBittorrent\n", "sha": "6b835f53ce9ee4c4eded4e057289a0c9bace5e30\n", "time": "2016-11-10T16:35:40Z\n", "diff": "mmm a / src / base / preferences . cpp <nl> ppp b / src / base / preferences . cpp <nl> void Preferences : : setRssHSplitterState ( const QByteArray & state ) <nl> QByteArray Preferences : : getRssVSplitterState ( ) const <nl> { <nl> # ifdef QBT_USES_QT5 <nl> - return value ( \" Rss / qt5 / splitter_v \" ) . toByteArray ( ) ; <nl> + return value ( \" Rss / qt5 / splitterV \" ) . toByteArray ( ) ; <nl> # else <nl> - return value ( \" Rss / splitter_v \" ) . toByteArray ( ) ; <nl> + return value ( \" Rss / splitterV \" ) . toByteArray ( ) ; <nl> # endif <nl> } <nl> <nl> void Preferences : : setRssVSplitterState ( const QByteArray & state ) <nl> { <nl> # ifdef QBT_USES_QT5 <nl> - setValue ( \" Rss / qt5 / splitter_v \" , state ) ; <nl> + setValue ( \" Rss / qt5 / splitterV \" , state ) ; <nl> # else <nl> - setValue ( \" Rss / splitter_v \" , state ) ; <nl> + setValue ( \" Rss / splitterV \" , state ) ; <nl> # endif <nl> } <nl> <nl>\n", "msg": "Use new key for storing RSS splitter_v value .\n", "score": 1}
{"diff_id": 7572, "repo": "CRYTEK/CRYENGINE\n", "sha": "01fc0687579a58c2a17c748255ad2b29ffa81321\n", "time": "2017-11-30T17:11:12Z\n", "diff": "mmm a / Code / CryEngine / CryAction / MaterialEffects / MaterialEffects . cpp <nl> ppp b / Code / CryEngine / CryAction / MaterialEffects / MaterialEffects . cpp <nl> TMFXEffectId CMaterialEffects : : GetEffectId ( int surfaceIndex1 , int surfaceIndex2 ) <nl> { <nl> m_pVisualDebug - > AddLastSearchHint ( effectId , surfaceIndex1 , surfaceIndex2 ) ; <nl> } <nl> + else <nl> + { <nl> + GameWarning ( \" Could not find a valid effect at row % i and column % i of libs / materialeffects / materialeffects . xml \" , idx1 , idx2 ) ; <nl> + } <nl> } <nl> <nl> return effectId ; <nl> TMFXEffectId CMaterialEffects : : GetEffectId ( const char * customName , int surfaceIn <nl> { <nl> m_pVisualDebug - > AddLastSearchHint ( effectId , customName , surfaceIndex2 ) ; <nl> } <nl> + else <nl> + { <nl> + GameWarning ( \" Could not find a valid effect at row % i and column % i of libs / materialeffects / materialeffects . xml \" , idx1 , idx2 ) ; <nl> + } <nl> } <nl> <nl> return effectId ; <nl> TMFXEffectId CMaterialEffects : : GetEffectId ( IEntityClass * pEntityClass , int surfa <nl> { <nl> m_pVisualDebug - > AddLastSearchHint ( effectId , pEntityClass , surfaceIndex2 ) ; <nl> } <nl> + else <nl> + { <nl> + GameWarning ( \" Could not find a valid effect at row % i and column % i of libs / materialeffects / materialeffects . xml \" , idx1 , idx2 ) ; <nl> + } <nl> } <nl> <nl> return effectId ; <nl>\n", "msg": "! T Adding a warning if the MFX fails to find a valid effect\n"}
{"diff_id": 7590, "repo": "apple/swift\n", "sha": "c4c6a820e5bce915e37306d75e23eea8d86a4303\n", "time": "2017-08-29T14:33:38Z\n", "diff": "mmm a / lib / Driver / ToolChains . cpp <nl> ppp b / lib / Driver / ToolChains . cpp <nl> toolchains : : GenericUnix : : constructInvocation ( const LinkJobAction & job , <nl> Arguments . push_back ( context . Args . MakeArgString ( A - > getValue ( ) ) ) ; <nl> } <nl> <nl> - if ( getTriple ( ) . getOS ( ) = = llvm : : Triple : : Linux ) { <nl> + if ( getTriple ( ) . getOS ( ) = = llvm : : Triple : : Linux & & ! getTriple ( ) . isAndroid ( ) ) { <nl> Arguments . push_back ( \" - pie \" ) ; <nl> } <nl> <nl>\n", "msg": "Avoid adding - pie on Android apps which are - shared\n"}
{"diff_id": 7640, "repo": "apple/swift\n", "sha": "c41969809370750a15cadeca126cf31b9a6571d5\n", "time": "2015-04-22T00:25:43Z\n", "diff": "mmm a / lib / SILGen / SILGenDecl . cpp <nl> ppp b / lib / SILGen / SILGenDecl . cpp <nl> namespace { <nl> / / / An initialization of a local ' var ' . <nl> class LocalVariableInitialization : public SingleBufferInitialization { <nl> / / / The local variable decl being initialized . <nl> - VarDecl * Var ; <nl> - SILGenFunction & Gen ; <nl> + VarDecl * decl ; <nl> + SILGenFunction & SGF ; <nl> <nl> / / / The cleanup we pushed to deallocate the local variable before it <nl> / / / gets initialized . <nl> class LocalVariableInitialization : public SingleBufferInitialization { <nl> / / / Sets up an initialization for the allocated box . This pushes a <nl> / / / CleanupUninitializedBox cleanup that will be replaced when <nl> / / / initialization is completed . <nl> - LocalVariableInitialization ( VarDecl * var , SILGenFunction & gen ) <nl> - : Var ( var ) , Gen ( gen ) { <nl> + LocalVariableInitialization ( VarDecl * decl , bool NeedsMarkUninit , <nl> + SILGenFunction & SGF ) <nl> + : decl ( decl ) , SGF ( SGF ) { <nl> + assert ( decl - > getDeclContext ( ) - > isLocalContext ( ) & & <nl> + \" can ' t emit a local var for a non - local var decl \" ) ; <nl> + assert ( decl - > hasStorage ( ) & & \" can ' t emit storage for a computed variable \" ) ; <nl> + assert ( ! SGF . VarLocs . count ( decl ) & & \" Already have an entry for this decl ? \" ) ; <nl> + <nl> + SILType lType = SGF . getLoweredType ( decl - > getType ( ) - > getRValueType ( ) ) ; <nl> + <nl> + / / The variable may have its lifetime extended by a closure , heap - allocate <nl> + / / it using a box . <nl> + AllocBoxInst * allocBox = SGF . B . createAllocBox ( decl , lType ) ; <nl> + auto box = SILValue ( allocBox , 0 ) ; <nl> + auto addr = SILValue ( allocBox , 1 ) ; <nl> + <nl> + / / Mark the memory as uninitialized , so DI will track it for us . <nl> + if ( NeedsMarkUninit ) <nl> + addr = SGF . B . createMarkUninitializedVar ( decl , addr ) ; <nl> + <nl> + / / / Remember that this is the memory location that we ' re emitting the <nl> + / / / decl to . <nl> + SGF . VarLocs [ decl ] = SILGenFunction : : VarLoc : : get ( addr , box ) ; <nl> + <nl> / / Push a cleanup to destroy the local variable . This has to be <nl> / / inactive until the variable is initialized . <nl> - gen . Cleanups . pushCleanupInState < DestroyLocalVariable > ( CleanupState : : Dormant , <nl> - var ) ; <nl> - ReleaseCleanup = gen . Cleanups . getTopCleanup ( ) ; <nl> + SGF . Cleanups . pushCleanupInState < DestroyLocalVariable > ( CleanupState : : Dormant , <nl> + decl ) ; <nl> + ReleaseCleanup = SGF . Cleanups . getTopCleanup ( ) ; <nl> <nl> / / Push a cleanup to deallocate the local variable . <nl> - gen . Cleanups . pushCleanup < DeallocateUninitializedLocalVariable > ( var ) ; <nl> - DeallocCleanup = gen . Cleanups . getTopCleanup ( ) ; <nl> + SGF . Cleanups . pushCleanup < DeallocateUninitializedLocalVariable > ( decl ) ; <nl> + DeallocCleanup = SGF . Cleanups . getTopCleanup ( ) ; <nl> } <nl> <nl> ~ LocalVariableInitialization ( ) override { <nl> class LocalVariableInitialization : public SingleBufferInitialization { <nl> } <nl> <nl> SILValue getAddressOrNull ( ) const override { <nl> - assert ( Gen . VarLocs . count ( Var ) & & \" did not emit var ? ! \" ) ; <nl> - return Gen . VarLocs [ Var ] . value ; <nl> + assert ( SGF . VarLocs . count ( decl ) & & \" did not emit var ? ! \" ) ; <nl> + return SGF . VarLocs [ decl ] . value ; <nl> } <nl> <nl> - void finishInitialization ( SILGenFunction & gen ) override { <nl> + void finishInitialization ( SILGenFunction & SGF ) override { <nl> assert ( ! DidFinish & & <nl> \" called LocalVariableInitialization : : finishInitialization twice ! \" ) ; <nl> - Gen . Cleanups . setCleanupState ( DeallocCleanup , CleanupState : : Dead ) ; <nl> - Gen . Cleanups . setCleanupState ( ReleaseCleanup , CleanupState : : Active ) ; <nl> + SGF . Cleanups . setCleanupState ( DeallocCleanup , CleanupState : : Dead ) ; <nl> + SGF . Cleanups . setCleanupState ( ReleaseCleanup , CleanupState : : Active ) ; <nl> DidFinish = true ; <nl> } <nl> } ; <nl> void SILGenModule : : emitExternalDefinition ( Decl * d ) { <nl> / / / Create a LocalVariableInitialization for the uninitialized var . <nl> InitializationPtr SILGenFunction : : <nl> emitLocalVariableWithCleanup ( VarDecl * vd , bool NeedsMarkUninit ) { <nl> - assert ( vd - > getDeclContext ( ) - > isLocalContext ( ) & & <nl> - \" can ' t emit a local var for a non - local var decl \" ) ; <nl> - assert ( vd - > hasStorage ( ) & & \" can ' t emit storage for a computed variable \" ) ; <nl> - assert ( ! VarLocs . count ( vd ) & & \" Already have an entry for this decl ? \" ) ; <nl> - <nl> - SILType lType = getLoweredType ( vd - > getType ( ) - > getRValueType ( ) ) ; <nl> - <nl> - / / The variable may have its lifetime extended by a closure , heap - allocate it <nl> - / / using a box . <nl> - AllocBoxInst * allocBox = B . createAllocBox ( vd , lType ) ; <nl> - auto box = SILValue ( allocBox , 0 ) ; <nl> - auto addr = SILValue ( allocBox , 1 ) ; <nl> - <nl> - / / Mark the memory as uninitialized , so DI will track it for us . <nl> - if ( NeedsMarkUninit ) <nl> - addr = B . createMarkUninitializedVar ( vd , addr ) ; <nl> - <nl> - / / / Remember that this is the memory location that we ' re emitting the <nl> - / / / decl to . <nl> - VarLocs [ vd ] = SILGenFunction : : VarLoc : : get ( addr , box ) ; <nl> - <nl> - return InitializationPtr ( new LocalVariableInitialization ( vd , * this ) ) ; <nl> + return InitializationPtr ( new LocalVariableInitialization ( vd , NeedsMarkUninit , <nl> + * this ) ) ; <nl> } <nl> <nl> / / / Create an Initialization for an uninitialized temporary . <nl>\n", "msg": "Now that emitLocalVariable is gone , we can merge all the complexity of\n"}
{"diff_id": 8146, "repo": "telegramdesktop/tdesktop\n", "sha": "0299ba48737dddc99b8d04ed752f8510d85ec2bd\n", "time": "2020-10-01T15:21:39Z\n", "diff": "mmm a / Telegram / SourceFiles / history / history_item . cpp <nl> ppp b / Telegram / SourceFiles / history / history_item . cpp <nl> bool HistoryItem : : canDeleteForEveryone ( TimeId now ) const { <nl> return false ; <nl> } <nl> } <nl> - if ( ! peer - > isUser ( ) & & ! toHistoryMessage ( ) ) { <nl> - return false ; <nl> - } else if ( const auto media = this - > media ( ) ) { <nl> + if ( const auto media = this - > media ( ) ) { <nl> if ( ! media - > allowsRevoke ( now ) ) { <nl> return false ; <nl> } <nl>\n", "msg": "Allow in groups to delete service messages for everyone .\n"}
{"diff_id": 8290, "repo": "pytorch/pytorch\n", "sha": "7879c979b56a0df6cfad21ff231f9241c065b380\n", "time": "2018-11-30T00:04:12Z\n", "diff": "mmm a / aten / src / ATen / native / EmbeddingBag . cpp <nl> ppp b / aten / src / ATen / native / EmbeddingBag . cpp <nl> static Tensor apply_bag_size ( const Tensor & offsets , const Tensor & indices , <nl> / / Avoid dividing by 0 for empty bags . <nl> / / Instead we want empty bags to return all 0s <nl> auto bag_size_ = at : : max ( bag_size , at : : ones_like ( bag_size ) ) <nl> - . toType ( output . type ( ) ) <nl> + . to ( output . options ( ) ) <nl> . unsqueeze ( 1 ) <nl> . expand_as ( output ) ; <nl> output / = bag_size_ ; <nl> static Tensor apply_bag_size_backward ( const Tensor & offsets , <nl> auto bag_size_ = indices . size ( 0 ) ; <nl> output / = bag_size_ ; <nl> } else { <nl> - auto inv_bag_size_ = ( 1 / bag_size . toType ( output . type ( ) ) ) <nl> + auto inv_bag_size_ = ( 1 / bag_size . to ( output . options ( ) ) ) <nl> . unsqueeze ( 1 ) <nl> . index_select ( 0 , offset2bag ) ; <nl> output * = inv_bag_size_ ; <nl> template < typename scalar_t > <nl> std : : tuple < Tensor , Tensor , Tensor , Tensor > embedding_bag_cpu_max ( <nl> const Tensor & weight , const Tensor & indices , const Tensor & offset2bag , const Tensor & output , const Tensor & bag_size , const Tensor & offsets ) { <nl> <nl> - auto max_indices = at : : zeros ( { offsets . size ( 0 ) , weight . size ( 1 ) } , indices . type ( ) ) ; <nl> + auto max_indices = at : : zeros ( { offsets . size ( 0 ) , weight . size ( 1 ) } , indices . options ( ) ) ; <nl> <nl> int64_t numel = indices . numel ( ) ; <nl> int64_t dims = weight . size ( 1 ) ; <nl> _embedding_bag_cpu ( const Tensor & weight , const Tensor & indices , <nl> auto weight_arg = TensorArg ( weight , \" weight \" , 1 ) ; <nl> checkScalarTypes ( \" embedding_bag \" , weight_arg , { kFloat , kDouble } ) ; <nl> <nl> - auto bag_size = at : : zeros ( offsets . sizes ( ) , indices . type ( ) ) ; <nl> + auto bag_size = at : : zeros ( offsets . sizes ( ) , indices . options ( ) ) ; <nl> make_bag_size ( offsets , indices , mode , bag_size ) ; <nl> <nl> / / If the last entries are empty , that the last offsets are irrelevant as they <nl> _embedding_bag_cpu ( const Tensor & weight , const Tensor & indices , <nl> auto output = at : : zeros ( { offsets . size ( 0 ) , weight . size ( 1 ) } , weight . options ( ) ) ; <nl> <nl> if ( mode = = MODE_MEAN | | mode = = MODE_SUM ) { <nl> - if ( weight . type ( ) . scalarType ( ) = = kFloat ) { <nl> + if ( weight . scalar_type ( ) = = kFloat ) { <nl> index_select_add < float > ( indices , offset2bag , weight , output ) ; <nl> - } else if ( weight . type ( ) . scalarType ( ) = = kDouble ) { <nl> + } else if ( weight . scalar_type ( ) = = kDouble ) { <nl> index_select_add < double > ( indices , offset2bag , weight , output ) ; <nl> } <nl> auto ret = apply_bag_size ( offsets , indices , mode , output , bag_size ) ; <nl> Tensor _embedding_bag_dense_backward_cpu ( const Tensor & grad_ , const Tensor & indi <nl> } <nl> <nl> auto index_grad_weight = <nl> - at : : zeros ( { num_weights , grad . size ( 1 ) } , grad . type ( ) ) . contiguous ( ) ; <nl> + at : : zeros ( { num_weights , grad . size ( 1 ) } , grad . options ( ) ) . contiguous ( ) ; <nl> <nl> std : : vector < int64_t > counts_uniq ; <nl> counts_uniq . reserve ( num_weights ) ; <nl> Tensor _embedding_bag_dense_backward_cpu ( const Tensor & grad_ , const Tensor & indi <nl> } <nl> } <nl> int64_t ddim = grad . size ( 1 ) ; <nl> - if ( grad . type ( ) . scalarType ( ) = = kFloat ) { <nl> + if ( grad . scalar_type ( ) = = kFloat ) { <nl> auto igwd = index_grad_weight . data < float > ( ) ; <nl> auto gd = grad . data < float > ( ) ; <nl> THBlas_axpy < float > ( ddim , ( float ) scale , gd + ddim * source , 1 , <nl> igwd + ddim * index , 1 ) ; <nl> - } else if ( grad . type ( ) . scalarType ( ) = = kDouble ) { <nl> + } else if ( grad . scalar_type ( ) = = kDouble ) { <nl> auto igwd = index_grad_weight . data < double > ( ) ; <nl> auto gd = grad . data < double > ( ) ; <nl> THBlas_axpy < double > ( ddim , ( double ) scale , gd + ddim * source , 1 , <nl>\n", "msg": "Expunge uses of type ( ) from EmbeddingBag . ( )\n"}
{"diff_id": 8313, "repo": "xbmc/xbmc\n", "sha": "87b242f779ed612c96c291061c6602914df0cc14\n", "time": "2012-11-11T02:42:45Z\n", "diff": "mmm a / xbmc / PlayListPlayer . cpp <nl> ppp b / xbmc / PlayListPlayer . cpp <nl> bool CPlayListPlayer : : Play ( int iSong , bool bAutoPlay / * = false * / , bool bPlayPr <nl> } <nl> } <nl> <nl> + / / reset the start offset of this item <nl> + if ( item - > m_lStartOffset = = STARTOFFSET_RESUME ) <nl> + item - > m_lStartOffset = 0 ; <nl> + <nl> / / TODO - move the above failure logic and the below success logic <nl> / / to callbacks instead so we don ' t rely on the return value <nl> / / of PlayFile ( ) <nl>\n", "msg": "reset resume point after playing items via the playlist player , so that when they repeat the start at the beginning . fixes\n", "score": 1}
{"diff_id": 8360, "msg": "[ PlaygroundTransform ] Implemented support for defer statements .\n", "msgGPT": "add support for transforming defer stmt in instrumenter class.", "METEOR Score": "24.34208404465628", "BLEU Score": "0.5376318674475572", "ROUGE-L Score": "0.3333333283333334", "score": 1, "repo": "apple/swift\n", "sha": "0a9a4e7d6f267bfb1b52cdbd3d72bcc628e9e96d\n", "time": "2018-01-09T19:21:52Z\n", "diff": "mmm a / lib / Sema / PlaygroundTransform . cpp <nl> ppp b / lib / Sema / PlaygroundTransform . cpp <nl> class Instrumenter : InstrumenterBase { <nl> return S ; <nl> case StmtKind : : Brace : <nl> return transformBraceStmt ( cast < BraceStmt > ( S ) ) ; <nl> + case StmtKind : : Defer : <nl> + return transformDeferStmt ( cast < DeferStmt > ( S ) ) ; <nl> case StmtKind : : If : <nl> return transformIfStmt ( cast < IfStmt > ( S ) ) ; <nl> case StmtKind : : Guard : <nl> class Instrumenter : InstrumenterBase { <nl> } <nl> } <nl> <nl> + DeferStmt * transformDeferStmt ( DeferStmt * DS ) { <nl> + if ( auto * FD = DS - > getTempDecl ( ) ) { <nl> + auto Implicit = FD - > isImplicit ( ) ; <nl> + FD - > setImplicit ( false ) ; <nl> + auto * D = transformDecl ( FD ) ; <nl> + D - > setImplicit ( Implicit ) ; <nl> + assert ( D = = FD ) ; <nl> + } <nl> + return DS ; <nl> + } <nl> + <nl> / / transform * ( ) return their input if it ' s unmodified , <nl> / / or a modified copy of their input otherwise . <nl> IfStmt * transformIfStmt ( IfStmt * IS ) { <nl>\n"}
{"diff_id": 8386, "repo": "aseprite/aseprite\n", "sha": "2ac1d38d623c82e7e79d5c038f7ca85854ae5b99\n", "time": "2011-03-02T01:37:00Z\n", "diff": "mmm a / src / gui / popup_frame . cpp <nl> ppp b / src / gui / popup_frame . cpp <nl> bool PopupFrame : : onProcessMessage ( JMessage msg ) <nl> break ; <nl> <nl> case JM_KEYPRESSED : <nl> - if ( m_filtering & & msg - > key . scancode < KEY_MODIFIERS ) <nl> + if ( m_filtering & & <nl> + ( msg - > key . scancode = = KEY_ESC | | <nl> + msg - > key . scancode = = KEY_ENTER | | <nl> + msg - > key . scancode = = KEY_ENTER_PAD ) ) { <nl> closeWindow ( NULL ) ; <nl> - break ; <nl> + } <nl> + return false ; <nl> <nl> case JM_BUTTONPRESSED : <nl> / * if the user click outside the window , we have to close the <nl>\n", "msg": "Avoid sending keys to gui manager when a popup frame is visible .\n"}
{"diff_id": 8509, "repo": "opencv/opencv\n", "sha": "670ef403b0c18019b0a2778f7d4e6ae4b37b01ff\n", "time": "2018-04-13T11:54:27Z\n", "diff": "mmm a / modules / core / src / ocl . cpp <nl> ppp b / modules / core / src / ocl . cpp <nl> class OpenCLBufferPoolImpl CV_FINAL : public OpenCLBufferPoolBaseImpl < OpenCLBuff <nl> entry . capacity_ = alignSize ( size , ( int ) _allocationGranularity ( size ) ) ; <nl> Context & ctx = Context : : getDefault ( ) ; <nl> cl_int retval = CL_SUCCESS ; <nl> - CV_OCL_CHECK_ ( entry . clBuffer_ = clCreateBuffer ( ( cl_context ) ctx . ptr ( ) , CL_MEM_READ_WRITE | createFlags_ , entry . capacity_ , 0 , & retval ) , retval ) ; <nl> + entry . clBuffer_ = clCreateBuffer ( ( cl_context ) ctx . ptr ( ) , CL_MEM_READ_WRITE | createFlags_ , entry . capacity_ , 0 , & retval ) ; <nl> + CV_OCL_CHECK_RESULT ( retval , cv : : format ( \" clCreateBuffer ( capacity = % lld ) = > % p \" , ( long long int ) entry . capacity_ , ( void * ) entry . clBuffer_ ) . c_str ( ) ) ; <nl> CV_Assert ( entry . clBuffer_ ! = NULL ) ; <nl> if ( retval = = CL_SUCCESS ) <nl> { <nl> class OpenCLAllocator CV_FINAL : public MatAllocator <nl> { <nl> handle = clCreateBuffer ( ctx_handle , CL_MEM_USE_HOST_PTR | createFlags , <nl> u - > size , u - > origdata , & retval ) ; <nl> + CV_OCL_DBG_CHECK_RESULT ( retval , cv : : format ( \" clCreateBuffer ( CL_MEM_USE_HOST_PTR | createFlags , sz = % lld , origdata = % p ) = > % p \" , <nl> + ( long long int ) u - > size , u - > origdata , ( void * ) handle ) . c_str ( ) ) ; <nl> } <nl> if ( ( ! handle | | retval < 0 ) & & ! ( accessFlags & ACCESS_FAST ) ) <nl> { <nl> handle = clCreateBuffer ( ctx_handle , CL_MEM_COPY_HOST_PTR | CL_MEM_READ_WRITE | createFlags , <nl> u - > size , u - > origdata , & retval ) ; <nl> + CV_OCL_DBG_CHECK_RESULT ( retval , cv : : format ( \" clCreateBuffer ( CL_MEM_COPY_HOST_PTR | CL_MEM_READ_WRITE | createFlags , sz = % lld , origdata = % p ) = > % p \" , <nl> + ( long long int ) u - > size , u - > origdata , ( void * ) handle ) . c_str ( ) ) ; <nl> tempUMatFlags | = UMatData : : TEMP_COPIED_UMAT ; <nl> } <nl> } <nl> - CV_OCL_DBG_CHECK_RESULT ( retval , \" clCreateBuffer ( ) \" ) ; <nl> + CV_OCL_DBG_CHECK_RESULT ( retval , cv : : format ( \" clCreateBuffer ( ) = > % p \" , ( void * ) handle ) . c_str ( ) ) ; <nl> if ( ! handle | | retval ! = CL_SUCCESS ) <nl> return false ; <nl> u - > handle = handle ; <nl> class OpenCLAllocator CV_FINAL : public MatAllocator <nl> void * data = clEnqueueMapBuffer ( q , ( cl_mem ) u - > handle , CL_TRUE , <nl> ( CL_MAP_READ | CL_MAP_WRITE ) , <nl> 0 , u - > size , 0 , 0 , 0 , & retval ) ; <nl> - CV_OCL_CHECK_RESULT ( retval , \" clEnqueueMapBuffer ( ) \" ) ; <nl> + CV_OCL_CHECK_RESULT ( retval , cv : : format ( \" clEnqueueMapBuffer ( handle = % p , sz = % lld ) = > % p \" , ( void * ) u - > handle , ( long long int ) u - > size , data ) . c_str ( ) ) ; <nl> CV_Assert ( u - > origdata = = data ) ; <nl> if ( u - > originalUMatData ) <nl> { <nl> CV_Assert ( u - > originalUMatData - > data = = data ) ; <nl> } <nl> - CV_OCL_CHECK ( clEnqueueUnmapMemObject ( q , ( cl_mem ) u - > handle , data , 0 , 0 , 0 ) ) ; <nl> + retval = clEnqueueUnmapMemObject ( q , ( cl_mem ) u - > handle , data , 0 , 0 , 0 ) ; <nl> + CV_OCL_CHECK_RESULT ( retval , cv : : format ( \" clEnqueueUnmapMemObject ( handle = % p , data = % p , [ sz = % lld ] ) \" , ( void * ) u - > handle , data , ( long long int ) u - > size ) . c_str ( ) ) ; <nl> CV_OCL_DBG_CHECK ( clFinish ( q ) ) ; <nl> } <nl> } <nl> class OpenCLAllocator CV_FINAL : public MatAllocator <nl> else <nl> # endif <nl> { <nl> - CV_OCL_DBG_CHECK ( clReleaseMemObject ( ( cl_mem ) u - > handle ) ) ; <nl> + cl_int retval = clReleaseMemObject ( ( cl_mem ) u - > handle ) ; <nl> + CV_OCL_DBG_CHECK_RESULT ( retval , cv : : format ( \" clReleaseMemObject ( ptr = % p ) \" , ( void * ) u - > handle ) . c_str ( ) ) ; <nl> } <nl> u - > handle = 0 ; <nl> u - > markDeviceCopyObsolete ( true ) ; <nl> class OpenCLAllocator CV_FINAL : public MatAllocator <nl> u - > data = ( uchar * ) clEnqueueMapBuffer ( q , ( cl_mem ) u - > handle , CL_TRUE , <nl> ( CL_MAP_READ | CL_MAP_WRITE ) , <nl> 0 , u - > size , 0 , 0 , 0 , & retval ) ; <nl> - CV_OCL_DBG_CHECK_RESULT ( retval , cv : : format ( \" clEnqueueMapBuffer ( sz = % lld ) \" , ( int64 ) u - > size ) . c_str ( ) ) ; <nl> + CV_OCL_DBG_CHECK_RESULT ( retval , cv : : format ( \" clEnqueueMapBuffer ( handle = % p , sz = % lld ) = > % p \" , ( void * ) u - > handle , ( long long int ) u - > size , u - > data ) . c_str ( ) ) ; <nl> } <nl> if ( u - > data & & retval = = CL_SUCCESS ) <nl> { <nl> class OpenCLAllocator CV_FINAL : public MatAllocator <nl> # ifdef HAVE_OPENCL_SVM <nl> CV_DbgAssert ( ( u - > allocatorFlags_ & svm : : OPENCL_SVM_BUFFER_MASK ) = = 0 ) ; <nl> # endif <nl> - CV_OCL_CHECK ( clEnqueueReadBuffer ( q , ( cl_mem ) u - > handle , CL_TRUE , <nl> - 0 , u - > size , alignedPtr . getAlignedPtr ( ) , 0 , 0 , 0 ) ) ; <nl> + cl_int retval = clEnqueueReadBuffer ( q , ( cl_mem ) u - > handle , CL_TRUE , <nl> + 0 , u - > size , alignedPtr . getAlignedPtr ( ) , 0 , 0 , 0 ) ; <nl> + CV_OCL_CHECK_RESULT ( retval , cv : : format ( \" clEnqueueReadBuffer ( q , handle = % p , CL_TRUE , 0 , sz = % lld , data = % p , 0 , 0 , 0 ) \" , <nl> + ( void * ) u - > handle , ( long long int ) u - > size , alignedPtr . getAlignedPtr ( ) ) . c_str ( ) ) ; <nl> u - > markHostCopyObsolete ( false ) ; <nl> } <nl> } <nl> class OpenCLAllocator CV_FINAL : public MatAllocator <nl> if ( u - > refcount = = 0 ) <nl> { <nl> CV_Assert ( u - > mapcount - - = = 1 ) ; <nl> - CV_OCL_CHECK ( retval = clEnqueueUnmapMemObject ( q , ( cl_mem ) u - > handle , u - > data , 0 , 0 , 0 ) ) ; <nl> + retval = clEnqueueUnmapMemObject ( q , ( cl_mem ) u - > handle , u - > data , 0 , 0 , 0 ) ; <nl> + CV_OCL_CHECK_RESULT ( retval , cv : : format ( \" clEnqueueUnmapMemObject ( handle = % p , data = % p , [ sz = % lld ] ) \" , ( void * ) u - > handle , u - > data , ( long long int ) u - > size ) . c_str ( ) ) ; <nl> if ( Device : : getDefault ( ) . isAMD ( ) ) <nl> { <nl> / / required for multithreaded applications ( see stitching test ) <nl> class OpenCLAllocator CV_FINAL : public MatAllocator <nl> # ifdef HAVE_OPENCL_SVM <nl> CV_DbgAssert ( ( u - > allocatorFlags_ & svm : : OPENCL_SVM_BUFFER_MASK ) = = 0 ) ; <nl> # endif <nl> - CV_OCL_CHECK ( retval = clEnqueueWriteBuffer ( q , ( cl_mem ) u - > handle , CL_TRUE , <nl> - 0 , u - > size , alignedPtr . getAlignedPtr ( ) , 0 , 0 , 0 ) ) ; <nl> + retval = clEnqueueWriteBuffer ( q , ( cl_mem ) u - > handle , CL_TRUE , <nl> + 0 , u - > size , alignedPtr . getAlignedPtr ( ) , 0 , 0 , 0 ) ; <nl> + CV_OCL_CHECK_RESULT ( retval , cv : : format ( \" clEnqueueWriteBuffer ( q , handle = % p , CL_TRUE , 0 , sz = % lld , data = % p , 0 , 0 , 0 ) \" , <nl> + ( void * ) u - > handle , ( long long int ) u - > size , alignedPtr . getAlignedPtr ( ) ) . c_str ( ) ) ; <nl> u - > markDeviceCopyObsolete ( false ) ; <nl> u - > markHostCopyObsolete ( true ) ; <nl> } <nl> class OpenCLAllocator CV_FINAL : public MatAllocator <nl> if ( iscontinuous ) <nl> { <nl> AlignedDataPtr < true , false > alignedPtr ( ( uchar * ) srcptr , total , CV_OPENCL_DATA_PTR_ALIGNMENT ) ; <nl> - CV_OCL_CHECK ( clEnqueueWriteBuffer ( q , ( cl_mem ) u - > handle , CL_TRUE , <nl> - dstrawofs , total , alignedPtr . getAlignedPtr ( ) , 0 , 0 , 0 ) ) ; <nl> + cl_int retval = clEnqueueWriteBuffer ( q , ( cl_mem ) u - > handle , CL_TRUE , <nl> + dstrawofs , total , alignedPtr . getAlignedPtr ( ) , 0 , 0 , 0 ) ; <nl> + CV_OCL_CHECK_RESULT ( retval , cv : : format ( \" clEnqueueWriteBuffer ( q , handle = % p , CL_TRUE , offset = % lld , sz = % lld , data = % p , 0 , 0 , 0 ) \" , <nl> + ( void * ) u - > handle , ( long long int ) dstrawofs , ( long long int ) u - > size , alignedPtr . getAlignedPtr ( ) ) . c_str ( ) ) ; <nl> } <nl> else if ( CV_OPENCL_DISABLE_BUFFER_RECT_OPERATIONS ) <nl> { <nl> class OpenCLAllocator CV_FINAL : public MatAllocator <nl> { <nl> if ( iscontinuous ) <nl> { <nl> - CV_OCL_CHECK ( retval = clEnqueueCopyBuffer ( q , ( cl_mem ) src - > handle , ( cl_mem ) dst - > handle , <nl> - srcrawofs , dstrawofs , total , 0 , 0 , 0 ) ) ; <nl> + retval = clEnqueueCopyBuffer ( q , ( cl_mem ) src - > handle , ( cl_mem ) dst - > handle , <nl> + srcrawofs , dstrawofs , total , 0 , 0 , 0 ) ; <nl> + CV_OCL_CHECK_RESULT ( retval , cv : : format ( \" clEnqueueCopyBuffer ( q , src = % p , dst = % p , src_offset = % lld , dst_offset = % lld , sz = % lld , 0 , 0 , 0 ) \" , <nl> + ( void * ) src - > handle , ( void * ) dst - > handle , ( long long int ) srcrawofs , ( long long int ) dstrawofs , ( long long int ) total ) . c_str ( ) ) ; <nl> } <nl> else if ( CV_OPENCL_DISABLE_BUFFER_RECT_OPERATIONS ) <nl> { <nl> struct Image2D : : Impl <nl> if ( ! alias & & ! src . isContinuous ( ) ) <nl> { <nl> devData = clCreateBuffer ( context , CL_MEM_READ_ONLY , src . cols * src . rows * src . elemSize ( ) , NULL , & err ) ; <nl> - CV_OCL_CHECK_RESULT ( err , \" clCreateBuffer ( ) \" ) ; <nl> + CV_OCL_CHECK_RESULT ( err , cv : : format ( \" clCreateBuffer ( CL_MEM_READ_ONLY , sz = % lld ) = > % p \" , <nl> + ( long long int ) ( src . cols * src . rows * src . elemSize ( ) ) , ( void * ) devData <nl> + ) . c_str ( ) ) ; <nl> <nl> const size_t roi [ 3 ] = { static_cast < size_t > ( src . cols ) * src . elemSize ( ) , static_cast < size_t > ( src . rows ) , 1 } ; <nl> CV_OCL_CHECK ( clEnqueueCopyBufferRect ( queue , ( cl_mem ) src . handle ( ACCESS_READ ) , devData , origin , origin , <nl>\n", "msg": "ocl : improve trace messages of OpenCL calls\n"}
{"diff_id": 8542, "repo": "opencv/opencv\n", "sha": "4255746c0090408ad43d7073ad64bbe0e38d3a1a\n", "time": "2014-07-28T11:20:25Z\n", "diff": "mmm a / modules / imgproc / src / demosaicing . cpp <nl> ppp b / modules / imgproc / src / demosaicing . cpp <nl> class SIMDBayerStubInterpolator_ <nl> { <nl> return 0 ; <nl> } <nl> - <nl> + <nl> int bayer2RGBA ( const T * , int , T * , int , int ) const <nl> { <nl> return 0 ; <nl> class SIMDBayerInterpolator_8u <nl> return ( int ) ( bayer - ( bayer_end - width ) ) ; <nl> } <nl> <nl> - int bayer2RGBA ( const uchar * bayer , int bayer_step , uchar * dst , int width , int blue ) const <nl> + int bayer2RGBA ( const uchar * , int , uchar * , int , int ) const <nl> { <nl> return 0 ; <nl> } <nl> class SIMDBayerInterpolator_8u <nl> vst1_u8 ( dst , p . val [ 0 ] ) ; <nl> vst1_u8 ( dst + 8 , p . val [ 1 ] ) ; <nl> } <nl> - <nl> + <nl> return ( int ) ( bayer - ( bayer_end - width ) ) ; <nl> } <nl> <nl> class SIMDBayerInterpolator_8u <nl> <nl> return ( int ) ( bayer - ( bayer_end - width ) ) ; <nl> } <nl> - <nl> + <nl> int bayer2RGBA ( const uchar * bayer , int bayer_step , uchar * dst , int width , int blue ) const <nl> { <nl> / * <nl> class SIMDBayerInterpolator_8u <nl> <nl> vst4q_u8 ( dst - 1 , pix ) ; <nl> } <nl> - <nl> + <nl> return ( int ) ( bayer - ( bayer_end - width ) ) ; <nl> } <nl> <nl> - int bayer2RGB_EA ( const uchar * bayer , int bayer_step , uchar * dst , int width , int blue ) const <nl> + int bayer2RGB_EA ( const uchar * , int , uchar * , int , int ) const <nl> { <nl> return 0 ; <nl> } <nl> class Bayer2RGB_Invoker : <nl> } <nl> <nl> / / simd optimization only for dcn = = 3 <nl> - int delta = dcn = = 4 ? <nl> + int delta = dcn = = 4 ? <nl> vecOp . bayer2RGBA ( bayer , bayer_step , dst , size . width , blue ) : <nl> vecOp . bayer2RGB ( bayer , bayer_step , dst , size . width , blue ) ; <nl> bayer + = delta ; <nl>\n", "msg": "fixed compile warnings and removed extra whitespaces\n"}
{"diff_id": 8543, "msg": "valuetest : add tests for rvalue references , reenable erase / remove pattern\n", "msgGPT": "add tests for move constructor and assignment operator using C++11 rvalue references in rapid json library.", "METEOR Score": "35.39946418767293", "BLEU Score": "0.3855595124268638", "ROUGE-L Score": "0.34482758126040436", "score": 1, "repo": "Tencent/rapidjson\n", "sha": "36031b1b6f12b38a0e92cd6fc8293f66725dc465\n", "time": "2014-08-31T15:32:31Z\n", "diff": "mmm a / test / unittest / valuetest . cpp <nl> ppp b / test / unittest / valuetest . cpp <nl> TEST ( Value , DefaultConstructor ) { <nl> / / Value y = x ; <nl> / / } <nl> <nl> + # if RAPIDJSON_HAS_CXX11_RVALUE_REFS <nl> + TEST ( Value , MoveConstructor ) { <nl> + typedef GenericValue < UTF8 < > , CrtAllocator > Value ; <nl> + Value : : AllocatorType allocator ; <nl> + <nl> + Value x ( ( Value ( kArrayType ) ) ) ; <nl> + x . Reserve ( 4u , allocator ) ; <nl> + x . PushBack ( 1 , allocator ) . PushBack ( 2 , allocator ) . PushBack ( 3 , allocator ) . PushBack ( 4 , allocator ) ; <nl> + EXPECT_TRUE ( x . IsArray ( ) ) ; <nl> + EXPECT_EQ ( 4u , x . Size ( ) ) ; <nl> + <nl> + / / Value y ( x ) ; / / should not compile <nl> + Value y ( std : : move ( x ) ) ; <nl> + EXPECT_TRUE ( x . IsNull ( ) ) ; <nl> + EXPECT_TRUE ( y . IsArray ( ) ) ; <nl> + EXPECT_EQ ( 4u , y . Size ( ) ) ; <nl> + <nl> + / / Value z = y ; / / should not compile <nl> + Value z = std : : move ( y ) ; <nl> + EXPECT_TRUE ( y . IsNull ( ) ) ; <nl> + EXPECT_TRUE ( z . IsArray ( ) ) ; <nl> + EXPECT_EQ ( 4u , z . Size ( ) ) ; <nl> + } <nl> + # endif / / RAPIDJSON_HAS_CXX11_RVALUE_REFS <nl> + <nl> TEST ( Value , AssignmentOperator ) { <nl> Value x ( 1234 ) ; <nl> Value y ; <nl> TEST ( Value , AssignmentOperator ) { <nl> y = StringRef ( mstr ) ; <nl> EXPECT_TRUE ( y . IsString ( ) ) ; <nl> EXPECT_EQ ( y . GetString ( ) , mstr ) ; <nl> + <nl> + # if RAPIDJSON_HAS_CXX11_RVALUE_REFS <nl> + / / C + + 11 move assignment <nl> + x = Value ( \" World \" ) ; <nl> + EXPECT_TRUE ( x . IsString ( ) ) ; <nl> + EXPECT_STREQ ( \" World \" , x . GetString ( ) ) ; <nl> + <nl> + x = std : : move ( y ) ; <nl> + EXPECT_TRUE ( y . IsNull ( ) ) ; <nl> + EXPECT_TRUE ( x . IsString ( ) ) ; <nl> + EXPECT_EQ ( x . GetString ( ) , mstr ) ; <nl> + <nl> + y = std : : move ( Value ( ) . SetInt ( 1234 ) ) ; <nl> + EXPECT_TRUE ( y . IsInt ( ) ) ; <nl> + EXPECT_EQ ( 1234 , y ) ; <nl> + # endif / / RAPIDJSON_HAS_CXX11_RVALUE_REFS <nl> } <nl> <nl> template < typename A , typename B > <nl> TEST ( Value , Array ) { <nl> EXPECT_TRUE ( y [ 4u ] . IsString ( ) ) ; <nl> EXPECT_STREQ ( \" foo \" , y [ 4u ] . GetString ( ) ) ; <nl> <nl> + # if RAPIDJSON_HAS_CXX11_RVALUE_REFS <nl> + / / PushBack ( GenericValue & & , Allocator & ) ; <nl> + { <nl> + Value y ( kArrayType ) ; <nl> + y . PushBack ( Value ( true ) , allocator ) ; <nl> + y . PushBack ( std : : move ( Value ( kArrayType ) . PushBack ( Value ( 1 ) , allocator ) . PushBack ( \" foo \" , allocator ) ) , allocator ) ; <nl> + EXPECT_EQ ( 2u , y . Size ( ) ) ; <nl> + EXPECT_TRUE ( y [ 0u ] . IsTrue ( ) ) ; <nl> + EXPECT_TRUE ( y [ 1u ] . IsArray ( ) ) ; <nl> + EXPECT_EQ ( 2u , y [ 1u ] . Size ( ) ) ; <nl> + EXPECT_TRUE ( y [ 1u ] [ 0u ] . IsInt ( ) ) ; <nl> + EXPECT_TRUE ( y [ 1u ] [ 1u ] . IsString ( ) ) ; <nl> + } <nl> + # endif <nl> + <nl> / / iterator <nl> Value : : ValueIterator itr = x . Begin ( ) ; <nl> EXPECT_TRUE ( itr ! = x . End ( ) ) ; <nl> TEST ( Value , Array ) { <nl> } <nl> <nl> / / Working in gcc without C + + 11 , but VS2013 cannot compile . To be diagnosed . <nl> - # if 0 <nl> / / http : / / en . wikipedia . org / wiki / Erase - remove_idiom <nl> x . Clear ( ) ; <nl> for ( int i = 0 ; i < 10 ; i + + ) <nl> TEST ( Value , Array ) { <nl> else <nl> x . PushBack ( Value ( kNullType ) . Move ( ) , allocator ) ; <nl> <nl> - x . Erase ( std : : remove ( x . Begin ( ) , x . End ( ) , Value ( kNullType ) ) , x . End ( ) ) ; <nl> + const Value null ( kNullType ) ; <nl> + x . Erase ( std : : remove ( x . Begin ( ) , x . End ( ) , null ) , x . End ( ) ) ; <nl> EXPECT_EQ ( 5u , x . Size ( ) ) ; <nl> for ( int i = 0 ; i < 5 ; i + + ) <nl> EXPECT_EQ ( i * 2 , x [ i ] ) ; <nl> - # endif <nl> <nl> / / SetArray ( ) <nl> Value z ; <nl> TEST ( Value , Object ) { <nl> EXPECT_EQ ( 8u , o . MemberCount ( ) ) ; <nl> } <nl> <nl> + # if RAPIDJSON_HAS_CXX11_RVALUE_REFS <nl> + / / AddMember ( GenericValue & & , . . . ) variants <nl> + { <nl> + Value o ( kObjectType ) ; <nl> + o . AddMember ( Value ( \" true \" ) , Value ( true ) , allocator ) ; <nl> + o . AddMember ( Value ( \" false \" ) , Value ( false ) . Move ( ) , allocator ) ; / / value is lvalue ref <nl> + o . AddMember ( Value ( \" int \" ) . Move ( ) , Value ( - 1 ) , allocator ) ; / / name is lvalue ref <nl> + o . AddMember ( \" uint \" , std : : move ( Value ( ) . SetUint ( 1u ) ) , allocator ) ; / / name is literal , value is rvalue <nl> + EXPECT_TRUE ( o [ \" true \" ] . GetBool ( ) ) ; <nl> + EXPECT_FALSE ( o [ \" false \" ] . GetBool ( ) ) ; <nl> + EXPECT_EQ ( - 1 , o [ \" int \" ] . GetInt ( ) ) ; <nl> + EXPECT_EQ ( 1u , o [ \" uint \" ] . GetUint ( ) ) ; <nl> + EXPECT_EQ ( 4u , o . MemberCount ( ) ) ; <nl> + } <nl> + # endif <nl> + <nl> / / Tests a member with null character <nl> Value name ; <nl> const Value C0D ( \" C \\ 0D \" , 3 ) ; <nl>\n"}
{"diff_id": 8735, "repo": "bitcoin/bitcoin\n", "sha": "2d914f89fee789defe1a1c692485b06105ff0ab3\n", "time": "2012-08-17T12:21:17Z\n", "diff": "mmm a / src / init . cpp <nl> ppp b / src / init . cpp <nl> bool AppInit2 ( ) <nl> <nl> if ( mapArgs . count ( \" - loadblock \" ) ) <nl> { <nl> + uiInterface . InitMessage ( _ ( \" Importing blocks . . . \" ) ) ; <nl> BOOST_FOREACH ( string strFile , mapMultiArgs [ \" - loadblock \" ] ) <nl> { <nl> FILE * file = fopen ( strFile . c_str ( ) , \" rb \" ) ; <nl>\n", "msg": "add splashscreen message when importing blocks via - loadblock\n"}
{"diff_id": 8812, "repo": "apple/swift\n", "sha": "89752e6dd4fc1d9f2ed595fc8f258de157b5425e\n", "time": "2012-04-19T02:21:02Z\n", "diff": "mmm a / lib / Sema / TypeCheckStmt . cpp <nl> ppp b / lib / Sema / TypeCheckStmt . cpp <nl> void TypeChecker : : typeCheckIgnoredExpr ( Expr * E ) { <nl> } <nl> } <nl> <nl> + void <nl> + PrintLiteralString ( StringRef Str , ASTContext & Context , SourceLoc Loc , <nl> + SmallVectorImpl < ValueDecl * > & PrintDecls , <nl> + SmallVectorImpl < BraceStmt : : ExprStmtOrDecl > & BodyContent ) { <nl> + Expr * PrintStr = new ( Context ) StringLiteralExpr ( Str , Loc ) ; <nl> + Expr * PrintStrFn = OverloadedDeclRefExpr : : createWithCopy ( PrintDecls , Loc ) ; <nl> + BodyContent . push_back ( new ( Context ) CallExpr ( PrintStrFn , PrintStr ) ) ; <nl> + } <nl> + <nl> + static void <nl> + PrintReplExpr ( TypeChecker & TC , VarDecl * Arg , CanType T , SourceLoc Loc , <nl> + SourceLoc EndLoc , <nl> + SmallVectorImpl < unsigned > & MemberIndexes , <nl> + SmallVectorImpl < BraceStmt : : ExprStmtOrDecl > & BodyContent ) { <nl> + ASTContext & Context = TC . Context ; <nl> + TranslationUnit & TU = TC . TU ; <nl> + <nl> + / / Lookup the \" print \" function used for strings . <nl> + SmallVector < ValueDecl * , 4 > PrintDecls ; <nl> + TU . lookupGlobalValue ( Context . getIdentifier ( \" print \" ) , <nl> + NLKind : : UnqualifiedLookup , PrintDecls ) ; <nl> + <nl> + if ( TupleType * TT = dyn_cast < TupleType > ( T ) ) { <nl> + / / We print a tuple by printing each element . <nl> + PrintLiteralString ( \" ( \" , Context , Loc , PrintDecls , BodyContent ) ; <nl> + <nl> + for ( unsigned i = 0 , e = TT - > getFields ( ) . size ( ) ; i < e ; + + i ) { <nl> + MemberIndexes . push_back ( i ) ; <nl> + CanType SubType = TT - > getElementType ( i ) - > getCanonicalType ( ) ; <nl> + PrintReplExpr ( TC , Arg , SubType , Loc , EndLoc , MemberIndexes , <nl> + BodyContent ) ; <nl> + MemberIndexes . pop_back ( ) ; <nl> + <nl> + if ( i + 1 ! = e ) <nl> + PrintLiteralString ( \" , \" , Context , Loc , PrintDecls , BodyContent ) ; <nl> + } <nl> + <nl> + PrintLiteralString ( \" ) \" , Context , Loc , PrintDecls , BodyContent ) ; <nl> + return ; <nl> + } <nl> + <nl> + Identifier MemberName = Context . getIdentifier ( \" replPrint \" ) ; <nl> + MemberLookup Lookup ( T , MemberName , TU ) ; <nl> + if ( Lookup . isSuccess ( ) ) { <nl> + Expr * ArgRef = new ( Context ) DeclRefExpr ( Arg , Loc , <nl> + Arg - > getTypeOfReference ( ) ) ; <nl> + ArgRef = TC . convertToRValue ( ArgRef ) ; <nl> + for ( unsigned i : MemberIndexes ) { <nl> + / / For each index , we look through a TupleType or transparent OneOfType . <nl> + CanType CurT = ArgRef - > getType ( ) - > getCanonicalType ( ) ; <nl> + if ( OneOfType * OOT = dyn_cast < OneOfType > ( CurT ) ) { <nl> + CurT = OOT - > getTransparentType ( ) - > getCanonicalType ( ) ; <nl> + ArgRef = new ( Context ) LookThroughOneofExpr ( ArgRef , CurT ) ; <nl> + } <nl> + TupleType * TT = cast < TupleType > ( CurT ) ; <nl> + ArgRef = new ( Context ) SyntacticTupleElementExpr ( ArgRef , Loc , i , Loc , <nl> + TT - > getElementType ( i ) ) ; <nl> + } <nl> + Expr * Res = TC . recheckTypes ( Lookup . createResultAST ( ArgRef , Loc , EndLoc , <nl> + Context ) ) ; <nl> + if ( ! Res ) <nl> + return ; <nl> + TupleExpr * CallArgs = <nl> + new ( Context ) TupleExpr ( Loc , MutableArrayRef < Expr * > ( ) , 0 , EndLoc , <nl> + TupleType : : getEmpty ( Context ) ) ; <nl> + CallExpr * CE = new ( Context ) CallExpr ( Res , CallArgs , Type ( ) ) ; <nl> + Res = TC . semaApplyExpr ( CE ) ; <nl> + if ( ! Res ) <nl> + return ; <nl> + BodyContent . push_back ( Res ) ; <nl> + return ; <nl> + } <nl> + <nl> + if ( OneOfType * OOT = dyn_cast < OneOfType > ( T ) ) { <nl> + if ( OOT - > isTransparentType ( ) ) { <nl> + / / Print \" struct \" types as if we are constructing one : the name <nl> + / / followed by the underlying tuple . <nl> + PrintLiteralString ( OOT - > getDecl ( ) - > getName ( ) . str ( ) , Context , Loc , <nl> + PrintDecls , BodyContent ) ; <nl> + CanType SubType = OOT - > getTransparentType ( ) - > getCanonicalType ( ) ; <nl> + PrintReplExpr ( TC , Arg , SubType , Loc , EndLoc , <nl> + MemberIndexes , BodyContent ) ; <nl> + return ; <nl> + } <nl> + <nl> + / / FIXME : We should handle non - transparent OneOfTypes at some point , but <nl> + / / it ' s tricky to represent in the AST without a \" match \" statement . <nl> + } <nl> + <nl> + PrintLiteralString ( \" < unprintable value > \" , Context , Loc , PrintDecls , <nl> + BodyContent ) ; <nl> + } <nl> + <nl> / / / Check an expression at the top level in a REPL . <nl> void TypeChecker : : typeCheckTopLevelReplExpr ( Expr * & E ) { <nl> / / If the input is an lvalue , force an lvalue - to - rvalue conversion . <nl> void TypeChecker : : typeCheckTopLevelReplExpr ( Expr * & E ) { <nl> SourceLoc Loc = E - > getStartLoc ( ) ; <nl> SourceLoc EndLoc = E - > getEndLoc ( ) ; <nl> <nl> - / / Build the function to call to print the expression . <nl> + / / Build a function to call to print the expression . <nl> Type FuncTy = T ; <nl> if ( ! isa < TupleType > ( FuncTy ) ) { <nl> TupleTypeElt Elt ( T , Context . getIdentifier ( \" arg \" ) ) ; <nl> void TypeChecker : : typeCheckTopLevelReplExpr ( Expr * & E ) { <nl> Pattern * ParamPat = new ( Context ) NamedPattern ( Arg ) ; <nl> FuncExpr * FE = FuncExpr : : create ( Context , Loc , ParamPat , FuncTy , 0 , & TU ) ; <nl> <nl> - / / Print the expression . <nl> - / / FIXME : Need structural printing for tuples . <nl> - / / FIXME : Need structural printing for oneofs . <nl> + / / Build the body of the function which prints the expression . <nl> + SmallVector < unsigned , 4 > MemberIndexes ; <nl> SmallVector < BraceStmt : : ExprStmtOrDecl , 4 > BodyContent ; <nl> - Identifier MemberName = Context . getIdentifier ( \" replPrint \" ) ; <nl> - MemberLookup Lookup ( T , MemberName , TU ) ; <nl> - if ( Lookup . isSuccess ( ) ) { <nl> - Expr * ArgRef = new ( Context ) DeclRefExpr ( Arg , Loc , <nl> - Arg - > getTypeOfReference ( ) ) ; <nl> - ArgRef = convertToRValue ( ArgRef ) ; <nl> - Expr * Res = recheckTypes ( Lookup . createResultAST ( ArgRef , Loc , EndLoc , <nl> - Context ) ) ; <nl> - if ( ! Res ) <nl> - return ; <nl> - TupleExpr * CallArgs = <nl> - new ( Context ) TupleExpr ( Loc , MutableArrayRef < Expr * > ( ) , 0 , EndLoc , <nl> - TupleType : : getEmpty ( Context ) ) ; <nl> - CallExpr * CE = new ( Context ) CallExpr ( Res , CallArgs , Type ( ) ) ; <nl> - Res = semaApplyExpr ( CE ) ; <nl> - if ( ! Res ) <nl> - return ; <nl> - BodyContent . push_back ( Res ) ; <nl> - } else { <nl> - Expr * PrintUnknown = new ( Context ) StringLiteralExpr ( \" < unprintable value > \" , <nl> - Loc ) ; <nl> - SmallVector < ValueDecl * , 4 > Decls ; <nl> - TU . lookupGlobalValue ( Context . getIdentifier ( \" print \" ) , <nl> - NLKind : : UnqualifiedLookup , Decls ) ; <nl> - Expr * PrintStrFn = OverloadedDeclRefExpr : : createWithCopy ( Decls , Loc ) ; <nl> - PrintUnknown = new ( Context ) CallExpr ( PrintStrFn , PrintUnknown , Type ( ) ) ; <nl> - BodyContent . push_back ( PrintUnknown ) ; <nl> - } <nl> + PrintReplExpr ( * this , Arg , T , Loc , EndLoc , MemberIndexes , BodyContent ) ; <nl> <nl> / / Print a newline at the end . <nl> Expr * PrintNewLine = new ( Context ) StringLiteralExpr ( \" \\ n \" , E - > getStartLoc ( ) ) ; <nl>\n", "msg": "REPL printing for structs and tuples .\n"}
{"diff_id": 8875, "repo": "telegramdesktop/tdesktop\n", "sha": "4dae89310ddd14df8916637715c8e200497f6ecf\n", "time": "2019-05-01T12:11:46Z\n", "diff": "mmm a / Telegram / SourceFiles / dialogs / dialogs_inner_widget . cpp <nl> ppp b / Telegram / SourceFiles / dialogs / dialogs_inner_widget . cpp <nl> bool InnerWidget : : updateReorderPinned ( QPoint localPosition ) { <nl> const auto delta = [ & ] { <nl> if ( localPosition . y ( ) < _visibleTop ) { <nl> return localPosition . y ( ) - _visibleTop ; <nl> + } else if ( _openedFolder & & localPosition . y ( ) > _visibleBottom ) { <nl> + return localPosition . y ( ) - _visibleBottom ; <nl> } <nl> return 0 ; <nl> } ( ) ; <nl>\n", "msg": "In archive allow scroll - down - by - pinned - drag .\n"}
{"diff_id": 8886, "repo": "xbmc/xbmc\n", "sha": "a584dce1777438522c29435cbecde9e6d54528eb\n", "time": "2016-01-06T22:55:49Z\n", "diff": "mmm a / xbmc / guilib / GUIWindow . cpp <nl> ppp b / xbmc / guilib / GUIWindow . cpp <nl> void CGUIWindow : : AllocResources ( bool forceLoad / * = FALSE * / ) <nl> } <nl> } <nl> <nl> + # ifdef _DEBUG <nl> int64_t slend ; <nl> slend = CurrentHostCounter ( ) ; <nl> + # endif <nl> <nl> / / and now allocate resources <nl> CGUIControlGroup : : AllocResources ( ) ; <nl>\n", "msg": "[ GUIWindow ] Variable ' slend ' is assigned a value that is never used .\n"}
{"diff_id": 8924, "repo": "apple/swift\n", "sha": "80061e0ba380bdc1cad6961352b096fe455bdcec\n", "time": "2013-07-19T21:28:49Z\n", "diff": "mmm a / lib / Sema / TypeCheckDecl . cpp <nl> ppp b / lib / Sema / TypeCheckDecl . cpp <nl> class DeclChecker : public DeclVisitor < DeclChecker > { <nl> return badType ; <nl> } <nl> <nl> - void semaFuncExpr ( FuncExpr * FE , DeclAttributes & Attr ) { <nl> + / / / \\ brief Validate and consume the attributes that are applicable to the <nl> + / / / AnyFunctionType . <nl> + / / / <nl> + / / / Currently , we only allow ' noreturn ' to be applied on a FuncDecl . <nl> + AnyFunctionType : : ExtInfo <nl> + validateAndConsumeFunctionTypeAttributes ( FuncDecl * FD ) { <nl> + DeclAttributes & Attrs = FD - > getMutableAttrs ( ) ; <nl> + auto Info = AnyFunctionType : : ExtInfo ( ) ; <nl> + <nl> + if ( Attrs . hasCC ( ) ) { <nl> + TC . diagnose ( FD - > getStartLoc ( ) , diag : : invalid_decl_attribute , \" cc \" ) ; <nl> + Attrs . cc = { } ; <nl> + } <nl> + <nl> + if ( Attrs . isThin ( ) ) { <nl> + TC . diagnose ( FD - > getStartLoc ( ) , diag : : invalid_decl_attribute , <nl> + \" thin \" ) ; <nl> + Attrs . Thin = false ; <nl> + } <nl> + <nl> + / / ' noreturn ' is allowed on a function declaration . <nl> + Info = Info . withIsNoReturn ( Attrs . isNoReturn ( ) ) ; <nl> + Attrs . NoReturn = false ; <nl> + <nl> + if ( Attrs . isAutoClosure ( ) ) { <nl> + TC . diagnose ( FD - > getStartLoc ( ) , diag : : invalid_decl_attribute , <nl> + \" auto_closure \" ) ; <nl> + Attrs . AutoClosure = false ; <nl> + } <nl> + <nl> + if ( Attrs . isObjCBlock ( ) ) { <nl> + TC . diagnose ( FD - > getStartLoc ( ) , diag : : invalid_decl_attribute , <nl> + \" objc_block \" ) ; <nl> + Attrs . ObjCBlock = false ; <nl> + } <nl> + <nl> + return Info ; <nl> + } <nl> + <nl> + void semaFuncExpr ( FuncDecl * FD ) { <nl> + FuncExpr * FE = FD - > getBody ( ) ; <nl> + <nl> if ( FE - > getType ( ) ) <nl> return ; <nl> <nl> class DeclChecker : public DeclVisitor < DeclChecker > { <nl> params = outerGenericParams ; <nl> } <nl> <nl> + / / Validate and consume the function type attributes . <nl> + auto Info = validateAndConsumeFunctionTypeAttributes ( FD ) ; <nl> if ( params ) { <nl> - / / FIXME : <nl> - / / We need to perform attribute checking here . <nl> - / / Should this code be unified with Parser : : applyAttributeToType ? <nl> - / / Not all of these attributes might be valid on a decl <nl> - / / ( such as CC , auto_closure , block ) . . <nl> - auto Info = PolymorphicFunctionType : : ExtInfo ( Attr . hasCC ( ) ? <nl> - Attr . getAbstractCC ( ) : <nl> - AbstractCC : : Freestanding , <nl> - Attr . isThin ( ) , <nl> - Attr . isNoReturn ( ) ) ; <nl> funcTy = PolymorphicFunctionType : : get ( argTy , funcTy , <nl> params , <nl> Info , <nl> TC . Context ) ; <nl> } else { <nl> - / / FIXME : <nl> - / / We need to perform attribute checking here . <nl> - / / Should this code be unified with Parser : : applyAttributeToType ? <nl> - / / Not all of these attributes might be valid on a decl . <nl> - auto Info = FunctionType : : ExtInfo ( Attr . hasCC ( ) ? <nl> - Attr . getAbstractCC ( ) : <nl> - AbstractCC : : Freestanding , <nl> - Attr . isThin ( ) , <nl> - Attr . isNoReturn ( ) , <nl> - Attr . isAutoClosure ( ) , <nl> - Attr . isObjCBlock ( ) ) ; <nl> funcTy = FunctionType : : get ( argTy , funcTy , Info , TC . Context ) ; <nl> } <nl> - / / FIXME : Reset the arttributes we consumed there . <nl> + <nl> } <nl> FE - > setType ( funcTy ) ; <nl> } <nl> class DeclChecker : public DeclVisitor < DeclChecker > { <nl> checkGenericParams ( gp ) ; <nl> } <nl> <nl> - semaFuncExpr ( body , FD - > getMutableAttrs ( ) ) ; <nl> + semaFuncExpr ( FD ) ; <nl> FD - > setType ( body - > getType ( ) ) ; <nl> <nl> validateAttributes ( FD ) ; <nl> void DeclChecker : : validateAttributes ( ValueDecl * VD ) { <nl> TC . diagnose ( VD - > getStartLoc ( ) , diag : : invalid_decl_attribute , \" cc \" ) ; <nl> VD - > getMutableAttrs ( ) . cc = { } ; <nl> } <nl> + <nl> + if ( Attrs . isThin ( ) ) { <nl> + TC . diagnose ( VD - > getStartLoc ( ) , diag : : invalid_decl_attribute , \" thin \" ) ; <nl> + VD - > getMutableAttrs ( ) . Thin = false ; <nl> + } <nl> + <nl> + if ( Attrs . isNoReturn ( ) ) { <nl> + TC . diagnose ( VD - > getStartLoc ( ) , diag : : invalid_decl_attribute , \" noreturn \" ) ; <nl> + VD - > getMutableAttrs ( ) . NoReturn = false ; <nl> + } <nl> + <nl> } <nl>\n", "msg": "Perform attribute checking on the type attributes for AnyFunctionDecl .\n"}
{"diff_id": 8982, "repo": "apple/swift\n", "sha": "9a964034960c2ec5cae78336813b63093f8bfe2a\n", "time": "2017-02-19T16:28:37Z\n", "diff": "mmm a / lib / SILGen / SILGenApply . cpp <nl> ppp b / lib / SILGen / SILGenApply . cpp <nl> static ManagedValue maybeEnterCleanupForTransformed ( SILGenFunction & gen , <nl> } <nl> } <nl> <nl> - static Callee prepareArchetypeCallee ( SILGenFunction & gen , SILLocation loc , <nl> - SILDeclRef constant , <nl> - ArgumentSource & selfValue , <nl> - CanFunctionType substFnType , <nl> - SubstitutionList & substitutions ) { <nl> - auto fd = cast < AbstractFunctionDecl > ( constant . getDecl ( ) ) ; <nl> - auto protocol = cast < ProtocolDecl > ( fd - > getDeclContext ( ) ) ; <nl> + namespace { <nl> + <nl> + class ArchetypeCalleeBuilder { <nl> + SILGenFunction & gen ; <nl> + SILLocation loc ; <nl> + ArgumentSource & selfValue ; <nl> + CanFunctionType substFnType ; <nl> + SILParameterInfo selfParam ; <nl> + AbstractFunctionDecl * fd ; <nl> + ProtocolDecl * protocol ; <nl> + SILDeclRef constant ; <nl> <nl> - / / Method calls through ObjC protocols require ObjC dispatch . <nl> - constant = constant . asForeign ( protocol - > isObjC ( ) ) ; <nl> + public : <nl> + ArchetypeCalleeBuilder ( SILGenFunction & gen , SILLocation loc , <nl> + SILDeclRef inputConstant , ArgumentSource & selfValue , <nl> + CanFunctionType substFnType ) <nl> + : gen ( gen ) , loc ( loc ) , selfValue ( selfValue ) , substFnType ( substFnType ) , <nl> + selfParam ( ) , fd ( cast < AbstractFunctionDecl > ( inputConstant . getDecl ( ) ) ) , <nl> + protocol ( cast < ProtocolDecl > ( fd - > getDeclContext ( ) ) ) , <nl> + constant ( inputConstant . asForeign ( protocol - > isObjC ( ) ) ) { } <nl> + <nl> + Callee build ( ) { <nl> + / / Link back to something to create a data dependency if we have <nl> + / / an opened type . <nl> + SILValue openingSite ; <nl> + auto archetype = <nl> + cast < ArchetypeType > ( CanType ( getSelfType ( ) - > getRValueInstanceType ( ) ) ) ; <nl> + if ( archetype - > getOpenedExistentialType ( ) ) { <nl> + openingSite = gen . getArchetypeOpeningSite ( archetype ) ; <nl> + } <nl> <nl> - CanType selfTy = selfValue . getSubstRValueType ( ) ; <nl> + / / Then if we need to materialize self into memory , do so . <nl> + if ( shouldMaterializeSelf ( ) ) { <nl> + SILLocation selfLoc = selfValue . getLocation ( ) ; <nl> + ManagedValue address = evaluateAddressIntoMemory ( selfLoc ) ; <nl> + setSelfValueToAddress ( selfLoc , address ) ; <nl> + } <nl> <nl> - SILParameterInfo _selfParam ; <nl> - auto getSelfParameter = [ & ] ( ) - > SILParameterInfo { <nl> - if ( _selfParam ! = SILParameterInfo ( ) ) return _selfParam ; <nl> - auto constantFnType = gen . SGM . Types . getConstantFunctionType ( constant ) ; <nl> - return ( _selfParam = constantFnType - > getSelfParameter ( ) ) ; <nl> - } ; <nl> - auto getSGFContextForSelf = [ & ] ( ) - > SGFContext { <nl> - return ( getSelfParameter ( ) . isConsumed ( ) <nl> - ? SGFContext ( ) : SGFContext : : AllowGuaranteedPlusZero ) ; <nl> - } ; <nl> + / / The protocol self is implicitly decurried . <nl> + substFnType = cast < FunctionType > ( substFnType . getResult ( ) ) ; <nl> <nl> - auto setSelfValueToAddress = [ & ] ( SILLocation loc , ManagedValue address ) { <nl> + return Callee : : forArchetype ( gen , openingSite , getSelfType ( ) , constant , <nl> + substFnType , loc ) ; <nl> + } <nl> + <nl> + private : <nl> + CanType getSelfType ( ) const { return selfValue . getSubstRValueType ( ) ; } <nl> + <nl> + SILParameterInfo getSelfParameterInfo ( ) const { <nl> + if ( selfParam = = SILParameterInfo ( ) ) { <nl> + auto & Self = const_cast < ArchetypeCalleeBuilder & > ( * this ) ; <nl> + auto constantFnType = gen . SGM . Types . getConstantFunctionType ( constant ) ; <nl> + Self . selfParam = constantFnType - > getSelfParameter ( ) ; <nl> + } <nl> + <nl> + return selfParam ; <nl> + } <nl> + <nl> + SGFContext getSGFContextForSelf ( ) { <nl> + if ( getSelfParameterInfo ( ) . isConsumed ( ) ) <nl> + return SGFContext ( ) ; <nl> + return SGFContext : : AllowGuaranteedPlusZero ; <nl> + } <nl> + <nl> + void setSelfValueToAddress ( SILLocation loc , ManagedValue address ) { <nl> assert ( address . getType ( ) . isAddress ( ) ) ; <nl> assert ( address . getType ( ) . is < ArchetypeType > ( ) ) ; <nl> auto formalTy = address . getType ( ) . getSwiftRValueType ( ) ; <nl> <nl> - if ( getSelfParameter ( ) . isIndirectMutating ( ) ) { <nl> + if ( getSelfParameterInfo ( ) . isIndirectMutating ( ) ) { <nl> / / Be sure not to consume the cleanup for an inout argument . <nl> auto selfLV = ManagedValue : : forLValue ( address . getValue ( ) ) ; <nl> selfValue = ArgumentSource ( loc , <nl> static Callee prepareArchetypeCallee ( SILGenFunction & gen , SILLocation loc , <nl> } else { <nl> selfValue = ArgumentSource ( loc , RValue ( gen , loc , formalTy , address ) ) ; <nl> } <nl> - } ; <nl> + } <nl> <nl> - / / If we ' re calling a member of a non - class - constrained protocol , <nl> - / / but our archetype refines it to be class - bound , then <nl> - / / we have to materialize the value in order to pass it indirectly . <nl> - auto materializeSelfIfNecessary = [ & ] { <nl> + bool shouldMaterializeSelf ( ) const { <nl> / / Only an instance method of a non - class protocol is ever passed <nl> / / indirectly . <nl> if ( ! fd - > isInstanceMember ( ) | | <nl> protocol - > requiresClass ( ) | | <nl> selfValue . hasLValueType ( ) | | <nl> ! cast < ArchetypeType > ( selfValue . getSubstRValueType ( ) ) - > requiresClass ( ) ) <nl> - return ; <nl> + return false ; <nl> <nl> - assert ( gen . silConv . useLoweredAddresses ( ) <nl> - = = gen . silConv . isSILIndirect ( getSelfParameter ( ) ) ) ; <nl> + assert ( gen . silConv . useLoweredAddresses ( ) = = <nl> + gen . silConv . isSILIndirect ( getSelfParameterInfo ( ) ) ) ; <nl> if ( ! gen . silConv . useLoweredAddresses ( ) ) <nl> - return ; <nl> - <nl> - SILLocation selfLoc = selfValue . getLocation ( ) ; <nl> + return false ; <nl> + return true ; <nl> + } <nl> <nl> - / / Evaluate the reference into memory . <nl> - ManagedValue address = [ & ] ( ) - > ManagedValue { <nl> - / / Do so at + 0 if we can . <nl> - auto ref = std : : move ( selfValue ) <nl> - . getAsSingleValue ( gen , getSGFContextForSelf ( ) ) ; <nl> + / / If we ' re calling a member of a non - class - constrained protocol , <nl> + / / but our archetype refines it to be class - bound , then <nl> + / / we have to materialize the value in order to pass it indirectly . <nl> + ManagedValue evaluateAddressIntoMemory ( SILLocation selfLoc ) { <nl> + / / Do so at + 0 if we can . <nl> + ManagedValue ref = <nl> + std : : move ( selfValue ) . getAsSingleValue ( gen , getSGFContextForSelf ( ) ) ; <nl> <nl> - / / If we ' re already in memory for some reason , great . <nl> - if ( ref . getType ( ) . isAddress ( ) ) <nl> - return ref ; <nl> + / / If we ' re already in memory for some reason , great . <nl> + if ( ref . getType ( ) . isAddress ( ) ) <nl> + return ref ; <nl> <nl> - / / Store the reference into a temporary . <nl> - auto temp = <nl> + / / Store the reference into a temporary . <nl> + SILValue temp = <nl> gen . emitTemporaryAllocation ( selfLoc , ref . getValue ( ) - > getType ( ) ) ; <nl> - gen . B . emitStoreValueOperation ( selfLoc , ref . getValue ( ) , temp , <nl> - StoreOwnershipQualifier : : Init ) ; <nl> - <nl> - / / If we had a cleanup , create a cleanup at the new address . <nl> - return maybeEnterCleanupForTransformed ( gen , ref , temp ) ; <nl> - } ( ) ; <nl> - <nl> - setSelfValueToAddress ( selfLoc , address ) ; <nl> - } ; <nl> - <nl> - / / Construct an archetype call . <nl> + gen . B . emitStoreValueOperation ( selfLoc , ref . getValue ( ) , temp , <nl> + StoreOwnershipQualifier : : Init ) ; <nl> <nl> - / / Link back to something to create a data dependency if we have <nl> - / / an opened type . <nl> - SILValue openingSite ; <nl> - auto archetype = <nl> - cast < ArchetypeType > ( CanType ( selfTy - > getRValueInstanceType ( ) ) ) ; <nl> - if ( archetype - > getOpenedExistentialType ( ) ) { <nl> - openingSite = gen . getArchetypeOpeningSite ( archetype ) ; <nl> + / / If we had a cleanup , create a cleanup at the new address . <nl> + return maybeEnterCleanupForTransformed ( gen , ref , temp ) ; <nl> } <nl> + } ; <nl> <nl> - materializeSelfIfNecessary ( ) ; <nl> - <nl> - / / The protocol self is implicitly decurried . <nl> - substFnType = cast < FunctionType > ( substFnType . getResult ( ) ) ; <nl> + } / / end anonymous namespace <nl> <nl> - return Callee : : forArchetype ( gen , openingSite , selfTy , <nl> - constant , substFnType , loc ) ; <nl> + static Callee prepareArchetypeCallee ( SILGenFunction & gen , SILLocation loc , <nl> + SILDeclRef constant , <nl> + ArgumentSource & selfValue , <nl> + CanFunctionType substFnType , <nl> + SubstitutionList & substitutions ) { <nl> + / / Construct an archetype call . <nl> + ArchetypeCalleeBuilder Builder { gen , loc , constant , selfValue , substFnType } ; <nl> + return Builder . build ( ) ; <nl> } <nl> <nl> / / / For ObjC init methods , we generate a shared - linkage Swift allocating entry <nl>\n", "msg": "[ silgen ] Refactor prepareArchetypeCallee to use a builder class instead of iterated closures .\n", "score": 1}
{"diff_id": 9058, "repo": "facebook/hhvm\n", "sha": "dd8d48f4463e9e55e4dd14aaf7afd499c62aaab1\n", "time": "2018-11-12T14:30:36Z\n", "diff": "mmm a / hphp / runtime / vm / jit / irgen - types . cpp <nl> ppp b / hphp / runtime / vm / jit / irgen - types . cpp <nl> namespace { <nl> <nl> / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / <nl> <nl> - const StaticString s_Awaitable ( \" HH \\ \\ Awaitable \" ) ; <nl> + const StaticString <nl> + s_Stringish ( \" Stringish \" ) , <nl> + s_Awaitable ( \" HH \\ \\ Awaitable \" ) ; <nl> <nl> / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / <nl> <nl> SSATmp * implInstanceCheck ( IRGS & env , SSATmp * src , const StringData * className , <nl> if ( s_Awaitable . get ( ) - > isame ( className ) ) { <nl> return gen ( env , IsWaitHandle , src ) ; <nl> } <nl> + if ( s_Stringish . get ( ) - > isame ( className ) ) { <nl> + return gen ( env , HasToString , src ) ; <nl> + } <nl> <nl> auto knownCls = checkCls - > hasConstVal ( TCls ) ? checkCls - > clsVal ( ) : nullptr ; <nl> assertx ( IMPLIES ( knownCls , classIsUniqueOrCtxParent ( env , knownCls ) ) ) ; <nl>\n", "msg": "` $ obj is Stringish ` short - circuit\n"}
{"diff_id": 9122, "repo": "xbmc/xbmc\n", "sha": "10c35a4b02f5cdfd971fe8555caf16dc42344e20\n", "time": "2010-10-13T19:22:12Z\n", "diff": "mmm a / xbmc / cores / dvdplayer / DVDTSCorrection . cpp <nl> ppp b / xbmc / cores / dvdplayer / DVDTSCorrection . cpp <nl> double CPullupCorrection : : CalcFrameDuration ( ) <nl> <nl> double lowestdiff = DVD_TIME_BASE ; <nl> int selected = - 1 ; <nl> - for ( int i = 0 ; i < sizeof ( durations ) / sizeof ( durations [ 0 ] ) ; i + + ) <nl> + for ( size_t i = 0 ; i < sizeof ( durations ) / sizeof ( durations [ 0 ] ) ; i + + ) <nl> { <nl> double diff = fabs ( frameduration - durations [ i ] ) ; <nl> if ( diff < DVD_MSEC_TO_TIME ( 0 . 02 ) & & diff < lowestdiff ) <nl>\n", "msg": "fixed compiler warning , signed / unsigned comparision\n"}
{"diff_id": 9196, "repo": "xbmc/xbmc\n", "sha": "9095e3b3c8aa0b5b1f5e72c00a9b3805edb7f079\n", "time": "2014-10-24T08:30:58Z\n", "diff": "mmm a / xbmc / Util . cpp <nl> ppp b / xbmc / Util . cpp <nl> void CUtil : : ScanForExternalSubtitles ( const std : : string & strMovie , std : : vector < st <nl> if ( URIUtils : : HasExtension ( strItem , sub_exts [ i ] ) ) <nl> { <nl> vecSubtitles . push_back ( items [ j ] - > GetPath ( ) ) ; <nl> - CLog : : Log ( LOGINFO , \" % s : found subtitle file % s \\ n \" , __FUNCTION__ , items [ j ] - > GetPath ( ) . c_str ( ) ) ; <nl> + CLog : : Log ( LOGINFO , \" % s : found subtitle file % s \\ n \" , __FUNCTION__ , CURL : : GetRedacted ( items [ j ] - > GetPath ( ) ) . c_str ( ) ) ; <nl> } <nl> } <nl> } <nl> void CUtil : : ScanForExternalSubtitles ( const std : : string & strMovie , std : : vector < st <nl> strDest = StringUtils : : Format ( \" special : / / temp / subtitle . % s . % d . smi \" , TagConv . m_Langclass [ k ] . Name . c_str ( ) , i ) ; <nl> if ( CFile : : Copy ( vecSubtitles [ i ] , strDest ) ) <nl> { <nl> - CLog : : Log ( LOGINFO , \" cached subtitle % s - > % s \\ n \" , vecSubtitles [ i ] . c_str ( ) , strDest . c_str ( ) ) ; <nl> + CLog : : Log ( LOGINFO , \" cached subtitle % s - > % s \\ n \" , CURL : : GetRedacted ( vecSubtitles [ i ] ) . c_str ( ) , strDest . c_str ( ) ) ; <nl> vecSubtitles . push_back ( strDest ) ; <nl> } <nl> } <nl>\n", "msg": "[ subtitles ] do not log username / password\n"}
{"diff_id": 9568, "repo": "Tencent/rapidjson\n", "sha": "0b793ea58a947fb6ea3b5b518399d8561a0eef33\n", "time": "2015-04-13T07:18:26Z\n", "diff": "mmm a / test / unittest / prettywritertest . cpp <nl> ppp b / test / unittest / prettywritertest . cpp <nl> TEST ( PrettyWriter , String_STDSTRING ) { <nl> EXPECT_STREQ ( \" [ \\ n \\ \" Hello \\ \\ n \\ \" \\ n ] \" , buffer . GetString ( ) ) ; <nl> } <nl> # endif <nl> + <nl> + # include < sstream > <nl> + <nl> + class OStreamWrapper { <nl> + public : <nl> + typedef char Ch ; <nl> + <nl> + OStreamWrapper ( std : : ostream & os ) : os_ ( os ) { } <nl> + <nl> + Ch Peek ( ) const { assert ( false ) ; return ' \\ 0 ' ; } <nl> + Ch Take ( ) { assert ( false ) ; return ' \\ 0 ' ; } <nl> + size_t Tell ( ) const { return 0 ; } <nl> + <nl> + Ch * PutBegin ( ) { assert ( false ) ; return 0 ; } <nl> + void Put ( Ch c ) { os_ . put ( c ) ; } <nl> + void Flush ( ) { os_ . flush ( ) ; } <nl> + size_t PutEnd ( Ch * ) { assert ( false ) ; return 0 ; } <nl> + <nl> + private : <nl> + OStreamWrapper ( const OStreamWrapper & ) ; <nl> + OStreamWrapper & operator = ( const OStreamWrapper & ) ; <nl> + <nl> + std : : ostream & os_ ; <nl> + } ; <nl> + <nl> + / / For covering PutN ( ) generic version <nl> + TEST ( PrettyWriter , OStreamWrapper ) { <nl> + StringStream s ( kJson ) ; <nl> + <nl> + std : : stringstream ss ; <nl> + OStreamWrapper os ( ss ) ; <nl> + <nl> + PrettyWriter < OStreamWrapper > writer ( os ) ; <nl> + <nl> + Reader reader ; <nl> + reader . Parse ( s , writer ) ; <nl> + <nl> + std : : string actual = ss . str ( ) ; <nl> + EXPECT_STREQ ( <nl> + \" { \\ n \" <nl> + \" \\ \" hello \\ \" : \\ \" world \\ \" , \\ n \" <nl> + \" \\ \" t \\ \" : true , \\ n \" <nl> + \" \\ \" f \\ \" : false , \\ n \" <nl> + \" \\ \" n \\ \" : null , \\ n \" <nl> + \" \\ \" i \\ \" : 123 , \\ n \" <nl> + \" \\ \" pi \\ \" : 3 . 1416 , \\ n \" <nl> + \" \\ \" a \\ \" : [ \\ n \" <nl> + \" 1 , \\ n \" <nl> + \" 2 , \\ n \" <nl> + \" 3 , \\ n \" <nl> + \" - 1 \\ n \" <nl> + \" ] , \\ n \" <nl> + \" \\ \" u64 \\ \" : 1234567890123456789 , \\ n \" <nl> + \" \\ \" i64 \\ \" : - 1234567890123456789 \\ n \" <nl> + \" } \" , <nl> + actual . c_str ( ) ) ; <nl> + } <nl>\n", "msg": "Add test for covering PutN ( ) generic version\n", "score": 1}
{"diff_id": 9783, "repo": "ClickHouse/ClickHouse\n", "sha": "09ca5e0032c0947c264e3674396ca13f43c0e06e\n", "time": "2017-05-09T18:52:58Z\n", "diff": "mmm a / dbms / src / Client / PerformanceTest . cpp <nl> ppp b / dbms / src / Client / PerformanceTest . cpp <nl> namespace ErrorCodes <nl> extern const int UNKNOWN_EXCEPTION ; <nl> } <nl> <nl> + bool isNumber ( const std : : string & str ) { <nl> + if ( str . empty ( ) ) { return false ; } <nl> + <nl> + size_t dotsCounter = 0 ; <nl> + <nl> + if ( str [ 0 ] = = ' . ' | | str [ str . size ( ) - 1 ] = = ' . ' ) { <nl> + return false ; <nl> + } <nl> + <nl> + for ( char chr : str ) { <nl> + if ( chr = = ' . ' ) { <nl> + if ( dotsCounter ) <nl> + return false ; <nl> + else <nl> + + + dotsCounter ; <nl> + continue ; <nl> + } <nl> + <nl> + if ( chr < ' 0 ' | | chr > ' 9 ' ) { <nl> + return false ; <nl> + } <nl> + } <nl> + <nl> + return true ; <nl> + } <nl> + <nl> + class JSONString { <nl> + private : <nl> + std : : map < std : : string , std : : string > content ; <nl> + std : : string current_key ; <nl> + size_t _padding = 1 ; <nl> + public : <nl> + JSONString ( ) { } ; <nl> + JSONString ( size_t padding ) : _padding ( padding ) { } ; <nl> + <nl> + JSONString & operator [ ] ( const std : : string & key ) <nl> + { <nl> + current_key = key ; <nl> + return * this ; <nl> + } <nl> + <nl> + template < typename T > <nl> + typename std : : enable_if < std : : is_arithmetic < T > : : value , JSONString & > : : type <nl> + operator [ ] ( const T key ) <nl> + { <nl> + current_key = std : : to_string ( key ) ; <nl> + return * this ; <nl> + } <nl> + <nl> + void set ( std : : string value ) <nl> + { <nl> + if ( current_key . empty ( ) ) { <nl> + throw \" cannot use set without key \" ; <nl> + } <nl> + <nl> + if ( value . empty ( ) ) { <nl> + value = \" null \" ; <nl> + } <nl> + <nl> + bool reserved = ( value [ 0 ] = = ' [ ' | | value [ 0 ] = = ' { ' | | value = = \" null \" ) ; <nl> + <nl> + if ( ! reserved & & ! isNumber ( value ) ) { <nl> + value = ' \\ \" ' + value + ' \\ \" ' ; <nl> + } <nl> + <nl> + content [ current_key ] = value ; <nl> + current_key = \" \" ; <nl> + } <nl> + <nl> + void set ( const JSONString & innerJSON ) <nl> + { <nl> + set ( innerJSON . constructOutput ( ) ) ; <nl> + } <nl> + <nl> + void set ( const std : : vector < JSONString > & runInfos ) <nl> + { <nl> + if ( current_key . empty ( ) ) { <nl> + throw \" cannot use set without key \" ; <nl> + } <nl> + <nl> + content [ current_key ] = \" [ \\ n \" ; <nl> + <nl> + for ( size_t i = 0 ; i < runInfos . size ( ) ; + + i ) { <nl> + for ( size_t i = 0 ; i < _padding + 1 ; + + i ) { <nl> + content [ current_key ] + = \" \\ t \" ; <nl> + } <nl> + content [ current_key ] + = runInfos [ i ] . constructOutput ( _padding + 2 ) ; <nl> + <nl> + if ( i ! = runInfos . size ( ) - 1 ) { <nl> + content [ current_key ] + = ' , ' ; <nl> + } <nl> + <nl> + content [ current_key ] + = \" \\ n \" ; <nl> + } <nl> + <nl> + for ( size_t i = 0 ; i < _padding ; + + i ) { <nl> + content [ current_key ] + = \" \\ t \" ; <nl> + } <nl> + content [ current_key ] + = ' ] ' ; <nl> + current_key = \" \" ; <nl> + } <nl> + <nl> + template < typename T > <nl> + typename std : : enable_if < std : : is_arithmetic < T > : : value , void > : : type set ( T value ) <nl> + { <nl> + set ( std : : to_string ( value ) ) ; <nl> + } <nl> + std : : string constructOutput ( ) const <nl> + { <nl> + return constructOutput ( _padding ) ; <nl> + } <nl> + <nl> + std : : string constructOutput ( size_t padding ) const <nl> + { <nl> + std : : string output = \" { \" ; <nl> + <nl> + bool first = true ; <nl> + <nl> + for ( auto it = content . begin ( ) ; it ! = content . end ( ) ; + + it ) { <nl> + if ( ! first ) { <nl> + output + = ' , ' ; <nl> + } else { <nl> + first = false ; <nl> + } <nl> + <nl> + output + = \" \\ n \" ; <nl> + for ( size_t i = 0 ; i < padding ; + + i ) { <nl> + output + = \" \\ t \" ; <nl> + } <nl> + <nl> + std : : string key = ' \\ \" ' + it - > first + ' \\ \" ' ; <nl> + std : : string value = it - > second ; <nl> + <nl> + output + = key + \" : \" + value ; <nl> + } <nl> + <nl> + output + = \" \\ n \" ; <nl> + for ( size_t i = 0 ; i < padding - 1 ; + + i ) { <nl> + output + = \" \\ t \" ; <nl> + } <nl> + output + = \" } \" ; <nl> + return output ; <nl> + } <nl> + } ; <nl> + <nl> + std : : ostream & operator < < ( std : : ostream & stream , const JSONString & jsonObj ) <nl> + { <nl> + stream < < jsonObj . constructOutput ( ) ; <nl> + <nl> + return stream ; <nl> + } <nl> + <nl> struct CriterionWithPriority { <nl> std : : string priority = \" \" ; <nl> size_t value = 0 ; <nl> class StopCriterions { <nl> } <nl> } <nl> <nl> + void reset ( ) <nl> + { <nl> + timeout_ms . fulfilled = false ; <nl> + rows_read . fulfilled = false ; <nl> + bytes_read_uncompressed . fulfilled = false ; <nl> + iterations . fulfilled = false ; <nl> + min_time_not_changing_for_ms . fulfilled = false ; <nl> + max_speed_not_changing_for_ms . fulfilled = false ; <nl> + average_speed_not_changing_for_ms . fulfilled = false ; <nl> + <nl> + fulfilled_criterions_min = 0 ; <nl> + fulfilled_criterions_max = 0 ; <nl> + } <nl> + <nl> struct CriterionWithPriority timeout_ms ; <nl> struct CriterionWithPriority rows_read ; <nl> struct CriterionWithPriority bytes_read_uncompressed ; <nl> struct Stats <nl> Stopwatch watch ; <nl> Stopwatch watch_per_query ; <nl> Stopwatch min_time_watch ; <nl> - Stopwatch max_speed_watch ; <nl> - Stopwatch average_speed_watch ; <nl> + Stopwatch max_rows_speed_watch ; <nl> + Stopwatch max_bytes_speed_watch ; <nl> + Stopwatch avg_rows_speed_watch ; <nl> + Stopwatch avg_bytes_speed_watch ; <nl> size_t queries ; <nl> size_t rows_read ; <nl> size_t bytes_read ; <nl> struct Stats <nl> / / / min_time in ms <nl> UInt64 min_time = std : : numeric_limits < UInt64 > : : max ( ) ; <nl> double total_time = 0 ; <nl> - double max_speed = 0 ; <nl> - double average_speed_value = 0 ; <nl> - double average_speed_first = 0 ; <nl> - double average_speed_precision = 0 . 001 ; <nl> - size_t number_of_speed_info_batches = 0 ; <nl> + <nl> + double max_rows_speed = 0 ; <nl> + double max_bytes_speed = 0 ; <nl> + <nl> + double avg_rows_speed_value = 0 ; <nl> + double avg_rows_speed_first = 0 ; <nl> + double avg_rows_speed_precision = 0 . 001 ; <nl> + <nl> + double avg_bytes_speed_value = 0 ; <nl> + double avg_bytes_speed_first = 0 ; <nl> + double avg_bytes_speed_precision = 0 . 001 ; <nl> + <nl> + size_t number_of_rows_speed_info_batches = 0 ; <nl> + size_t number_of_bytes_speed_info_batches = 0 ; <nl> + <nl> + std : : string getStatisticByName ( const std : : string & statisticName ) { <nl> + if ( statisticName = = \" min_time \" ) { <nl> + return std : : to_string ( min_time ) + \" ms \" ; <nl> + } <nl> + if ( statisticName = = \" quantiles \" ) { <nl> + std : : string result = \" \\ n \" ; <nl> + <nl> + for ( double percent = 10 ; percent < = 90 ; percent + = 10 ) { <nl> + result + = \" \\ t \" + std : : to_string ( ( percent / 100 ) ) ; <nl> + result + = \" : \" + std : : to_string ( sampler . quantileInterpolated ( percent / 100 . 0 ) ) ; <nl> + result + = \" \\ n \" ; <nl> + } <nl> + result + = \" \\ t0 . 95 : \" + std : : to_string ( sampler . quantileInterpolated ( 95 / 100 . 0 ) ) + \" \\ n \" ; <nl> + result + = \" \\ t0 . 99 : \" + std : : to_string ( sampler . quantileInterpolated ( 99 / 100 . 0 ) ) + \" \\ n \" ; <nl> + result + = \" \\ t0 . 999 : \" + std : : to_string ( sampler . quantileInterpolated ( 99 . 9 / 100 . ) ) + \" \\ n \" ; <nl> + result + = \" \\ t0 . 9999 : \" + std : : to_string ( sampler . quantileInterpolated ( 99 . 99 / 100 . ) ) ; <nl> + <nl> + return result ; <nl> + } <nl> + if ( statisticName = = \" total_time \" ) { <nl> + return std : : to_string ( total_time ) + \" s \" ; <nl> + } <nl> + if ( statisticName = = \" queries_per_second \" ) { <nl> + return std : : to_string ( queries / total_time ) ; <nl> + } <nl> + if ( statisticName = = \" rows_per_second \" ) { <nl> + return std : : to_string ( rows_read / total_time ) ; <nl> + } <nl> + if ( statisticName = = \" bytes_per_second \" ) { <nl> + return std : : to_string ( bytes_read / total_time ) ; <nl> + } <nl> + <nl> + if ( statisticName = = \" max_rows_per_second \" ) { <nl> + return std : : to_string ( max_rows_speed ) ; <nl> + } <nl> + if ( statisticName = = \" max_bytes_per_second \" ) { <nl> + return std : : to_string ( max_bytes_speed ) ; <nl> + } <nl> + if ( statisticName = = \" avg_rows_per_second \" ) { <nl> + return std : : to_string ( avg_rows_speed_value ) ; <nl> + } <nl> + if ( statisticName = = \" avg_bytes_per_second \" ) { <nl> + return std : : to_string ( avg_bytes_speed_value ) ; <nl> + } <nl> + <nl> + return \" \" ; <nl> + } <nl> <nl> void update_min_time ( const UInt64 min_time_candidate ) <nl> { <nl> struct Stats <nl> } <nl> } <nl> <nl> - void update_average_speed ( const double new_speed_info ) <nl> + void update_average_speed ( const double new_speed_info , Stopwatch & avg_speed_watch , <nl> + size_t & number_of_info_batches , double precision , <nl> + double & avg_speed_first , double & avg_speed_value ) <nl> { <nl> - average_speed_value = ( ( average_speed_value * number_of_speed_info_batches ) <nl> - + new_speed_info ) ; <nl> - average_speed_value / = ( + + number_of_speed_info_batches ) ; <nl> + avg_speed_value = ( ( avg_speed_value * number_of_info_batches ) <nl> + + new_speed_info ) ; <nl> + avg_speed_value / = ( + + number_of_info_batches ) ; <nl> <nl> - if ( average_speed_first = = 0 ) { <nl> - average_speed_first = average_speed_value ; <nl> + if ( avg_speed_first = = 0 ) { <nl> + avg_speed_first = avg_speed_value ; <nl> } <nl> <nl> - if ( abs ( average_speed_value - average_speed_first ) > = average_speed_precision ) { <nl> - average_speed_first = average_speed_value ; <nl> - average_speed_watch . restart ( ) ; <nl> + if ( abs ( avg_speed_value - avg_speed_first ) > = precision ) { <nl> + avg_speed_first = avg_speed_value ; <nl> + avg_speed_watch . restart ( ) ; <nl> } <nl> } <nl> <nl> - void update_max_speed ( const size_t max_speed_candidate ) <nl> + void update_max_speed ( const size_t max_speed_candidate , Stopwatch & max_speed_watch , <nl> + double & max_speed ) <nl> { <nl> if ( max_speed_candidate > max_speed ) { <nl> max_speed = max_speed_candidate ; <nl> struct Stats <nl> rows_read + = rows_read_inc ; <nl> bytes_read + = bytes_read_inc ; <nl> <nl> - double new_speed = rows_read_inc / watch_per_query . elapsedSeconds ( ) ; <nl> - update_max_speed ( new_speed ) ; <nl> - update_average_speed ( new_speed ) ; <nl> + double new_rows_speed = rows_read_inc / watch_per_query . elapsedSeconds ( ) ; <nl> + double new_bytes_speed = bytes_read_inc / watch_per_query . elapsedSeconds ( ) ; <nl> + <nl> + / / / Update rows speed <nl> + update_max_speed ( new_rows_speed , max_rows_speed_watch , max_rows_speed ) ; <nl> + update_average_speed ( new_rows_speed , avg_rows_speed_watch , <nl> + number_of_rows_speed_info_batches , avg_rows_speed_precision , <nl> + avg_rows_speed_first , avg_rows_speed_value ) ; <nl> + / / / Update bytes speed <nl> + update_max_speed ( new_bytes_speed , max_bytes_speed_watch , max_bytes_speed ) ; <nl> + update_average_speed ( new_bytes_speed , avg_bytes_speed_watch , <nl> + number_of_bytes_speed_info_batches , avg_bytes_speed_precision , <nl> + avg_bytes_speed_first , avg_bytes_speed_value ) ; <nl> } <nl> <nl> void updateQueryInfo ( ) <nl> struct Stats <nl> watch . restart ( ) ; <nl> watch_per_query . restart ( ) ; <nl> min_time_watch . restart ( ) ; <nl> - max_speed_watch . restart ( ) ; <nl> - average_speed_watch . restart ( ) ; <nl> + max_rows_speed_watch . restart ( ) ; <nl> + max_bytes_speed_watch . restart ( ) ; <nl> + avg_rows_speed_watch . restart ( ) ; <nl> + avg_bytes_speed_watch . restart ( ) ; <nl> <nl> sampler . clear ( ) ; <nl> <nl> struct Stats <nl> <nl> min_time = std : : numeric_limits < UInt64 > : : max ( ) ; <nl> total_time = 0 ; <nl> - max_speed = 0 ; <nl> - average_speed_value = 0 ; <nl> - average_speed_first = 0 ; <nl> - average_speed_precision = 0 . 001 ; <nl> - number_of_speed_info_batches = 0 ; <nl> + max_rows_speed = 0 ; <nl> + max_bytes_speed = 0 ; <nl> + avg_rows_speed_value = 0 ; <nl> + avg_bytes_speed_value = 0 ; <nl> + avg_rows_speed_first = 0 ; <nl> + avg_bytes_speed_first = 0 ; <nl> + avg_rows_speed_precision = 0 . 001 ; <nl> + avg_bytes_speed_precision = 0 . 001 ; <nl> + number_of_rows_speed_info_batches = 0 ; <nl> + number_of_bytes_speed_info_batches = 0 ; <nl> } <nl> } ; <nl> <nl> class PerformanceTest <nl> throw Poco : : Exception ( \" No tests were specified \" , 1 ) ; <nl> } <nl> <nl> - / / std : : cerr < < std : : fixed < < std : : setprecision ( 3 ) ; <nl> + std : : cerr < < std : : fixed < < std : : setprecision ( 3 ) ; <nl> + std : : cout < < std : : fixed < < std : : setprecision ( 3 ) ; <nl> readTestsConfiguration ( input_files ) ; <nl> } <nl> <nl> class PerformanceTest <nl> using Queue = ConcurrentBoundedQueue < Query > ; <nl> Queue queue ; <nl> <nl> + using Keys = std : : vector < std : : string > ; <nl> + <nl> ConnectionPool connections ; <nl> ThreadPool pool ; <nl> Settings settings ; <nl> class PerformanceTest <nl> using Config = Poco : : AutoPtr < XMLConfiguration > ; <nl> using Paths = std : : vector < std : : string > ; <nl> using StringToVector = std : : map < std : : string , std : : vector < std : : string > > ; <nl> + StringToVector substitutions ; <nl> std : : vector < Config > testsConfigurations ; <nl> <nl> + using StringKeyValue = std : : map < std : : string , std : : string > ; <nl> + std : : vector < StringKeyValue > substitutionsMaps ; <nl> + <nl> struct StopCriterions stopCriterions ; <nl> <nl> # define incFulfilledCriterions ( CRITERION ) \\ <nl> class PerformanceTest <nl> enum ExecutionType { loop , once } ; <nl> ExecutionType execType ; <nl> <nl> - Stats info_total ; <nl> + size_t timesToRun = 1 ; <nl> + std : : vector < Stats > statistics ; <nl> std : : mutex mutex ; <nl> <nl> - <nl> void readTestsConfiguration ( const Paths & input_files ) <nl> { <nl> testsConfigurations . resize ( input_files . size ( ) ) ; <nl> class PerformanceTest <nl> std : : cout < < \" Running : \" < < testName < < \" \\ n \" ; <nl> <nl> / / / Preprocess configuration file <nl> - using Keys = std : : vector < std : : string > ; <nl> - <nl> if ( testConfig - > has ( \" settings \" ) ) { <nl> Keys configSettings ; <nl> testConfig - > keys ( \" settings \" , configSettings ) ; <nl> class PerformanceTest <nl> } <nl> <nl> if ( std : : find ( configSettings . begin ( ) , configSettings . end ( ) , <nl> - \" average_speed_precision \" ) ! = configSettings . end ( ) ) { <nl> - info_total . average_speed_precision = testConfig - > getDouble ( \" settings . average_speed_precision \" ) ; <nl> + \" average_rows_speed_precision \" ) ! = configSettings . end ( ) ) { <nl> + statistics . back ( ) . avg_rows_speed_precision = testConfig - > getDouble ( \" settings . average_rows_speed_precision \" ) ; <nl> + } <nl> + <nl> + if ( std : : find ( configSettings . begin ( ) , configSettings . end ( ) , <nl> + \" average_bytes_speed_precision \" ) ! = configSettings . end ( ) ) { <nl> + statistics . back ( ) . avg_bytes_speed_precision = testConfig - > getDouble ( \" settings . average_bytes_speed_precision \" ) ; <nl> } <nl> } <nl> <nl> class PerformanceTest <nl> / / / Make \" subconfig \" of inner xml block <nl> AbstractConfig substitutionsView ( testConfig <nl> - > createView ( \" substitutions \" ) ) ; <nl> - <nl> - StringToVector substitutions ; <nl> constructSubstitutions ( substitutionsView , substitutions ) ; <nl> <nl> queries = formatQueries ( query , substitutions ) ; <nl> class PerformanceTest <nl> throw Poco : : Exception ( \" No termination conditions were found \" , 1 ) ; <nl> } <nl> <nl> - if ( execType = = loop ) { <nl> - runLoopQuery ( queries [ 0 ] ) ; <nl> + if ( testConfig - > has ( \" timesToRun \" ) ) { <nl> + timesToRun = testConfig - > getUInt ( \" timesToRun \" ) ; <nl> + } <nl> + <nl> + for ( size_t numberOfLaunch = 0 ; numberOfLaunch < timesToRun ; + + numberOfLaunch ) { <nl> + stopCriterions . reset ( ) ; <nl> + statistics . emplace_back ( ) ; <nl> + <nl> + if ( execType = = loop ) { <nl> + runLoopQuery ( queries [ 0 ] ) ; <nl> + } else { <nl> + runQueries ( queries ) ; <nl> + } <nl> + <nl> + statistics . back ( ) . setTotalTime ( ) ; <nl> + } <nl> + <nl> + AbstractConfig metricsView ( testConfig - > createView ( \" metric \" ) ) ; <nl> + <nl> + Keys metrics ; <nl> + metricsView - > keys ( metrics ) ; <nl> + if ( metrics . size ( ) > 1 ) { <nl> + throw Poco : : Exception ( \" More than 1 main metric is not allowed \" ) ; <nl> + } <nl> + <nl> + if ( metrics . size ( ) = = 1 ) { <nl> + checkMetricInput ( metrics [ 0 ] ) ; <nl> + minOutput ( metrics [ 0 ] ) ; <nl> } else { <nl> - runQueries ( queries ) ; <nl> + constructTotalInfo ( ) ; <nl> } <nl> + } <nl> <nl> - info_total . setTotalTime ( ) ; <nl> - constructTotalInfo ( ) ; <nl> + void checkMetricInput ( const std : : string & main_metric ) const { <nl> + std : : vector < std : : string > loopMetrics = { <nl> + \" min_time \" , \" quantiles \" , \" total_time \" , \" queries_per_second \" , <nl> + \" rows_per_second \" , \" bytes_per_second \" <nl> + } ; <nl> + <nl> + std : : vector < std : : string > infiniteMetrics = { <nl> + \" max_rows_per_second \" , \" max_bytes_per_second \" , \" avg_rows_per_second \" , <nl> + \" avg_bytes_per_second \" <nl> + } ; <nl> + <nl> + if ( execType = = loop ) { <nl> + if ( std : : find ( infiniteMetrics . begin ( ) , infiniteMetrics . end ( ) , main_metric ) ! = infiniteMetrics . end ( ) ) { <nl> + throw Poco : : Exception ( \" Wrong type of main metric for loop \" <nl> + \" execution type \" ) ; <nl> + } <nl> + } else { <nl> + if ( std : : find ( loopMetrics . begin ( ) , loopMetrics . end ( ) , main_metric ) ! = loopMetrics . end ( ) ) { <nl> + throw Poco : : Exception ( \" Wrong type of main metric for \" <nl> + \" inifinite execution type \" ) ; <nl> + } <nl> + } <nl> } <nl> <nl> void runLoopQuery ( const Query & query ) <nl> { <nl> - info_total . clear ( ) ; <nl> + statistics . back ( ) . clear ( ) ; <nl> <nl> size_t max_iterations = stopCriterions . iterations . value ; <nl> size_t i = - 1 ; <nl> class PerformanceTest <nl> <nl> void runQueries ( const Queries & queries ) <nl> { <nl> - info_total . clear ( ) ; <nl> + statistics . back ( ) . clear ( ) ; <nl> <nl> for ( size_t i = 0 ; i < concurrency ; + + i ) { <nl> pool . schedule ( std : : bind ( <nl> class PerformanceTest <nl> void execute ( ConnectionPool : : Entry & connection , const Query & query ) <nl> { <nl> InterruptListener thread_interrupt_listener ; <nl> - info_total . watch_per_query . restart ( ) ; <nl> + statistics . back ( ) . watch_per_query . restart ( ) ; <nl> <nl> RemoteBlockInputStream * stream = new RemoteBlockInputStream ( <nl> connection , query , & settings , nullptr , Tables ( ) / * , query_processing_stage * / <nl> class PerformanceTest <nl> streams . erase ( streams . begin ( ) + stream_index ) ; <nl> delete stream ; <nl> <nl> - info_total . updateQueryInfo ( ) ; <nl> + statistics . back ( ) . updateQueryInfo ( ) ; <nl> <nl> / / const BlockStreamProfileInfo & info = stream - > getProfileInfo ( ) ; <nl> / / double seconds = watch . elapsedSeconds ( ) ; <nl> / / std : : lock_guard < std : : mutex > lock ( mutex ) ; <nl> / / info_per_interval . add ( seconds , progress . rows , progress . bytes , info . rows , info . bytes ) ; <nl> - / / info_total . add ( seconds , progress . rows , progress . bytes , info . rows , info . bytes ) ; <nl> + / / statistics . back ( ) . add ( seconds , progress . rows , progress . bytes , info . rows , info . bytes ) ; <nl> } <nl> <nl> void checkFulfilledCriterionsAndUpdate ( const Progress & progress , <nl> class PerformanceTest <nl> { <nl> std : : lock_guard < std : : mutex > lock ( mutex ) ; <nl> <nl> - info_total . add ( progress . rows , progress . bytes ) ; <nl> + statistics . back ( ) . add ( progress . rows , progress . bytes ) ; <nl> <nl> size_t max_rows_to_read = stopCriterions . rows_read . value ; <nl> - if ( max_rows_to_read & & info_total . rows_read > = max_rows_to_read ) { <nl> + if ( max_rows_to_read & & statistics . back ( ) . rows_read > = max_rows_to_read ) { <nl> incFulfilledCriterions ( rows_read ) ; <nl> } <nl> <nl> size_t max_bytes_to_read = stopCriterions . bytes_read_uncompressed . value ; <nl> - if ( max_bytes_to_read & & info_total . bytes_read > = max_bytes_to_read ) { <nl> + if ( max_bytes_to_read & & statistics . back ( ) . bytes_read > = max_bytes_to_read ) { <nl> incFulfilledCriterions ( bytes_read_uncompressed ) ; <nl> } <nl> <nl> if ( UInt64 max_timeout_ms = stopCriterions . timeout_ms . value ) { <nl> / / / cast nanoseconds to ms <nl> - if ( ( info_total . watch . elapsed ( ) / ( 1000 * 1000 ) ) > max_timeout_ms ) { <nl> + if ( ( statistics . back ( ) . watch . elapsed ( ) / ( 1000 * 1000 ) ) > max_timeout_ms ) { <nl> incFulfilledCriterions ( timeout_ms ) ; <nl> } <nl> } <nl> class PerformanceTest <nl> size_t min_time_not_changing_for_ms = stopCriterions <nl> . min_time_not_changing_for_ms . value ; <nl> if ( min_time_not_changing_for_ms ) { <nl> - size_t min_time_did_not_change_for = info_total <nl> + size_t min_time_did_not_change_for = statistics . back ( ) <nl> . min_time_watch <nl> . elapsed ( ) / ( 1000 * 1000 ) ; <nl> <nl> class PerformanceTest <nl> . max_speed_not_changing_for_ms <nl> . value ; <nl> if ( max_speed_not_changing_for_ms ) { <nl> - UInt64 speed_not_changing_time = info_total <nl> - . max_speed_watch <nl> + UInt64 speed_not_changing_time = statistics . back ( ) <nl> + . max_rows_speed_watch <nl> . elapsed ( ) / ( 1000 * 1000 ) ; <nl> if ( speed_not_changing_time > = max_speed_not_changing_for_ms ) { <nl> incFulfilledCriterions ( max_speed_not_changing_for_ms ) ; <nl> class PerformanceTest <nl> . average_speed_not_changing_for_ms <nl> . value ; <nl> if ( average_speed_not_changing_for_ms ) { <nl> - UInt64 speed_not_changing_time = info_total <nl> - . average_speed_watch <nl> + UInt64 speed_not_changing_time = statistics . back ( ) <nl> + . avg_rows_speed_watch <nl> . elapsed ( ) / ( 1000 * 1000 ) ; <nl> if ( speed_not_changing_time > = average_speed_not_changing_for_ms ) { <nl> incFulfilledCriterions ( average_speed_not_changing_for_ms ) ; <nl> class PerformanceTest <nl> void constructSubstitutions ( AbstractConfig & substitutionsView , <nl> StringToVector & substitutions ) <nl> { <nl> - using Keys = std : : vector < std : : string > ; <nl> Keys xml_substitutions ; <nl> substitutionsView - > keys ( xml_substitutions ) ; <nl> <nl> class PerformanceTest <nl> } <nl> <nl> std : : vector < std : : string > formatQueries ( const std : : string & query , <nl> - StringToVector substitutions ) const <nl> + StringToVector substitutions ) <nl> { <nl> std : : vector < std : : string > queries ; <nl> <nl> class PerformanceTest <nl> StringToVector : : iterator substitutions_last = substitutions . end ( ) ; <nl> - - substitutions_last ; <nl> <nl> + std : : map < std : : string , std : : string > substitutionsMap ; <nl> + <nl> runThroughAllOptionsAndPush ( <nl> - substitutions_first , substitutions_last , query , queries <nl> + substitutions_first , substitutions_last , query , queries , substitutionsMap <nl> ) ; <nl> <nl> return queries ; <nl> class PerformanceTest <nl> StringToVector : : iterator substitutions_left , <nl> StringToVector : : iterator substitutions_right , <nl> const std : : string & template_query , <nl> - std : : vector < std : : string > & queries <nl> - ) const <nl> + std : : vector < std : : string > & queries , <nl> + const StringKeyValue & templateSubstitutionsMap = StringKeyValue ( ) <nl> + ) <nl> { <nl> std : : string name = substitutions_left - > first ; <nl> std : : vector < std : : string > values = substitutions_left - > second ; <nl> <nl> - for ( auto value = values . begin ( ) ; value ! = values . end ( ) ; + + value ) { <nl> + for ( const std : : string & value : values ) { <nl> / / / Copy query string for each unique permutation <nl> Query query = template_query ; <nl> + StringKeyValue substitutionsMap = templateSubstitutionsMap ; <nl> size_t substrPos = 0 ; <nl> <nl> while ( substrPos ! = std : : string : : npos ) { <nl> class PerformanceTest <nl> if ( substrPos ! = std : : string : : npos ) { <nl> query . replace ( <nl> substrPos , 1 + name . length ( ) + 1 , <nl> - * value <nl> + value <nl> ) ; <nl> } <nl> } <nl> <nl> + substitutionsMap [ name ] = value ; <nl> + <nl> / / / If we ' ve reached the end of substitution chain <nl> if ( substitutions_left = = substitutions_right ) { <nl> queries . push_back ( query ) ; <nl> + substitutionsMaps . push_back ( substitutionsMap ) ; <nl> } else { <nl> StringToVector : : iterator next_it = substitutions_left ; <nl> + + next_it ; <nl> <nl> runThroughAllOptionsAndPush ( <nl> - next_it , substitutions_right , query , queries <nl> + next_it , substitutions_right , query , queries , substitutionsMap <nl> ) ; <nl> } <nl> } <nl> class PerformanceTest <nl> public : <nl> void constructTotalInfo ( ) <nl> { <nl> - std : : string hostname = \" null \" ; <nl> + JSONString jsonOutput ; <nl> + std : : string hostname = \" \" ; <nl> <nl> char hostname_buffer [ 256 ] ; <nl> if ( gethostname ( hostname_buffer , 256 ) = = 0 ) { <nl> hostname = std : : string ( hostname_buffer ) ; <nl> } <nl> <nl> - std : : cout < < \" total info : \" < < std : : endl ; <nl> - std : : cout < < \" hostname : \" < < hostname < < std : : endl ; <nl> - std : : cout < < \" Number of CPUs : \" < < sysconf ( _SC_NPROCESSORS_ONLN ) < < std : : endl ; <nl> - std : : cout < < \" test_name : \" < < testName < < std : : endl ; <nl> - std : : cout < < \" ? ? main_metric : total_time ? ? \" < < std : : endl ; <nl> - std : : cout < < \" parameters : { some substitutions here . . . } \" < < std : : endl ; <nl> - <nl> - if ( execType = = loop ) { <nl> - std : : cout < < \" min_time : \" < < info_total . min_time / 1000 <nl> - < < \" . \" < < info_total . min_time % 1000 < < \" s \" < < std : : endl ; <nl> - <nl> - / / TODO : < quantile > 90 < / quantile > <nl> - <nl> - std : : cout < < \" total_time : \" < < info_total . total_time < < \" s \" < < std : : endl ; <nl> - std : : cout < < \" queries_per_second : \" < < double ( info_total . queries ) / info_total . total_time < < std : : endl ; <nl> - std : : cout < < \" rows_per_second : \" < < double ( info_total . rows_read ) / info_total . total_time < < std : : endl ; <nl> - std : : cout < < \" bytes_per_second : \" < < double ( info_total . bytes_read ) / info_total . total_time < < std : : endl ; <nl> - } else { <nl> - std : : cout < < \" max_rows_per_second : \" < < info_total . max_speed < < std : : endl ; <nl> - / / std : : cout < < \" max_bytes_per_second : \" < < < < std : : endl ; <nl> - std : : cout < < \" avg_rows_per_second : \" < < info_total . average_speed_value < < std : : endl ; <nl> - / / std : : cout < < \" avg_bytes_per_second : \" < < < < std : : endl ; <nl> - } <nl> + jsonOutput [ \" hostname \" ] . set ( hostname ) ; <nl> + jsonOutput [ \" Number of CPUs : \" ] . set ( sysconf ( _SC_NPROCESSORS_ONLN ) ) ; <nl> + jsonOutput [ \" test_name \" ] . set ( testName ) ; <nl> + <nl> + if ( substitutions . size ( ) ) { <nl> + JSONString jsonParameters ; <nl> + <nl> + for ( auto it = substitutions . begin ( ) ; it ! = substitutions . end ( ) ; + + it ) { <nl> + std : : string parameter = it - > first ; <nl> + std : : vector < std : : string > values = it - > second ; <nl> + <nl> + std : : string arrayString = \" [ \" ; <nl> + for ( size_t i = 0 ; i ! = values . size ( ) ; + + i ) { <nl> + arrayString + = ' \\ \" ' + values [ i ] + ' \\ \" ' ; <nl> + if ( i ! = values . size ( ) - 1 ) { <nl> + arrayString + = \" , \" ; <nl> + } <nl> + } <nl> + arrayString + = ' ] ' ; <nl> + <nl> + jsonParameters [ parameter ] . set ( arrayString ) ; <nl> + } <nl> + <nl> + jsonOutput [ \" parameters \" ] . set ( jsonParameters ) ; <nl> + } <nl> + <nl> + std : : vector < JSONString > runInfos ( timesToRun ) ; <nl> + for ( size_t numberOfLaunch = 0 ; numberOfLaunch < timesToRun ; + + numberOfLaunch ) { <nl> + JSONString runJSON ; <nl> + <nl> + if ( execType = = loop ) { <nl> + runJSON [ \" min_time \" ] . set ( std : : to_string ( statistics [ numberOfLaunch ] . min_time / 1000 ) <nl> + + \" . \" + std : : to_string ( statistics [ numberOfLaunch ] . min_time % 1000 ) + \" s \" ) ; <nl> + <nl> + JSONString quantiles ( 4 ) ; / / / here , 4 is the size of \\ t padding <nl> + for ( double percent = 10 ; percent < = 90 ; percent + = 10 ) { <nl> + quantiles [ percent / 100 ] . set ( statistics [ numberOfLaunch ] . sampler . quantileInterpolated ( percent / 100 . 0 ) ) ; <nl> + } <nl> + quantiles [ 0 . 95 ] . set ( statistics [ numberOfLaunch ] . sampler . quantileInterpolated ( 95 / 100 . 0 ) ) ; <nl> + quantiles [ 0 . 99 ] . set ( statistics [ numberOfLaunch ] . sampler . quantileInterpolated ( 99 / 100 . 0 ) ) ; <nl> + quantiles [ 0 . 999 ] . set ( statistics [ numberOfLaunch ] . sampler . quantileInterpolated ( 99 . 9 / 100 . 0 ) ) ; <nl> + quantiles [ 0 . 9999 ] . set ( statistics [ numberOfLaunch ] . sampler . quantileInterpolated ( 99 . 99 / 100 . 0 ) ) ; <nl> + <nl> + runJSON [ \" quantiles \" ] . set ( quantiles ) ; <nl> + <nl> + runJSON [ \" total_time \" ] . set ( std : : to_string ( statistics [ numberOfLaunch ] . total_time ) + \" s \" ) ; <nl> + runJSON [ \" queries_per_second \" ] . set ( double ( statistics [ numberOfLaunch ] . queries ) / statistics [ numberOfLaunch ] . total_time ) ; <nl> + runJSON [ \" rows_per_second \" ] . set ( double ( statistics [ numberOfLaunch ] . rows_read ) / statistics [ numberOfLaunch ] . total_time ) ; <nl> + runJSON [ \" bytes_per_second \" ] . set ( double ( statistics [ numberOfLaunch ] . bytes_read ) / statistics [ numberOfLaunch ] . total_time ) ; <nl> + } else { <nl> + runJSON [ \" max_rows_per_second \" ] . set ( statistics [ numberOfLaunch ] . max_rows_speed ) ; <nl> + runJSON [ \" max_bytes_per_second \" ] . set ( statistics [ numberOfLaunch ] . max_bytes_speed ) ; <nl> + runJSON [ \" avg_rows_per_second \" ] . set ( statistics [ numberOfLaunch ] . avg_rows_speed_value ) ; <nl> + runJSON [ \" avg_bytes_per_second \" ] . set ( statistics [ numberOfLaunch ] . avg_bytes_speed_value ) ; <nl> + } <nl> + <nl> + runInfos [ numberOfLaunch ] = runJSON ; <nl> + } <nl> + <nl> + jsonOutput [ \" runs \" ] . set ( runInfos ) ; <nl> + <nl> + std : : cout < < jsonOutput < < std : : endl ; <nl> + } <nl> + <nl> + void minOutput ( const std : : string & main_metric ) <nl> + { <nl> + / / TODO : remove <nl> + std : : cout < < \" test \" < < std : : endl ; <nl> + <nl> + for ( size_t numberOfLaunch = 0 ; numberOfLaunch < timesToRun ; + + numberOfLaunch ) { <nl> + std : : cout < < \" run \" < < numberOfLaunch + 1 < < \" : \" ; <nl> + std : : cout < < main_metric < < \" = \" < < statistics [ numberOfLaunch ] . getStatisticByName ( main_metric ) ; <nl> + std : : cout < < std : : endl ; <nl> + } <nl> } <nl> } ; <nl> <nl>\n", "msg": "Construct and output info at the end\n"}
{"diff_id": 9827, "repo": "apple/swift\n", "sha": "951fd5620e4ee6006c93e8f108eafaac13345401\n", "time": "2013-12-09T14:23:29Z\n", "diff": "mmm a / lib / Sema / CSRanking . cpp <nl> ppp b / lib / Sema / CSRanking . cpp <nl> <nl> / / = = = mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm - = = = / / <nl> # include \" ConstraintSystem . h \" <nl> # include \" swift / AST / ArchetypeBuilder . h \" <nl> + # include \" llvm / ADT / Statistic . h \" <nl> <nl> using namespace swift ; <nl> using namespace constraints ; <nl> <nl> + / / = = = mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm - - = = = / / <nl> + / / Statistics <nl> + / / = = = mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm - - = = = / / <nl> + # define DEBUG_TYPE \" Constraint solver overall \" <nl> + STATISTIC ( NumDiscardedSolutions , \" # of solutions discarded \" ) ; <nl> + <nl> / / / \\ brief Remove the initializers from any tuple types within the <nl> / / / given type . <nl> static Type stripInitializers ( TypeChecker & tc , Type origType ) { <nl> ConstraintSystem : : findBestSolution ( SmallVectorImpl < Solution > & viable , <nl> } <nl> <nl> / / If the result was not ambiguous , we ' re done . <nl> - if ( ! ambiguous ) <nl> + if ( ! ambiguous ) { <nl> + NumDiscardedSolutions + = viable . size ( ) - 1 ; <nl> return bestIdx ; <nl> + } <nl> <nl> / / The comparison was ambiguous . Identify any solutions that are worse than <nl> / / any other solution . <nl> ConstraintSystem : : findBestSolution ( SmallVectorImpl < Solution > & viable , <nl> + + outIndex ; <nl> } <nl> viable . erase ( viable . begin ( ) + outIndex , viable . end ( ) ) ; <nl> + NumDiscardedSolutions + = viable . size ( ) - outIndex ; <nl> <nl> return Nothing ; <nl> } <nl>\n", "msg": "Track the # of solutions computed and discarded .\n", "score": 1}
{"diff_id": 9868, "repo": "apple/swift\n", "sha": "9a0437fd13af5be0d62f4e52e3f8923483bc0501\n", "time": "2015-11-04T15:55:20Z\n", "diff": "mmm a / lib / SILPasses / GlobalDeadStoreElimination . cpp <nl> ppp b / lib / SILPasses / GlobalDeadStoreElimination . cpp <nl> class BBState { <nl> / / / The basic block this BBState represents . <nl> SILBasicBlock * BB ; <nl> <nl> + / / / Keep the number of MemLocations in the LocationVault . <nl> + unsigned MemLocationCount ; <nl> + <nl> / / / A bit vector for which the ith bit represents the ith MemLocation in <nl> / / / MemLocationVault . If the bit is set , then the location currently has an <nl> / / / upward visible store . <nl> class BBState { <nl> / / / predecessors needs to be rerun . <nl> llvm : : BitVector WriteSetIn ; <nl> <nl> + / / / A bit vector for which the ith bit represents the ith MemLocation in <nl> + / / / MemLocationVault . If the bit is set , then the current basic block <nl> + / / / generates an upward visible store . <nl> + llvm : : BitVector BBGenSet ; <nl> + <nl> + / / / A bit vector for which the ith bit represents the ith MemLocation in <nl> + / / / MemLocationVault . If the bit is set , then the current basic block <nl> + / / / kills an upward visible store . <nl> + llvm : : BitVector BBKillSet ; <nl> + <nl> / / / The dead stores in the current basic block . <nl> llvm : : DenseSet < SILInstruction * > DeadStores ; <nl> <nl> class BBState { <nl> <nl> / / / Constructors . <nl> BBState ( ) : BB ( nullptr ) { } <nl> - BBState ( SILBasicBlock * B , unsigned lcnt ) : BB ( B ) { <nl> + BBState ( SILBasicBlock * B , unsigned lcnt ) : BB ( B ) , MemLocationCount ( lcnt ) { <nl> / / The initial state of WriteSetIn should be all 1 ' s . Otherwise the <nl> / / dataflow solution could be too conservative . <nl> / / <nl> class BBState { <nl> / / However , by doing so , we can only eliminate the dead stores after the <nl> / / data flow stablizes . <nl> / / <nl> - WriteSetIn . resize ( lcnt , true ) ; <nl> - WriteSetOut . resize ( lcnt , false ) ; <nl> + WriteSetIn . resize ( MemLocationCount , true ) ; <nl> + WriteSetOut . resize ( MemLocationCount , false ) ; <nl> + <nl> + / / GenSet and KillSet initially empty . <nl> + BBGenSet . resize ( MemLocationCount , false ) ; <nl> + BBKillSet . resize ( MemLocationCount , false ) ; <nl> } <nl> <nl> / / / Check whether the WriteSetIn has changed . If it does , we need to <nl> bool BBState : : isTrackingMemLocation ( unsigned bit ) { <nl> void BBState : : initialize ( const BBState & Succ ) { WriteSetOut = Succ . WriteSetIn ; } <nl> <nl> void BBState : : intersect ( const BBState & Succ ) { <nl> - for ( unsigned i = 0 ; i < WriteSetOut . size ( ) ; + + i ) { <nl> + for ( unsigned i = 0 ; i < MemLocationCount ; + + i ) { <nl> if ( Succ . WriteSetIn . test ( i ) ) <nl> continue ; <nl> / / WriteSetIn is not set . <nl> class DSEContext { <nl> return getBBLocState ( I - > getParent ( ) ) ; <nl> } <nl> <nl> + / / / MemLocation read has been extracted , expanded and mapped to the bit <nl> + / / / position in the bitvector . update the gen kill set using the bit <nl> + / / / position . <nl> + void updateGenKillSetForRead ( SILInstruction * I , BBState * S , unsigned bit ) ; <nl> + <nl> + / / / MemLocation written has been extracted , expanded and mapped to the bit <nl> + / / / position in the bitvector . update the gen kill set using the bit <nl> + / / / position . <nl> + void updateGenKillSetForWrite ( SILInstruction * I , BBState * S , unsigned bit ) ; <nl> + <nl> / / / MemLocation read has been extracted , expanded and mapped to the bit <nl> / / / position in the bitvector . process it using the bit position . <nl> void updateWriteSetForRead ( SILInstruction * Inst , BBState * State , <nl> class DSEContext { <nl> <nl> / / / There is a read to a location , expand the location into individual fields <nl> / / / before processing them . <nl> - void processRead ( SILInstruction * Inst , BBState * State , SILValue Mem ) ; <nl> + void processRead ( SILInstruction * Inst , BBState * State , SILValue Mem , <nl> + bool BuildGenKillSet ) ; <nl> <nl> / / / There is a write to a location , expand the location into individual fields <nl> / / / before processing them . <nl> void processWrite ( SILInstruction * Inst , BBState * State , SILValue Val , <nl> - SILValue Mem , bool PDSE ) ; <nl> + SILValue Mem , bool BuildGenKillSet ) ; <nl> <nl> / / / Process Instructions . Extract MemLocations from SIL LoadInst . <nl> - void processLoadInst ( SILInstruction * Inst ) ; <nl> + void processLoadInst ( SILInstruction * Inst , bool BuildGenKillSet ) ; <nl> <nl> / / / Process Instructions . Extract MemLocations from SIL StoreInst . <nl> - void processStoreInst ( SILInstruction * Inst , bool PDSE ) ; <nl> + void processStoreInst ( SILInstruction * Inst , bool BuildGenKillSet ) ; <nl> <nl> / / / Process Instructions . Extract MemLocations from SIL Unknown Memory Inst . <nl> - void processUnknownReadMemInst ( SILInstruction * Inst ) ; <nl> + void processUnknownReadMemInst ( SILInstruction * Inst , bool BuildGenKillSet ) ; <nl> <nl> / / / Check whether the instruction invalidate any MemLocations due to change in <nl> / / / its MemLocation Base . <nl> class DSEContext { <nl> / / / the loop basic block will have store to x . a and therefore x . a = 13 can now <nl> / / / be considered dead . <nl> / / / <nl> - void invalidateMemLocationBase ( SILInstruction * Inst ) ; <nl> + void invalidateMemLocationBase ( SILInstruction * Inst , bool BuildGenKillSet ) ; <nl> <nl> / / / Get the bit representing the location in the MemLocationVault . <nl> / / / <nl> class DSEContext { <nl> <nl> / / / Compute the kill set for the basic block . return true if the store set <nl> / / / changes . <nl> - bool processBasicBlock ( SILBasicBlock * BB , bool PDSE = false ) ; <nl> + bool processBasicBlock ( SILBasicBlock * BB ) ; <nl> + <nl> + / / / Compute the genset and killset for the current basic block . <nl> + void processBasicBlockForGenKillSet ( SILBasicBlock * BB ) ; <nl> + <nl> + / / / Compute the WriteSetOut and WriteSetIn for the current basic <nl> + / / / block with the generated gen and kill set . <nl> + bool processBasicBlockWithGenKillSet ( SILBasicBlock * BB ) ; <nl> <nl> / / / Intersect the successor live - ins . <nl> void mergeSuccessorStates ( SILBasicBlock * BB ) ; <nl> <nl> / / / Update the BBState based on the given instruction . <nl> - void processInstruction ( SILInstruction * I , bool PDSE ) ; <nl> + void processInstruction ( SILInstruction * I , bool BuildGenKillSet ) ; <nl> <nl> / / / Entry point for global dead store elimination . <nl> void run ( ) ; <nl> unsigned DSEContext : : getMemLocationBit ( const MemLocation & Loc ) { <nl> return Iter - > second ; <nl> } <nl> <nl> - bool DSEContext : : processBasicBlock ( SILBasicBlock * BB , bool PDSE ) { <nl> + void DSEContext : : processBasicBlockForGenKillSet ( SILBasicBlock * BB ) { <nl> + for ( auto I = BB - > rbegin ( ) , E = BB - > rend ( ) ; I ! = E ; + + I ) { <nl> + processInstruction ( & ( * I ) , true ) ; <nl> + } <nl> + } <nl> + <nl> + bool DSEContext : : processBasicBlockWithGenKillSet ( SILBasicBlock * BB ) { <nl> + / / Compute the WriteSetOut at the end of the basic block . <nl> + mergeSuccessorStates ( BB ) ; <nl> + <nl> + / / Compute the WriteSetOut at the beginning of the basic block . <nl> + BBState * S = getBBLocState ( BB ) ; <nl> + llvm : : BitVector T = S - > BBKillSet ; <nl> + S - > WriteSetOut & = T . flip ( ) ; <nl> + S - > WriteSetOut | = S - > BBGenSet ; <nl> + <nl> + / / If WriteSetIn changes , then keep iterating until reached a fixed <nl> + / / point . <nl> + return S - > updateWriteSetIn ( ) ; <nl> + } <nl> + <nl> + bool DSEContext : : processBasicBlock ( SILBasicBlock * BB ) { <nl> / / Intersect in the successor live - ins . A store is dead if it is not read from <nl> / / any path to the end of the program . Thus an intersection . <nl> mergeSuccessorStates ( BB ) ; <nl> <nl> / / Process instructions in post - order fashion . <nl> for ( auto I = BB - > rbegin ( ) , E = BB - > rend ( ) ; I ! = E ; + + I ) { <nl> - processInstruction ( & ( * I ) , PDSE ) ; <nl> + processInstruction ( & ( * I ) , false ) ; <nl> } <nl> <nl> / / If WriteSetIn changes , then keep iterating until reached a fixed <nl> void DSEContext : : mergeSuccessorStates ( SILBasicBlock * BB ) { <nl> } <nl> } <nl> <nl> - void DSEContext : : invalidateMemLocationBase ( SILInstruction * I ) { <nl> + void DSEContext : : invalidateMemLocationBase ( SILInstruction * I , <nl> + bool GenKillSet ) { <nl> BBState * S = getBBLocState ( I ) ; <nl> + if ( GenKillSet ) { <nl> + for ( unsigned i = 0 ; i < S - > MemLocationCount ; + + i ) { <nl> + if ( MemLocationVault [ i ] . getBase ( ) . getDef ( ) ! = I ) <nl> + continue ; <nl> + S - > BBGenSet . reset ( i ) ; <nl> + S - > BBKillSet . set ( i ) ; <nl> + } <nl> + return ; <nl> + } <nl> + <nl> / / If this instruction defines the base of a location , then we need to <nl> / / invalidate any locations with the same base . <nl> - for ( unsigned i = 0 ; i < S - > WriteSetOut . size ( ) ; + + i ) { <nl> + for ( unsigned i = 0 ; i < S - > MemLocationCount ; + + i ) { <nl> if ( ! S - > WriteSetOut . test ( i ) ) <nl> continue ; <nl> if ( MemLocationVault [ i ] . getBase ( ) . getDef ( ) ! = I ) <nl> void DSEContext : : updateWriteSetForRead ( SILInstruction * I , BBState * S , <nl> / / used <nl> / / to kill any upward visible stores due to the intefering load . <nl> MemLocation & R = MemLocationVault [ bit ] ; <nl> - for ( unsigned i = 0 ; i < S - > WriteSetOut . size ( ) ; + + i ) { <nl> + for ( unsigned i = 0 ; i < S - > MemLocationCount ; + + i ) { <nl> if ( ! S - > isTrackingMemLocation ( i ) ) <nl> continue ; <nl> MemLocation & L = MemLocationVault [ i ] ; <nl> void DSEContext : : updateWriteSetForRead ( SILInstruction * I , BBState * S , <nl> } <nl> } <nl> <nl> + void DSEContext : : updateGenKillSetForRead ( SILInstruction * I , BBState * S , <nl> + unsigned bit ) { <nl> + / / Start tracking the read to this MemLocation in the killset and update <nl> + / / the genset accordingly . <nl> + MemLocation & R = MemLocationVault [ bit ] ; <nl> + for ( unsigned i = 0 ; i < S - > MemLocationCount ; + + i ) { <nl> + if ( ! S - > BBGenSet . test ( i ) ) <nl> + continue ; <nl> + MemLocation & L = MemLocationVault [ i ] ; <nl> + if ( ! L . isMayAliasMemLocation ( R , AA ) ) <nl> + continue ; <nl> + S - > BBGenSet . reset ( i ) ; <nl> + } <nl> + / / Update the kill set . <nl> + S - > BBKillSet . set ( bit ) ; <nl> + } <nl> + <nl> bool DSEContext : : updateWriteSetForWrite ( SILInstruction * I , BBState * S , <nl> unsigned bit ) { <nl> / / If a tracked store must aliases with this store , then this store is dead . <nl> bool IsDead = false ; <nl> MemLocation & R = MemLocationVault [ bit ] ; <nl> - for ( unsigned i = 0 ; i < S - > WriteSetOut . size ( ) ; + + i ) { <nl> + for ( unsigned i = 0 ; i < S - > MemLocationCount ; + + i ) { <nl> if ( ! S - > isTrackingMemLocation ( i ) ) <nl> continue ; <nl> / / If 2 locations may alias , we can still keep both stores . <nl> bool DSEContext : : updateWriteSetForWrite ( SILInstruction * I , BBState * S , <nl> return IsDead ; <nl> } <nl> <nl> - void DSEContext : : processRead ( SILInstruction * I , BBState * S , SILValue Mem ) { <nl> + void DSEContext : : updateGenKillSetForWrite ( SILInstruction * I , BBState * S , <nl> + unsigned bit ) { <nl> + / / Start tracking the store to this MemLoation . <nl> + S - > BBGenSet . set ( bit ) ; <nl> + } <nl> + <nl> + void DSEContext : : processRead ( SILInstruction * I , BBState * S , SILValue Mem , <nl> + bool BuildGenKillSet ) { <nl> / / Construct a MemLocation to represent the memory read by this instruction . <nl> / / NOTE : The base will point to the actual object this inst is accessing , <nl> / / not this particular field . <nl> void DSEContext : : processRead ( SILInstruction * I , BBState * S , SILValue Mem ) { <nl> / / If we cant figure out the Base or Projection Path for the read instruction , <nl> / / process it as an unknown memory instruction for now . <nl> if ( ! L . isValid ( ) ) { <nl> - processUnknownReadMemInst ( I ) ; <nl> + processUnknownReadMemInst ( I , BuildGenKillSet ) ; <nl> return ; <nl> } <nl> <nl> void DSEContext : : processRead ( SILInstruction * I , BBState * S , SILValue Mem ) { <nl> MemLocationList Locs ; <nl> MemLocation : : expand ( L , & I - > getModule ( ) , Locs , TypeExpansionVault ) ; <nl> for ( auto & E : Locs ) { <nl> + if ( BuildGenKillSet ) { <nl> + / / Only building the gen and kill sets for now . <nl> + updateGenKillSetForRead ( I , S , getMemLocationBit ( E ) ) ; <nl> + continue ; <nl> + } <nl> + / / This is the last iteration , compute WriteSetOut and perform the dead <nl> + / / store elimination . <nl> updateWriteSetForRead ( I , S , getMemLocationBit ( E ) ) ; <nl> } <nl> } <nl> <nl> void DSEContext : : processWrite ( SILInstruction * I , BBState * S , SILValue Val , <nl> - SILValue Mem , bool PDSE ) { <nl> + SILValue Mem , bool BuildGenKillSet ) { <nl> / / Construct a MemLocation to represent the memory read by this instruction . <nl> / / NOTE : The base will point to the actual object this inst is accessing , <nl> / / not this particular field . <nl> void DSEContext : : processWrite ( SILInstruction * I , BBState * S , SILValue Val , <nl> llvm : : BitVector V ( Locs . size ( ) ) ; <nl> unsigned idx = 0 ; <nl> for ( auto & E : Locs ) { <nl> + if ( BuildGenKillSet ) { <nl> + / / Only building the gen and kill sets here . <nl> + updateGenKillSetForWrite ( I , S , getMemLocationBit ( E ) ) ; <nl> + continue ; <nl> + } <nl> + / / This is the last iteration , compute WriteSetOut and perform the dead <nl> + / / store elimination . <nl> if ( updateWriteSetForWrite ( I , S , getMemLocationBit ( E ) ) ) <nl> V . set ( idx ) ; <nl> Dead & = V . test ( idx ) ; <nl> void DSEContext : : processWrite ( SILInstruction * I , BBState * S , SILValue Val , <nl> } <nl> <nl> / / Data flow has not stablized , do not perform the DSE just yet . <nl> - if ( ! PDSE ) <nl> + if ( BuildGenKillSet ) <nl> return ; <nl> <nl> / / Fully dead store - stores to all the components are dead , therefore this <nl> void DSEContext : : processWrite ( SILInstruction * I , BBState * S , SILValue Val , <nl> } <nl> } <nl> <nl> - void DSEContext : : processLoadInst ( SILInstruction * I ) { <nl> + void DSEContext : : processLoadInst ( SILInstruction * I , bool BuildGenKillSet ) { <nl> SILValue Mem = cast < LoadInst > ( I ) - > getOperand ( ) ; <nl> - processRead ( I , getBBLocState ( I ) , Mem ) ; <nl> + processRead ( I , getBBLocState ( I ) , Mem , BuildGenKillSet ) ; <nl> } <nl> <nl> - void DSEContext : : processStoreInst ( SILInstruction * I , bool PDSE ) { <nl> + void DSEContext : : processStoreInst ( SILInstruction * I , bool BuildGenKillSet ) { <nl> SILValue Val = cast < StoreInst > ( I ) - > getSrc ( ) ; <nl> SILValue Mem = cast < StoreInst > ( I ) - > getDest ( ) ; <nl> - processWrite ( I , getBBLocState ( I ) , Val , Mem , PDSE ) ; <nl> + processWrite ( I , getBBLocState ( I ) , Val , Mem , BuildGenKillSet ) ; <nl> } <nl> <nl> - void DSEContext : : processUnknownReadMemInst ( SILInstruction * I ) { <nl> + void DSEContext : : processUnknownReadMemInst ( SILInstruction * I , <nl> + bool BuildGenKillSet ) { <nl> + BBState * S = getBBLocState ( I ) ; <nl> + / / Update the gen kill set . <nl> + if ( BuildGenKillSet ) { <nl> + for ( unsigned i = 0 ; i < S - > MemLocationCount ; + + i ) { <nl> + if ( ! AA - > mayReadFromMemory ( I , MemLocationVault [ i ] . getBase ( ) ) ) <nl> + continue ; <nl> + S - > BBKillSet . set ( i ) ; <nl> + S - > BBGenSet . reset ( i ) ; <nl> + } <nl> + return ; <nl> + } <nl> + <nl> / / We do not know what this instruction does or the memory that it * may * <nl> / / touch . Hand it to alias analysis to see whether we need to invalidate <nl> / / any MemLocation . <nl> - BBState * S = getBBLocState ( I ) ; <nl> - for ( unsigned i = 0 ; i < S - > WriteSetOut . size ( ) ; + + i ) { <nl> + for ( unsigned i = 0 ; i < S - > MemLocationCount ; + + i ) { <nl> if ( ! S - > isTrackingMemLocation ( i ) ) <nl> continue ; <nl> if ( ! AA - > mayReadFromMemory ( I , MemLocationVault [ i ] . getBase ( ) ) ) <nl> void DSEContext : : processUnknownReadMemInst ( SILInstruction * I ) { <nl> } <nl> } <nl> <nl> - void DSEContext : : processInstruction ( SILInstruction * I , bool PDSE ) { <nl> + void DSEContext : : processInstruction ( SILInstruction * I , bool BuildGenKillSet ) { <nl> / / If this instruction has side effects , but is inert from a store <nl> / / perspective , skip it . <nl> if ( isDeadStoreInertInstruction ( I ) ) <nl> void DSEContext : : processInstruction ( SILInstruction * I , bool PDSE ) { <nl> / / TODO : process more instructions . <nl> / / <nl> if ( isa < LoadInst > ( I ) ) { <nl> - processLoadInst ( I ) ; <nl> + processLoadInst ( I , BuildGenKillSet ) ; <nl> } else if ( isa < StoreInst > ( I ) ) { <nl> - processStoreInst ( I , PDSE ) ; <nl> + processStoreInst ( I , BuildGenKillSet ) ; <nl> } else if ( I - > mayReadFromMemory ( ) ) { <nl> - processUnknownReadMemInst ( I ) ; <nl> + processUnknownReadMemInst ( I , BuildGenKillSet ) ; <nl> } <nl> <nl> / / Check whether this instruction will invalidate any other MemLocations . <nl> - invalidateMemLocationBase ( I ) ; <nl> + invalidateMemLocationBase ( I , BuildGenKillSet ) ; <nl> } <nl> <nl> SILValue DSEContext : : createExtract ( SILValue Base , <nl> void DSEContext : : run ( ) { <nl> BBToLocState [ & B ] = BBState ( & B , MemLocationVault . size ( ) ) ; <nl> } <nl> <nl> + / / Generate the genset and killset for each basic block . <nl> + for ( auto & B : * F ) { <nl> + processBasicBlockForGenKillSet ( & B ) ; <nl> + } <nl> + <nl> + / / Process each basic block with the gen and kill set . Every time the <nl> + / / WriteSetIn of a basic block changes , the optimization is rerun on its <nl> + / / predecessors . <nl> auto * PO = PM - > getAnalysis < PostOrderAnalysis > ( ) - > get ( F ) ; <nl> - / / Keep iterating over all basicblocks in a post - order fashion until <nl> - / / convergence . Everytime the WriteSetIn of a basic block changes , the <nl> - / / optimization is rerun . <nl> - / / <nl> - / / TODO : We only need to rerun basic blocks with successors changed . <nl> - / / use a worklist in the future . <nl> - / / <nl> - bool Changed = false ; <nl> - do { <nl> - Changed = false ; <nl> - for ( SILBasicBlock * BB : PO - > getPostOrder ( ) ) { <nl> - Changed | = processBasicBlock ( BB ) ; <nl> + llvm : : SmallVector < SILBasicBlock * , 16 > WorkList ; <nl> + for ( SILBasicBlock * B : PO - > getPostOrder ( ) ) { <nl> + WorkList . push_back ( B ) ; <nl> + } <nl> + <nl> + while ( ! WorkList . empty ( ) ) { <nl> + SILBasicBlock * BB = WorkList . pop_back_val ( ) ; <nl> + if ( processBasicBlockWithGenKillSet ( BB ) ) { <nl> + for ( auto X : BB - > getPreds ( ) ) <nl> + WorkList . push_back ( X ) ; <nl> } <nl> - } while ( Changed ) ; <nl> + } <nl> <nl> / / The data flow has stablized , run one last iteration over all the basic <nl> / / blocks and try to remove dead stores . <nl> - for ( SILBasicBlock * BB : PO - > getPostOrder ( ) ) { <nl> - processBasicBlock ( BB , true ) ; <nl> + for ( SILBasicBlock & BB : * F ) { <nl> + processBasicBlock ( & BB ) ; <nl> } <nl> <nl> / / Finally , delete the dead stores and create the live stores . <nl> - for ( SILBasicBlock * BB : PO - > getPostOrder ( ) ) { <nl> + for ( SILBasicBlock & BB : * F ) { <nl> / / Create the stores that are alive . <nl> - for ( auto & I : getBBLocState ( BB ) - > LiveStores ) { <nl> + for ( auto & I : getBBLocState ( & BB ) - > LiveStores ) { <nl> SILInstruction * IT = cast < SILInstruction > ( I . first ) - > getNextNode ( ) ; <nl> SILBuilderWithScope < 16 > Builder ( IT ) ; <nl> Builder . createStore ( I . first . getLoc ( ) . getValue ( ) , I . second , I . first ) ; <nl> } <nl> / / Delete the dead stores . <nl> - for ( auto & I : getBBLocState ( BB ) - > DeadStores ) { <nl> + for ( auto & I : getBBLocState ( & BB ) - > DeadStores ) { <nl> DEBUG ( llvm : : dbgs ( ) < < \" * * * Removing : \" < < * I < < \" * * * \\ n \" ) ; <nl> I - > eraseFromParent ( ) ; <nl> } <nl>\n", "msg": "Move to a gen and kill set based data flow for dead store elimination .\n", "score": 1}
{"diff_id": 9873, "repo": "apple/foundationdb\n", "sha": "484393e8796d5f1299e5b4ce2c3368e39bd11ff9\n", "time": "2020-03-31T16:42:42Z\n", "diff": "mmm a / fdbserver / Status . actor . cpp <nl> ppp b / fdbserver / Status . actor . cpp <nl> ACTOR Future < Optional < Value > > getActivePrimaryDC ( Database cx ) { <nl> <nl> loop { <nl> try { <nl> - tr . setOption ( FDBTransactionOptions : : ACCESS_SYSTEM_KEYS ) ; <nl> + tr . setOption ( FDBTransactionOptions : : READ_SYSTEM_KEYS ) ; <nl> Optional < Value > res = wait ( tr . get ( primaryDatacenterKey ) ) ; <nl> return res ; <nl> } catch ( Error & e ) { <nl>\n", "msg": "Update fdbserver / Status . actor . cpp\n"}
{"diff_id": 9934, "repo": "mongodb/mongo\n", "sha": "0aac1805c04aa5b1481ba99dcab2273d423df10c\n", "time": "2020-02-25T01:57:19Z\n", "diff": "mmm a / src / mongo / db / transaction_participant . cpp <nl> ppp b / src / mongo / db / transaction_participant . cpp <nl> Timestamp TransactionParticipant : : Participant : : prepareTransaction ( <nl> / / instead . <nl> LOGV2_FATAL ( 22525 , <nl> \" Caught exception during abort of prepared transaction \" <nl> - \" { opCtx_getTxnNumber } on { sessionId } : { exceptionToStatus } \" , <nl> - \" opCtx_getTxnNumber \" _attr = opCtx - > getTxnNumber ( ) , <nl> - \" sessionId \" _attr = _sessionId ( ) . toBSON ( ) , <nl> + \" { txnNumber } on { lsid } : { exceptionToStatus } \" , <nl> + \" txnNumber \" _attr = opCtx - > getTxnNumber ( ) , <nl> + \" lsid \" _attr = _sessionId ( ) . toBSON ( ) , <nl> \" exceptionToStatus \" _attr = exceptionToStatus ( ) ) ; <nl> std : : terminate ( ) ; <nl> } <nl> Timestamp TransactionParticipant : : Participant : : prepareTransaction ( <nl> LOGV2 ( 22521 , <nl> \" transaction - hangAfterReservingPrepareTimestamp fail point \" <nl> \" enabled . Blocking until fail point is disabled . Prepare OpTime : \" <nl> - \" { prepareOplogSlot } \" , <nl> - \" prepareOplogSlot \" _attr = prepareOplogSlot ) ; <nl> + \" { prepareOpTime } \" , <nl> + \" prepareOpTime \" _attr = prepareOplogSlot ) ; <nl> hangAfterReservingPrepareTimestamp . pauseWhileSet ( ) ; <nl> } <nl> } <nl> void TransactionParticipant : : Participant : : commitPreparedTransaction ( <nl> / / It is illegal for committing a prepared transaction to fail for any reason , other than an <nl> / / invalid command , so we crash instead . <nl> LOGV2_FATAL ( 22526 , <nl> - \" Caught exception during commit of prepared transaction { opCtx_getTxnNumber } \" <nl> - \" on { sessionId } : { exceptionToStatus } \" , <nl> - \" opCtx_getTxnNumber \" _attr = opCtx - > getTxnNumber ( ) , <nl> - \" sessionId \" _attr = _sessionId ( ) . toBSON ( ) , <nl> + \" Caught exception during commit of prepared transaction { txnNumber } \" <nl> + \" on { lsid } : { exceptionToStatus } \" , <nl> + \" txnNumber \" _attr = opCtx - > getTxnNumber ( ) , <nl> + \" lsid \" _attr = _sessionId ( ) . toBSON ( ) , <nl> \" exceptionToStatus \" _attr = exceptionToStatus ( ) ) ; <nl> std : : terminate ( ) ; <nl> } <nl> void TransactionParticipant : : Participant : : _abortActiveTransaction ( <nl> / / after aborting the storage transaction , so we crash instead . <nl> LOGV2_FATAL ( 22527 , <nl> \" Caught exception during abort of transaction that must write abort oplog \" <nl> - \" entry { opCtx_getTxnNumber } on { sessionId } : { exceptionToStatus } \" , <nl> - \" opCtx_getTxnNumber \" _attr = opCtx - > getTxnNumber ( ) , <nl> - \" sessionId \" _attr = _sessionId ( ) . toBSON ( ) , <nl> + \" entry { txnNumber } on { lsid } : { exceptionToStatus } \" , <nl> + \" txnNumber \" _attr = opCtx - > getTxnNumber ( ) , <nl> + \" lsid \" _attr = _sessionId ( ) . toBSON ( ) , <nl> \" exceptionToStatus \" _attr = exceptionToStatus ( ) ) ; <nl> std : : terminate ( ) ; <nl> } <nl> void TransactionParticipant : : Participant : : _logSlowTransaction ( <nl> } <nl> / / TODO SERVER - 46219 : Log also with old log system to not break unit tests <nl> { <nl> - LOGV2_OPTIONS ( <nl> - 22523 , <nl> - { logComponentV1toV2 ( logger : : LogComponent : : kTransaction ) } , <nl> - \" transaction \" <nl> - \" { transactionInfoForLog_opCtx_lockStats_terminationCause_readConcernArgs } \" , <nl> - \" transactionInfoForLog_opCtx_lockStats_terminationCause_readConcernArgs \" _attr = <nl> - _transactionInfoForLog ( <nl> - opCtx , lockStats , terminationCause , readConcernArgs ) ) ; <nl> + LOGV2_OPTIONS ( 22523 , <nl> + { logComponentV1toV2 ( logger : : LogComponent : : kTransaction ) } , <nl> + \" transaction \" <nl> + \" { transactionInfo } \" , <nl> + \" transactionInfo \" _attr = _transactionInfoForLog ( <nl> + opCtx , lockStats , terminationCause , readConcernArgs ) ) ; <nl> } <nl> } <nl> } <nl>\n", "msg": "SERVER - 46072 Improve log attributes for transaction_participant . cpp\n"}
{"diff_id": 9952, "repo": "apple/foundationdb\n", "sha": "9edc872041300c5ffa75c4a021edb1e5765ad3b3\n", "time": "2020-06-03T23:05:21Z\n", "diff": "mmm a / fdbserver / worker . actor . cpp <nl> ppp b / fdbserver / worker . actor . cpp <nl> ACTOR Future < Void > fdbd ( <nl> Promise < Void > recoveredDiskFiles ; <nl> <nl> v . push_back ( reportErrors ( monitorAndWriteCCPriorityInfo ( fitnessFilePath , asyncPriorityInfo ) , \" MonitorAndWriteCCPriorityInfo \" ) ) ; <nl> - v . push_back ( reportErrors ( processClass = = ProcessClass : : TesterClass ? monitorLeader ( connFile , cc ) : clusterController ( connFile , cc , asyncPriorityInfo , recoveredDiskFiles . getFuture ( ) , localities ) , \" ClusterController \" ) ) ; <nl> + if ( processClass . machineClassFitness ( ProcessClass : : ClusterController ) = = ProcessClass : : NeverAssign ) { <nl> + v . push_back ( reportErrors ( monitorLeader ( connFile , cc ) , \" ClusterController \" ) ) ; <nl> + } <nl> + else { <nl> + v . push_back ( reportErrors ( clusterController ( connFile , cc , asyncPriorityInfo , recoveredDiskFiles . getFuture ( ) , localities ) , \" ClusterController \" ) ) ; <nl> + } <nl> v . push_back ( reportErrors ( extractClusterInterface ( cc , ci ) , \" ExtractClusterInterface \" ) ) ; <nl> v . push_back ( reportErrors ( failureMonitorClient ( ci , true ) , \" FailureMonitorClient \" ) ) ; <nl> v . push_back ( reportErrorsExcept ( workerServer ( connFile , cc , localities , asyncPriorityInfo , processClass , dataFolder , memoryLimit , metricsConnFile , metricsPrefix , recoveredDiskFiles , memoryProfileThreshold , coordFolder , whitelistBinPaths ) , \" WorkerServer \" , UID ( ) , & normalWorkerErrors ( ) ) ) ; <nl>\n", "msg": "Don ' t attempt to become a cluster controller on any process with a class that has NeverAssign fitness .\n", "score": 1}
{"diff_id": 10103, "repo": "telegramdesktop/tdesktop\n", "sha": "1be064e2dc2bdc4065ce56ef58ec3672344e77eb\n", "time": "2020-10-30T15:32:21Z\n", "diff": "mmm a / Telegram / SourceFiles / boxes / confirm_box . cpp <nl> ppp b / Telegram / SourceFiles / boxes / confirm_box . cpp <nl> void PinMessageBox : : prepare ( ) { <nl> addButton ( tr : : lng_pinned_pin ( ) , [ this ] { pinMessage ( ) ; } ) ; <nl> addButton ( tr : : lng_cancel ( ) , [ this ] { closeBox ( ) ; } ) ; <nl> <nl> - if ( ! _pinningOld & & ( _peer - > isChat ( ) | | _peer - > isMegagroup ( ) ) ) { <nl> - _notify . create ( <nl> - this , <nl> - tr : : lng_pinned_notify ( tr : : now ) , <nl> - true , <nl> - st : : defaultBoxCheckbox ) ; <nl> - _checkbox = _notify ; <nl> - } else if ( _peer - > isUser ( ) & & ! _peer - > isSelf ( ) ) { <nl> + if ( _peer - > isUser ( ) & & ! _peer - > isSelf ( ) ) { <nl> _pinForPeer . create ( <nl> this , <nl> tr : : lng_pinned_also_for_other ( <nl> tr : : now , <nl> lt_user , <nl> _peer - > shortName ( ) ) , <nl> - true , <nl> + false , <nl> st : : defaultBoxCheckbox ) ; <nl> _checkbox = _pinForPeer ; <nl> + } else if ( ! _pinningOld & & ( _peer - > isChat ( ) | | _peer - > isMegagroup ( ) ) ) { <nl> + _notify . create ( <nl> + this , <nl> + tr : : lng_pinned_notify ( tr : : now ) , <nl> + true , <nl> + st : : defaultBoxCheckbox ) ; <nl> + _checkbox = _notify ; <nl> } <nl> <nl> auto height = st : : boxPadding . top ( ) + _text - > height ( ) + st : : boxPadding . bottom ( ) ; <nl>\n", "msg": "Don ' t pin for other by default .\n"}
{"diff_id": 10242, "repo": "godotengine/godot\n", "sha": "e6d83a766a7adf6193d9f0dfbb08b16702616199\n", "time": "2017-12-22T06:17:31Z\n", "diff": "mmm a / core / script_debugger_remote . cpp <nl> ppp b / core / script_debugger_remote . cpp <nl> Error ScriptDebuggerRemote : : connect_to_host ( const String & p_host , uint16_t p_por <nl> <nl> int port = p_port ; <nl> <nl> - int tries = 3 ; <nl> + const int tries = 6 ; <nl> + int waits [ tries ] = { 1 , 10 , 100 , 1000 , 1000 , 1000 } ; <nl> + <nl> tcp_client - > connect_to_host ( ip , port ) ; <nl> <nl> - while ( tries - - ) { <nl> + for ( int i = 0 ; i < tries ; i + + ) { <nl> <nl> if ( tcp_client - > get_status ( ) = = StreamPeerTCP : : STATUS_CONNECTED ) { <nl> break ; <nl> } else { <nl> <nl> - OS : : get_singleton ( ) - > delay_usec ( 1000000 ) ; <nl> - print_line ( \" Remote Debugger : Connection failed with status : ' \" + String : : num ( tcp_client - > get_status ( ) ) + \" ' , retrying in 1 sec . \" ) ; <nl> + const int ms = waits [ i ] ; <nl> + OS : : get_singleton ( ) - > delay_usec ( ms * 1000 ) ; <nl> + print_line ( \" Remote Debugger : Connection failed with status : ' \" + String : : num ( tcp_client - > get_status ( ) ) + \" ' , retrying in \" + String : : num ( ms ) + \" msec . \" ) ; <nl> } ; <nl> } ; <nl> <nl>\n", "msg": "Ramp up remote debugger wait time\n"}
{"diff_id": 10309, "repo": "xbmc/xbmc\n", "sha": "5fe14414a95fe202131e190aa0f98c6179546c5c\n", "time": "2009-11-26T20:50:25Z\n", "diff": "mmm a / xbmc / cores / dvdplayer / DVDCodecs / Video / VDPAU . cpp <nl> ppp b / xbmc / cores / dvdplayer / DVDCodecs / Video / VDPAU . cpp <nl> int CVDPAU : : ConfigVDPAU ( AVCodecContext * avctx , int ref_frames ) <nl> totalAvailableOutputSurfaces , <nl> tmpMaxOutputSurfaces , <nl> NUM_OUTPUT_SURFACES ) ; <nl> - assert ( totalAvailableOutputSurfaces > 0 ) ; <nl> <nl> surfaceNum = presentSurfaceNum = 0 ; <nl> outputSurface = outputSurfaces [ surfaceNum ] ; <nl>\n", "msg": "remove assertion to allow recovery attempt if vdp_output_surface_create fails\n", "score": 1}
{"diff_id": 10454, "repo": "xbmc/xbmc\n", "sha": "bb090d3c930a217c5d6e7b0575076c54ff3ee770\n", "time": "2019-02-22T23:04:48Z\n", "diff": "mmm a / xbmc / Application . cpp <nl> ppp b / xbmc / Application . cpp <nl> bool CApplication : : OnMessage ( CGUIMessage & message ) <nl> case GUI_MSG_PLAYLISTPLAYER_STOPPED : <nl> m_itemCurrentFile - > Reset ( ) ; <nl> CServiceBroker : : GetGUI ( ) - > GetInfoManager ( ) . ResetCurrentItem ( ) ; <nl> + if ( m_appPlayer . IsPlaying ( ) ) <nl> + StopPlaying ( ) ; <nl> PlaybackCleanup ( ) ; <nl> return true ; <nl> <nl>\n", "msg": "Stop playing current file when playlist player has stopped .\n"}
{"diff_id": 10504, "repo": "CRYTEK/CRYENGINE\n", "sha": "95ed93f21b6dcb9890df9272933be40b2bcf4440\n", "time": "2017-07-19T14:50:17Z\n", "diff": "mmm a / Code / CryEngine / CryPhysics / livingentity . cpp <nl> ppp b / Code / CryEngine / CryPhysics / livingentity . cpp <nl> int CLivingEntity : : Step ( float time_interval ) <nl> nents = m_pWorld - > GetEntitiesAround ( BBoxOuter0 , BBoxOuter1 , <nl> pentlist , m_collTypes | ent_independent | ent_triggers | ent_sort_by_mass , this , 0 , iCaller ) ; <nl> <nl> - if ( m_vel . len2 ( ) ) for ( i = 0 ; i < m_nColliders ; i + + ) if ( m_pColliders [ i ] - > HasConstraintContactsWith ( this , constraint_inactive ) ) <nl> + if ( m_vel . len2 ( ) > sqr ( 0 . 01f ) | | m_velRequested . len2 ( ) ) for ( i = 0 ; i < m_nColliders ; i + + ) if ( m_pColliders [ i ] - > HasConstraintContactsWith ( this , constraint_inactive ) ) <nl> m_pColliders [ i ] - > Awake ( ) ; <nl> <nl> const float fMassInv = m_massinv ; <nl> int CLivingEntity : : RegisterContacts ( float time_interval , int nMaxPlaneContacts ) <nl> pcontact - > ipart [ 1 ] = - 1 ; <nl> } <nl> pcontact - > pbody [ 1 ] = pcontact - > pent [ 1 ] - > GetRigidBody ( pcontact - > ipart [ 1 ] ) ; <nl> - pcontact - > friction = 0 ; <nl> + pcontact - > friction = m_velRequested . len2 ( ) | | m_slopeClimb < = 0 ? 0 . 0f : ( 1 - sqr ( m_slopeClimb ) ) / m_slopeClimb ; <nl> pcontact - > pt [ 0 ] = pcontact - > pt [ 1 ] = m_pos ; <nl> pcontact - > n = m_bFlying ? m_qrot * Vec3 ( 0 , 0 , 1 ) : m_nslope ; <nl> / / pcontact - > K . SetZero ( ) ; <nl>\n", "msg": "! O ( Physics ) allow rigidbodies attached to living ents to fall asleep\n"}
{"diff_id": 10728, "repo": "godotengine/godot\n", "sha": "22ffaded01188f9a531495c55cfb876b766cabab\n", "time": "2018-07-30T22:12:31Z\n", "diff": "mmm a / editor / editor_node . cpp <nl> ppp b / editor / editor_node . cpp <nl> EditorNode : : EditorNode ( ) { <nl> bottom_panel - > add_child ( bottom_panel_vb ) ; <nl> <nl> bottom_panel_hb = memnew ( HBoxContainer ) ; <nl> + bottom_panel_hb - > set_custom_minimum_size ( Size2 ( 0 , 24 ) ) ; / / Adjust for the height of the \" Expand Bottom Dock \" icon . <nl> bottom_panel_vb - > add_child ( bottom_panel_hb ) ; <nl> <nl> bottom_panel_hb_editors = memnew ( HBoxContainer ) ; <nl>\n", "msg": "Adjust bottom panel ' s minimal height for the expand icon\n", "score": 1}
{"diff_id": 10742, "repo": "facebook/folly\n", "sha": "58ecc90355e2b311682a8136aec79e3dee279c14\n", "time": "2016-08-08T17:08:30Z\n", "diff": "mmm a / folly / test / DeterministicScheduleTest . cpp <nl> ppp b / folly / test / DeterministicScheduleTest . cpp <nl> TEST ( DeterministicSchedule , buggyAdd ) { <nl> } / / for bug <nl> } / / TEST <nl> <nl> - / / / Testing support for auxiliary variables and global invariants <nl> + / / / Test support for auxiliary data and global invariants <nl> + / / / <nl> <nl> - / * * auxiliary variables for atomic counter test * / <nl> - struct AtomicCounterAux { <nl> - std : : vector < int > local_ ; <nl> + / / / How to use DSched support for auxiliary data and global invariants : <nl> + / / / 1 . Forward declare an annotated shared class <nl> + / / / 2 . Add the annotated shared class as a friend of the original class ( es ) <nl> + / / / to be tested <nl> + / / / 3 . Define auxiliary data <nl> + / / / 4 . Define function ( s ) for updating auxiliary data to match shared updates <nl> + / / / 5 . Define the annotated shared class <nl> + / / / It supports an interface to the original class along with auxiliary <nl> + / / / functions for updating aux data , checking invariants , and / or logging <nl> + / / / It may have to duplicate the steps of multi - step operations in the <nl> + / / / / original code in order to manage aux data and check invariants after <nl> + / / / shared accesses other than the first access in an opeeration <nl> + / / / 6 . Define function for checking global invariants and / or logging global <nl> + / / / state <nl> + / / / 7 . Define function generator ( s ) for function object ( s ) that update aux <nl> + / / / data , check invariants , and / or log state <nl> + / / / 8 . Define TEST using anotated shared data , aux data , and aux functions <nl> + <nl> + using DSched = DeterministicSchedule ; <nl> + using AuxFn = std : : function < void ( uint64_t , bool ) > ; <nl> + <nl> + / * * forward declaration of annotated shared class * / <nl> + class AnnotatedAtomicCounter ; <nl> + <nl> + / * * original shared class to be tested * / <nl> + template < typename T , template < typename > class Atom = std : : atomic > <nl> + class AtomicCounter { <nl> + friend AnnotatedAtomicCounter ; <nl> <nl> - explicit AtomicCounterAux ( int nthr ) { <nl> + public : <nl> + explicit AtomicCounter ( T val ) : counter_ ( val ) { } <nl> + <nl> + void inc ( ) { <nl> + counter_ . fetch_add ( 1 ) ; <nl> + } <nl> + <nl> + void inc_bug ( ) { <nl> + int newval = counter_ . load ( ) + 1 ; <nl> + counter_ . store ( newval ) ; <nl> + } <nl> + <nl> + T load ( ) { <nl> + return counter_ . load ( ) ; <nl> + } <nl> + <nl> + private : <nl> + Atom < T > counter_ = { 0 } ; <nl> + } ; <nl> + <nl> + / * * auxiliary data * / <nl> + struct AuxData { <nl> + explicit AuxData ( int nthr ) { <nl> local_ . resize ( nthr , 0 ) ; <nl> } <nl> + <nl> + std : : vector < int > local_ ; <nl> } ; <nl> <nl> - / * * auxiliary function for checking global invariants and logging <nl> - * steps of atomic counter test * / <nl> - void checkAtomicCounter ( <nl> - int tid , <nl> - uint64_t step , <nl> - DeterministicAtomic < int > & shared , <nl> - AtomicCounterAux & aux ) { <nl> + / * * aux update function ( s ) * / <nl> + void auxUpdateAfterInc ( int tid , AuxData & auxdata , bool success ) { <nl> + if ( success ) { <nl> + auxdata . local_ [ tid ] + + ; <nl> + } <nl> + } <nl> + <nl> + / * * annotated shared class * / <nl> + class AnnotatedAtomicCounter { <nl> + public : <nl> + explicit AnnotatedAtomicCounter ( int val ) : shared_ ( val ) { } <nl> + <nl> + void inc ( AuxFn & auxfn ) { <nl> + DSched : : setAux ( auxfn ) ; <nl> + / * calls the fine - grained original * / <nl> + shared_ . inc ( ) ; <nl> + } <nl> + <nl> + void inc_bug ( AuxFn auxfn ) { <nl> + / * duplicates the steps of the multi - access original in order to <nl> + * annotate the second access * / <nl> + int newval = shared_ . counter_ . load ( ) + 1 ; <nl> + DSched : : setAux ( auxfn ) ; <nl> + shared_ . counter_ . store ( newval ) ; <nl> + } <nl> + <nl> + int load_direct ( ) { <nl> + return shared_ . counter_ . load_direct ( ) ; <nl> + } <nl> + <nl> + private : <nl> + AtomicCounter < int , DeterministicAtomic > shared_ ; <nl> + } ; <nl> + <nl> + using Annotated = AnnotatedAtomicCounter ; <nl> + <nl> + / * * aux log & check function * / <nl> + void auxCheck ( int tid , uint64_t step , Annotated & annotated , AuxData & auxdata ) { <nl> / * read shared data * / <nl> - int val = shared . load_direct ( ) ; <nl> - / * read auxiliary variables * / <nl> + int val = annotated . load_direct ( ) ; <nl> + / * read auxiliary data * / <nl> int sum = 0 ; <nl> - for ( int v : aux . local_ ) { <nl> + for ( int v : auxdata . local_ ) { <nl> sum + = v ; <nl> } <nl> / * log state * / <nl> - VLOG ( 2 ) < < \" Step \" < < step < < \" - - tid \" < < tid < < \" - - shared counter \" <nl> - < < val < < \" - - sum increments \" < < sum ; <nl> + VLOG ( 2 ) < < \" Step \" < < step < < \" - - tid \" < < tid <nl> + < < \" - - shared counter = \" < < val < < \" - - sum increments = \" < < sum ; <nl> / * check invariant * / <nl> if ( val ! = sum ) { <nl> LOG ( ERROR ) < < \" Failed after step \" < < step ; <nl> void checkAtomicCounter ( <nl> } <nl> } <nl> <nl> - std : : function < void ( uint64_t , bool ) > auxAtomicCounter ( <nl> - DeterministicAtomic < int > & shared , <nl> - AtomicCounterAux & aux , <nl> - int tid ) { <nl> - return [ & shared , & aux , tid ] ( uint64_t step , bool success ) { <nl> - / / update auxiliary data <nl> - if ( success ) { <nl> - aux . local_ [ tid ] + + ; <nl> - } <nl> - / / check invariants <nl> - checkAtomicCounter ( tid , step , shared , aux ) ; <nl> + / * * function generator ( s ) * / <nl> + AuxFn auxAfterInc ( int tid , Annotated & annotated , AuxData & auxdata ) { <nl> + return [ & annotated , & auxdata , tid ] ( uint64_t step , bool success ) { <nl> + auxUpdateAfterInc ( tid , auxdata , success ) ; <nl> + auxCheck ( tid , step , annotated , auxdata ) ; <nl> } ; <nl> } <nl> <nl> TEST ( DSchedCustom , atomic_add ) { <nl> <nl> CHECK_GT ( nthr , 0 ) ; <nl> <nl> - DeterministicAtomic < int > counter { 0 } ; <nl> - AtomicCounterAux auxData ( nthr ) ; <nl> - DeterministicSchedule sched ( DeterministicSchedule : : uniform ( seed ) ) ; <nl> + Annotated annotated ( 0 ) ; <nl> + AuxData auxdata ( nthr ) ; <nl> + DSched sched ( DSched : : uniform ( seed ) ) ; <nl> <nl> std : : vector < std : : thread > threads ( nthr ) ; <nl> for ( int tid = 0 ; tid < nthr ; + + tid ) { <nl> - threads [ tid ] = DeterministicSchedule : : thread ( [ & , tid ] ( ) { <nl> - auto auxFn = auxAtomicCounter ( counter , auxData , tid ) ; <nl> + threads [ tid ] = DSched : : thread ( [ & , tid ] ( ) { <nl> + AuxFn auxfn = auxAfterInc ( tid , annotated , auxdata ) ; <nl> for ( int i = 0 ; i < niter ; + + i ) { <nl> if ( bug & & ( tid = = 0 ) & & ( i % 10 = = 0 ) ) { <nl> - int newval = counter . load ( ) + 1 ; <nl> - DeterministicSchedule : : setAux ( auxFn ) ; <nl> - counter . store ( newval ) ; <nl> + annotated . inc_bug ( auxfn ) ; <nl> } else { <nl> - DeterministicSchedule : : setAux ( auxFn ) ; <nl> - counter . fetch_add ( 1 ) ; <nl> + annotated . inc ( auxfn ) ; <nl> } <nl> } <nl> } ) ; <nl> } <nl> for ( auto & t : threads ) { <nl> - DeterministicSchedule : : join ( t ) ; <nl> + DSched : : join ( t ) ; <nl> } <nl> - EXPECT_EQ ( counter . load_direct ( ) , nthr * niter ) ; <nl> + EXPECT_EQ ( annotated . load_direct ( ) , nthr * niter ) ; <nl> } <nl> <nl> int main ( int argc , char * * argv ) { <nl>\n", "msg": "Methodology for using DeterministicSchedule support for auxiliary data and global invariants\n"}
{"diff_id": 10964, "repo": "apple/swift\n", "sha": "97c89acb9a8808c0e6e7f2d5c728a77ddd07d13b\n", "time": "2014-03-25T23:38:27Z\n", "diff": "mmm a / lib / Serialization / Serialization . cpp <nl> ppp b / lib / Serialization / Serialization . cpp <nl> return ; <nl> <nl> / / / Returns true if the represented set of attributes can be serialized <nl> / / / for an operator . <nl> - static void verifyAttrOperatorSerializable ( const OperatorDecl * D ) { <nl> + static void verifyAttrSerializable ( const OperatorDecl * D ) { <nl> # ifndef NDEBUG <nl> for ( auto Attr : D - > getAttrs ( ) ) { <nl> switch ( Attr - > getKind ( ) ) { <nl> return ; <nl> <nl> / / / Returns true if the represented set of attributes can be serialized <nl> / / / for a type declarations . <nl> - static void verifyAttrTypeSerializable ( const TypeDecl * D ) { <nl> + static void verifyAttrSerializable ( const TypeDecl * D ) { <nl> # ifndef NDEBUG <nl> for ( auto Attr : D - > getAttrs ( ) ) { <nl> switch ( Attr - > getKind ( ) ) { <nl> void Serializer : : writeDecl ( const Decl * D ) { <nl> case DeclKind : : InfixOperator : { <nl> auto op = cast < InfixOperatorDecl > ( D ) ; <nl> checkAllowedAttributes < > ( op ) ; <nl> - verifyAttrOperatorSerializable ( op ) ; <nl> + verifyAttrSerializable ( op ) ; <nl> <nl> const Decl * DC = getDeclForContext ( op - > getDeclContext ( ) ) ; <nl> auto associativity = getRawStableAssociativity ( op - > getAssociativity ( ) ) ; <nl> void Serializer : : writeDecl ( const Decl * D ) { <nl> case DeclKind : : PrefixOperator : { <nl> auto op = cast < PrefixOperatorDecl > ( D ) ; <nl> checkAllowedAttributes < > ( op ) ; <nl> - verifyAttrOperatorSerializable ( op ) ; <nl> + verifyAttrSerializable ( op ) ; <nl> <nl> const Decl * DC = getDeclForContext ( op - > getDeclContext ( ) ) ; <nl> <nl> void Serializer : : writeDecl ( const Decl * D ) { <nl> case DeclKind : : PostfixOperator : { <nl> auto op = cast < PostfixOperatorDecl > ( D ) ; <nl> checkAllowedAttributes < > ( op ) ; <nl> - verifyAttrOperatorSerializable ( op ) ; <nl> + verifyAttrSerializable ( op ) ; <nl> <nl> const Decl * DC = getDeclForContext ( op - > getDeclContext ( ) ) ; <nl> <nl> void Serializer : : writeDecl ( const Decl * D ) { <nl> case DeclKind : : GenericTypeParam : { <nl> auto genericParam = cast < GenericTypeParamDecl > ( D ) ; <nl> checkAllowedAttributes < > ( genericParam ) ; <nl> - verifyAttrTypeSerializable ( genericParam ) ; <nl> + verifyAttrSerializable ( genericParam ) ; <nl> <nl> const Decl * DC = getDeclForContext ( genericParam - > getDeclContext ( ) ) ; <nl> <nl> void Serializer : : writeDecl ( const Decl * D ) { <nl> case DeclKind : : AssociatedType : { <nl> auto assocType = cast < AssociatedTypeDecl > ( D ) ; <nl> checkAllowedAttributes < > ( assocType ) ; <nl> - verifyAttrTypeSerializable ( assocType ) ; <nl> + verifyAttrSerializable ( assocType ) ; <nl> <nl> const Decl * DC = getDeclForContext ( assocType - > getDeclContext ( ) ) ; <nl> <nl>\n", "msg": "Convert remaining veryAttr * Serializable functions to verifyAttrSerializable overloads .\n"}
{"diff_id": 11034, "repo": "xbmc/xbmc\n", "sha": "9a09d8ecd245419dbbbf55a455a2da1e80ac3c22\n", "time": "2015-05-23T08:52:10Z\n", "diff": "mmm a / xbmc / filesystem / CurlFile . cpp <nl> ppp b / xbmc / filesystem / CurlFile . cpp <nl> bool CCurlFile : : Download ( const std : : string & strURL , const std : : string & strFileNa <nl> / / Detect whether we are \" online \" or not ! Very simple and dirty ! <nl> bool CCurlFile : : IsInternet ( ) <nl> { <nl> - CURL url ( \" http : / / www . google . com \" ) ; <nl> + CURL url ( \" http : / / www . msftncsi . com / ncsi . txt \" ) ; <nl> bool found = Exists ( url ) ; <nl> + if ( ! found ) <nl> + { <nl> + / / fallback <nl> + Close ( ) ; <nl> + url . Parse ( \" http : / / www . w3 . org / \" ) ; <nl> + found = Exists ( url ) ; <nl> + } <nl> Close ( ) ; <nl> <nl> return found ; <nl>\n", "msg": "ADD : add a fallback site for internet detection\n"}
{"diff_id": 11091, "repo": "xbmc/xbmc\n", "sha": "977fa9bb8df66388986e4eb88932a88bc39503c9\n", "time": "2015-09-10T21:14:56Z\n", "diff": "mmm a / xbmc / music / windows / GUIWindowMusicNav . cpp <nl> ppp b / xbmc / music / windows / GUIWindowMusicNav . cpp <nl> bool CGUIWindowMusicNav : : Update ( const std : : string & strDirectory , bool updateFilt <nl> <nl> if ( CGUIWindowMusicBase : : Update ( strDirectory , updateFilterPath ) ) <nl> { <nl> + if ( m_vecItems - > GetContent ( ) . empty ( ) ) <nl> + m_vecItems - > SetContent ( \" files \" ) ; <nl> + <nl> m_thumbLoader . Load ( * m_unfilteredItems ) ; <nl> return true ; <nl> } <nl>\n", "msg": "changed : integrate custom : : Update code from songs in to Nav\n"}
{"diff_id": 11132, "repo": "yuzu-emu/yuzu\n", "sha": "aec3b28547c4f7bf1bd94340dd423b49df9e3db0\n", "time": "2018-01-16T21:49:48Z\n", "diff": "mmm a / src / yuzu / configuration / configure_input . cpp <nl> ppp b / src / yuzu / configuration / configure_input . cpp <nl> static void SetAnalogButton ( const Common : : ParamPackage & input_param , <nl> analog_param . Set ( button_name , input_param . Serialize ( ) ) ; <nl> } <nl> <nl> + static QString ButtonToText ( const Common : : ParamPackage & param ) { <nl> + if ( ! param . Has ( \" engine \" ) ) { <nl> + return QObject : : tr ( \" [ not set ] \" ) ; <nl> + } else if ( param . Get ( \" engine \" , \" \" ) = = \" keyboard \" ) { <nl> + return getKeyName ( param . Get ( \" code \" , 0 ) ) ; <nl> + } else if ( param . Get ( \" engine \" , \" \" ) = = \" sdl \" ) { <nl> + QString text = QString ( QObject : : tr ( \" Joystick % 1 \" ) ) . arg ( param . Get ( \" joystick \" , \" \" ) . c_str ( ) ) ; <nl> + if ( param . Has ( \" hat \" ) ) { <nl> + text + = QString ( QObject : : tr ( \" Hat % 1 % 2 \" ) ) <nl> + . arg ( param . Get ( \" hat \" , \" \" ) . c_str ( ) , param . Get ( \" direction \" , \" \" ) . c_str ( ) ) ; <nl> + } <nl> + if ( param . Has ( \" axis \" ) ) { <nl> + text + = QString ( QObject : : tr ( \" Axis % 1 % 2 \" ) ) <nl> + . arg ( param . Get ( \" axis \" , \" \" ) . c_str ( ) , param . Get ( \" direction \" , \" \" ) . c_str ( ) ) ; <nl> + } <nl> + if ( param . Has ( \" button \" ) ) { <nl> + text + = QString ( QObject : : tr ( \" Button % 1 \" ) ) . arg ( param . Get ( \" button \" , \" \" ) . c_str ( ) ) ; <nl> + } <nl> + return text ; <nl> + } else { <nl> + return QObject : : tr ( \" [ unknown ] \" ) ; <nl> + } <nl> + } ; <nl> + <nl> + static QString AnalogToText ( const Common : : ParamPackage & param , const std : : string & dir ) { <nl> + if ( ! param . Has ( \" engine \" ) ) { <nl> + return QObject : : tr ( \" [ not set ] \" ) ; <nl> + } else if ( param . Get ( \" engine \" , \" \" ) = = \" analog_from_button \" ) { <nl> + return ButtonToText ( Common : : ParamPackage { param . Get ( dir , \" \" ) } ) ; <nl> + } else if ( param . Get ( \" engine \" , \" \" ) = = \" sdl \" ) { <nl> + if ( dir = = \" modifier \" ) { <nl> + return QString ( QObject : : tr ( \" [ unused ] \" ) ) ; <nl> + } <nl> + <nl> + QString text = QString ( QObject : : tr ( \" Joystick % 1 \" ) ) . arg ( param . Get ( \" joystick \" , \" \" ) . c_str ( ) ) ; <nl> + if ( dir = = \" left \" | | dir = = \" right \" ) { <nl> + text + = QString ( QObject : : tr ( \" Axis % 1 \" ) ) . arg ( param . Get ( \" axis_x \" , \" \" ) . c_str ( ) ) ; <nl> + } else if ( dir = = \" up \" | | dir = = \" down \" ) { <nl> + text + = QString ( QObject : : tr ( \" Axis % 1 \" ) ) . arg ( param . Get ( \" axis_y \" , \" \" ) . c_str ( ) ) ; <nl> + } <nl> + return text ; <nl> + } else { <nl> + return QObject : : tr ( \" [ unknown ] \" ) ; <nl> + } <nl> + } ; <nl> + <nl> ConfigureInput : : ConfigureInput ( QWidget * parent ) <nl> : QWidget ( parent ) , ui ( std : : make_unique < Ui : : ConfigureInput > ( ) ) , <nl> timeout_timer ( std : : make_unique < QTimer > ( ) ) , poll_timer ( std : : make_unique < QTimer > ( ) ) { <nl> void ConfigureInput : : restoreDefaults ( ) { <nl> } <nl> <nl> void ConfigureInput : : updateButtonLabels ( ) { <nl> - QString unknown_mapping ( tr ( \" [ unknown ] \" ) ) ; <nl> - QString mapping_not_set ( tr ( \" [ not set ] \" ) ) ; <nl> - <nl> - auto ButtonToText = [ & unknown_mapping , & mapping_not_set ] ( const Common : : ParamPackage & param ) { <nl> - if ( ! param . Has ( \" engine \" ) ) { <nl> - return mapping_not_set ; <nl> - } else if ( param . Get ( \" engine \" , \" \" ) = = \" keyboard \" ) { <nl> - return getKeyName ( param . Get ( \" code \" , 0 ) ) ; <nl> - } else if ( param . Get ( \" engine \" , \" \" ) = = \" sdl \" ) { <nl> - QString text = QString ( tr ( \" Joystick % 1 \" ) ) . arg ( param . Get ( \" joystick \" , \" \" ) . c_str ( ) ) ; <nl> - if ( param . Has ( \" hat \" ) ) { <nl> - text + = QString ( tr ( \" Hat % 1 % 2 \" ) ) <nl> - . arg ( param . Get ( \" hat \" , \" \" ) . c_str ( ) , param . Get ( \" direction \" , \" \" ) . c_str ( ) ) ; <nl> - } <nl> - if ( param . Has ( \" axis \" ) ) { <nl> - text + = QString ( tr ( \" Axis % 1 % 2 \" ) ) <nl> - . arg ( param . Get ( \" axis \" , \" \" ) . c_str ( ) , param . Get ( \" direction \" , \" \" ) . c_str ( ) ) ; <nl> - } <nl> - if ( param . Has ( \" button \" ) ) { <nl> - text + = QString ( tr ( \" Button % 1 \" ) ) . arg ( param . Get ( \" button \" , \" \" ) . c_str ( ) ) ; <nl> - } <nl> - return text ; <nl> - } else { <nl> - return unknown_mapping ; <nl> - } <nl> - } ; <nl> - auto AnalogToText = [ & unknown_mapping , & mapping_not_set , <nl> - & ButtonToText ] ( const Common : : ParamPackage & param , const std : : string & dir ) { <nl> - if ( ! param . Has ( \" engine \" ) ) { <nl> - return mapping_not_set ; <nl> - } else if ( param . Get ( \" engine \" , \" \" ) = = \" analog_from_button \" ) { <nl> - return ButtonToText ( Common : : ParamPackage { param . Get ( dir , \" \" ) } ) ; <nl> - } else if ( param . Get ( \" engine \" , \" \" ) = = \" sdl \" ) { <nl> - if ( dir = = \" modifier \" ) { <nl> - return QString ( tr ( \" [ unused ] \" ) ) ; <nl> - } <nl> - <nl> - QString text = QString ( tr ( \" Joystick % 1 \" ) ) . arg ( param . Get ( \" joystick \" , \" \" ) . c_str ( ) ) ; <nl> - if ( dir = = \" left \" | | dir = = \" right \" ) { <nl> - text + = QString ( tr ( \" Axis % 1 \" ) ) . arg ( param . Get ( \" axis_x \" , \" \" ) . c_str ( ) ) ; <nl> - } else if ( dir = = \" up \" | | dir = = \" down \" ) { <nl> - text + = QString ( tr ( \" Axis % 1 \" ) ) . arg ( param . Get ( \" axis_y \" , \" \" ) . c_str ( ) ) ; <nl> - } <nl> - return text ; <nl> - } else { <nl> - return unknown_mapping ; <nl> - } <nl> - } ; <nl> - <nl> for ( int button = 0 ; button < Settings : : NativeButton : : NumButtons ; button + + ) { <nl> button_map [ button ] - > setText ( ButtonToText ( buttons_param [ button ] ) ) ; <nl> } <nl>\n", "msg": "Use static functions instead of lambdas\n"}
{"diff_id": 11139, "repo": "xbmc/xbmc\n", "sha": "05150adf683bb8d24e76e7a0ceec216dccaf1ff6\n", "time": "2014-11-22T22:53:58Z\n", "diff": "mmm a / xbmc / music / MusicDatabase . cpp <nl> ppp b / xbmc / music / MusicDatabase . cpp <nl> bool CMusicDatabase : : GetAlbumsByYear ( const CStdString & strBaseDir , CFileItemList <nl> return false ; <nl> <nl> musicUrl . AddOption ( \" year \" , year ) ; <nl> - musicUrl . AddOption ( \" singles \" , true ) ; / / allow singles to be listed <nl> + musicUrl . AddOption ( \" show_singles \" , true ) ; / / allow singles to be listed <nl> <nl> Filter filter ; <nl> return GetAlbumsByWhere ( musicUrl . ToString ( ) , filter , items ) ; <nl> bool CMusicDatabase : : GetFilter ( CDbUrl & musicUrl , Filter & filter , SortDescription <nl> / / no artist given , so exclude any single albums ( aka empty tagged albums ) <nl> else <nl> { <nl> - option = options . find ( \" singles \" ) ; <nl> + option = options . find ( \" show_singles \" ) ; <nl> if ( option = = options . end ( ) | | ! option - > second . asBoolean ( ) ) <nl> filter . AppendWhere ( \" albumview . strAlbum < > ' ' \" ) ; <nl> } <nl>\n", "msg": "musicdb : fix conflicting \" singles \" filter option introduced by 9fbf13eded5d682d4ae210043e536895c9356c18 ( fixes )\n"}
{"diff_id": 11174, "repo": "microsoft/CNTK\n", "sha": "400a278ad9e089e315c7caf68f80469fe8a016ac\n", "time": "2016-03-07T12:07:38Z\n", "diff": "mmm a / Source / Readers / ReaderLib / ReaderShim . cpp <nl> ppp b / Source / Readers / ReaderLib / ReaderShim . cpp <nl> void ReaderShim < ElemType > : : StartDistributedMinibatchLoop ( <nl> m_reader - > StartEpoch ( config ) ; <nl> m_endOfEpoch = false ; <nl> <nl> + / / For adaptive minibatch , make sure there are no outstanding reads . <nl> + if ( m_prefetchTask . valid ( ) ) <nl> + { <nl> + m_prefetchTask . wait ( ) ; <nl> + } <nl> + <nl> m_prefetchTask = std : : async ( m_launchType , [ this ] ( ) <nl> { <nl> return m_reader - > ReadMinibatch ( ) ; <nl>\n", "msg": "ReaderLib / ReaderShim . cpp : wait for outstanding prefetch when epoch started\n", "score": 1}
{"diff_id": 11263, "repo": "yuzu-emu/yuzu\n", "sha": "d5237342668db88cc81fefbee81f468b5214e655\n", "time": "2020-04-26T01:54:14Z\n", "diff": "mmm a / src / video_core / shader / decode / register_set_predicate . cpp <nl> ppp b / src / video_core / shader / decode / register_set_predicate . cpp <nl> <nl> / / Licensed under GPLv2 or any later version <nl> / / Refer to the license . txt file included . <nl> <nl> + # include < utility > <nl> + <nl> # include \" common / assert . h \" <nl> # include \" common / common_types . h \" <nl> # include \" video_core / engines / shader_bytecode . h \" <nl> <nl> <nl> namespace VideoCommon : : Shader { <nl> <nl> + using std : : move ; <nl> using Tegra : : Shader : : Instruction ; <nl> using Tegra : : Shader : : OpCode ; <nl> <nl> u32 ShaderIR : : DecodeRegisterSetPredicate ( NodeBlock & bb , u32 pc ) { <nl> <nl> UNIMPLEMENTED_IF ( instr . p2r_r2p . mode ! = Tegra : : Shader : : R2pMode : : Pr ) ; <nl> <nl> - const Node apply_mask = [ & ] { <nl> + Node apply_mask = [ this , opcode , instr ] { <nl> switch ( opcode - > get ( ) . GetId ( ) ) { <nl> case OpCode : : Id : : R2P_IMM : <nl> case OpCode : : Id : : P2R_IMM : <nl> u32 ShaderIR : : DecodeRegisterSetPredicate ( NodeBlock & bb , u32 pc ) { <nl> } <nl> } ( ) ; <nl> <nl> - const auto offset = static_cast < u32 > ( instr . p2r_r2p . byte ) * 8 ; <nl> + const u32 offset = static_cast < u32 > ( instr . p2r_r2p . byte ) * 8 ; <nl> <nl> switch ( opcode - > get ( ) . GetId ( ) ) { <nl> case OpCode : : Id : : R2P_IMM : { <nl> - const Node mask = GetRegister ( instr . gpr8 ) ; <nl> + Node mask = GetRegister ( instr . gpr8 ) ; <nl> <nl> for ( u64 pred = 0 ; pred < NUM_PROGRAMMABLE_PREDICATES ; + + pred ) { <nl> - const auto shift = static_cast < u32 > ( pred ) ; <nl> + const u32 shift = static_cast < u32 > ( pred ) ; <nl> <nl> - const Node apply_compare = BitfieldExtract ( apply_mask , shift , 1 ) ; <nl> - const Node condition = <nl> - Operation ( OperationCode : : LogicalUNotEqual , apply_compare , Immediate ( 0 ) ) ; <nl> + Node apply = BitfieldExtract ( apply_mask , shift , 1 ) ; <nl> + Node condition = Operation ( OperationCode : : LogicalUNotEqual , apply , Immediate ( 0 ) ) ; <nl> <nl> - const Node value_compare = BitfieldExtract ( mask , offset + shift , 1 ) ; <nl> - const Node value = <nl> - Operation ( OperationCode : : LogicalUNotEqual , value_compare , Immediate ( 0 ) ) ; <nl> + Node compare = BitfieldExtract ( mask , offset + shift , 1 ) ; <nl> + Node value = Operation ( OperationCode : : LogicalUNotEqual , move ( compare ) , Immediate ( 0 ) ) ; <nl> <nl> - const Node code = Operation ( OperationCode : : LogicalAssign , GetPredicate ( pred ) , value ) ; <nl> - bb . push_back ( Conditional ( condition , { code } ) ) ; <nl> + Node code = Operation ( OperationCode : : LogicalAssign , GetPredicate ( pred ) , move ( value ) ) ; <nl> + bb . push_back ( Conditional ( condition , { move ( code ) } ) ) ; <nl> } <nl> break ; <nl> } <nl> u32 ShaderIR : : DecodeRegisterSetPredicate ( NodeBlock & bb , u32 pc ) { <nl> for ( u64 pred = 0 ; pred < NUM_PROGRAMMABLE_PREDICATES ; + + pred ) { <nl> Node bit = Operation ( OperationCode : : Select , GetPredicate ( pred ) , Immediate ( 1U < < pred ) , <nl> Immediate ( 0 ) ) ; <nl> - value = Operation ( OperationCode : : UBitwiseOr , std : : move ( value ) , std : : move ( bit ) ) ; <nl> + value = Operation ( OperationCode : : UBitwiseOr , move ( value ) , move ( bit ) ) ; <nl> } <nl> - value = Operation ( OperationCode : : UBitwiseAnd , std : : move ( value ) , apply_mask ) ; <nl> - value = BitfieldInsert ( GetRegister ( instr . gpr8 ) , std : : move ( value ) , offset , 8 ) ; <nl> + value = Operation ( OperationCode : : UBitwiseAnd , move ( value ) , apply_mask ) ; <nl> + value = BitfieldInsert ( GetRegister ( instr . gpr8 ) , move ( value ) , offset , 8 ) ; <nl> <nl> - SetRegister ( bb , instr . gpr0 , std : : move ( value ) ) ; <nl> + SetRegister ( bb , instr . gpr0 , move ( value ) ) ; <nl> break ; <nl> } <nl> default : <nl>\n", "msg": "decode / register_set_predicate : Use move for shared pointers\n"}
{"diff_id": 11339, "msg": "Add compatibility class for FixedSpatialMaterial\n", "msgGPT": "add compatibility class and idle callback for fixed spatial material in register_scene_types.", "METEOR Score": "49.67127501525561", "BLEU Score": "0.5214713399474115", "ROUGE-L Score": "0.7368421006094183", "score": 1, "repo": "godotengine/godot\n", "sha": "d8f011828e9282f6f931c5fe838399c062e7fa2d\n", "time": "2017-04-07T16:59:10Z\n", "diff": "mmm a / scene / register_scene_types . cpp <nl> ppp b / scene / register_scene_types . cpp <nl> void register_scene_types ( ) { <nl> ClassDB : : register_class < QuadMesh > ( ) ; <nl> ClassDB : : register_virtual_class < Material > ( ) ; <nl> ClassDB : : register_class < SpatialMaterial > ( ) ; <nl> + ClassDB : : add_compatibility_class ( \" FixedSpatialMaterial \" , \" SpatialMaterial \" ) ; <nl> SceneTree : : add_idle_callback ( SpatialMaterial : : flush_changes ) ; <nl> SpatialMaterial : : init_shaders ( ) ; <nl> <nl>\n"}
{"diff_id": 11358, "msg": "[ Generic signature builder ] Use addSameTypeRequirementBetweenArchetypes consistently .\n", "msgGPT": "refactor code to use the builder method for adding same type requirements between potential archetypes.", "METEOR Score": "45.65657991504018", "BLEU Score": "0.5794673529260664", "ROUGE-L Score": "0.35714285216836733", "score": 1, "repo": "apple/swift\n", "sha": "416d935df694d9b2e21fbed1bdb228b3fb19df1e\n", "time": "2017-02-11T08:04:12Z\n", "diff": "mmm a / lib / AST / GenericSignatureBuilder . cpp <nl> ppp b / lib / AST / GenericSignatureBuilder . cpp <nl> bool GenericSignatureBuilder : : PotentialArchetype : : addConformance ( <nl> / / Otherwise , create a new potential archetype for this associated type <nl> / / and make it equivalent to the first potential archetype we encountered . <nl> auto otherPA = new PotentialArchetype ( this , assocType ) ; <nl> - otherPA - > addSameTypeConstraint ( known - > second . front ( ) , redundantSource ) ; <nl> - <nl> - / / Update the equivalence class . <nl> - auto frontRep = known - > second . front ( ) - > getRepresentative ( ) ; <nl> - otherPA - > Representative = frontRep ; <nl> - frontRep - > EquivalenceClass . push_back ( otherPA ) ; <nl> - <nl> known - > second . push_back ( otherPA ) ; <nl> + builder . addSameTypeRequirementBetweenArchetypes ( known - > second . front ( ) , <nl> + otherPA , redundantSource ) ; <nl> <nl> / / If there ' s a superclass constraint that conforms to the protocol , <nl> / / add the appropriate same - type relationship . <nl> auto GenericSignatureBuilder : : PotentialArchetype : : getNestedType ( <nl> <nl> / / Produce a same - type constraint between the two same - named <nl> / / potential archetypes . <nl> - pa - > addSameTypeConstraint ( nested . front ( ) , redundantSource ) ; <nl> - <nl> - auto frontRep = nested . front ( ) - > getRepresentative ( ) ; <nl> - pa - > Representative = frontRep ; <nl> - frontRep - > EquivalenceClass . push_back ( pa ) ; <nl> + builder . addSameTypeRequirementBetweenArchetypes ( pa , existing , <nl> + redundantSource ) ; <nl> } else { <nl> nested . push_back ( pa ) ; <nl> <nl>\n"}
{"diff_id": 11378, "repo": "facebook/hhvm\n", "sha": "2fbfba627e74b4526bff96060cb551fb2f73f369\n", "time": "2014-01-28T17:17:48Z\n", "diff": "mmm a / hphp / runtime / vm / jit / print . cpp <nl> ppp b / hphp / runtime / vm / jit / print . cpp <nl> void print ( std : : ostream & os , const Block * block , <nl> } <nl> <nl> os < < std : : string ( kIndent - 2 , ' ' ) ; <nl> - if ( auto next = block - > next ( ) ) { <nl> + auto next = block - > empty ( ) ? nullptr : block - > next ( ) ; <nl> + if ( next ) { <nl> os < < punc ( \" - > \" ) ; <nl> printLabel ( os , next ) ; <nl> os < < ' \\ n ' ; <nl>\n", "msg": "Avoid assertion failure while trying to print an empty block\n"}
{"diff_id": 11466, "repo": "apple/swift\n", "sha": "631b0c361ad03e9c9ff371edd8b3c609787d3743\n", "time": "2014-01-02T16:04:11Z\n", "diff": "mmm a / lib / ClangImporter / ImportDecl . cpp <nl> ppp b / lib / ClangImporter / ImportDecl . cpp <nl> namespace { <nl> <nl> / / FIXME : Related result type ? <nl> <nl> + / / Check whether we recursively imported this method <nl> + if ( ! forceClassMethod & & dc = = Impl . importDeclContextOf ( decl ) ) { <nl> + / / FIXME : Should also be able to do this for forced class <nl> + / / methods . <nl> + auto known = Impl . ImportedDecls . find ( decl - > getCanonicalDecl ( ) ) ; <nl> + if ( known ! = Impl . ImportedDecls . end ( ) ) <nl> + return known - > second ; <nl> + } <nl> + <nl> / / FIXME : Poor location info . <nl> auto nameLoc = Impl . importSourceLoc ( decl - > getLocation ( ) ) ; <nl> auto result = FuncDecl : : create ( <nl> namespace { <nl> / / Check whether there ' s some special method to import . <nl> result - > setClangNode ( decl ) ; <nl> if ( ! forceClassMethod ) { <nl> - if ( ! Impl . ImportedDecls [ decl - > getCanonicalDecl ( ) ] ) <nl> + if ( dc = = Impl . importDeclContextOf ( decl ) & & <nl> + ! Impl . ImportedDecls [ decl - > getCanonicalDecl ( ) ] ) <nl> Impl . ImportedDecls [ decl - > getCanonicalDecl ( ) ] = result ; <nl> <nl> if ( decl - > getMethodFamily ( ) ! = clang : : OMF_init | | <nl>\n", "msg": "Don ' t import the same Objective - C method twice ( recursively ) .\n"}
{"diff_id": 11564, "repo": "mongodb/mongo\n", "sha": "444675bbd5a01a2149a4f112ba966ae85e3deed4\n", "time": "2012-11-08T16:58:44Z\n", "diff": "mmm a / src / mongo / db / projection . cpp <nl> ppp b / src / mongo / db / projection . cpp <nl> namespace mongo { <nl> <nl> / / initialize new Matcher object ( s ) <nl> <nl> - _matchers . insert ( make_pair ( mongoutils : : str : : before ( e . fieldName ( ) , ' . ' ) , <nl> - new Matcher ( e . wrap ( ) , true ) ) ) ; <nl> + _matchers . insert ( make_pair ( <nl> + mongoutils : : str : : before ( e . fieldName ( ) , ' . ' ) , <nl> + shared_ptr < Matcher > ( new Matcher ( e . wrap ( ) , true ) ) ) ) ; <nl> add ( e . fieldName ( ) , true ) ; <nl> } <nl> else { <nl>\n", "msg": "Be more explicit about types when constructing pair for insert\n"}
{"diff_id": 11954, "repo": "openalpr/openalpr\n", "sha": "a9bc2042e3a9129700586c428fe0b7da8faaa234\n", "time": "2015-07-09T12:48:13Z\n", "diff": "mmm a / src / misc_utilities / calibrate . cpp <nl> ppp b / src / misc_utilities / calibrate . cpp <nl> int main ( int argc , char * * argv ) { <nl> if ( c = = ' o ' ) <nl> { <nl> cout < < \" prewarp = \" < < get_config ( ) < < endl ; <nl> - <nl> + } else if ( c = = ' q ' ) <nl> + { <nl> + cout < < \" prewarp = \" < < get_config ( ) < < endl ; <nl> + break ; <nl> } <nl> } <nl> <nl>\n", "msg": "When pressing keyboard key ' q ' , output prewarp configuration and exit program .\n"}
{"diff_id": 12096, "repo": "apple/swift\n", "sha": "f6e24fa1e96148aee2a3b62e6dafcafd238c13a1\n", "time": "2017-05-12T06:29:43Z\n", "diff": "mmm a / lib / SIL / SILVerifier . cpp <nl> ppp b / lib / SIL / SILVerifier . cpp <nl> void SILModule : : verify ( ) const { <nl> } <nl> } <nl> <nl> - # ifndef NDEBUG <nl> / / / Determine whether an instruction may not have a SILDebugScope . <nl> bool swift : : maybeScopeless ( SILInstruction & I ) { <nl> if ( I . getFunction ( ) - > isBare ( ) ) <nl> return true ; <nl> return ! isa < DebugValueInst > ( I ) & & ! isa < DebugValueAddrInst > ( I ) ; <nl> } <nl> - # endif <nl>\n", "msg": "Remove conditional compilation from maybeScopeless , because SILVerifier is not conditionally compiled anymore\n"}
{"diff_id": 12097, "repo": "apple/foundationdb\n", "sha": "3640dfed9973c148fed9036327470157a6de15c5\n", "time": "2020-03-31T07:09:38Z\n", "diff": "mmm a / fdbserver / workloads / SpecialKeySpaceCorrectness . actor . cpp <nl> ppp b / fdbserver / workloads / SpecialKeySpaceCorrectness . actor . cpp <nl> struct SpecialKeySpaceCorrectnessWorkload : TestWorkload { <nl> ASSERT ( testResultFuture . isReady ( ) ) ; <nl> auto testResult = testResultFuture . getValue ( ) ; <nl> <nl> - / / check the same <nl> + / / check the consistency of results <nl> if ( ! self - > compareRangeResult ( correctResult , testResult ) ) { <nl> - / / TODO : log here <nl> - / / TraceEvent ( \" WrongGetRangeResult \" ) . detail ( \" KeySeleco \" ) <nl> - auto temp1 = self - > ryw - > getRange ( begin , end , limit , false , reverse ) ; <nl> - auto temp2 = cx - > specialKeySpace - > getRange ( self - > ryw , begin , end , limit , false , reverse ) ; <nl> + TraceEvent ( SevError , \" TestFailure \" ) <nl> + . detail ( \" Reason \" , \" Results from getRange are inconsistent \" ) <nl> + . detail ( \" Begin \" , begin . toString ( ) ) <nl> + . detail ( \" End \" , end . toString ( ) ) <nl> + . detail ( \" LimitRows \" , limit . rows ) <nl> + . detail ( \" LimitBytes \" , limit . bytes ) <nl> + . detail ( \" Reverse \" , reverse ) ; <nl> + + self - > wrongResults ; <nl> } <nl> } <nl> struct SpecialKeySpaceCorrectnessWorkload : TestWorkload { <nl> if ( ( res1 . more ! = res2 . more ) | | ( res1 . readToBegin ! = res2 . readToBegin ) | | <nl> ( res1 . readThroughEnd ! = res2 . readThroughEnd ) ) { <nl> TraceEvent ( SevError , \" TestFailure \" ) <nl> - . detail ( \" Reason \" , \" flags are different \" ) <nl> + . detail ( \" Reason \" , \" RangeResultRef flags are inconsistent \" ) <nl> . detail ( \" More \" , res1 . more ) <nl> . detail ( \" ReadToBegin \" , res1 . readToBegin ) <nl> . detail ( \" ReadThroughEnd \" , res1 . readThroughEnd ) <nl> struct SpecialKeySpaceCorrectnessWorkload : TestWorkload { <nl> . detail ( \" ReadThroughEnd2 \" , res2 . readThroughEnd ) ; <nl> return false ; <nl> } <nl> - / / if ( res1 . more ! = res2 . more ) { <nl> - / / TraceEvent ( SevError , \" TestFailure \" ) . detail ( \" Reason \" , \" More flags are different \" ) . detail ( \" More \" , res1 . more ) ; <nl> - / / return false ; <nl> - / / } <nl> if ( res1 . size ( ) ! = res2 . size ( ) ) return false ; <nl> for ( int i = 0 ; i < res1 . size ( ) ; + + i ) { <nl> if ( res1 [ i ] ! = res2 [ i ] ) return false ; <nl>\n", "msg": "add trace lines fore test failures\n", "score": 1}
{"diff_id": 12116, "repo": "apple/swift\n", "sha": "a7361fea9c4aabb873a483439c5fc6547cb4d7eb\n", "time": "2016-03-26T01:44:12Z\n", "diff": "mmm a / lib / SILGen / SILGenType . cpp <nl> ppp b / lib / SILGen / SILGenType . cpp <nl> <nl> # include \" swift / AST / TypeMemberVisitor . h \" <nl> # include \" swift / Basic / Fallthrough . h \" <nl> # include \" swift / SIL / SILArgument . h \" <nl> - # include \" swift / SIL / SILWitnessVisitor . h \" <nl> # include \" swift / SIL / TypeLowering . h \" <nl> <nl> using namespace swift ; <nl>\n", "msg": "SILGen : Remove unused include , NFC\n"}
{"diff_id": 12187, "repo": "apple/swift\n", "sha": "1fec0510f73f695eaade635bbfd620ab1f786a0d\n", "time": "2014-03-20T21:53:48Z\n", "diff": "mmm a / lib / Driver / Tools . cpp <nl> ppp b / lib / Driver / Tools . cpp <nl> static void addCommonFrontendArgs ( const ToolChain & TC , <nl> / / Pass through the values passed to - Xfrontend . <nl> inputArgs . AddAllArgValues ( arguments , options : : OPT_Xfrontend ) ; <nl> <nl> - / / Pass through any - Xllvm flags . <nl> + / / Pass through any subsystem flags . <nl> inputArgs . AddAllArgs ( arguments , options : : OPT_Xllvm ) ; <nl> + inputArgs . AddAllArgs ( arguments , options : : OPT_Xcc ) ; <nl> <nl> const std : : string & moduleDocOutputPath = <nl> output - > getAdditionalOutputForType ( types : : TY_SwiftModuleDocFile ) ; <nl>\n", "msg": "[ driver ] Pass - Xcc options down to frontend tools .\n"}
{"diff_id": 12213, "repo": "EOSIO/eos\n", "sha": "559dbd6498e3090e1b2314ae8f0d01485dadfd3b\n", "time": "2019-02-22T18:48:41Z\n", "diff": "mmm a / plugins / net_plugin / net_plugin . cpp <nl> ppp b / plugins / net_plugin / net_plugin . cpp <nl> namespace eosio { <nl> void sync_manager : : recv_notice ( const connection_ptr & c , const notice_message & msg ) { <nl> fc_ilog ( logger , \" sync_manager got $ { m } block notice \" , ( \" m \" , modes_str ( msg . known_blocks . mode ) ) ) ; <nl> if ( msg . known_blocks . ids . size ( ) > 1 ) { <nl> - fc_elog ( logger , \" Invalid notice_message , known_blocks . ids . size $ { s } \" , ( \" s \" , msg . known_blocks . ids . size ( ) ) ) ; <nl> + fc_elog ( logger , \" Invalid notice_message , known_blocks . ids . size $ { s } , closing connection : $ { p } \" , <nl> + ( \" s \" , msg . known_blocks . ids . size ( ) ) ( \" p \" , c - > peer_name ( ) ) ) ; <nl> my_impl - > close ( c ) ; <nl> return ; <nl> } <nl> namespace eosio { <nl> <nl> void sync_manager : : rejected_block ( const connection_ptr & c , uint32_t blk_num ) { <nl> if ( state ! = in_sync ) { <nl> - fc_ilog ( logger , \" block $ { bn } not accepted from $ { p } \" , ( \" bn \" , blk_num ) ( \" p \" , c - > peer_name ( ) ) ) ; <nl> + fc_wlog ( logger , \" block $ { bn } not accepted from $ { p } , closing connection \" , ( \" bn \" , blk_num ) ( \" p \" , c - > peer_name ( ) ) ) ; <nl> sync_last_requested_num = 0 ; <nl> source . reset ( ) ; <nl> my_impl - > close ( c ) ; <nl> namespace eosio { <nl> fc_dlog ( logger , \" got block $ { bn } from $ { p } \" , ( \" bn \" , blk_num ) ( \" p \" , c - > peer_name ( ) ) ) ; <nl> if ( state = = lib_catchup ) { <nl> if ( blk_num ! = sync_next_expected_num ) { <nl> - fc_ilog ( logger , \" expected block $ { ne } but got $ { bn } \" , ( \" ne \" , sync_next_expected_num ) ( \" bn \" , blk_num ) ) ; <nl> + fc_wlog ( logger , \" expected block $ { ne } but got $ { bn } , closing connection : $ { p } \" , <nl> + ( \" ne \" , sync_next_expected_num ) ( \" bn \" , blk_num ) ( \" p \" , c - > peer_name ( ) ) ) ; <nl> my_impl - > close ( c ) ; <nl> return ; <nl> } <nl> namespace eosio { <nl> } <nl> } <nl> catch ( const std : : exception & ex ) { <nl> - string pname = conn ? conn - > peer_name ( ) : \" no connection name \" ; <nl> - fc_elog ( logger , \" Exception in handling read data from $ { p } $ { s } \" , ( \" p \" , pname ) ( \" s \" , ex . what ( ) ) ) ; <nl> + fc_elog ( logger , \" Exception in handling read data from $ { p } : $ { s } \" , <nl> + ( \" p \" , conn - > peer_name ( ) ) ( \" s \" , ex . what ( ) ) ) ; <nl> close ( conn ) ; <nl> } <nl> catch ( const fc : : exception & ex ) { <nl> - string pname = conn ? conn - > peer_name ( ) : \" no connection name \" ; <nl> - fc_elog ( logger , \" Exception in handling read data $ { s } \" , ( \" p \" , pname ) ( \" s \" , ex . to_string ( ) ) ) ; <nl> + fc_elog ( logger , \" Exception in handling read data from $ { p } : $ { s } \" , <nl> + ( \" p \" , conn - > peer_name ( ) ) ( \" s \" , ex . to_string ( ) ) ) ; <nl> close ( conn ) ; <nl> } <nl> catch ( . . . ) { <nl> - string pname = conn ? conn - > peer_name ( ) : \" no connection name \" ; <nl> - fc_elog ( logger , \" Undefined exception hanlding the read data from connection $ { p } \" , ( \" p \" , pname ) ) ; <nl> + fc_elog ( logger , \" Undefined exception handling the read data from $ { p } \" , ( \" p \" , conn - > peer_name ( ) ) ) ; <nl> close ( conn ) ; <nl> } <nl> } ) ; <nl> namespace eosio { <nl> msg . visit ( m ) ; <nl> } <nl> } catch ( const fc : : exception & e ) { <nl> - edump ( ( e . to_detail_string ( ) ) ) ; <nl> + fc_elog ( logger , \" Exception in handling message from $ { p } : $ { s } \" , <nl> + ( \" p \" , conn - > peer_name ( ) ) ( \" s \" , e . to_detail_string ( ) ) ) ; <nl> close ( conn ) ; <nl> return false ; <nl> } <nl> namespace eosio { <nl> } <nl> <nl> void net_plugin_impl : : handle_message ( const connection_ptr & c , const go_away_message & msg ) { <nl> - string rsn = reason_str ( msg . reason ) ; <nl> - peer_wlog ( c , \" received go_away_message \" ) ; <nl> - fc_wlog ( logger , \" received a go away message from $ { p } , reason = $ { r } \" , <nl> - ( \" p \" , c - > peer_name ( ) ) ( \" r \" , rsn ) ) ; <nl> + peer_wlog ( c , \" received go_away_message , reason = $ { r } \" , ( \" r \" , reason_str ( msg . reason ) ) ) ; <nl> c - > no_retry = msg . reason ; <nl> if ( msg . reason = = duplicate ) { <nl> c - > node_id = msg . node_id ; <nl> namespace eosio { <nl> <nl> void net_plugin_impl : : handle_message ( const connection_ptr & c , const request_message & msg ) { <nl> if ( msg . req_blocks . ids . size ( ) > 1 ) { <nl> - fc_elog ( logger , \" Invalid request_message , req_blocks . ids . size $ { s } \" , ( \" s \" , msg . req_blocks . ids . size ( ) ) ) ; <nl> + fc_elog ( logger , \" Invalid request_message , req_blocks . ids . size $ { s } , closing $ { p } \" , <nl> + ( \" s \" , msg . req_blocks . ids . size ( ) ) ( \" p \" , c - > peer_name ( ) ) ) ; <nl> close ( c ) ; <nl> return ; <nl> } <nl> namespace eosio { <nl> <nl> fc_ilog ( logger , \" close $ { s } connections \" , ( \" s \" , my - > connections . size ( ) ) ) ; <nl> for ( auto & con : my - > connections ) { <nl> + fc_dlog ( logger , \" close : $ { p } \" , ( \" p \" , con - > peer_name ( ) ) ) ; <nl> my - > close ( con ) ; <nl> } <nl> my - > connections . clear ( ) ; <nl> namespace eosio { <nl> for ( auto itr = my - > connections . begin ( ) ; itr ! = my - > connections . end ( ) ; + + itr ) { <nl> if ( ( * itr ) - > peer_addr = = host ) { <nl> ( * itr ) - > reset ( ) ; <nl> + fc_ilog ( logger , \" disconnecting : $ { p } \" , ( \" p \" , ( * itr ) - > peer_name ( ) ) ) ; <nl> my - > close ( * itr ) ; <nl> my - > connections . erase ( itr ) ; <nl> return \" connection removed \" ; <nl>\n", "msg": "Cleanup logging , add some additional on closing\n"}
{"diff_id": 12345, "msg": "[ silgen ] Add documentation to the fields of SILGenApply .\n", "msgGPT": "add private fields and documentation for the callee class.", "METEOR Score": "25.07145851355905", "BLEU Score": "0.5021482076757628", "ROUGE-L Score": "0.2857142808163266", "score": 1, "repo": "apple/swift\n", "sha": "214253fdc4fcec195f23e2a76ce7ab3f31c8c9e9\n", "time": "2017-08-23T22:52:58Z\n", "diff": "mmm a / lib / SILGen / SILGenApply . cpp <nl> ppp b / lib / SILGen / SILGenApply . cpp <nl> class Callee { <nl> / / Move , don ' t copy . <nl> Callee ( const Callee & ) = delete ; <nl> Callee & operator = ( const Callee & ) = delete ; <nl> + <nl> private : <nl> + / / / An IndirectValue callee represents something like a swift closure or a c <nl> + / / / function pointer where we have / no / information at all on what the callee <nl> + / / / is . This contrasts with a class method , where we may not know the exact <nl> + / / / method that is being called , but we have some information from the type <nl> + / / / system that we have an actual method . <nl> + / / / <nl> + / / / * NOTE * This will never be non - null if Constant is non - null . <nl> ManagedValue IndirectValue ; <nl> + <nl> + / / / If we are trying to call a specific method or function , this field is set <nl> + / / / to the decl ref information for that callee . <nl> + / / / <nl> + / / / * NOTE * This should never be non - null if IndirectValue is non - null . <nl> SILDeclRef Constant ; <nl> + <nl> + / / / This field is set if we are calling to a SuperMethod or ClassMethod and <nl> + / / / thus need to pass self to get the correct implementation . <nl> SILValue SelfValue ; <nl> + <nl> + / / / The abstraction pattern of the callee . <nl> AbstractionPattern OrigFormalInterfaceType ; <nl> + <nl> + / / / The callee ' s formal type with substitutions applied . <nl> CanFunctionType SubstFormalInterfaceType ; <nl> + <nl> + / / / The substitutions applied to OrigFormalInterfaceType to produce <nl> + / / / SubstFormalInterfaceType . <nl> SubstitutionList Substitutions ; <nl> + <nl> + / / / The list of values captured by our callee . <nl> Optional < SmallVector < ManagedValue , 2 > > Captures ; <nl> <nl> / / The pointer back to the AST node that produced the callee . <nl>\n"}
{"diff_id": 12371, "repo": "EOSIO/eos\n", "sha": "c63f86def9f068f11252d6af07df21465e59b3dc\n", "time": "2018-04-17T20:28:04Z\n", "diff": "mmm a / programs / cleos / main . cpp <nl> ppp b / programs / cleos / main . cpp <nl> int main ( int argc , char * * argv ) { <nl> reqperm = requested_perm_var . as < vector < permission_level > > ( ) ; <nl> } EOS_RETHROW_EXCEPTIONS ( transaction_type_exception , \" Wrong requested permissions format : ' $ { data } ' \" , ( \" data \" , requested_perm_var ) ) ; <nl> <nl> + vector < permission_level > trxperm ; <nl> try { <nl> - transaction_perm_var . as < vector < permission_level > > ( ) ; <nl> + trxperm = transaction_perm_var . as < vector < permission_level > > ( ) ; <nl> } EOS_RETHROW_EXCEPTIONS ( transaction_type_exception , \" Wrong transaction permissions format : ' $ { data } ' \" , ( \" data \" , transaction_perm_var ) ) ; <nl> <nl> auto accountPermissions = get_account_permissions ( tx_permission ) ; <nl> int main ( int argc , char * * argv ) { <nl> proposer = name ( accountPermissions . at ( 0 ) . actor ) . to_string ( ) ; <nl> } <nl> <nl> + transaction trx ; <nl> + <nl> + trx . expiration = fc : : time_point_sec ( fc : : time_point : : now ( ) + fc : : hours ( proposal_expiration_hours ) ) ; <nl> + trx . region = 0 ; <nl> + trx . ref_block_num = 0 ; <nl> + trx . ref_block_prefix = 0 ; <nl> + trx . max_net_usage_words = 0 ; <nl> + trx . max_kcpu_usage = 0 ; <nl> + trx . delay_sec = 0 ; <nl> + trx . actions = { chain : : action ( trxperm , name ( proposed_contract ) , name ( proposed_action ) , proposed_trx_serialized ) } ; <nl> + <nl> + fc : : to_variant ( trx , trx_var ) ; <nl> + <nl> arg = fc : : mutable_variant_object ( ) <nl> ( \" code \" , \" eosio . msig \" ) <nl> ( \" action \" , \" propose \" ) <nl> int main ( int argc , char * * argv ) { <nl> ( \" proposer \" , proposer ) <nl> ( \" proposal_name \" , proposal_name ) <nl> ( \" requested \" , requested_perm_var ) <nl> - ( \" trx \" , fc : : mutable_variant_object ( ) <nl> - ( \" expiration \" , fc : : time_point_sec ( fc : : time_point : : now ( ) + fc : : hours ( proposal_expiration_hours ) ) . to_iso_string ( ) ) <nl> - ( \" region \" , 0 ) <nl> - ( \" ref_block_num \" , 0 ) <nl> - ( \" ref_block_prefix \" , 0 ) <nl> - ( \" max_net_usage_words \" , 0 ) <nl> - ( \" max_kcpu_usage \" , 0 ) <nl> - ( \" delay_sec \" , 0 ) <nl> - ( \" context_free_actions \" , fc : : variants ( ) ) <nl> - ( \" actions \" , fc : : variants { fc : : mutable_variant_object ( ) <nl> - ( \" account \" , proposed_contract ) <nl> - ( \" name \" , proposed_action ) <nl> - ( \" authorization \" , transaction_perm_var ) <nl> - ( \" data \" , proposed_trx_serialized ) <nl> - } <nl> - ) <nl> - ) <nl> + ( \" trx \" , trx_var ) <nl> ) ; <nl> result = call ( json_to_bin_func , arg ) ; <nl> send_actions ( { chain : : action { accountPermissions , \" eosio . msig \" , \" propose \" , result . get_object ( ) [ \" binargs \" ] . as < bytes > ( ) } } ) ; <nl>\n", "msg": "construct transaction as a structure instead of json\n"}
{"diff_id": 12398, "msg": "Made changes to stack program using array implementation\n", "msgGPT": "add topmost element functionality to the stack implementation.", "METEOR Score": "22.067796610169484", "BLEU Score": "0.41517863628600027", "ROUGE-L Score": "0.37499999500000003", "score": 1, "repo": "TheAlgorithms/C-Plus-Plus\n", "sha": "fce50afe2a8493ae3123ab19045031178b941584\n", "time": "2017-05-16T19:01:19Z\n", "diff": "diff - - git a / Stack Using Array . cpp b / Stack Using Array . cpp <nl> mmm a / Stack Using Array . cpp <nl> ppp b / Stack Using Array . cpp <nl> void show ( ) <nl> } <nl> } <nl> <nl> + void topmost ( ) <nl> + { <nl> + cout < < \" \\ nTopmost element : \" < < stack [ top - 1 ] ; <nl> + } <nl> int main ( ) <nl> { <nl> int ch , x ; <nl> int main ( ) <nl> cout < < \" \\ n1 . Push \" ; <nl> cout < < \" \\ n2 . Pop \" ; <nl> cout < < \" \\ n3 . Print \" ; <nl> - cout < < \" \\ nEnter Your Choice : \" ; <nl> + cout < < \" \\ n4 . Print topmost element : \" ; <nl> + cout < < \" \\ nEnter Your Choice : \" ; <nl> cin > > ch ; <nl> if ( ch = = 1 ) <nl> { <nl> int main ( ) <nl> { <nl> show ( ) ; <nl> } <nl> + else if ( ch = = 4 ) <nl> + { <nl> + topmost ( ) ; <nl> + } <nl> } <nl> while ( ch ! = 0 ) ; <nl> <nl>\n"}
{"diff_id": 12419, "repo": "xbmc/xbmc\n", "sha": "f6ade12d4e13782461cc45964f28c04b4af95743\n", "time": "2012-11-10T20:08:58Z\n", "diff": "mmm a / xbmc / video / dialogs / GUIDialogVideoInfo . cpp <nl> ppp b / xbmc / video / dialogs / GUIDialogVideoInfo . cpp <nl> void CGUIDialogVideoInfo : : OnGetArt ( ) <nl> db . Close ( ) ; <nl> } <nl> CUtil : : DeleteVideoDatabaseDirectoryCache ( ) ; / / to get them new thumbs to show <nl> - / / update the art - we need to call the map version of SetArt to force <nl> - / / the thumb image to update in the case it ' s a fallback image <nl> - map < string , string > itemArt ( m_movieItem - > GetArt ( ) ) ; <nl> - if ( currentArt . find ( \" thumb \" ) = = currentArt . end ( ) ) <nl> - { / / no \" thumb \" image , so make sure we reset the thumb fallback <nl> - itemArt . erase ( \" thumb \" ) ; <nl> - } <nl> - itemArt [ type ] = newThumb ; <nl> - m_movieItem - > SetArt ( itemArt ) ; <nl> + m_movieItem - > SetArt ( type , newThumb ) ; <nl> if ( m_movieItem - > HasProperty ( \" set_folder_thumb \" ) ) <nl> { / / have a folder thumb to set as well <nl> VIDEO : : CVideoInfoScanner : : ApplyThumbToFolder ( m_movieItem - > GetProperty ( \" set_folder_thumb \" ) . asString ( ) , newThumb ) ; <nl>\n", "msg": "[ art ] cleanup - no need for convoluted resetting of thumb now that it ' s just a fallback\n", "score": 1}
{"diff_id": 12518, "repo": "mongodb/mongo\n", "sha": "c6e4f305909c18ff2efca138c070e501d89c9cc9\n", "time": "2009-02-03T02:39:54Z\n", "diff": "mmm a / dbtests / dbtests . cpp <nl> ppp b / dbtests / dbtests . cpp <nl> int main ( int argc , char * * argv ) { <nl> tests . add ( jsobjTests ( ) , \" jsobj \" ) ; <nl> tests . add ( jsonTests ( ) , \" json \" ) ; <nl> tests . add ( matcherTests ( ) , \" matcher \" ) ; <nl> - tests . add ( namespaceTests ( ) , \" namespace \" ) ; <nl> + / / tests . add ( namespaceTests ( ) , \" namespace \" ) ; <nl> tests . add ( pairingTests ( ) , \" pairing \" ) ; <nl> - tests . add ( pdfileTests ( ) , \" pdfile \" ) ; <nl> + / / tests . add ( pdfileTests ( ) , \" pdfile \" ) ; <nl> tests . add ( queryTests ( ) , \" query \" ) ; <nl> tests . add ( replTests ( ) , \" repl \" ) ; <nl> tests . add ( sockTests ( ) , \" sock \" ) ; <nl>\n", "msg": "Disable tests until I can fix the failures tomorrow\n"}
{"diff_id": 12541, "repo": "apple/swift\n", "sha": "705cfa423a9372ced1e8a3dbf9a7e6569d464cb6\n", "time": "2018-10-19T21:15:45Z\n", "diff": "mmm a / lib / IRGen / GenDecl . cpp <nl> ppp b / lib / IRGen / GenDecl . cpp <nl> void IRGenModule : : emitRuntimeRegistration ( ) { <nl> if ( DebugInfo & & ! Context . LangOpts . DebuggerSupport ) <nl> DebugInfo - > emitArtificialFunction ( RegIGF , RegistrationFunction ) ; <nl> <nl> - / / Register ObjC protocols , classes , and extensions we added . <nl> + / / Register ObjC protocols we added . <nl> if ( ObjCInterop ) { <nl> if ( ! ObjCProtocols . empty ( ) ) { <nl> / / We need to initialize ObjC protocols in inheritance order , parents <nl> void IRGenModule : : emitRuntimeRegistration ( ) { <nl> . visitMembers ( proto ) ; <nl> } <nl> } <nl> - <nl> - for ( llvm : : WeakTrackingVH & ObjCClass : ObjCClasses ) { <nl> - RegIGF . Builder . CreateCall ( getInstantiateObjCClassFn ( ) , { ObjCClass } ) ; <nl> - } <nl> - <nl> - for ( ExtensionDecl * ext : ObjCCategoryDecls ) { <nl> - CategoryInitializerVisitor ( RegIGF , ext ) . visitMembers ( ext ) ; <nl> - } <nl> } <nl> <nl> / / Register Swift protocols if we added any . <nl> void IRGenModule : : emitRuntimeRegistration ( ) { <nl> RegIGF . Builder . CreateCall ( getRegisterTypeMetadataRecordsFn ( ) , { begin , end } ) ; <nl> } <nl> <nl> + / / Register Objective - C classes and extensions we added . <nl> + if ( ObjCInterop ) { <nl> + for ( llvm : : WeakTrackingVH & ObjCClass : ObjCClasses ) { <nl> + RegIGF . Builder . CreateCall ( getInstantiateObjCClassFn ( ) , { ObjCClass } ) ; <nl> + } <nl> + <nl> + for ( ExtensionDecl * ext : ObjCCategoryDecls ) { <nl> + CategoryInitializerVisitor ( RegIGF , ext ) . visitMembers ( ext ) ; <nl> + } <nl> + } <nl> + <nl> if ( ! FieldDescriptors . empty ( ) ) { <nl> emitFieldDescriptors ( ) ; <nl> } <nl>\n", "msg": "[ IRGen JIT ] Register Objective - C classes / categories after other metadata .\n"}
{"diff_id": 12628, "repo": "arangodb/arangodb\n", "sha": "86707b336e90d38b5be658b1bdd7c3c2894a4304\n", "time": "2014-08-21T12:23:07Z\n", "diff": "mmm a / arangod / Aql / ExecutionPlan . cpp <nl> ppp b / arangod / Aql / ExecutionPlan . cpp <nl> struct NodeRemover : public WalkerWorker < ExecutionNode > { <nl> } <nl> <nl> void after ( ExecutionNode * en ) { <nl> - _plan - > unregisterNode ( en ) ; <nl> parents . pop_back ( ) ; <nl> } <nl> } ; <nl>\n", "msg": "do not unregister nodes on unlink\n"}
{"diff_id": 12838, "repo": "apple/swift\n", "sha": "88718308fd4127cb0bcdf2e8e3436d9875e0bee4\n", "time": "2015-12-23T09:18:54Z\n", "diff": "mmm a / lib / IRGen / GenDecl . cpp <nl> ppp b / lib / IRGen / GenDecl . cpp <nl> void IRGenModule : : emitGlobalLists ( ) { <nl> ExistingLLVMUsed - > eraseFromParent ( ) ; <nl> } <nl> <nl> - assert ( std : : all_of ( LLVMUsed . begin ( ) , LLVMUsed . end ( ) , <nl> - [ ] ( const llvm : : WeakVH & global ) { <nl> - return ! isa < llvm : : GlobalValue > ( global ) | | <nl> - ! cast < llvm : : GlobalValue > ( global ) - > isDeclaration ( ) ; <nl> - } ) & & \" all globals in the ' used ' list must be definitions \" ) ; <nl> + std : : for_each ( LLVMUsed . begin ( ) , LLVMUsed . end ( ) , <nl> + [ ] ( const llvm : : WeakVH & global ) { <nl> + assert ( ! isa < llvm : : GlobalValue > ( global ) | | <nl> + ! cast < llvm : : GlobalValue > ( global ) - > isDeclaration ( ) & & <nl> + \" all globals in the ' used ' list must be definitions \" ) ; <nl> + } ) ; <nl> emitGlobalList ( * this , LLVMUsed , \" llvm . used \" , \" llvm . metadata \" , <nl> llvm : : GlobalValue : : AppendingLinkage , <nl> Int8PtrTy , <nl>\n", "msg": "IRGen : Improve an assertion for easier debugging\n", "score": 1}
{"diff_id": 12889, "repo": "mongodb/mongo\n", "sha": "f447474a7acc19c6bf6df2fcf1248d6188a19aea\n", "time": "2009-02-23T19:32:00Z\n", "diff": "mmm a / s / strategy_shard . cpp <nl> ppp b / s / strategy_shard . cpp <nl> namespace mongo { <nl> <nl> ShardInfo * info = r . getShardInfo ( ) ; <nl> assert ( info ) ; <nl> + <nl> + Query query ( q . query ) ; <nl> <nl> vector < Shard * > shards ; <nl> - if ( info - > getShardsForQuery ( shards , q . query ) = = 1 ) { <nl> + if ( info - > getShardsForQuery ( shards , query . getFilter ( ) ) = = 1 ) { <nl> doQuery ( r , shards [ 0 ] - > getServer ( ) ) ; <nl> return ; <nl> } <nl> <nl> + <nl> throw UserException ( \" real sharding doesn ' t nwork \" ) ; <nl> } <nl> <nl>\n", "msg": "only make decision on shards based on filter\n"}
{"diff_id": 13049, "repo": "sqlitebrowser/sqlitebrowser\n", "sha": "ec2d060df6439dfe0030802496ae274276b1f4c3\n", "time": "2016-08-28T14:41:18Z\n", "diff": "mmm a / src / PreferencesDialog . cpp <nl> ppp b / src / PreferencesDialog . cpp <nl> QVariant PreferencesDialog : : getSettingsDefaultValue ( const QString & group , const <nl> { <nl> QFont font ( \" Monospace \" ) ; <nl> font . setStyleHint ( QFont : : TypeWriter ) ; <nl> - return font . family ( ) ; <nl> + return QFontInfo ( font ) . family ( ) ; <nl> } <nl> <nl> / / editor / fontsize or log / fontsize ? <nl>\n", "msg": "Use QFontInfo so Windows chooses a correct font\n"}
{"diff_id": 13200, "repo": "EOSIO/eos\n", "sha": "2acea9a741bd4c9d3c6e346ba045007bcf3fa632\n", "time": "2019-02-20T00:14:09Z\n", "diff": "mmm a / programs / cleos / main . cpp <nl> ppp b / programs / cleos / main . cpp <nl> struct canceldelay_subcommand { <nl> } <nl> } ; <nl> <nl> + struct deposit_subcommand { <nl> + string owner_str ; <nl> + string amount_str ; <nl> + <nl> + deposit_subcommand ( CLI : : App * actionRoot ) { <nl> + auto deposit = actionRoot - > add_subcommand ( \" deposit \" , localized ( \" Deposit into REX fund by transfering from owner ' s liquid token balance \" ) ) ; <nl> + deposit - > add_option ( \" owner \" , owner_str , localized ( \" Account which owns the REX fund \" ) ) - > required ( ) ; <nl> + deposit - > add_option ( \" amount \" , amount_str , localized ( \" Amount to be deposited into REX fund \" ) ) - > required ( ) ; <nl> + add_standard_transaction_options ( deposit , \" owner @ active \" ) ; <nl> + deposit - > set_callback ( [ this ] { <nl> + fc : : variant act_payload = fc : : mutable_variant_object ( ) <nl> + ( \" owner \" , owner_str ) <nl> + ( \" amount \" , amount_str ) ; <nl> + auto accountPermissions = get_account_permissions ( tx_permission , { owner_str , config : : active_name } ) ; <nl> + send_actions ( { create_action ( accountPermissions , config : : system_account_name , N ( deposit ) , act_payload ) } ) ; <nl> + } ) ; <nl> + } <nl> + } ; <nl> + <nl> + struct withdraw_subcommand { <nl> + string owner_str ; <nl> + string amount_str ; <nl> + <nl> + withdraw_subcommand ( CLI : : App * actionRoot ) { <nl> + auto withdraw = actionRoot - > add_subcommand ( \" withdraw \" , localized ( \" Withdraw from REX fund by transfering to owner ' s liquid token balance \" ) ) ; <nl> + withdraw - > add_option ( \" owner \" , owner_str , localized ( \" Account which owns the REX fund \" ) ) - > required ( ) ; <nl> + withdraw - > add_option ( \" amount \" , amount_str , localized ( \" Amount to be withdrawn from REX fund \" ) ) - > required ( ) ; <nl> + add_standard_transaction_options ( withdraw , \" owner @ active \" ) ; <nl> + withdraw - > set_callback ( [ this ] { <nl> + fc : : variant act_payload = fc : : mutable_variant_object ( ) <nl> + ( \" owner \" , owner_str ) <nl> + ( \" amount \" , amount_str ) ; <nl> + auto accountPermissions = get_account_permissions ( tx_permission , { owner_str , config : : active_name } ) ; <nl> + send_actions ( { create_action ( accountPermissions , config : : system_account_name , N ( withdraw ) , act_payload ) } ) ; <nl> + } ) ; <nl> + } <nl> + } ; <nl> + <nl> + struct buyrex_subcommand { <nl> + string from_str ; <nl> + string amount_str ; <nl> + <nl> + buyrex_subcommand ( CLI : : App * actionRoot ) { <nl> + auto buyrex = actionRoot - > add_subcommand ( \" buyrex \" , localized ( \" Buy REX tokens \" ) ) ; <nl> + buyrex - > add_option ( \" from \" , from_str , localized ( \" Account buying REX tokens \" ) ) - > required ( ) ; <nl> + buyrex - > add_option ( \" amount \" , amount_str , localized ( \" Amount to be taken from REX fund and used in buying REX tokens \" ) ) - > required ( ) ; <nl> + add_standard_transaction_options ( buyrex , \" owner @ active \" ) ; <nl> + buyrex - > set_callback ( [ this ] { <nl> + fc : : variant act_payload = fc : : mutable_variant_object ( ) <nl> + ( \" from \" , from_str ) <nl> + ( \" amount \" , amount_str ) ; <nl> + auto accountPermissions = get_account_permissions ( tx_permission , { from_str , config : : active_name } ) ; <nl> + send_actions ( { create_action ( accountPermissions , config : : system_account_name , N ( buyrex ) , act_payload ) } ) ; <nl> + } ) ; <nl> + } <nl> + } ; <nl> + <nl> + struct unstaketorex_subcommand { <nl> + string owner_str ; <nl> + string receiver_str ; <nl> + string from_net_str ; <nl> + string from_cpu_str ; <nl> + <nl> + unstaketorex_subcommand ( CLI : : App * actionRoot ) { <nl> + auto unstaketorex = actionRoot - > add_subcommand ( \" unstaketorex \" , localized ( \" Buy REX using staked tokens \" ) ) ; <nl> + unstaketorex - > add_option ( \" owner \" , owner_str , localized ( \" Account buying REX tokens \" ) ) - > required ( ) ; <nl> + unstaketorex - > add_option ( \" receiver \" , receiver_str , localized ( \" Account tokens have been staked to \" ) ) - > required ( ) ; <nl> + unstaketorex - > add_option ( \" from_net \" , from_net_str , localized ( \" Amount to be unstaked from CPU resources and used in REX purchase \" ) ) - > required ( ) ; <nl> + unstaketorex - > add_option ( \" from_cpu \" , from_cpu_str , localized ( \" Amount to be unstaked from Net resources and used in REX purchase \" ) ) - > required ( ) ; <nl> + add_standard_transaction_options ( unstaketorex , \" owner @ active \" ) ; <nl> + unstaketorex - > set_callback ( [ this ] { <nl> + fc : : variant act_payload = fc : : mutable_variant_object ( ) <nl> + ( \" owner \" , owner_str ) <nl> + ( \" receiver \" , receiver_str ) <nl> + ( \" from_net \" , from_net_str ) <nl> + ( \" from_cpu \" , from_cpu_str ) ; <nl> + auto accountPermissions = get_account_permissions ( tx_permission , { owner_str , config : : active_name } ) ; <nl> + send_actions ( { create_action ( accountPermissions , config : : system_account_name , N ( unstaketorex ) , act_payload ) } ) ; <nl> + } ) ; <nl> + } <nl> + } ; <nl> + <nl> + struct sellrex_subcommand { <nl> + string from_str ; <nl> + string rex_str ; <nl> + <nl> + sellrex_subcommand ( CLI : : App * actionRoot ) { <nl> + auto sellrex = actionRoot - > add_subcommand ( \" sellrex \" , localized ( \" Sell REX tokens \" ) ) ; <nl> + sellrex - > add_option ( \" from \" , from_str , localized ( \" Account selling REX tokens \" ) ) - > required ( ) ; <nl> + sellrex - > add_option ( \" rex \" , rex_str , localized ( \" Amount of REX tokens to be sold \" ) ) - > required ( ) ; <nl> + add_standard_transaction_options ( sellrex , \" from @ active \" ) ; <nl> + sellrex - > set_callback ( [ this ] { <nl> + fc : : variant act_payload = fc : : mutable_variant_object ( ) <nl> + ( \" from \" , from_str ) <nl> + ( \" rex \" , rex_str ) ; <nl> + auto accountPermissions = get_account_permissions ( tx_permission , { from_str , config : : active_name } ) ; <nl> + send_actions ( { create_action ( accountPermissions , config : : system_account_name , N ( sellrex ) , act_payload ) } ) ; <nl> + } ) ; <nl> + } <nl> + } ; <nl> + <nl> + struct cancelrexorder_subcommand { <nl> + string owner_str ; <nl> + <nl> + cancelrexorder_subcommand ( CLI : : App * actionRoot ) { <nl> + auto cancelrexoder = actionRoot - > add_subcommand ( \" cancelrexorder \" , localized ( \" Cancel queued REX sell order if one exists \" ) ) ; <nl> + cancelrexoder - > add_option ( \" owner \" , owner_str , localized ( \" Owner account of sell order \" ) ) - > required ( ) ; <nl> + add_standard_transaction_options ( cancelrexoder , \" owner @ active \" ) ; <nl> + cancelrexoder - > set_callback ( [ this ] { <nl> + fc : : variant act_payload = fc : : mutable_variant_object ( ) ( \" owner \" , owner_str ) ; <nl> + auto accountPermissions = get_account_permissions ( tx_permission , { owner_str , config : : active_name } ) ; <nl> + send_actions ( { create_action ( accountPermissions , config : : system_account_name , N ( cnclrexorder ) , act_payload ) } ) ; <nl> + } ) ; <nl> + } <nl> + } ; <nl> + <nl> + struct rentcpu_subcommand { <nl> + string from_str ; <nl> + string receiver_str ; <nl> + string loan_payment_str ; <nl> + string loan_fund_str ; <nl> + <nl> + rentcpu_subcommand ( CLI : : App * actionRoot ) { <nl> + auto rentcpu = actionRoot - > add_subcommand ( \" rentcpu \" , localized ( \" Rent CPU bandwidth for 30 days \" ) ) ; <nl> + rentcpu - > add_option ( \" from \" , from_str , localized ( \" Account paying rent fees \" ) ) - > required ( ) ; <nl> + rentcpu - > add_option ( \" receiver \" , receiver_str , localized ( \" Account to whom rented CPU bandwidth is staked \" ) ) - > required ( ) ; <nl> + rentcpu - > add_option ( \" loan_payment \" , loan_payment_str , localized ( \" Loan fee , used to calculate amount of rented bandwidth \" ) ) - > required ( ) ; <nl> + rentcpu - > add_option ( \" loan_fund \" , loan_fund_str , localized ( \" Optional loan fund to be used in automatic renewal \" ) ) - > required ( ) ; <nl> + add_standard_transaction_options ( rentcpu , \" from @ active \" ) ; <nl> + rentcpu - > set_callback ( [ this ] { <nl> + fc : : variant act_payload = fc : : mutable_variant_object ( ) <nl> + ( \" from \" , from_str ) <nl> + ( \" receiver \" , receiver_str ) <nl> + ( \" loan_payment \" , loan_payment_str ) <nl> + ( \" loan_fund \" , loan_fund_str ) ; <nl> + auto accountPermissions = get_account_permissions ( tx_permission , { from_str , config : : active_name } ) ; <nl> + send_actions ( { create_action ( accountPermissions , config : : system_account_name , N ( rentcpu ) , act_payload ) } ) ; <nl> + } ) ; <nl> + } <nl> + } ; <nl> + <nl> + struct rentnet_subcommand { <nl> + string from_str ; <nl> + string receiver_str ; <nl> + string loan_payment_str ; <nl> + string loan_fund_str ; <nl> + <nl> + rentnet_subcommand ( CLI : : App * actionRoot ) { <nl> + auto rentnet = actionRoot - > add_subcommand ( \" rentnet \" , localized ( \" Rent Network bandwidth for 30 days \" ) ) ; <nl> + rentnet - > add_option ( \" from \" , from_str , localized ( \" Account paying rent fees \" ) ) - > required ( ) ; <nl> + rentnet - > add_option ( \" receiver \" , receiver_str , localized ( \" Account to whom rented Network bandwidth is staked \" ) ) - > required ( ) ; <nl> + rentnet - > add_option ( \" loan_payment \" , loan_payment_str , localized ( \" Loan fee , used to calculate amount of rented bandwidth \" ) ) - > required ( ) ; <nl> + rentnet - > add_option ( \" loan_fund \" , loan_fund_str , localized ( \" Optional loan fund to be used in automatic renewal \" ) ) - > required ( ) ; <nl> + add_standard_transaction_options ( rentnet , \" from @ active \" ) ; <nl> + rentnet - > set_callback ( [ this ] { <nl> + fc : : variant act_payload = fc : : mutable_variant_object ( ) <nl> + ( \" from \" , from_str ) <nl> + ( \" receiver \" , receiver_str ) <nl> + ( \" loan_payment \" , loan_payment_str ) <nl> + ( \" loan_fund \" , loan_fund_str ) ; <nl> + auto accountPermissions = get_account_permissions ( tx_permission , { from_str , config : : active_name } ) ; <nl> + send_actions ( { create_action ( accountPermissions , config : : system_account_name , N ( rentnet ) , act_payload ) } ) ; <nl> + } ) ; <nl> + } <nl> + } ; <nl> + <nl> + struct fundcpuloan_subcommand { <nl> + string from_str ; <nl> + string loan_num_str ; <nl> + string payment_str ; <nl> + <nl> + fundcpuloan_subcommand ( CLI : : App * actionRoot ) { <nl> + auto fundcpuloan = actionRoot - > add_subcommand ( \" fundcpuloan \" , localized ( \" Deposit into a CPU loan fund \" ) ) ; <nl> + fundcpuloan - > add_option ( \" from \" , from_str , localized ( \" Loan owner \" ) ) - > required ( ) ; <nl> + fundcpuloan - > add_option ( \" loan_num \" , loan_num_str , localized ( \" Loan ID \" ) ) - > required ( ) ; <nl> + fundcpuloan - > add_option ( \" payment \" , payment_str , localized ( \" Amount to be deposited \" ) ) - > required ( ) ; <nl> + add_standard_transaction_options ( fundcpuloan , \" from @ active \" ) ; <nl> + fundcpuloan - > set_callback ( [ this ] { <nl> + fc : : variant act_payload = fc : : mutable_variant_object ( ) <nl> + ( \" from \" , from_str ) <nl> + ( \" loan_num \" , loan_num_str ) <nl> + ( \" payment \" , payment_str ) ; <nl> + auto accountPermissions = get_account_permissions ( tx_permission , { from_str , config : : active_name } ) ; <nl> + send_actions ( { create_action ( accountPermissions , config : : system_account_name , N ( fundcpuloan ) , act_payload ) } ) ; <nl> + } ) ; <nl> + } <nl> + } ; <nl> + <nl> + struct fundnetloan_subcommand { <nl> + string from_str ; <nl> + string loan_num_str ; <nl> + string payment_str ; <nl> + <nl> + fundnetloan_subcommand ( CLI : : App * actionRoot ) { <nl> + auto fundnetloan = actionRoot - > add_subcommand ( \" fundnetloan \" , localized ( \" Deposit into a Network loan fund \" ) ) ; <nl> + fundnetloan - > add_option ( \" from \" , from_str , localized ( \" Loan owner \" ) ) - > required ( ) ; <nl> + fundnetloan - > add_option ( \" loan_num \" , loan_num_str , localized ( \" Loan ID \" ) ) - > required ( ) ; <nl> + fundnetloan - > add_option ( \" payment \" , payment_str , localized ( \" Amount to be deposited \" ) ) - > required ( ) ; <nl> + add_standard_transaction_options ( fundnetloan , \" from @ active \" ) ; <nl> + fundnetloan - > set_callback ( [ this ] { <nl> + fc : : variant act_payload = fc : : mutable_variant_object ( ) <nl> + ( \" from \" , from_str ) <nl> + ( \" loan_num \" , loan_num_str ) <nl> + ( \" payment \" , payment_str ) ; <nl> + auto accountPermissions = get_account_permissions ( tx_permission , { from_str , config : : active_name } ) ; <nl> + send_actions ( { create_action ( accountPermissions , config : : system_account_name , N ( fundnetloan ) , act_payload ) } ) ; <nl> + } ) ; <nl> + } <nl> + } ; <nl> + <nl> + struct mvtosavings_subcommand { <nl> + string owner_str ; <nl> + string rex_str ; <nl> + <nl> + mvtosavings_subcommand ( CLI : : App * actionRoot ) { <nl> + auto mvtosavings = actionRoot - > add_subcommand ( \" mvtosavings \" , localized ( \" Move REX tokens to savings bucket \" ) ) ; <nl> + mvtosavings - > add_option ( \" owner \" , owner_str , localized ( \" REX owner \" ) ) - > required ( ) ; <nl> + mvtosavings - > add_option ( \" rex \" , rex_str , localized ( \" Amount of REX to be moved to savings bucket \" ) ) - > required ( ) ; <nl> + add_standard_transaction_options ( mvtosavings , \" owner @ active \" ) ; <nl> + mvtosavings - > set_callback ( [ this ] { <nl> + fc : : variant act_payload = fc : : mutable_variant_object ( ) <nl> + ( \" owner \" , owner_str ) <nl> + ( \" rex \" , rex_str ) ; <nl> + auto accountPermissions = get_account_permissions ( tx_permission , { owner_str , config : : active_name } ) ; <nl> + send_actions ( { create_action ( accountPermissions , config : : system_account_name , N ( mvtosavings ) , act_payload ) } ) ; <nl> + } ) ; <nl> + } <nl> + } ; <nl> + <nl> + struct mvfrsavings_subcommand { <nl> + string owner_str ; <nl> + string rex_str ; <nl> + <nl> + mvfrsavings_subcommand ( CLI : : App * actionRoot ) { <nl> + auto mvfrsavings = actionRoot - > add_subcommand ( \" mvfromsavings \" , localized ( \" Move REX tokens out of savings bucket \" ) ) ; <nl> + mvfrsavings - > add_option ( \" owner \" , owner_str , localized ( \" REX owner \" ) ) - > required ( ) ; <nl> + mvfrsavings - > add_option ( \" rex \" , rex_str , localized ( \" Amount of REX to be moved out of savings bucket \" ) ) - > required ( ) ; <nl> + add_standard_transaction_options ( mvfrsavings , \" owner @ active \" ) ; <nl> + mvfrsavings - > set_callback ( [ this ] { <nl> + fc : : variant act_payload = fc : : mutable_variant_object ( ) <nl> + ( \" owner \" , owner_str ) <nl> + ( \" rex \" , rex_str ) ; <nl> + auto accountPermissions = get_account_permissions ( tx_permission , { owner_str , config : : active_name } ) ; <nl> + send_actions ( { create_action ( accountPermissions , config : : system_account_name , N ( mvfrsavings ) , act_payload ) } ) ; <nl> + } ) ; <nl> + } <nl> + } ; <nl> + <nl> + struct updaterex_subcommand { <nl> + string owner_str ; <nl> + <nl> + updaterex_subcommand ( CLI : : App * actionRoot ) { <nl> + auto updaterex = actionRoot - > add_subcommand ( \" updaterex \" , localized ( \" Update REX owner vote stake and vote weight \" ) ) ; <nl> + updaterex - > add_option ( \" owner \" , owner_str , localized ( \" REX owner \" ) ) - > required ( ) ; <nl> + add_standard_transaction_options ( updaterex , \" owner @ active \" ) ; <nl> + updaterex - > set_callback ( [ this ] { <nl> + fc : : variant act_payload = fc : : mutable_variant_object ( ) ( \" owner \" , owner_str ) ; <nl> + auto accountPermissions = get_account_permissions ( tx_permission , { owner_str , config : : active_name } ) ; <nl> + send_actions ( { create_action ( accountPermissions , config : : system_account_name , N ( updaterex ) , act_payload ) } ) ; <nl> + } ) ; <nl> + } <nl> + } ; <nl> + <nl> + struct consolidate_subcommand { <nl> + string owner_str ; <nl> + <nl> + consolidate_subcommand ( CLI : : App * actionRoot ) { <nl> + auto consolidate = actionRoot - > add_subcommand ( \" consolidate \" , localized ( \" Consolidate REX maturity buckets into one that matures in 4 days \" ) ) ; <nl> + consolidate - > add_option ( \" owner \" , owner_str , localized ( \" REX owner \" ) ) - > required ( ) ; <nl> + add_standard_transaction_options ( consolidate , \" owner @ active \" ) ; <nl> + consolidate - > set_callback ( [ this ] { <nl> + fc : : variant act_payload = fc : : mutable_variant_object ( ) ( \" owner \" , owner_str ) ; <nl> + auto accountPermissions = get_account_permissions ( tx_permission , { owner_str , config : : active_name } ) ; <nl> + send_actions ( { create_action ( accountPermissions , config : : system_account_name , N ( consolidate ) , act_payload ) } ) ; <nl> + } ) ; <nl> + } <nl> + } ; <nl> + <nl> + struct closerex_subcommand { <nl> + string owner_str ; <nl> + <nl> + closerex_subcommand ( CLI : : App * actionRoot ) { <nl> + auto closerex = actionRoot - > add_subcommand ( \" closerex \" , localized ( \" Delete unused REX - related user table entries \" ) ) ; <nl> + closerex - > add_option ( \" owner \" , owner_str , localized ( \" REX owner \" ) ) - > required ( ) ; <nl> + add_standard_transaction_options ( closerex , \" owner @ active \" ) ; <nl> + closerex - > set_callback ( [ this ] { <nl> + fc : : variant act_payload = fc : : mutable_variant_object ( ) ( \" owner \" , owner_str ) ; <nl> + auto accountPermissions = get_account_permissions ( tx_permission , { owner_str , config : : active_name } ) ; <nl> + send_actions ( { create_action ( accountPermissions , config : : system_account_name , N ( closerex ) , act_payload ) } ) ; <nl> + } ) ; <nl> + } <nl> + } ; <nl> + <nl> void get_account ( const string & accountName , const string & coresym , bool json_format ) { <nl> fc : : variant json ; <nl> if ( coresym . empty ( ) ) { <nl> int main ( int argc , char * * argv ) { <nl> <nl> auto cancelDelay = canceldelay_subcommand ( system ) ; <nl> <nl> + auto rex = system - > add_subcommand ( \" rex \" , localized ( \" Actions related to REX ( the resource exchange ) \" ) ) ; <nl> + rex - > require_subcommand ( ) ; <nl> + auto deposit = deposit_subcommand ( rex ) ; <nl> + auto withdraw = withdraw_subcommand ( rex ) ; <nl> + auto buyrex = buyrex_subcommand ( rex ) ; <nl> + auto unstaketorex = unstaketorex_subcommand ( rex ) ; <nl> + auto sellrex = sellrex_subcommand ( rex ) ; <nl> + auto cancelrexorder = cancelrexorder_subcommand ( rex ) ; <nl> + auto mvtosavings = mvtosavings_subcommand ( rex ) ; <nl> + auto mvfromsavings = mvfrsavings_subcommand ( rex ) ; <nl> + auto rentcpu = rentcpu_subcommand ( rex ) ; <nl> + auto autorentcpu = rentnet_subcommand ( rex ) ; <nl> + auto consolidate = consolidate_subcommand ( rex ) ; <nl> + auto updaterex = updaterex_subcommand ( rex ) ; <nl> + auto closerex = closerex_subcommand ( rex ) ; <nl> + <nl> + <nl> + <nl> try { <nl> app . parse ( argc , argv ) ; <nl> } catch ( const CLI : : ParseError & e ) { <nl>\n", "msg": "Add cleos support for REX actions\n"}
{"diff_id": 13237, "repo": "microsoft/LightGBM\n", "sha": "b5e211ba7270a37da358b43d52b443cf554fb6b5\n", "time": "2017-08-30T08:57:59Z\n", "diff": "mmm a / src / io / bin . cpp <nl> ppp b / src / io / bin . cpp <nl> namespace LightGBM { <nl> std : : vector < double > GreedyFindBin ( const double * distinct_values , const int * counts , <nl> int num_distinct_values , int max_bin , size_t total_cnt , int min_data_in_bin ) { <nl> std : : vector < double > bin_upper_bound ; <nl> + CHECK ( max_bin > 0 ) ; <nl> if ( num_distinct_values < = max_bin ) { <nl> bin_upper_bound . clear ( ) ; <nl> int cur_cnt_inbin = 0 ; <nl> namespace LightGBM { <nl> <nl> if ( left_cnt > 0 ) { <nl> int left_max_bin = static_cast < int > ( static_cast < double > ( left_cnt_data ) / ( total_sample_cnt - cnt_zero ) * ( max_bin - 1 ) ) ; <nl> + left_max_bin = std : : max ( 1 , left_max_bin ) ; <nl> bin_upper_bound = GreedyFindBin ( distinct_values , counts , left_cnt , left_max_bin , left_cnt_data , min_data_in_bin ) ; <nl> bin_upper_bound . back ( ) = - kZeroAsMissingValueRange ; <nl> } <nl> namespace LightGBM { <nl> <nl> if ( right_start > = 0 ) { <nl> int right_max_bin = max_bin - 1 - static_cast < int > ( bin_upper_bound . size ( ) ) ; <nl> + CHECK ( right_max_bin > 0 ) ; <nl> auto right_bounds = GreedyFindBin ( distinct_values + right_start , counts + right_start , <nl> num_distinct_values - right_start , right_max_bin , right_cnt_data , min_data_in_bin ) ; <nl> bin_upper_bound . push_back ( kZeroAsMissingValueRange ) ; <nl>\n", "msg": "check edge case for bin finder .\n"}
{"diff_id": 13295, "repo": "cocos2d/cocos2d-x\n", "sha": "f0ab05f9e784ca305d52797b11f53a9490c89b2e\n", "time": "2013-08-01T08:52:39Z\n", "diff": "mmm a / scripting / javascript / bindings / jsb_websocket . cpp <nl> ppp b / scripting / javascript / bindings / jsb_websocket . cpp <nl> JSBool js_cocos2dx_extension_WebSocket_constructor ( JSContext * cx , uint32_t argc , <nl> JSB_WebSocketDelegate * delegate = new JSB_WebSocketDelegate ( ) ; <nl> delegate - > setJSDelegate ( obj ) ; <nl> <nl> - if ( argc = = 2 ) <nl> + if ( argc = = 2 & & ! JSVAL_IS_VOID ( argv [ 1 ] ) ) <nl> { <nl> std : : vector < std : : string > protocols ; <nl> <nl>\n", "msg": "undefined argument should not be counted as a valid argument\n"}
{"diff_id": 13296, "repo": "aseprite/aseprite\n", "sha": "14c1bceb4c9abc9f5ec1457182057b843feedd96\n", "time": "2019-03-28T05:22:47Z\n", "diff": "mmm a / src / app / doc_exporter . cpp <nl> ppp b / src / app / doc_exporter . cpp <nl> class DocExporter : : BestFitLayoutSamples : <nl> public DocExporter : : LayoutSamples { <nl> public : <nl> void layoutSamples ( Samples & samples , int borderPadding , int shapePadding , int & width , int & height ) override { <nl> - gfx : : PackingRects pr ; <nl> - <nl> - / / TODO Add support for shape paddings <nl> + gfx : : PackingRects pr ( borderPadding , shapePadding ) ; <nl> <nl> for ( auto & sample : samples ) { <nl> if ( sample . isDuplicated ( ) | | <nl>\n", "msg": "Add padding support for - - sheet - pack\n"}
{"diff_id": 13303, "repo": "godotengine/godot\n", "sha": "6a48f952ca6969dcbf8e79f11a3859ca426bfba0\n", "time": "2018-02-21T14:04:51Z\n", "diff": "mmm a / scene / gui / file_dialog . cpp <nl> ppp b / scene / gui / file_dialog . cpp <nl> void FileDialog : : deselect_items ( ) { <nl> <nl> case MODE_OPEN_FILE : <nl> case MODE_OPEN_FILES : <nl> - get_ok ( ) - > set_text ( TTR ( \" Open \" ) ) ; <nl> + get_ok ( ) - > set_text ( RTR ( \" Open \" ) ) ; <nl> break ; <nl> case MODE_OPEN_DIR : <nl> - get_ok ( ) - > set_text ( TTR ( \" Select Current Folder \" ) ) ; <nl> + get_ok ( ) - > set_text ( RTR ( \" Select Current Folder \" ) ) ; <nl> break ; <nl> } <nl> } <nl> void FileDialog : : _tree_selected ( ) { <nl> <nl> file - > set_text ( d [ \" name \" ] ) ; <nl> } else if ( mode = = MODE_OPEN_DIR ) { <nl> - get_ok ( ) - > set_text ( TTR ( \" Select this Folder \" ) ) ; <nl> + get_ok ( ) - > set_text ( RTR ( \" Select this Folder \" ) ) ; <nl> } <nl> <nl> get_ok ( ) - > set_disabled ( _is_open_should_be_disabled ( ) ) ; <nl> FileDialog : : FileDialog ( ) { <nl> HBoxContainer * hbc = memnew ( HBoxContainer ) ; <nl> <nl> dir_up = memnew ( ToolButton ) ; <nl> - dir_up - > set_tooltip ( TTR ( \" Go to parent folder \" ) ) ; <nl> + dir_up - > set_tooltip ( RTR ( \" Go to parent folder \" ) ) ; <nl> hbc - > add_child ( dir_up ) ; <nl> dir_up - > connect ( \" pressed \" , this , \" _go_up \" ) ; <nl> <nl>\n", "msg": "Fixed disappearing text on filedialog buttons\n"}
{"diff_id": 13313, "repo": "apple/foundationdb\n", "sha": "daf1e09af4844c707356159dcb80fc811da64499\n", "time": "2019-07-31T03:08:56Z\n", "diff": "mmm a / fdbrpc / crc32c . cpp <nl> ppp b / fdbrpc / crc32c . cpp <nl> static inline uint32_t shift_crc ( uint32_t shift_table [ ] [ 256 ] , uint32_t crc ) <nl> } <nl> <nl> / * Compute CRC - 32C using the Intel hardware instruction . * / <nl> - # ifndef _WIN32 <nl> + # if defined ( __clang__ ) | | defined ( __GNUG__ ) <nl> __attribute__ ( ( target ( \" sse4 . 2 \" ) ) ) <nl> # endif <nl> static uint32_t append_hw ( uint32_t crc , const uint8_t * buf , size_t len ) <nl>\n", "msg": "Explicitly check for clang and g + +\n"}
{"diff_id": 13505, "repo": "apple/swift\n", "sha": "16deb28eac183b372b336ded2b164ad0157a1388\n", "time": "2016-02-04T03:50:25Z\n", "diff": "mmm a / lib / ClangImporter / ClangImporter . cpp <nl> ppp b / lib / ClangImporter / ClangImporter . cpp <nl> static bool shouldIgnoreMacro ( const clang : : IdentifierInfo * identifier , <nl> <nl> / / Currently we only convert non - function - like macros . <nl> if ( macro - > isFunctionLike ( ) ) <nl> - return false ; <nl> + return true ; <nl> <nl> / / Consult the blacklist of macros to suppress . <nl> auto suppressMacro = <nl>\n", "msg": "[ Clang importer ] Function - like macros are ignored .\n"}
{"diff_id": 13516, "repo": "telegramdesktop/tdesktop\n", "sha": "3c022b893aad5b45685085c71c3ac75bee3d468b\n", "time": "2020-01-24T07:27:08Z\n", "diff": "mmm a / Telegram / SourceFiles / history / view / media / history_view_poll . cpp <nl> ppp b / Telegram / SourceFiles / history / view / media / history_view_poll . cpp <nl> void Poll : : paintFilling ( <nl> <nl> if ( chosen & & ! correct ) { <nl> p . setBrush ( st : : boxTextFgError ) ; <nl> + } else if ( chosen & & correct & & _poll - > quiz ( ) & & ! outbg ) { <nl> + p . setBrush ( st : : boxTextFgGood ) ; <nl> } else { <nl> const auto bar = outbg ? ( selected ? st : : msgWaveformOutActiveSelected : st : : msgWaveformOutActive ) : ( selected ? st : : msgWaveformInActiveSelected : st : : msgWaveformInActive ) ; <nl> p . setBrush ( bar ) ; <nl>\n", "msg": "Show correct incoming quiz votes in green .\n"}
{"diff_id": 13523, "repo": "microsoft/LightGBM\n", "sha": "1a1c2fd752ee2ea27312663a6c3ccfdb6574b298\n", "time": "2019-05-11T01:25:11Z\n", "diff": "mmm a / src / treelearner / voting_parallel_tree_learner . cpp <nl> ppp b / src / treelearner / voting_parallel_tree_learner . cpp <nl> void VotingParallelTreeLearner < TREELEARNER_T > : : GlobalVoting ( int leaf_idx , const <nl> / / get top k <nl> std : : vector < LightSplitInfo > top_k_splits ; <nl> ArrayArgs < LightSplitInfo > : : MaxK ( feature_best_split , top_k_ , & top_k_splits ) ; <nl> - std : : sort ( top_k_splits . begin ( ) , top_k_splits . end ( ) , std : : greater < LightSplitInfo > ( ) ) ; <nl> + std : : stable_sort ( top_k_splits . begin ( ) , top_k_splits . end ( ) , std : : greater < LightSplitInfo > ( ) ) ; <nl> for ( auto & split : top_k_splits ) { <nl> if ( split . gain = = kMinScore | | split . feature = = - 1 ) { <nl> continue ; <nl>\n", "msg": "use stable_sort for splits ( )\n"}
{"diff_id": 13639, "repo": "apple/swift\n", "sha": "6c85fff3896e257525eac5b9f696d530989380e2\n", "time": "2017-10-04T21:50:16Z\n", "diff": "mmm a / lib / SILGen / SILGenType . cpp <nl> ppp b / lib / SILGen / SILGenType . cpp <nl> class SILGenConformance : public SILGenWitnessTable < SILGenConformance > { <nl> if ( witnessSerialized & & <nl> fixmeWitnessHasLinkageThatNeedsToBePublic ( witnessLinkage ) ) { <nl> witnessLinkage = SILLinkage : : Public ; <nl> - witnessSerialized = IsNotSerialized ; <nl> + witnessSerialized = ( SGM . M . getOptions ( ) . SILSerializeWitnessTables <nl> + ? IsSerialized <nl> + : IsNotSerialized ) ; <nl> } else { <nl> / / This is the \" real \" rule ; the above case should go away once we <nl> / / figure out what ' s going on . <nl>\n", "msg": "Serialize witnesses if - sil - serialize - witness - tables is provided\n"}
{"diff_id": 13657, "repo": "apple/swift\n", "sha": "518cd21218cff71e2fd867737e4aaad3b52490f5\n", "time": "2013-12-22T05:40:15Z\n", "diff": "mmm a / lib / Sema / TypeCheckProtocol . cpp <nl> ppp b / lib / Sema / TypeCheckProtocol . cpp <nl> using namespace swift ; <nl> namespace { <nl> struct RequirementMatch ; <nl> <nl> + / / / Helper class whose objects invoke a function when destroyed . <nl> + / / / <nl> + / / / Use this via the SCOPE_GUARD macro . <nl> + template < typename F > <nl> + class ScopeGuard { <nl> + F & TheFunc ; <nl> + <nl> + public : <nl> + ScopeGuard ( F & func ) : TheFunc ( func ) { } <nl> + ~ ScopeGuard ( ) { TheFunc ( ) ; } <nl> + <nl> + ScopeGuard ( const ScopeGuard & ) = delete ; <nl> + ScopeGuard & operator = ( const ScopeGuard & ) = delete ; <nl> + } ; <nl> + <nl> + # define JOIN ( X , Y ) JOIN2 ( X , Y ) <nl> + # define JOIN2 ( X , Y ) X # # Y <nl> + <nl> + / / / Provides a block of code that will be executed when exiting the <nl> + / / / current scope , e . g . , to clean up resources not held by some other <nl> + / / / RAII object . <nl> + # define SCOPE_GUARD ( Code ) \\ <nl> + auto JOIN ( scope_guard_func_ , __LINE__ ) = [ & ] { Code ; } ; \\ <nl> + ScopeGuard < decltype ( JOIN ( scope_guard_func_ , __LINE__ ) ) > \\ <nl> + JOIN ( scope_guard_ , __LINE__ ) ( JOIN ( scope_guard_func_ , __LINE__ ) ) ; <nl> + <nl> / / / The result of attempting to resolve a witness . <nl> enum class ResolveWitnessResult { <nl> / / / The resolution succeeded . <nl> namespace { <nl> Type Adoptee ; <nl> DeclContext * DC ; <nl> SourceLoc Loc ; <nl> + <nl> + / / / Type witnesses that are currently being resolved . <nl> + llvm : : SmallPtrSet < AssociatedTypeDecl * , 4 > ResolvingTypeWitnesses ; <nl> + <nl> + / / / Witnesses that are currently being resolved . <nl> + llvm : : SmallPtrSet < ValueDecl * , 4 > ResolvingWitnesses ; <nl> <nl> / / / Whether we ' ve already complained about problems with this conformance . <nl> bool AlreadyComplained = false ; <nl> namespace { <nl> DC ( conformance - > getDeclContext ( ) ) , <nl> Loc ( conformance - > getLoc ( ) ) { } <nl> <nl> + / / / Resolve the type witness for the given associated type as <nl> + / / / directly as possible , only resolving other witnesses if <nl> + / / / needed , e . g . , to deduce this type witness . <nl> + / / / <nl> + / / / This entry point is designed to be used when the type witness <nl> + / / / for a particular associated type and adoptee is required , <nl> + / / / before the conformance has been completed checked . <nl> + void resolveSingleTypeWitness ( AssociatedTypeDecl * assocType ) ; <nl> + <nl> + / / / Resolve the witness for the given non - type requirement as <nl> + / / / directly as possible , only resolving other witnesses if <nl> + / / / needed , e . g . , to determine type witnesses used within the <nl> + / / / requirement . <nl> + / / / <nl> + / / / This entry point is designed to be used when the witness for a <nl> + / / / particular requirement and adoptee is required , before the <nl> + / / / conformance has been completed checked . <nl> + void resolveSingleWitness ( ValueDecl * requirement ) ; <nl> + <nl> / / / Check the entire protocol conformance , ensuring that all <nl> / / / witnesses are resolved and emitting any diagnostics . <nl> void checkConformance ( ) ; <nl> ResolveWitnessResult ConformanceChecker : : resolveTypeWitnessViaDerivation ( <nl> return ResolveWitnessResult : : Success ; <nl> } <nl> <nl> - # pragma mark Protocol conformance checking <nl> + void <nl> + ConformanceChecker : : resolveSingleTypeWitness ( AssociatedTypeDecl * assocType ) { <nl> + assert ( ! Conformance - > hasTypeWitness ( assocType ) & & \" Already resolved \" ) ; <nl> + <nl> + / / Note that we ' re resolving this witness . <nl> + assert ( ResolvingTypeWitnesses . count ( assocType ) = = 0 & & \" Currently resolving \" ) ; <nl> + ResolvingTypeWitnesses . insert ( assocType ) ; <nl> + SCOPE_GUARD ( ResolvingTypeWitnesses . erase ( assocType ) ) ; <nl> + <nl> + / / Try to resolve this type witness via name lookup , which is the <nl> + / / most direct mechanism . <nl> + switch ( resolveTypeWitnessViaLookup ( assocType ) ) { <nl> + case ResolveWitnessResult : : Success : <nl> + return ; <nl> + <nl> + case ResolveWitnessResult : : ExplicitFailed : <nl> + Conformance - > setState ( ProtocolConformanceState : : Invalid ) ; <nl> + return ; <nl> + <nl> + case ResolveWitnessResult : : Missing : <nl> + / / Keep trying . <nl> + break ; <nl> + } <nl> + <nl> + / / Look for requirements that refer to this associated type ; <nl> + / / determining their witnesses can deduce this associated type . <nl> + for ( auto member : Proto - > getMembers ( ) ) { <nl> + / / Ignore associated types . <nl> + if ( isa < AssociatedTypeDecl > ( member ) ) <nl> + continue ; <nl> + <nl> + auto requirement = dyn_cast < ValueDecl > ( member ) ; <nl> + if ( ! requirement ) <nl> + continue ; <nl> + <nl> + if ( ! requirement - > hasType ( ) ) <nl> + TC . validateDecl ( requirement , true ) ; <nl> + <nl> + / / If we have or are trying to resolve this witness , don ' t try again . <nl> + if ( ResolvingWitnesses . count ( requirement ) > 0 | | <nl> + Conformance - > hasWitness ( requirement ) ) <nl> + continue ; <nl> + <nl> + / / Determine whether this requirement refers to the associated <nl> + / / type we ' re resolving . <nl> + / / FIXME : Cache this dependency information somewhere ? <nl> + bool hasAssocType = requirement - > getInterfaceType ( ) . findIf ( [ & ] ( Type type ) { <nl> + if ( auto dependentMember = type - > getAs < DependentMemberType > ( ) ) { <nl> + return dependentMember - > getAssocType ( ) = = assocType ; <nl> + } <nl> + <nl> + return false ; <nl> + } ) ; <nl> + <nl> + / / If the requirement doesn ' t refer to the associated type we ' re <nl> + / / resolving , ignore it . <nl> + if ( ! hasAssocType ) <nl> + continue ; <nl> + <nl> + / / Try to resolve that witness . <nl> + resolveSingleWitness ( requirement ) ; <nl> + <nl> + / / If resolving the witness deduced our associated type , we ' re done . <nl> + if ( Conformance - > hasTypeWitness ( assocType ) ) <nl> + return ; <nl> + } <nl> + <nl> + / / Otherwise , try to resolve via a default . <nl> + switch ( resolveTypeWitnessViaDefault ( assocType ) ) { <nl> + case ResolveWitnessResult : : Success : <nl> + return ; <nl> + <nl> + case ResolveWitnessResult : : ExplicitFailed : <nl> + Conformance - > setState ( ProtocolConformanceState : : Invalid ) ; <nl> + return ; <nl> + <nl> + case ResolveWitnessResult : : Missing : <nl> + / / Keep trying . <nl> + break ; <nl> + } <nl> + <nl> + / / Otherwise , try to derive an answer . <nl> + switch ( resolveTypeWitnessViaDerivation ( assocType ) ) { <nl> + case ResolveWitnessResult : : Success : <nl> + return ; <nl> + <nl> + case ResolveWitnessResult : : ExplicitFailed : <nl> + Conformance - > setState ( ProtocolConformanceState : : Invalid ) ; <nl> + return ; <nl> + <nl> + case ResolveWitnessResult : : Missing : <nl> + / / Diagnose failure below . <nl> + break ; <nl> + } <nl> + <nl> + / / FIXME : Note this failure so we don ' t try again ? <nl> + <nl> + TC . diagnose ( Loc , diag : : type_does_not_conform , <nl> + Adoptee , Proto - > getDeclaredType ( ) ) ; <nl> + <nl> + TC . diagnose ( assocType , diag : : no_witnesses_type , <nl> + assocType - > getName ( ) ) ; <nl> + Conformance - > setState ( ProtocolConformanceState : : Invalid ) ; <nl> + } <nl> + <nl> + void ConformanceChecker : : resolveSingleWitness ( ValueDecl * requirement ) { <nl> + assert ( ! isa < AssociatedTypeDecl > ( requirement ) & & \" Not a value witness \" ) ; <nl> + assert ( ! Conformance - > hasWitness ( requirement ) & & \" Already resolved \" ) ; <nl> + <nl> + / / Note that we ' re resolving this witness . <nl> + assert ( ResolvingWitnesses . count ( requirement ) = = 0 & & \" Currently resolving \" ) ; <nl> + ResolvingWitnesses . insert ( requirement ) ; <nl> + SCOPE_GUARD ( ResolvingWitnesses . erase ( requirement ) ) ; <nl> + <nl> + / / Make sure we ' ve validated the requirement . <nl> + if ( ! requirement - > hasType ( ) ) <nl> + TC . validateDecl ( requirement , true ) ; <nl> + <nl> + if ( requirement - > isInvalid ( ) ) { <nl> + / / FIXME : Note that there is no witness ? <nl> + Conformance - > setState ( ProtocolConformanceState : : Invalid ) ; <nl> + return ; <nl> + } <nl> + <nl> + / / Try to resolve each of the associated types referenced within the <nl> + / / requirement ' s type to type witnesses via name lookup . Such <nl> + / / bindings can inform the choice of witness . <nl> + bool failed = requirement - > getInterfaceType ( ) . findIf ( [ & ] ( Type type ) - > bool { <nl> + if ( auto dependentMember = type - > getAs < DependentMemberType > ( ) ) { <nl> + auto assocType = dependentMember - > getAssocType ( ) ; <nl> + if ( cast < ProtocolDecl > ( assocType - > getDeclContext ( ) ) = = Proto ) { <nl> + / / If we don ' t already have a type witness and aren ' t in the <nl> + / / process of trying to resolve it already . . . <nl> + if ( ! Conformance - > hasTypeWitness ( assocType ) & & <nl> + ResolvingTypeWitnesses . count ( assocType ) = = 0 ) { <nl> + switch ( resolveTypeWitnessViaLookup ( assocType ) ) { <nl> + case ResolveWitnessResult : : Success : <nl> + break ; <nl> + <nl> + case ResolveWitnessResult : : ExplicitFailed : <nl> + return true ; <nl> + <nl> + case ResolveWitnessResult : : Missing : <nl> + / / Okay : this associated type can be deduced . <nl> + break ; <nl> + } <nl> + } <nl> + <nl> + / / If the type witness is an error , just fail quietly . <nl> + if ( Conformance - > hasTypeWitness ( assocType ) & & <nl> + Conformance - > getTypeWitness ( assocType , nullptr ) . Replacement <nl> + - > is < ErrorType > ( ) ) <nl> + return true ; <nl> + } <nl> + } <nl> + return false ; <nl> + } ) ; <nl> + <nl> + / / If one of the associated types had an outright error , don ' t bother <nl> + / / trying to check this witness : we won ' t be able to meaningfully <nl> + / / compare the types anyway . <nl> + if ( failed ) { <nl> + Conformance - > setState ( ProtocolConformanceState : : Invalid ) ; <nl> + return ; <nl> + } <nl> + <nl> + / / Try to resolve the witness via explicit definitions . <nl> + switch ( resolveWitnessViaLookup ( requirement ) ) { <nl> + case ResolveWitnessResult : : Success : <nl> + return ; <nl> + <nl> + case ResolveWitnessResult : : ExplicitFailed : <nl> + Conformance - > setState ( ProtocolConformanceState : : Invalid ) ; <nl> + return ; <nl> + <nl> + case ResolveWitnessResult : : Missing : <nl> + / / Continue trying below . <nl> + break ; <nl> + } <nl> + <nl> + / / Try to resolve the witness via derivation . <nl> + switch ( resolveWitnessViaDerivation ( requirement ) ) { <nl> + case ResolveWitnessResult : : Success : <nl> + return ; <nl> + <nl> + case ResolveWitnessResult : : ExplicitFailed : <nl> + Conformance - > setState ( ProtocolConformanceState : : Invalid ) ; <nl> + return ; <nl> + <nl> + case ResolveWitnessResult : : Missing : <nl> + / / Continue trying below . <nl> + break ; <nl> + } <nl> + <nl> + / / Try to resolve the witness via defaults . <nl> + switch ( resolveWitnessViaDefault ( requirement ) ) { <nl> + case ResolveWitnessResult : : Success : <nl> + return ; <nl> + <nl> + case ResolveWitnessResult : : ExplicitFailed : <nl> + Conformance - > setState ( ProtocolConformanceState : : Invalid ) ; <nl> + return ; <nl> + <nl> + case ResolveWitnessResult : : Missing : <nl> + llvm_unreachable ( \" Should have failed \" ) ; <nl> + break ; <nl> + } <nl> + } <nl> + <nl> + # pragma mark Protocol conformance checking <nl> void ConformanceChecker : : checkConformance ( ) { <nl> assert ( ! Conformance - > isComplete ( ) & & \" Conformance is already complete \" ) ; <nl> <nl> void ConformanceChecker : : checkConformance ( ) { <nl> / / FIXME : Caller checks that this the type conforms to all of the <nl> / / inherited protocols . <nl> <nl> + if ( / * FIXME : resolve via temporary slower path * / false ) { <nl> + llvm : : SmallVector < Decl * , 4 > members ; <nl> + members . append ( Proto - > getMembers ( ) . rbegin ( ) , Proto - > getMembers ( ) . rend ( ) ) ; <nl> + for ( auto member : members ) { <nl> + if ( auto assocType = dyn_cast < AssociatedTypeDecl > ( member ) ) { <nl> + if ( ! Conformance - > hasTypeWitness ( assocType ) ) <nl> + resolveSingleTypeWitness ( assocType ) ; <nl> + } else if ( auto requirement = dyn_cast < ValueDecl > ( member ) ) <nl> + if ( ! Conformance - > hasWitness ( requirement ) ) <nl> + resolveSingleWitness ( requirement ) ; <nl> + } <nl> + <nl> + / / We ' ve checked everything . If we haven ' t managed to fail , then <nl> + / / this conformance is complete . <nl> + if ( ! Conformance - > isInvalid ( ) ) <nl> + Conformance - > setState ( ProtocolConformanceState : : Complete ) ; <nl> + return ; <nl> + } <nl> + <nl> / / Resolve any associated type members via lookup . <nl> for ( auto member : Proto - > getMembers ( ) ) { <nl> auto assocType = dyn_cast < AssociatedTypeDecl > ( member ) ; <nl>\n", "msg": "Introduce entry points to resolve a single witness within a conformance .\n"}
{"diff_id": 13887, "repo": "apple/swift\n", "sha": "627534144dd85424c88e69c8b0f537cd02aa7c4c\n", "time": "2014-04-04T21:51:58Z\n", "diff": "mmm a / lib / SILPasses / AllocBoxToStack . cpp <nl> ppp b / lib / SILPasses / AllocBoxToStack . cpp <nl> static size_t getParameterIndexForOperand ( Operand * O ) { <nl> <nl> / / / Given an operand of a direct apply or partial_apply of a <nl> / / / non - generic function , return the parameter used in the body of the <nl> - / / / function to represent this operand . <nl> - static SILValue getParameterForOperand ( Operand * O ) { <nl> - auto * FRI = getDirectCallee ( O - > getUser ( ) ) ; <nl> - if ( ! FRI ) <nl> - return SILValue ( ) ; <nl> - <nl> - auto * F = FRI - > getReferencedFunction ( ) ; <nl> - assert ( F & & \" Expected a referenced function ! \" ) ; <nl> - <nl> - / / TODO : Support generics at some point . <nl> - if ( callIsPolymorphic ( O - > getUser ( ) ) ) <nl> - return SILValue ( ) ; <nl> + / / / function to represent this operand . For non - direct calls and for <nl> + / / / functions that we cannot examine the body of , return an empty <nl> + / / / SILValue . <nl> + static SILValue getParameterForOperand ( SILFunction * F , Operand * O ) { <nl> + assert ( F & & ! F - > empty ( ) & & \" Expected a function with a body ! \" ) ; <nl> <nl> auto & Entry = F - > front ( ) ; <nl> size_t ParamIndex = getParameterIndexForOperand ( O ) ; <nl> static SILValue getParameterForOperand ( Operand * O ) { <nl> return SILValue ( Param ) ; <nl> } <nl> <nl> + / / / Return a pointer to the SILFunction called by Call if we can <nl> + / / / determine which funciton that is , and we have a body for that <nl> + / / / function . Otherwise return nullptr . <nl> + static SILFunction * getFunctionBody ( SILInstruction * Call ) { <nl> + / / TODO : Support generics at some point . <nl> + if ( callIsPolymorphic ( Call ) ) <nl> + return nullptr ; <nl> + <nl> + if ( auto * FRI = getDirectCallee ( Call ) ) <nl> + if ( auto * F = FRI - > getReferencedFunction ( ) ) <nl> + if ( ! F - > empty ( ) ) <nl> + return F ; <nl> + <nl> + return nullptr ; <nl> + } <nl> <nl> / / / Could this operand to an apply escape that function by being <nl> / / / stored or returned ? <nl> static bool operandEscapesApply ( Operand * O ) { <nl> + SILFunction * F = getFunctionBody ( O - > getUser ( ) ) ; <nl> + / / If we cannot examine the function body , assume the worst . <nl> + if ( ! F ) <nl> + return true ; <nl> + <nl> / / Check the uses of the operand , but do not recurse down into other <nl> / / apply instructions . <nl> - if ( auto Param = getParameterForOperand ( O ) ) <nl> - return canValueEscape ( Param , / * examineApply = * / false ) ; <nl> - <nl> - return true ; <nl> + auto Param = getParameterForOperand ( F , O ) ; <nl> + return canValueEscape ( Param , / * examineApply = * / false ) ; <nl> } <nl> <nl> / / / checkPartialApplyBody - Check the body of a partial apply to see <nl> static bool operandEscapesApply ( Operand * O ) { <nl> / / / disqualify it from being protmoted to a stack location . Return <nl> / / / true if this partial apply will not block our promoting the box . <nl> static bool checkPartialApplyBody ( Operand * O ) { <nl> + SILFunction * F = getFunctionBody ( O - > getUser ( ) ) ; <nl> + / / If we cannot examine the function body , assume the worst . <nl> + if ( ! F ) <nl> + return false ; <nl> + <nl> / / We don ' t actually use these because we ' re not recursively <nl> / / rewriting the partial applies we find . <nl> llvm : : SmallVector < Operand * , 1 > ElidedOperands ; <nl> - if ( auto Param = getParameterForOperand ( O ) ) <nl> - return ! findUnexpectedBoxUse ( Param , / * examinePartialApply = * / false , <nl> - / * inAppliedFunction = * / true , <nl> - ElidedOperands ) ; <nl> - <nl> - return false ; <nl> + auto Param = getParameterForOperand ( F , O ) ; <nl> + return ! findUnexpectedBoxUse ( Param , / * examinePartialApply = * / false , <nl> + / * inAppliedFunction = * / true , <nl> + ElidedOperands ) ; <nl> } <nl> <nl> <nl>\n", "msg": "Small clean - up in box - to - stack prmomotion .\n"}
{"diff_id": 13940, "repo": "apple/swift\n", "sha": "a7653da192db5921ac7c2853a10534ba4bf34e99\n", "time": "2020-01-14T16:39:22Z\n", "diff": "mmm a / lib / ParseSIL / ParseSIL . cpp <nl> ppp b / lib / ParseSIL / ParseSIL . cpp <nl> namespace { <nl> bool parseScopeRef ( SILDebugScope * & DS ) ; <nl> bool parseSILDebugLocation ( SILLocation & L , SILBuilder & B , <nl> bool parsedComma = false ) ; <nl> + bool parseSpecificSILInstruction ( SILBuilder & B , SILInstructionKind Opcode , <nl> + SourceLoc OpcodeLoc , StringRef OpcodeName , <nl> + SILInstruction * & ResultVal ) ; <nl> + <nl> bool parseSILInstruction ( SILBuilder & B ) ; <nl> bool parseCallInstruction ( SILLocation InstLoc , <nl> SILInstructionKind Opcode , SILBuilder & B , <nl> SILParser : : parseKeyPathPatternComponent ( KeyPathPatternComponent & component , <nl> } <nl> } <nl> <nl> - / / / sil - instruction - result : : = sil - value - name ' = ' <nl> - / / / sil - instruction - result : : = ' ( ' sil - value - name ? ' ) ' <nl> - / / / sil - instruction - result : : = ' ( ' sil - value - name ( ' , ' sil - value - name ) * ' ) ' <nl> - / / / sil - instruction - source - info : : = ( ' , ' sil - scope - ref ) ? ( ' , ' sil - loc ) ? <nl> - / / / sil - instruction - def : : = <nl> - / / / ( sil - instruction - result ' = ' ) ? sil - instruction sil - instruction - source - info <nl> - bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> - / / We require SIL instructions to be at the start of a line to assist <nl> - / / recovery . <nl> - if ( ! P . Tok . isAtStartOfLine ( ) ) { <nl> - P . diagnose ( P . Tok , diag : : expected_sil_instr_start_of_line ) ; <nl> - return true ; <nl> - } <nl> - <nl> - SmallVector < Located < StringRef > , 4 > resultNames ; <nl> - SourceLoc resultClauseBegin ; <nl> - <nl> - / / If the instruction has a name ' % foo = ' , parse it . <nl> - if ( P . Tok . is ( tok : : sil_local_name ) ) { <nl> - resultClauseBegin = P . Tok . getLoc ( ) ; <nl> - resultNames . push_back ( { P . Tok . getText ( ) , P . Tok . getLoc ( ) } ) ; <nl> - P . consumeToken ( tok : : sil_local_name ) ; <nl> - <nl> - / / If the instruction has a ' ( % foo , % bar ) = ' , parse it . <nl> - } else if ( P . consumeIf ( tok : : l_paren ) ) { <nl> - resultClauseBegin = P . PreviousLoc ; <nl> - <nl> - if ( ! P . consumeIf ( tok : : r_paren ) ) { <nl> - while ( true ) { <nl> - if ( ! P . Tok . is ( tok : : sil_local_name ) ) { <nl> - P . diagnose ( P . Tok , diag : : expected_sil_value_name ) ; <nl> - return true ; <nl> - } <nl> - <nl> - resultNames . push_back ( { P . Tok . getText ( ) , P . Tok . getLoc ( ) } ) ; <nl> - P . consumeToken ( tok : : sil_local_name ) ; <nl> - <nl> - if ( P . consumeIf ( tok : : comma ) ) <nl> - continue ; <nl> - if ( P . consumeIf ( tok : : r_paren ) ) <nl> - break ; <nl> - <nl> - P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" , \" ) ; <nl> - return true ; <nl> - } <nl> - } <nl> - } <nl> - <nl> - if ( resultClauseBegin . isValid ( ) ) { <nl> - if ( P . parseToken ( tok : : equal , diag : : expected_equal_in_sil_instr ) ) <nl> - return true ; <nl> - } <nl> - <nl> - SILInstructionKind Opcode ; <nl> - SourceLoc OpcodeLoc ; <nl> - StringRef OpcodeName ; <nl> - <nl> - / / Parse the opcode name . <nl> - if ( parseSILOpcode ( Opcode , OpcodeLoc , OpcodeName ) ) <nl> - return true ; <nl> - <nl> + bool SILParser : : parseSpecificSILInstruction ( SILBuilder & B , <nl> + SILInstructionKind Opcode , <nl> + SourceLoc OpcodeLoc , <nl> + StringRef OpcodeName , <nl> + SILInstruction * & ResultVal ) { <nl> SmallVector < SILValue , 4 > OpList ; <nl> SILValue Val ; <nl> SILType Ty ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> CanType SourceType , TargetType ; <nl> SILValue SourceAddr , DestAddr ; <nl> auto parseSourceAndDestAddress = [ & ] { <nl> - return parseFormalTypeAndValue ( SourceType , SourceAddr ) <nl> - | | parseVerbatim ( \" to \" ) <nl> - | | parseFormalTypeAndValue ( TargetType , DestAddr ) ; <nl> + return parseFormalTypeAndValue ( SourceType , SourceAddr ) | | <nl> + parseVerbatim ( \" to \" ) | | parseFormalTypeAndValue ( TargetType , DestAddr ) ; <nl> } ; <nl> <nl> Identifier SuccessBBName , FailureBBName ; <nl> SourceLoc SuccessBBLoc , FailureBBLoc ; <nl> auto parseConditionalBranchDestinations = [ & ] { <nl> - return P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) <nl> - | | parseSILIdentifier ( SuccessBBName , SuccessBBLoc , <nl> - diag : : expected_sil_block_name ) <nl> - | | P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) <nl> - | | parseSILIdentifier ( FailureBBName , FailureBBLoc , <nl> - diag : : expected_sil_block_name ) <nl> - | | parseSILDebugLocation ( InstLoc , B ) ; <nl> + return P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILIdentifier ( SuccessBBName , SuccessBBLoc , <nl> + diag : : expected_sil_block_name ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILIdentifier ( FailureBBName , FailureBBLoc , <nl> + diag : : expected_sil_block_name ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ; <nl> } ; <nl> <nl> / / Validate the opcode name , and do opcode - specific parsing logic based on the <nl> / / opcode we find . <nl> - SILInstruction * ResultVal ; <nl> + <nl> switch ( Opcode ) { <nl> case SILInstructionKind : : AllocBoxInst : { <nl> bool hasDynamicLifetime = false ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> return true ; <nl> <nl> SILType Ty ; <nl> - if ( parseSILType ( Ty ) ) return true ; <nl> + if ( parseSILType ( Ty ) ) <nl> + return true ; <nl> SILDebugVariable VarInfo ; <nl> if ( parseSILDebugVar ( VarInfo ) ) <nl> return true ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> case SILInstructionKind : : AbortApplyInst : <nl> case SILInstructionKind : : EndApplyInst : { <nl> UnresolvedValueName argName ; <nl> - if ( parseValueName ( argName ) ) return true ; <nl> + if ( parseValueName ( argName ) ) <nl> + return true ; <nl> <nl> if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> if ( parseSILType ( Ty ) | | <nl> P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) ) <nl> return true ; <nl> - <nl> + <nl> bool Negative = false ; <nl> if ( P . Tok . isAnyOperator ( ) & & P . Tok . getText ( ) = = \" - \" ) { <nl> Negative = true ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" integer \" ) ; <nl> return true ; <nl> } <nl> - <nl> + <nl> auto intTy = Ty . getAs < AnyBuiltinIntegerType > ( ) ; <nl> if ( ! intTy ) { <nl> P . diagnose ( P . Tok , diag : : sil_integer_literal_not_integer_type ) ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> if ( parseSILType ( Ty ) | | <nl> P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) ) <nl> return true ; <nl> - <nl> + <nl> / / The value is expressed as bits . <nl> if ( P . Tok . getKind ( ) ! = tok : : integer_literal ) { <nl> P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" integer \" ) ; <nl> return true ; <nl> } <nl> - <nl> + <nl> auto floatTy = Ty . getAs < BuiltinFloatType > ( ) ; <nl> if ( ! floatTy ) { <nl> P . diagnose ( P . Tok , diag : : sil_float_literal_not_float_type ) ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> } <nl> <nl> StringRef text = prepareIntegerLiteralForParsing ( P . Tok . getText ( ) ) ; <nl> - <nl> + <nl> APInt bits ( floatTy - > getBitWidth ( ) , 0 ) ; <nl> bool error = text . getAsInteger ( 0 , bits ) ; <nl> assert ( ! error & & \" float_literal token did not parse as APInt ? ! \" ) ; <nl> ( void ) error ; <nl> - <nl> + <nl> if ( bits . getBitWidth ( ) ! = floatTy - > getBitWidth ( ) ) <nl> bits = bits . zextOrTrunc ( floatTy - > getBitWidth ( ) ) ; <nl> - <nl> + <nl> APFloat value ( floatTy - > getAPFloatSemantics ( ) , bits ) ; <nl> if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> break ; <nl> } <nl> <nl> - StringRef string = P . L - > getEncodedStringSegment ( segments . front ( ) , <nl> - stringBuffer ) ; <nl> + StringRef string = <nl> + P . L - > getEncodedStringSegment ( segments . front ( ) , stringBuffer ) ; <nl> ResultVal = B . createStringLiteral ( InstLoc , string , encoding ) ; <nl> break ; <nl> } <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> <nl> case SILInstructionKind : : AllocValueBufferInst : { <nl> SILType Ty ; <nl> - if ( parseSILType ( Ty ) | | <nl> - parseVerbatim ( \" in \" ) | | <nl> - parseTypedValueRef ( Val , B ) | | <nl> + if ( parseSILType ( Ty ) | | parseVerbatim ( \" in \" ) | | parseTypedValueRef ( Val , B ) | | <nl> parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> ResultVal = B . createAllocValueBuffer ( InstLoc , Ty , Val ) ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> } <nl> case SILInstructionKind : : ProjectValueBufferInst : { <nl> SILType Ty ; <nl> - if ( parseSILType ( Ty ) | | <nl> - parseVerbatim ( \" in \" ) | | <nl> - parseTypedValueRef ( Val , B ) | | <nl> + if ( parseSILType ( Ty ) | | parseVerbatim ( \" in \" ) | | parseTypedValueRef ( Val , B ) | | <nl> parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> ResultVal = B . createProjectValueBuffer ( InstLoc , Ty , Val ) ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> } <nl> case SILInstructionKind : : DeallocValueBufferInst : { <nl> SILType Ty ; <nl> - if ( parseSILType ( Ty ) | | <nl> - parseVerbatim ( \" in \" ) | | <nl> - parseTypedValueRef ( Val , B ) | | <nl> + if ( parseSILType ( Ty ) | | parseVerbatim ( \" in \" ) | | parseTypedValueRef ( Val , B ) | | <nl> parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> ResultVal = B . createDeallocValueBuffer ( InstLoc , Ty , Val ) ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> if ( parseTypedValueRef ( Val , B ) | | <nl> P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) ) <nl> return true ; <nl> - <nl> + <nl> if ( ! P . Tok . is ( tok : : integer_literal ) ) { <nl> P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" integer \" ) ; <nl> return true ; <nl> } <nl> - <nl> + <nl> unsigned Index ; <nl> bool error = parseIntegerLiteral ( P . Tok . getText ( ) , 0 , Index ) ; <nl> assert ( ! error & & \" project_box index did not parse as integer ? ! \" ) ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> P . consumeToken ( tok : : integer_literal ) ; <nl> if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> - <nl> + <nl> ResultVal = B . createProjectBox ( InstLoc , Val , Index ) ; <nl> break ; <nl> } <nl> - <nl> + <nl> case SILInstructionKind : : ProjectExistentialBoxInst : { <nl> SILType Ty ; <nl> - if ( parseSILType ( Ty ) | | <nl> - parseVerbatim ( \" in \" ) | | <nl> - parseTypedValueRef ( Val , B ) | | <nl> + if ( parseSILType ( Ty ) | | parseVerbatim ( \" in \" ) | | parseTypedValueRef ( Val , B ) | | <nl> parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> ResultVal = B . createProjectExistentialBox ( InstLoc , Ty , Val ) ; <nl> break ; <nl> } <nl> - <nl> + <nl> case SILInstructionKind : : FunctionRefInst : { <nl> SILFunction * Fn ; <nl> - if ( parseSILFunctionRef ( InstLoc , Fn ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseSILFunctionRef ( InstLoc , Fn ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> ResultVal = B . createFunctionRef ( InstLoc , Fn ) ; <nl> break ; <nl> } <nl> case SILInstructionKind : : DynamicFunctionRefInst : { <nl> SILFunction * Fn ; <nl> - if ( parseSILFunctionRef ( InstLoc , Fn ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseSILFunctionRef ( InstLoc , Fn ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> / / Set a forward reference ' s dynamic property for the first time . <nl> if ( ! Fn - > isDynamicallyReplaceable ( ) ) { <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> } <nl> case SILInstructionKind : : PreviousDynamicFunctionRefInst : { <nl> SILFunction * Fn ; <nl> - if ( parseSILFunctionRef ( InstLoc , Fn ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseSILFunctionRef ( InstLoc , Fn ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> ResultVal = B . createPreviousDynamicFunctionRef ( InstLoc , Fn ) ; <nl> break ; <nl> } <nl> case SILInstructionKind : : BuiltinInst : { <nl> if ( P . Tok . getKind ( ) ! = tok : : string_literal ) { <nl> - P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" builtin name \" ) ; <nl> + P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" builtin name \" ) ; <nl> return true ; <nl> } <nl> StringRef Str = P . Tok . getText ( ) ; <nl> - Identifier Id = P . Context . getIdentifier ( Str . substr ( 1 , Str . size ( ) - 2 ) ) ; <nl> + Identifier Id = P . Context . getIdentifier ( Str . substr ( 1 , Str . size ( ) - 2 ) ) ; <nl> P . consumeToken ( tok : : string_literal ) ; <nl> - <nl> + <nl> / / Find the builtin in the Builtin module <nl> - SmallVector < ValueDecl * , 2 > foundBuiltins ; <nl> - P . Context . TheBuiltinModule - > lookupMember ( foundBuiltins , <nl> - P . Context . TheBuiltinModule , Id , <nl> - Identifier ( ) ) ; <nl> + SmallVector < ValueDecl * , 2 > foundBuiltins ; <nl> + P . Context . TheBuiltinModule - > lookupMember ( <nl> + foundBuiltins , P . Context . TheBuiltinModule , Id , Identifier ( ) ) ; <nl> if ( foundBuiltins . empty ( ) ) { <nl> - P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" builtin name \" ) ; <nl> + P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" builtin name \" ) ; <nl> return true ; <nl> } <nl> assert ( foundBuiltins . size ( ) = = 1 & & \" ambiguous builtin name ? ! \" ) ; <nl> <nl> auto * builtinFunc = cast < FuncDecl > ( foundBuiltins [ 0 ] ) ; <nl> GenericEnvironment * genericEnv = builtinFunc - > getGenericEnvironment ( ) ; <nl> - <nl> + <nl> SmallVector < ParsedSubstitution , 4 > parsedSubs ; <nl> SubstitutionMap subMap ; <nl> if ( parseSubstitutions ( parsedSubs ) ) <nl> return true ; <nl> - <nl> + <nl> if ( ! parsedSubs . empty ( ) ) { <nl> if ( ! genericEnv ) { <nl> P . diagnose ( P . Tok , diag : : sil_substitutions_on_non_polymorphic_type ) ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> if ( ! subMap ) <nl> return true ; <nl> } <nl> - <nl> + <nl> if ( P . Tok . getKind ( ) ! = tok : : l_paren ) { <nl> P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" ( \" ) ; <nl> return true ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" ) ' or ' , \" ) ; <nl> return true ; <nl> } <nl> - <nl> + <nl> if ( P . Tok . getKind ( ) ! = tok : : colon ) { <nl> P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" : \" ) ; <nl> return true ; <nl> } <nl> P . consumeToken ( tok : : colon ) ; <nl> - <nl> + <nl> SILType ResultTy ; <nl> if ( parseSILType ( ResultTy ) ) <nl> return true ; <nl> - <nl> + <nl> if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> ResultVal = B . createBuiltin ( InstLoc , Id , ResultTy , subMap , Args ) ; <nl> break ; <nl> } <nl> case SILInstructionKind : : OpenExistentialAddrInst : <nl> - if ( parseOpenExistAddrKind ( ) | | parseTypedValueRef ( Val , B ) <nl> - | | parseVerbatim ( \" to \" ) | | parseSILType ( Ty ) <nl> - | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseOpenExistAddrKind ( ) | | parseTypedValueRef ( Val , B ) | | <nl> + parseVerbatim ( \" to \" ) | | parseSILType ( Ty ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> <nl> ResultVal = B . createOpenExistentialAddr ( InstLoc , Val , Ty , AccessKind ) ; <nl> break ; <nl> <nl> case SILInstructionKind : : OpenExistentialBoxInst : <nl> - if ( parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" to \" ) | | parseSILType ( Ty ) <nl> - | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" to \" ) | | parseSILType ( Ty ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> <nl> ResultVal = B . createOpenExistentialBox ( InstLoc , Val , Ty ) ; <nl> break ; <nl> <nl> case SILInstructionKind : : OpenExistentialBoxValueInst : <nl> - if ( parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" to \" ) | | parseSILType ( Ty ) <nl> - | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" to \" ) | | parseSILType ( Ty ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> ResultVal = B . createOpenExistentialBoxValue ( InstLoc , Val , Ty ) ; <nl> break ; <nl> <nl> case SILInstructionKind : : OpenExistentialMetatypeInst : <nl> - if ( parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" to \" ) | | parseSILType ( Ty ) <nl> - | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" to \" ) | | parseSILType ( Ty ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> ResultVal = B . createOpenExistentialMetatype ( InstLoc , Val , Ty ) ; <nl> break ; <nl> <nl> case SILInstructionKind : : OpenExistentialRefInst : <nl> - if ( parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" to \" ) | | parseSILType ( Ty ) <nl> - | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" to \" ) | | parseSILType ( Ty ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> ResultVal = B . createOpenExistentialRef ( InstLoc , Val , Ty ) ; <nl> break ; <nl> <nl> case SILInstructionKind : : OpenExistentialValueInst : <nl> - if ( parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" to \" ) | | parseSILType ( Ty ) <nl> - | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" to \" ) | | parseSILType ( Ty ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> ResultVal = B . createOpenExistentialValue ( InstLoc , Val , Ty ) ; <nl> break ; <nl> <nl> - # define UNARY_INSTRUCTION ( ID ) \\ <nl> - case SILInstructionKind : : ID # # Inst : \\ <nl> - if ( parseTypedValueRef ( Val , B ) ) return true ; \\ <nl> - if ( parseSILDebugLocation ( InstLoc , B ) ) return true ; \\ <nl> - ResultVal = B . create # # ID ( InstLoc , Val ) ; \\ <nl> + # define UNARY_INSTRUCTION ( ID ) \\ <nl> + case SILInstructionKind : : ID # # Inst : \\ <nl> + if ( parseTypedValueRef ( Val , B ) ) \\ <nl> + return true ; \\ <nl> + if ( parseSILDebugLocation ( InstLoc , B ) ) \\ <nl> + return true ; \\ <nl> + ResultVal = B . create # # ID ( InstLoc , Val ) ; \\ <nl> break ; <nl> <nl> # define REFCOUNTING_INSTRUCTION ( ID ) \\ <nl> - case SILInstructionKind : : ID # # Inst : { \\ <nl> + case SILInstructionKind : : ID # # Inst : { \\ <nl> Atomicity atomicity = Atomicity : : Atomic ; \\ <nl> StringRef Optional ; \\ <nl> if ( parseSILOptional ( Optional , * this ) ) { \\ <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> bool IsObjcVerifcationType = false ; <nl> if ( parseSILOptional ( IsObjcVerifcationType , * this , \" objc \" ) ) <nl> return true ; <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseTypedValueRef ( Val , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> ResultVal = B . createIsEscapingClosure ( <nl> InstLoc , Val , <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> break ; <nl> } <nl> <nl> - case SILInstructionKind : : DebugValueInst : <nl> - case SILInstructionKind : : DebugValueAddrInst : { <nl> - SILDebugVariable VarInfo ; <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - parseSILDebugVar ( VarInfo ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - if ( Opcode = = SILInstructionKind : : DebugValueInst ) <nl> - ResultVal = B . createDebugValue ( InstLoc , Val , VarInfo ) ; <nl> - else <nl> - ResultVal = B . createDebugValueAddr ( InstLoc , Val , VarInfo ) ; <nl> - break ; <nl> - } <nl> - <nl> - / / unchecked_ownership_conversion < reg > : < type > , < ownership > to < ownership > <nl> - case SILInstructionKind : : UncheckedOwnershipConversionInst : { <nl> - ValueOwnershipKind LHSKind = ValueOwnershipKind : : None ; <nl> - ValueOwnershipKind RHSKind = ValueOwnershipKind : : None ; <nl> - SourceLoc Loc ; <nl> - <nl> - if ( parseTypedValueRef ( Val , Loc , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_sil_colon , <nl> - \" unchecked_ownership_conversion value ownership kind \" <nl> - \" conversion specification \" ) | | <nl> - parseSILOwnership ( LHSKind ) | | parseVerbatim ( \" to \" ) | | <nl> - parseSILOwnership ( RHSKind ) | | parseSILDebugLocation ( InstLoc , B ) ) { <nl> - return true ; <nl> - } <nl> - <nl> - if ( Val . getOwnershipKind ( ) ! = LHSKind ) { <nl> - return true ; <nl> - } <nl> - <nl> - ResultVal = B . createUncheckedOwnershipConversion ( InstLoc , Val , RHSKind ) ; <nl> - break ; <nl> - } <nl> - <nl> - case SILInstructionKind : : LoadInst : { <nl> - LoadOwnershipQualifier Qualifier ; <nl> - SourceLoc AddrLoc ; <nl> - <nl> - if ( parseLoadOwnershipQualifier ( Qualifier , * this ) | | <nl> - parseTypedValueRef ( Val , AddrLoc , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - <nl> - ResultVal = B . createLoad ( InstLoc , Val , Qualifier ) ; <nl> - break ; <nl> - } <nl> - <nl> - case SILInstructionKind : : LoadBorrowInst : { <nl> - SourceLoc AddrLoc ; <nl> - <nl> - if ( parseTypedValueRef ( Val , AddrLoc , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - <nl> - ResultVal = B . createLoadBorrow ( InstLoc , Val ) ; <nl> - break ; <nl> - } <nl> - <nl> - case SILInstructionKind : : BeginBorrowInst : { <nl> - SourceLoc AddrLoc ; <nl> - <nl> - if ( parseTypedValueRef ( Val , AddrLoc , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - <nl> - ResultVal = B . createBeginBorrow ( InstLoc , Val ) ; <nl> - break ; <nl> - } <nl> - <nl> - # define NEVER_OR_SOMETIMES_LOADABLE_CHECKED_REF_STORAGE ( Name , . . . ) \\ <nl> - case SILInstructionKind : : Load # # Name # # Inst : { \\ <nl> - bool isTake = false ; \\ <nl> - SourceLoc addrLoc ; \\ <nl> - if ( parseSILOptional ( isTake , * this , \" take \" ) | | \\ <nl> - parseTypedValueRef ( Val , addrLoc , B ) | | \\ <nl> - parseSILDebugLocation ( InstLoc , B ) ) \\ <nl> - return true ; \\ <nl> - if ( ! Val - > getType ( ) . is < Name # # StorageType > ( ) ) { \\ <nl> - P . diagnose ( addrLoc , diag : : sil_operand_not_ref_storage_address , \\ <nl> - \" source \" , OpcodeName , ReferenceOwnership : : Name ) ; \\ <nl> - } \\ <nl> - ResultVal = B . createLoad # # Name ( InstLoc , Val , IsTake_t ( isTake ) ) ; \\ <nl> - break ; \\ <nl> + case SILInstructionKind : : DebugValueInst : <nl> + case SILInstructionKind : : DebugValueAddrInst : { <nl> + SILDebugVariable VarInfo ; <nl> + if ( parseTypedValueRef ( Val , B ) | | parseSILDebugVar ( VarInfo ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + if ( Opcode = = SILInstructionKind : : DebugValueInst ) <nl> + ResultVal = B . createDebugValue ( InstLoc , Val , VarInfo ) ; <nl> + else <nl> + ResultVal = B . createDebugValueAddr ( InstLoc , Val , VarInfo ) ; <nl> + break ; <nl> + } <nl> + <nl> + / / unchecked_ownership_conversion < reg > : < type > , < ownership > to < ownership > <nl> + case SILInstructionKind : : UncheckedOwnershipConversionInst : { <nl> + ValueOwnershipKind LHSKind = ValueOwnershipKind : : None ; <nl> + ValueOwnershipKind RHSKind = ValueOwnershipKind : : None ; <nl> + SourceLoc Loc ; <nl> + <nl> + if ( parseTypedValueRef ( Val , Loc , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_sil_colon , <nl> + \" unchecked_ownership_conversion value ownership kind \" <nl> + \" conversion specification \" ) | | <nl> + parseSILOwnership ( LHSKind ) | | parseVerbatim ( \" to \" ) | | <nl> + parseSILOwnership ( RHSKind ) | | parseSILDebugLocation ( InstLoc , B ) ) { <nl> + return true ; <nl> + } <nl> + <nl> + if ( Val . getOwnershipKind ( ) ! = LHSKind ) { <nl> + return true ; <nl> + } <nl> + <nl> + ResultVal = B . createUncheckedOwnershipConversion ( InstLoc , Val , RHSKind ) ; <nl> + break ; <nl> + } <nl> + <nl> + case SILInstructionKind : : LoadInst : { <nl> + LoadOwnershipQualifier Qualifier ; <nl> + SourceLoc AddrLoc ; <nl> + <nl> + if ( parseLoadOwnershipQualifier ( Qualifier , * this ) | | <nl> + parseTypedValueRef ( Val , AddrLoc , B ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + <nl> + ResultVal = B . createLoad ( InstLoc , Val , Qualifier ) ; <nl> + break ; <nl> + } <nl> + <nl> + case SILInstructionKind : : LoadBorrowInst : { <nl> + SourceLoc AddrLoc ; <nl> + <nl> + if ( parseTypedValueRef ( Val , AddrLoc , B ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + <nl> + ResultVal = B . createLoadBorrow ( InstLoc , Val ) ; <nl> + break ; <nl> + } <nl> + <nl> + case SILInstructionKind : : BeginBorrowInst : { <nl> + SourceLoc AddrLoc ; <nl> + <nl> + if ( parseTypedValueRef ( Val , AddrLoc , B ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + <nl> + ResultVal = B . createBeginBorrow ( InstLoc , Val ) ; <nl> + break ; <nl> + } <nl> + <nl> + # define NEVER_OR_SOMETIMES_LOADABLE_CHECKED_REF_STORAGE ( Name , . . . ) \\ <nl> + case SILInstructionKind : : Load # # Name # # Inst : { \\ <nl> + bool isTake = false ; \\ <nl> + SourceLoc addrLoc ; \\ <nl> + if ( parseSILOptional ( isTake , * this , \" take \" ) | | \\ <nl> + parseTypedValueRef ( Val , addrLoc , B ) | | \\ <nl> + parseSILDebugLocation ( InstLoc , B ) ) \\ <nl> + return true ; \\ <nl> + if ( ! Val - > getType ( ) . is < Name # # StorageType > ( ) ) { \\ <nl> + P . diagnose ( addrLoc , diag : : sil_operand_not_ref_storage_address , \" source \" , \\ <nl> + OpcodeName , ReferenceOwnership : : Name ) ; \\ <nl> + } \\ <nl> + ResultVal = B . createLoad # # Name ( InstLoc , Val , IsTake_t ( isTake ) ) ; \\ <nl> + break ; \\ <nl> } <nl> # include \" swift / AST / ReferenceStorage . def \" <nl> <nl> case SILInstructionKind : : CopyBlockWithoutEscapingInst : { <nl> SILValue Closure ; <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - parseVerbatim ( \" withoutEscaping \" ) | | <nl> - parseTypedValueRef ( Closure , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" withoutEscaping \" ) | | <nl> + parseTypedValueRef ( Closure , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> <nl> ResultVal = B . createCopyBlockWithoutEscaping ( InstLoc , Val , Closure ) ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> <nl> case SILInstructionKind : : MarkDependenceInst : { <nl> SILValue Base ; <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - parseVerbatim ( \" on \" ) | | <nl> - parseTypedValueRef ( Base , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" on \" ) | | <nl> + parseTypedValueRef ( Base , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> <nl> ResultVal = B . createMarkDependence ( InstLoc , Val , Base ) ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> case SILInstructionKind : : KeyPathInst : { <nl> SmallVector < KeyPathPatternComponent , 4 > components ; <nl> SILType Ty ; <nl> - if ( parseSILType ( Ty ) <nl> - | | P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) ) <nl> + if ( parseSILType ( Ty ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) ) <nl> return true ; <nl> <nl> GenericParamList * generics = nullptr ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> <nl> if ( P . parseToken ( tok : : l_paren , diag : : expected_tok_in_sil_instr , \" ( \" ) ) <nl> return true ; <nl> - <nl> + <nl> while ( true ) { <nl> Identifier componentKind ; <nl> SourceLoc componentLoc ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> diag : : sil_keypath_expected_component_kind ) ) <nl> return true ; <nl> <nl> - <nl> if ( componentKind . str ( ) = = \" root \" ) { <nl> - if ( P . parseToken ( tok : : sil_dollar , diag : : expected_tok_in_sil_instr , \" $ \" ) <nl> - | | parseASTType ( rootType , patternEnv ) ) <nl> + if ( P . parseToken ( tok : : sil_dollar , diag : : expected_tok_in_sil_instr , <nl> + \" $ \" ) | | <nl> + parseASTType ( rootType , patternEnv ) ) <nl> return true ; <nl> } else if ( componentKind . str ( ) = = \" objc \" ) { <nl> auto tok = P . Tok ; <nl> if ( P . parseToken ( tok : : string_literal , diag : : expected_tok_in_sil_instr , <nl> \" string literal \" ) ) <nl> return true ; <nl> - <nl> + <nl> auto objcStringValue = tok . getText ( ) . drop_front ( ) . drop_back ( ) ; <nl> - objcString = StringRef ( <nl> - P . Context . AllocateCopy < char > ( objcStringValue . begin ( ) , <nl> - objcStringValue . end ( ) ) , <nl> - objcStringValue . size ( ) ) ; <nl> + objcString = <nl> + StringRef ( P . Context . AllocateCopy < char > ( objcStringValue . begin ( ) , <nl> + objcStringValue . end ( ) ) , <nl> + objcStringValue . size ( ) ) ; <nl> } else { <nl> KeyPathPatternComponent component ; <nl> if ( parseKeyPathPatternComponent ( component , operandTypes , <nl> - componentLoc , componentKind , <nl> - InstLoc , patternEnv ) ) <nl> + componentLoc , componentKind , InstLoc , <nl> + patternEnv ) ) <nl> return true ; <nl> components . push_back ( component ) ; <nl> } <nl> - <nl> + <nl> if ( ! P . consumeIf ( tok : : semi ) ) <nl> break ; <nl> } <nl> - <nl> + <nl> if ( P . parseToken ( tok : : r_paren , diag : : expected_tok_in_sil_instr , \" ) \" ) | | <nl> parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> } <nl> - <nl> + <nl> if ( rootType . isNull ( ) ) <nl> P . diagnose ( InstLoc . getSourceLoc ( ) , diag : : sil_keypath_no_root ) ; <nl> - <nl> + <nl> SmallVector < ParsedSubstitution , 4 > parsedSubs ; <nl> if ( parseSubstitutions ( parsedSubs , ContextGenericEnv ) ) <nl> return true ; <nl> - <nl> + <nl> SubstitutionMap subMap ; <nl> if ( ! parsedSubs . empty ( ) ) { <nl> if ( ! patternEnv ) { <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> if ( ! subMap ) <nl> return true ; <nl> } <nl> - <nl> + <nl> SmallVector < SILValue , 4 > operands ; <nl> - <nl> + <nl> if ( P . consumeIf ( tok : : l_paren ) ) { <nl> while ( true ) { <nl> SILValue v ; <nl> - <nl> - if ( operands . size ( ) > = operandTypes . size ( ) <nl> - | | ! operandTypes [ operands . size ( ) ] ) { <nl> + <nl> + if ( operands . size ( ) > = operandTypes . size ( ) | | <nl> + ! operandTypes [ operands . size ( ) ] ) { <nl> P . diagnose ( P . Tok , diag : : sil_keypath_no_use_of_operand_in_pattern , <nl> operands . size ( ) ) ; <nl> return true ; <nl> } <nl> - <nl> + <nl> auto ty = operandTypes [ operands . size ( ) ] . subst ( SILMod , subMap ) ; <nl> - <nl> + <nl> if ( parseValueRef ( v , ty , RegularLocation ( P . Tok . getLoc ( ) ) , B ) ) <nl> return true ; <nl> operands . push_back ( v ) ; <nl> - <nl> + <nl> if ( P . consumeIf ( tok : : comma ) ) <nl> continue ; <nl> if ( P . consumeIf ( tok : : r_paren ) ) <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> return true ; <nl> } <nl> } <nl> - <nl> + <nl> if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> leafType = components . back ( ) . getComponentType ( ) ; <nl> else <nl> leafType = rootType ; <nl> - auto pattern = KeyPathPattern : : get ( B . getModule ( ) , canSig , <nl> - rootType , leafType , <nl> - components , objcString ) ; <nl> + auto pattern = KeyPathPattern : : get ( B . getModule ( ) , canSig , rootType , <nl> + leafType , components , objcString ) ; <nl> <nl> ResultVal = B . createKeyPath ( InstLoc , pattern , subMap , operands , Ty ) ; <nl> break ; <nl> } <nl> <nl> - / / Conversion instructions . <nl> + / / Conversion instructions . <nl> case SILInstructionKind : : UncheckedRefCastInst : <nl> case SILInstructionKind : : UncheckedAddrCastInst : <nl> case SILInstructionKind : : UncheckedTrivialBitCastInst : <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> case SILInstructionKind : : BridgeObjectToWordInst : <nl> case SILInstructionKind : : RefToRawPointerInst : <nl> case SILInstructionKind : : RawPointerToRefInst : <nl> - # define LOADABLE_REF_STORAGE ( Name , . . . ) \\ <nl> - case SILInstructionKind : : RefTo # # Name # # Inst : \\ <nl> + # define LOADABLE_REF_STORAGE ( Name , . . . ) \\ <nl> + case SILInstructionKind : : RefTo # # Name # # Inst : \\ <nl> case SILInstructionKind : : Name # # ToRefInst : <nl> # include \" swift / AST / ReferenceStorage . def \" <nl> case SILInstructionKind : : ThinFunctionToPointerInst : <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> return true ; <nl> } <nl> } <nl> - if ( parseTypedValueRef ( Val , B ) <nl> - | | parseSILIdentifier ( ToToken , ToLoc , diag : : expected_tok_in_sil_instr , <nl> - \" to \" ) ) <nl> + if ( parseTypedValueRef ( Val , B ) | | <nl> + parseSILIdentifier ( ToToken , ToLoc , diag : : expected_tok_in_sil_instr , <nl> + \" to \" ) ) <nl> return true ; <nl> <nl> if ( ToToken . str ( ) ! = \" to \" ) { <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> return true ; <nl> <nl> switch ( Opcode ) { <nl> - default : llvm_unreachable ( \" Out of sync with parent switch \" ) ; <nl> + default : <nl> + llvm_unreachable ( \" Out of sync with parent switch \" ) ; <nl> case SILInstructionKind : : UncheckedRefCastInst : <nl> ResultVal = B . createUncheckedRefCast ( InstLoc , Val , Ty ) ; <nl> break ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> case SILInstructionKind : : RawPointerToRefInst : <nl> ResultVal = B . createRawPointerToRef ( InstLoc , Val , Ty ) ; <nl> break ; <nl> - # define LOADABLE_REF_STORAGE ( Name , . . . ) \\ <nl> - case SILInstructionKind : : RefTo # # Name # # Inst : \\ <nl> - ResultVal = B . createRefTo # # Name ( InstLoc , Val , Ty ) ; \\ <nl> - break ; \\ <nl> - case SILInstructionKind : : Name # # ToRefInst : \\ <nl> - ResultVal = B . create # # Name # # ToRef ( InstLoc , Val , Ty ) ; \\ <nl> - break ; <nl> + # define LOADABLE_REF_STORAGE ( Name , . . . ) \\ <nl> + case SILInstructionKind : : RefTo # # Name # # Inst : \\ <nl> + ResultVal = B . createRefTo # # Name ( InstLoc , Val , Ty ) ; \\ <nl> + break ; \\ <nl> + case SILInstructionKind : : Name # # ToRefInst : \\ <nl> + ResultVal = B . create # # Name # # ToRef ( InstLoc , Val , Ty ) ; \\ <nl> + break ; <nl> # include \" swift / AST / ReferenceStorage . def \" <nl> case SILInstructionKind : : ThinFunctionToPointerInst : <nl> ResultVal = B . createThinFunctionToPointer ( InstLoc , Val , Ty ) ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> SourceLoc ToLoc ; <nl> StringRef attr ; <nl> if ( parseTypedValueRef ( Val , B ) | | <nl> - parseSILIdentifier ( ToToken , ToLoc , <nl> - diag : : expected_tok_in_sil_instr , \" to \" ) ) <nl> + parseSILIdentifier ( ToToken , ToLoc , diag : : expected_tok_in_sil_instr , <nl> + \" to \" ) ) <nl> return true ; <nl> if ( parseSILOptional ( attr , * this ) & & attr . empty ( ) ) <nl> return true ; <nl> - if ( parseSILType ( Ty ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseSILType ( Ty ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> <nl> bool isStrict = attr . equals ( \" strict \" ) ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> return true ; <nl> } <nl> <nl> - ResultVal = B . createPointerToAddress ( InstLoc , Val , Ty , <nl> - isStrict , isInvariant ) ; <nl> + ResultVal = <nl> + B . createPointerToAddress ( InstLoc , Val , Ty , isStrict , isInvariant ) ; <nl> break ; <nl> } <nl> case SILInstructionKind : : RefToBridgeObjectInst : { <nl> SILValue BitsVal ; <nl> if ( parseTypedValueRef ( Val , B ) | | <nl> P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseTypedValueRef ( BitsVal , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> + parseTypedValueRef ( BitsVal , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> ResultVal = B . createRefToBridgeObject ( InstLoc , Val , BitsVal ) ; <nl> break ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> } <nl> auto consumptionKind = kind . getValue ( ) ; <nl> <nl> - if ( parseSourceAndDestAddress ( ) | | parseConditionalBranchDestinations ( ) <nl> - | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseSourceAndDestAddress ( ) | | parseConditionalBranchDestinations ( ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> <nl> ResultVal = B . createCheckedCastAddrBranch ( <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> break ; <nl> <nl> case SILInstructionKind : : UnconditionalCheckedCastValueInst : { <nl> - if ( parseASTType ( SourceType ) <nl> - | | parseVerbatim ( \" in \" ) <nl> - | | parseTypedValueRef ( Val , B ) <nl> - | | parseVerbatim ( \" to \" ) <nl> - | | parseASTType ( TargetType ) <nl> - | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseASTType ( SourceType ) | | parseVerbatim ( \" in \" ) | | <nl> + parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" to \" ) | | <nl> + parseASTType ( TargetType ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> <nl> auto opaque = Lowering : : AbstractionPattern : : getOpaque ( ) ; <nl> - ResultVal = <nl> - B . createUnconditionalCheckedCastValue ( InstLoc , <nl> - Val , SourceType , <nl> - F - > getLoweredType ( opaque , TargetType ) , <nl> - TargetType ) ; <nl> + ResultVal = B . createUnconditionalCheckedCastValue ( <nl> + InstLoc , Val , SourceType , F - > getLoweredType ( opaque , TargetType ) , <nl> + TargetType ) ; <nl> break ; <nl> } <nl> <nl> case SILInstructionKind : : UnconditionalCheckedCastInst : { <nl> - if ( parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" to \" ) <nl> - | | parseASTType ( TargetType ) ) <nl> + if ( parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" to \" ) | | <nl> + parseASTType ( TargetType ) ) <nl> return true ; <nl> <nl> if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> <nl> auto opaque = Lowering : : AbstractionPattern : : getOpaque ( ) ; <nl> - ResultVal = <nl> - B . createUnconditionalCheckedCast ( InstLoc , Val , <nl> - F - > getLoweredType ( opaque , TargetType ) , <nl> - TargetType ) ; <nl> + ResultVal = B . createUnconditionalCheckedCast ( <nl> + InstLoc , Val , F - > getLoweredType ( opaque , TargetType ) , TargetType ) ; <nl> break ; <nl> } <nl> <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> parseSILOptional ( isExact , * this , \" exact \" ) ) <nl> return true ; <nl> <nl> - if ( parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" to \" ) <nl> - | | parseASTType ( TargetType ) <nl> - | | parseConditionalBranchDestinations ( ) ) <nl> + if ( parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" to \" ) | | <nl> + parseASTType ( TargetType ) | | parseConditionalBranchDestinations ( ) ) <nl> return true ; <nl> <nl> auto opaque = Lowering : : AbstractionPattern : : getOpaque ( ) ; <nl> ResultVal = B . createCheckedCastBranch ( <nl> - InstLoc , isExact , Val , <nl> - F - > getLoweredType ( opaque , TargetType ) , TargetType , <nl> - getBBForReference ( SuccessBBName , SuccessBBLoc ) , <nl> + InstLoc , isExact , Val , F - > getLoweredType ( opaque , TargetType ) , <nl> + TargetType , getBBForReference ( SuccessBBName , SuccessBBLoc ) , <nl> getBBForReference ( FailureBBName , FailureBBLoc ) ) ; <nl> break ; <nl> } <nl> case SILInstructionKind : : CheckedCastValueBranchInst : { <nl> - if ( parseASTType ( SourceType ) <nl> - | | parseVerbatim ( \" in \" ) <nl> - | | parseTypedValueRef ( Val , B ) <nl> - | | parseVerbatim ( \" to \" ) <nl> - | | parseASTType ( TargetType ) <nl> - | | parseConditionalBranchDestinations ( ) ) <nl> + if ( parseASTType ( SourceType ) | | parseVerbatim ( \" in \" ) | | <nl> + parseTypedValueRef ( Val , B ) | | parseVerbatim ( \" to \" ) | | <nl> + parseASTType ( TargetType ) | | parseConditionalBranchDestinations ( ) ) <nl> return true ; <nl> <nl> auto opaque = Lowering : : AbstractionPattern : : getOpaque ( ) ; <nl> ResultVal = B . createCheckedCastValueBranch ( <nl> - InstLoc , Val , SourceType , <nl> - F - > getLoweredType ( opaque , TargetType ) , TargetType , <nl> - getBBForReference ( SuccessBBName , SuccessBBLoc ) , <nl> + InstLoc , Val , SourceType , F - > getLoweredType ( opaque , TargetType ) , <nl> + TargetType , getBBForReference ( SuccessBBName , SuccessBBLoc ) , <nl> getBBForReference ( FailureBBName , FailureBBLoc ) ) ; <nl> break ; <nl> } <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> case SILInstructionKind : : MarkUninitializedInst : { <nl> if ( P . parseToken ( tok : : l_square , diag : : expected_tok_in_sil_instr , \" [ \" ) ) <nl> return true ; <nl> - <nl> + <nl> Identifier KindId ; <nl> SourceLoc KindLoc = P . Tok . getLoc ( ) ; <nl> if ( P . consumeIf ( tok : : kw_var ) ) <nl> KindId = P . Context . getIdentifier ( \" var \" ) ; <nl> - else if ( P . parseIdentifier ( KindId , KindLoc , <nl> - diag : : expected_tok_in_sil_instr , \" kind \" ) ) <nl> + else if ( P . parseIdentifier ( KindId , KindLoc , diag : : expected_tok_in_sil_instr , <nl> + \" kind \" ) ) <nl> return true ; <nl> - <nl> + <nl> if ( P . parseToken ( tok : : r_square , diag : : expected_tok_in_sil_instr , \" ] \" ) ) <nl> return true ; <nl> <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> return true ; <nl> } <nl> <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseTypedValueRef ( Val , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> ResultVal = B . createMarkUninitialized ( InstLoc , Val , Kind ) ; <nl> break ; <nl> } <nl> - <nl> + <nl> case SILInstructionKind : : MarkFunctionEscapeInst : { <nl> SmallVector < SILValue , 4 > OpList ; <nl> do { <nl> - if ( parseTypedValueRef ( Val , B ) ) return true ; <nl> + if ( parseTypedValueRef ( Val , B ) ) <nl> + return true ; <nl> OpList . push_back ( Val ) ; <nl> } while ( ! peekSILDebugLocation ( P ) & & P . consumeIf ( tok : : comma ) ) ; <nl> <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> SILType ValType = AddrVal - > getType ( ) . getObjectType ( ) ; <nl> <nl> if ( IsStore ) { <nl> - ResultVal = B . createStore ( InstLoc , <nl> - getLocalValue ( From , ValType , InstLoc , B ) , <nl> - AddrVal , StoreQualifier ) ; <nl> + ResultVal = <nl> + B . createStore ( InstLoc , getLocalValue ( From , ValType , InstLoc , B ) , <nl> + AddrVal , StoreQualifier ) ; <nl> } else { <nl> assert ( IsAssign ) ; <nl> <nl> - ResultVal = B . createAssign ( InstLoc , <nl> - getLocalValue ( From , ValType , InstLoc , B ) , <nl> - AddrVal , AssignQualifier ) ; <nl> + ResultVal = <nl> + B . createAssign ( InstLoc , getLocalValue ( From , ValType , InstLoc , B ) , <nl> + AddrVal , AssignQualifier ) ; <nl> } <nl> <nl> break ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> SILValue Src , DestAddr , InitFn , SetFn ; <nl> SourceLoc DestLoc ; <nl> AssignOwnershipQualifier AssignQualifier ; <nl> - if ( parseTypedValueRef ( Src , B ) | | <nl> - parseVerbatim ( \" to \" ) | | <nl> + if ( parseTypedValueRef ( Src , B ) | | parseVerbatim ( \" to \" ) | | <nl> parseAssignOwnershipQualifier ( AssignQualifier , * this ) | | <nl> parseTypedValueRef ( DestAddr , DestLoc , B ) | | <nl> P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseVerbatim ( \" init \" ) | | <nl> - parseTypedValueRef ( InitFn , B ) | | <nl> + parseVerbatim ( \" init \" ) | | parseTypedValueRef ( InitFn , B ) | | <nl> P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseVerbatim ( \" set \" ) | | <nl> - parseTypedValueRef ( SetFn , B ) | | <nl> + parseVerbatim ( \" set \" ) | | parseTypedValueRef ( SetFn , B ) | | <nl> parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> } <nl> <nl> ResultVal = B . createAssignByWrapper ( InstLoc , Src , DestAddr , InitFn , SetFn , <nl> - AssignQualifier ) ; <nl> + AssignQualifier ) ; <nl> break ; <nl> } <nl> <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> ParsedEnum < bool > noNestedConflict ; <nl> ParsedEnum < bool > fromBuiltin ; <nl> <nl> - bool isBeginAccess = ( Opcode = = SILInstructionKind : : BeginAccessInst | | <nl> - Opcode = = SILInstructionKind : : BeginUnpairedAccessInst ) ; <nl> - bool wantsEnforcement = ( isBeginAccess | | <nl> - Opcode = = SILInstructionKind : : EndUnpairedAccessInst ) ; <nl> + bool isBeginAccess = <nl> + ( Opcode = = SILInstructionKind : : BeginAccessInst | | <nl> + Opcode = = SILInstructionKind : : BeginUnpairedAccessInst ) ; <nl> + bool wantsEnforcement = <nl> + ( isBeginAccess | | Opcode = = SILInstructionKind : : EndUnpairedAccessInst ) ; <nl> <nl> while ( P . consumeIf ( tok : : l_square ) ) { <nl> Identifier ident ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> return true ; <nl> <nl> if ( ! addrVal - > getType ( ) . isAddress ( ) ) { <nl> - P . diagnose ( addrLoc , diag : : sil_operand_not_address , \" operand \" , <nl> - OpcodeName ) ; <nl> + P . diagnose ( addrLoc , diag : : sil_operand_not_address , \" operand \" , OpcodeName ) ; <nl> return true ; <nl> } <nl> <nl> if ( Opcode = = SILInstructionKind : : BeginAccessInst ) { <nl> - ResultVal = <nl> - B . createBeginAccess ( InstLoc , addrVal , * kind , * enforcement , <nl> - * noNestedConflict , * fromBuiltin ) ; <nl> + ResultVal = B . createBeginAccess ( InstLoc , addrVal , * kind , * enforcement , <nl> + * noNestedConflict , * fromBuiltin ) ; <nl> } else if ( Opcode = = SILInstructionKind : : EndAccessInst ) { <nl> ResultVal = B . createEndAccess ( InstLoc , addrVal , * aborting ) ; <nl> } else if ( Opcode = = SILInstructionKind : : BeginUnpairedAccessInst ) { <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> break ; <nl> } <nl> <nl> - # define NEVER_OR_SOMETIMES_LOADABLE_CHECKED_REF_STORAGE ( Name , . . . ) \\ <nl> + # define NEVER_OR_SOMETIMES_LOADABLE_CHECKED_REF_STORAGE ( Name , . . . ) \\ <nl> case SILInstructionKind : : Store # # Name # # Inst : <nl> # include \" swift / AST / ReferenceStorage . def \" <nl> case SILInstructionKind : : StoreBorrowInst : { <nl> UnresolvedValueName from ; <nl> bool isRefStorage = false ; <nl> - # define NEVER_OR_SOMETIMES_LOADABLE_CHECKED_REF_STORAGE ( Name , . . . ) \\ <nl> - isRefStorage | = Opcode = = SILInstructionKind : : Store # # Name # # Inst ; <nl> + # define NEVER_OR_SOMETIMES_LOADABLE_CHECKED_REF_STORAGE ( Name , . . . ) \\ <nl> + isRefStorage | = Opcode = = SILInstructionKind : : Store # # Name # # Inst ; <nl> # include \" swift / AST / ReferenceStorage . def \" <nl> <nl> SourceLoc toLoc , addrLoc ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> SILValue addrVal ; <nl> bool isInit = false ; <nl> if ( parseValueName ( from ) | | <nl> - parseSILIdentifier ( toToken , toLoc , <nl> - diag : : expected_tok_in_sil_instr , \" to \" ) | | <nl> + parseSILIdentifier ( toToken , toLoc , diag : : expected_tok_in_sil_instr , <nl> + \" to \" ) | | <nl> ( isRefStorage & & parseSILOptional ( isInit , * this , \" initialization \" ) ) | | <nl> parseTypedValueRef ( addrVal , addrLoc , B ) | | <nl> parseSILDebugLocation ( InstLoc , B ) ) <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> } <nl> <nl> if ( ! addrVal - > getType ( ) . isAddress ( ) ) { <nl> - P . diagnose ( addrLoc , diag : : sil_operand_not_address , <nl> - \" destination \" , OpcodeName ) ; <nl> + P . diagnose ( addrLoc , diag : : sil_operand_not_address , \" destination \" , <nl> + OpcodeName ) ; <nl> return true ; <nl> } <nl> <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> break ; <nl> } <nl> <nl> - # define NEVER_OR_SOMETIMES_LOADABLE_CHECKED_REF_STORAGE ( Name , . . . ) \\ <nl> - if ( Opcode = = SILInstructionKind : : Store # # Name # # Inst ) { \\ <nl> - auto refType = addrVal - > getType ( ) . getAs < Name # # StorageType > ( ) ; \\ <nl> - if ( ! refType ) { \\ <nl> - P . diagnose ( addrLoc , diag : : sil_operand_not_ref_storage_address , \\ <nl> - \" destination \" , OpcodeName , ReferenceOwnership : : Name ) ; \\ <nl> - return true ; \\ <nl> - } \\ <nl> - auto valueTy = SILType : : getPrimitiveObjectType ( refType . getReferentType ( ) ) ; \\ <nl> - ResultVal = B . createStore # # Name ( InstLoc , \\ <nl> - getLocalValue ( from , valueTy , InstLoc , B ) , \\ <nl> - addrVal , IsInitialization_t ( isInit ) ) ; \\ <nl> - break ; \\ <nl> - } <nl> + # define NEVER_OR_SOMETIMES_LOADABLE_CHECKED_REF_STORAGE ( Name , . . . ) \\ <nl> + if ( Opcode = = SILInstructionKind : : Store # # Name # # Inst ) { \\ <nl> + auto refType = addrVal - > getType ( ) . getAs < Name # # StorageType > ( ) ; \\ <nl> + if ( ! refType ) { \\ <nl> + P . diagnose ( addrLoc , diag : : sil_operand_not_ref_storage_address , \\ <nl> + \" destination \" , OpcodeName , ReferenceOwnership : : Name ) ; \\ <nl> + return true ; \\ <nl> + } \\ <nl> + auto valueTy = SILType : : getPrimitiveObjectType ( refType . getReferentType ( ) ) ; \\ <nl> + ResultVal = \\ <nl> + B . createStore # # Name ( InstLoc , getLocalValue ( from , valueTy , InstLoc , B ) , \\ <nl> + addrVal , IsInitialization_t ( isInit ) ) ; \\ <nl> + break ; \\ <nl> + } <nl> # include \" swift / AST / ReferenceStorage . def \" <nl> <nl> break ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> <nl> if ( Opcode = = SILInstructionKind : : AllocStackInst ) { <nl> SILDebugVariable VarInfo ; <nl> - if ( parseSILDebugVar ( VarInfo ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseSILDebugVar ( VarInfo ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> ResultVal = B . createAllocStack ( InstLoc , Ty , VarInfo , hasDynamicLifetime ) ; <nl> } else { <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> OnStack = true ; <nl> } else if ( Optional = = \" tail_elems \" ) { <nl> SILType ElemTy ; <nl> - if ( parseSILType ( ElemTy ) | | <nl> - ! P . Tok . isAnyOperator ( ) | | <nl> + if ( parseSILType ( ElemTy ) | | ! P . Tok . isAnyOperator ( ) | | <nl> P . Tok . getText ( ) ! = \" * \" ) <nl> return true ; <nl> P . consumeToken ( ) ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> if ( OnStack ) <nl> return true ; <nl> <nl> - ResultVal = B . createAllocRefDynamic ( InstLoc , Metadata , ObjectType , <nl> - IsObjC , ElementTypes , ElementCounts ) ; <nl> + ResultVal = B . createAllocRefDynamic ( InstLoc , Metadata , ObjectType , IsObjC , <nl> + ElementTypes , ElementCounts ) ; <nl> } else { <nl> ResultVal = B . createAllocRef ( InstLoc , ObjectType , IsObjC , OnStack , <nl> ElementTypes , ElementCounts ) ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> } <nl> <nl> case SILInstructionKind : : DeallocStackInst : <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseTypedValueRef ( Val , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> ResultVal = B . createDeallocStack ( InstLoc , Val ) ; <nl> break ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> if ( parseSILOptional ( OnStack , * this , \" stack \" ) ) <nl> return true ; <nl> <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> + if ( parseTypedValueRef ( Val , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> ResultVal = B . createDeallocRef ( InstLoc , Val , OnStack ) ; <nl> break ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> SILValue Metatype , Instance ; <nl> if ( parseTypedValueRef ( Instance , B ) | | <nl> P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseTypedValueRef ( Metatype , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> + parseTypedValueRef ( Metatype , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> <nl> ResultVal = B . createDeallocPartialRef ( InstLoc , Instance , Metatype ) ; <nl> break ; <nl> } <nl> - case SILInstructionKind : : DeallocBoxInst : <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - <nl> - ResultVal = B . createDeallocBox ( InstLoc , Val ) ; <nl> - break ; <nl> - case SILInstructionKind : : ValueMetatypeInst : <nl> - case SILInstructionKind : : ExistentialMetatypeInst : { <nl> - SILType Ty ; <nl> - if ( parseSILType ( Ty ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseTypedValueRef ( Val , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - switch ( Opcode ) { <nl> - default : llvm_unreachable ( \" Out of sync with parent switch \" ) ; <nl> - case SILInstructionKind : : ValueMetatypeInst : <nl> - ResultVal = B . createValueMetatype ( InstLoc , Ty , Val ) ; <nl> - break ; <nl> - case SILInstructionKind : : ExistentialMetatypeInst : <nl> - ResultVal = B . createExistentialMetatype ( InstLoc , Ty , Val ) ; <nl> - break ; <nl> case SILInstructionKind : : DeallocBoxInst : <nl> + if ( parseTypedValueRef ( Val , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + <nl> ResultVal = B . createDeallocBox ( InstLoc , Val ) ; <nl> break ; <nl> - } <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : DeallocExistentialBoxInst : { <nl> - CanType ConcreteTy ; <nl> - if ( parseTypedValueRef ( Val , B ) <nl> - | | P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) <nl> - | | P . parseToken ( tok : : sil_dollar , diag : : expected_tok_in_sil_instr , \" $ \" ) <nl> - | | parseASTType ( ConcreteTy ) <nl> - | | parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - <nl> - ResultVal = B . createDeallocExistentialBox ( InstLoc , ConcreteTy , Val ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : TupleInst : { <nl> - / / Tuple instructions have two different syntaxes , one for simple tuple <nl> - / / types , one for complicated ones . <nl> - if ( P . Tok . isNot ( tok : : sil_dollar ) ) { <nl> - / / If there is no type , parse the simple form . <nl> - if ( P . parseToken ( tok : : l_paren , diag : : expected_tok_in_sil_instr , \" ( \" ) ) <nl> + case SILInstructionKind : : ValueMetatypeInst : <nl> + case SILInstructionKind : : ExistentialMetatypeInst : { <nl> + SILType Ty ; <nl> + if ( parseSILType ( Ty ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseTypedValueRef ( Val , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> - <nl> - / / TODO : Check for a type here . This is how tuples with \" interesting \" <nl> - / / types are described . <nl> - <nl> - / / This form is used with tuples that have elements with no names or <nl> - / / default values . <nl> + switch ( Opcode ) { <nl> + default : <nl> + llvm_unreachable ( \" Out of sync with parent switch \" ) ; <nl> + case SILInstructionKind : : ValueMetatypeInst : <nl> + ResultVal = B . createValueMetatype ( InstLoc , Ty , Val ) ; <nl> + break ; <nl> + case SILInstructionKind : : ExistentialMetatypeInst : <nl> + ResultVal = B . createExistentialMetatype ( InstLoc , Ty , Val ) ; <nl> + break ; <nl> + case SILInstructionKind : : DeallocBoxInst : <nl> + ResultVal = B . createDeallocBox ( InstLoc , Val ) ; <nl> + break ; <nl> + } <nl> + break ; <nl> + } <nl> + case SILInstructionKind : : DeallocExistentialBoxInst : { <nl> + CanType ConcreteTy ; <nl> + if ( parseTypedValueRef ( Val , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + P . parseToken ( tok : : sil_dollar , diag : : expected_tok_in_sil_instr , \" $ \" ) | | <nl> + parseASTType ( ConcreteTy ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + <nl> + ResultVal = B . createDeallocExistentialBox ( InstLoc , ConcreteTy , Val ) ; <nl> + break ; <nl> + } <nl> + case SILInstructionKind : : TupleInst : { <nl> + / / Tuple instructions have two different syntaxes , one for simple tuple <nl> + / / types , one for complicated ones . <nl> + if ( P . Tok . isNot ( tok : : sil_dollar ) ) { <nl> + / / If there is no type , parse the simple form . <nl> + if ( P . parseToken ( tok : : l_paren , diag : : expected_tok_in_sil_instr , \" ( \" ) ) <nl> + return true ; <nl> + <nl> + / / TODO : Check for a type here . This is how tuples with \" interesting \" <nl> + / / types are described . <nl> + <nl> + / / This form is used with tuples that have elements with no names or <nl> + / / default values . <nl> + SmallVector < TupleTypeElt , 4 > TypeElts ; <nl> + if ( P . Tok . isNot ( tok : : r_paren ) ) { <nl> + do { <nl> + if ( parseTypedValueRef ( Val , B ) ) <nl> + return true ; <nl> + OpList . push_back ( Val ) ; <nl> + TypeElts . push_back ( Val - > getType ( ) . getASTType ( ) ) ; <nl> + } while ( P . consumeIf ( tok : : comma ) ) ; <nl> + } <nl> + HadError | = <nl> + P . parseToken ( tok : : r_paren , diag : : expected_tok_in_sil_instr , \" ) \" ) ; <nl> + <nl> + auto Ty = TupleType : : get ( TypeElts , P . Context ) ; <nl> + auto Ty2 = SILType : : getPrimitiveObjectType ( Ty - > getCanonicalType ( ) ) ; <nl> + if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + ResultVal = B . createTuple ( InstLoc , Ty2 , OpList ) ; <nl> + break ; <nl> + } <nl> + <nl> + / / Otherwise , parse the fully general form . <nl> + SILType Ty ; <nl> + if ( parseSILType ( Ty ) | | <nl> + P . parseToken ( tok : : l_paren , diag : : expected_tok_in_sil_instr , \" ( \" ) ) <nl> + return true ; <nl> + <nl> + TupleType * TT = Ty . getAs < TupleType > ( ) ; <nl> + if ( TT = = nullptr ) { <nl> + P . diagnose ( OpcodeLoc , diag : : expected_tuple_type_in_tuple ) ; <nl> + return true ; <nl> + } <nl> + <nl> SmallVector < TupleTypeElt , 4 > TypeElts ; <nl> if ( P . Tok . isNot ( tok : : r_paren ) ) { <nl> do { <nl> - if ( parseTypedValueRef ( Val , B ) ) return true ; <nl> + if ( TypeElts . size ( ) > TT - > getNumElements ( ) ) { <nl> + P . diagnose ( P . Tok , diag : : sil_tuple_inst_wrong_value_count , <nl> + TT - > getNumElements ( ) ) ; <nl> + return true ; <nl> + } <nl> + Type EltTy = TT - > getElement ( TypeElts . size ( ) ) . getType ( ) ; <nl> + if ( parseValueRef ( <nl> + Val , <nl> + SILType : : getPrimitiveObjectType ( EltTy - > getCanonicalType ( ) ) , <nl> + RegularLocation ( P . Tok . getLoc ( ) ) , B ) ) <nl> + return true ; <nl> OpList . push_back ( Val ) ; <nl> TypeElts . push_back ( Val - > getType ( ) . getASTType ( ) ) ; <nl> } while ( P . consumeIf ( tok : : comma ) ) ; <nl> bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> HadError | = P . parseToken ( tok : : r_paren , <nl> diag : : expected_tok_in_sil_instr , \" ) \" ) ; <nl> <nl> - auto Ty = TupleType : : get ( TypeElts , P . Context ) ; <nl> - auto Ty2 = SILType : : getPrimitiveObjectType ( Ty - > getCanonicalType ( ) ) ; <nl> + if ( TypeElts . size ( ) ! = TT - > getNumElements ( ) ) { <nl> + P . diagnose ( OpcodeLoc , diag : : sil_tuple_inst_wrong_value_count , <nl> + TT - > getNumElements ( ) ) ; <nl> + return true ; <nl> + } <nl> + <nl> if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> - ResultVal = B . createTuple ( InstLoc , Ty2 , OpList ) ; <nl> + ResultVal = B . createTuple ( InstLoc , Ty , OpList ) ; <nl> break ; <nl> } <nl> - <nl> - / / Otherwise , parse the fully general form . <nl> - SILType Ty ; <nl> - if ( parseSILType ( Ty ) | | <nl> - P . parseToken ( tok : : l_paren , diag : : expected_tok_in_sil_instr , \" ( \" ) ) <nl> - return true ; <nl> - <nl> - TupleType * TT = Ty . getAs < TupleType > ( ) ; <nl> - if ( TT = = nullptr ) { <nl> - P . diagnose ( OpcodeLoc , diag : : expected_tuple_type_in_tuple ) ; <nl> - return true ; <nl> - } <nl> - <nl> - SmallVector < TupleTypeElt , 4 > TypeElts ; <nl> - if ( P . Tok . isNot ( tok : : r_paren ) ) { <nl> - do { <nl> - if ( TypeElts . size ( ) > TT - > getNumElements ( ) ) { <nl> - P . diagnose ( P . Tok , diag : : sil_tuple_inst_wrong_value_count , <nl> - TT - > getNumElements ( ) ) ; <nl> - return true ; <nl> - } <nl> - Type EltTy = TT - > getElement ( TypeElts . size ( ) ) . getType ( ) ; <nl> - if ( parseValueRef ( Val , <nl> - SILType : : getPrimitiveObjectType ( EltTy - > getCanonicalType ( ) ) , <nl> - RegularLocation ( P . Tok . getLoc ( ) ) , B ) ) <nl> - return true ; <nl> - OpList . push_back ( Val ) ; <nl> - TypeElts . push_back ( Val - > getType ( ) . getASTType ( ) ) ; <nl> - } while ( P . consumeIf ( tok : : comma ) ) ; <nl> - } <nl> - HadError | = P . parseToken ( tok : : r_paren , <nl> - diag : : expected_tok_in_sil_instr , \" ) \" ) ; <nl> + case SILInstructionKind : : EnumInst : { <nl> + SILType Ty ; <nl> + SILDeclRef Elt ; <nl> + SILValue Operand ; <nl> + if ( parseSILType ( Ty ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILDeclRef ( Elt ) ) <nl> + return true ; <nl> <nl> - if ( TypeElts . size ( ) ! = TT - > getNumElements ( ) ) { <nl> - P . diagnose ( OpcodeLoc , diag : : sil_tuple_inst_wrong_value_count , <nl> - TT - > getNumElements ( ) ) ; <nl> - return true ; <nl> - } <nl> + if ( P . Tok . is ( tok : : comma ) & & ! peekSILDebugLocation ( P ) ) { <nl> + P . consumeToken ( tok : : comma ) ; <nl> + if ( parseTypedValueRef ( Operand , B ) ) <nl> + return true ; <nl> + } <nl> <nl> - if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - ResultVal = B . createTuple ( InstLoc , Ty , OpList ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : EnumInst : { <nl> - SILType Ty ; <nl> - SILDeclRef Elt ; <nl> - SILValue Operand ; <nl> - if ( parseSILType ( Ty ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILDeclRef ( Elt ) ) <nl> - return true ; <nl> - <nl> - if ( P . Tok . is ( tok : : comma ) & & ! peekSILDebugLocation ( P ) ) { <nl> - P . consumeToken ( tok : : comma ) ; <nl> - if ( parseTypedValueRef ( Operand , B ) ) <nl> + if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> + ResultVal = B . createEnum ( InstLoc , Operand , <nl> + cast < EnumElementDecl > ( Elt . getDecl ( ) ) , Ty ) ; <nl> + break ; <nl> } <nl> - <nl> - if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - ResultVal = B . createEnum ( InstLoc , Operand , <nl> - cast < EnumElementDecl > ( Elt . getDecl ( ) ) , Ty ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : InitEnumDataAddrInst : <nl> - case SILInstructionKind : : UncheckedEnumDataInst : <nl> - case SILInstructionKind : : UncheckedTakeEnumDataAddrInst : { <nl> - SILValue Operand ; <nl> - SILDeclRef EltRef ; <nl> - if ( parseTypedValueRef ( Operand , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILDeclRef ( EltRef ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - <nl> - EnumElementDecl * Elt = cast < EnumElementDecl > ( EltRef . getDecl ( ) ) ; <nl> - auto ResultTy = Operand - > getType ( ) . getEnumElementType ( <nl> - Elt , SILMod , B . getTypeExpansionContext ( ) ) ; <nl> + case SILInstructionKind : : InitEnumDataAddrInst : <nl> + case SILInstructionKind : : UncheckedEnumDataInst : <nl> + case SILInstructionKind : : UncheckedTakeEnumDataAddrInst : { <nl> + SILValue Operand ; <nl> + SILDeclRef EltRef ; <nl> + if ( parseTypedValueRef ( Operand , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILDeclRef ( EltRef ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> <nl> - switch ( Opcode ) { <nl> - case swift : : SILInstructionKind : : InitEnumDataAddrInst : <nl> - ResultVal = B . createInitEnumDataAddr ( InstLoc , Operand , Elt , ResultTy ) ; <nl> - break ; <nl> - case swift : : SILInstructionKind : : UncheckedTakeEnumDataAddrInst : <nl> - ResultVal = B . createUncheckedTakeEnumDataAddr ( InstLoc , Operand , Elt , <nl> - ResultTy ) ; <nl> - break ; <nl> - case swift : : SILInstructionKind : : UncheckedEnumDataInst : <nl> - ResultVal = B . createUncheckedEnumData ( InstLoc , Operand , Elt , ResultTy ) ; <nl> + EnumElementDecl * Elt = cast < EnumElementDecl > ( EltRef . getDecl ( ) ) ; <nl> + auto ResultTy = Operand - > getType ( ) . getEnumElementType ( <nl> + Elt , SILMod , B . getTypeExpansionContext ( ) ) ; <nl> + <nl> + switch ( Opcode ) { <nl> + case swift : : SILInstructionKind : : InitEnumDataAddrInst : <nl> + ResultVal = B . createInitEnumDataAddr ( InstLoc , Operand , Elt , ResultTy ) ; <nl> + break ; <nl> + case swift : : SILInstructionKind : : UncheckedTakeEnumDataAddrInst : <nl> + ResultVal = <nl> + B . createUncheckedTakeEnumDataAddr ( InstLoc , Operand , Elt , ResultTy ) ; <nl> + break ; <nl> + case swift : : SILInstructionKind : : UncheckedEnumDataInst : <nl> + ResultVal = B . createUncheckedEnumData ( InstLoc , Operand , Elt , ResultTy ) ; <nl> + break ; <nl> + default : <nl> + llvm_unreachable ( \" switch out of sync \" ) ; <nl> + } <nl> break ; <nl> - default : <nl> - llvm_unreachable ( \" switch out of sync \" ) ; <nl> } <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : InjectEnumAddrInst : { <nl> - SILValue Operand ; <nl> - SILDeclRef EltRef ; <nl> - if ( parseTypedValueRef ( Operand , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILDeclRef ( EltRef ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - <nl> - EnumElementDecl * Elt = cast < EnumElementDecl > ( EltRef . getDecl ( ) ) ; <nl> - ResultVal = B . createInjectEnumAddr ( InstLoc , Operand , Elt ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : TupleElementAddrInst : <nl> - case SILInstructionKind : : TupleExtractInst : { <nl> - SourceLoc NameLoc ; <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) ) <nl> - return true ; <nl> + case SILInstructionKind : : InjectEnumAddrInst : { <nl> + SILValue Operand ; <nl> + SILDeclRef EltRef ; <nl> + if ( parseTypedValueRef ( Operand , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILDeclRef ( EltRef ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> <nl> - unsigned Field = 0 ; <nl> - TupleType * TT = Val - > getType ( ) . getAs < TupleType > ( ) ; <nl> - if ( P . Tok . isNot ( tok : : integer_literal ) | | <nl> - parseIntegerLiteral ( P . Tok . getText ( ) , 10 , Field ) | | <nl> - Field > = TT - > getNumElements ( ) ) { <nl> - P . diagnose ( P . Tok , diag : : sil_tuple_inst_wrong_field ) ; <nl> - return true ; <nl> + EnumElementDecl * Elt = cast < EnumElementDecl > ( EltRef . getDecl ( ) ) ; <nl> + ResultVal = B . createInjectEnumAddr ( InstLoc , Operand , Elt ) ; <nl> + break ; <nl> } <nl> - P . consumeToken ( tok : : integer_literal ) ; <nl> - if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - auto ResultTy = TT - > getElement ( Field ) . getType ( ) - > getCanonicalType ( ) ; <nl> - if ( Opcode = = SILInstructionKind : : TupleElementAddrInst ) <nl> - ResultVal = B . createTupleElementAddr ( InstLoc , Val , Field , <nl> - SILType : : getPrimitiveAddressType ( ResultTy ) ) ; <nl> - else <nl> - ResultVal = B . createTupleExtract ( InstLoc , Val , Field , <nl> - SILType : : getPrimitiveObjectType ( ResultTy ) ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : ReturnInst : { <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - ResultVal = B . createReturn ( InstLoc , Val ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : ThrowInst : { <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - ResultVal = B . createThrow ( InstLoc , Val ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : UnwindInst : { <nl> - if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - ResultVal = B . createUnwind ( InstLoc ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : YieldInst : { <nl> - SmallVector < SILValue , 6 > values ; <nl> + case SILInstructionKind : : TupleElementAddrInst : <nl> + case SILInstructionKind : : TupleExtractInst : { <nl> + SourceLoc NameLoc ; <nl> + if ( parseTypedValueRef ( Val , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) ) <nl> + return true ; <nl> <nl> - / / Parse a parenthesized ( unless length - 1 ) , comma - separated list <nl> - / / of yielded values . <nl> - if ( P . consumeIf ( tok : : l_paren ) ) { <nl> - if ( ! P . Tok . is ( tok : : r_paren ) ) { <nl> - do { <nl> - if ( parseTypedValueRef ( Val , B ) ) <nl> - return true ; <nl> - values . push_back ( Val ) ; <nl> - } while ( P . consumeIf ( tok : : comma ) ) ; <nl> + unsigned Field = 0 ; <nl> + TupleType * TT = Val - > getType ( ) . getAs < TupleType > ( ) ; <nl> + if ( P . Tok . isNot ( tok : : integer_literal ) | | <nl> + parseIntegerLiteral ( P . Tok . getText ( ) , 10 , Field ) | | <nl> + Field > = TT - > getNumElements ( ) ) { <nl> + P . diagnose ( P . Tok , diag : : sil_tuple_inst_wrong_field ) ; <nl> + return true ; <nl> } <nl> - <nl> - if ( P . parseToken ( tok : : r_paren , diag : : expected_tok_in_sil_instr , \" ) \" ) ) <nl> + P . consumeToken ( tok : : integer_literal ) ; <nl> + if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> - <nl> - } else { <nl> - if ( parseTypedValueRef ( Val , B ) ) <nl> + auto ResultTy = TT - > getElement ( Field ) . getType ( ) - > getCanonicalType ( ) ; <nl> + if ( Opcode = = SILInstructionKind : : TupleElementAddrInst ) <nl> + ResultVal = B . createTupleElementAddr ( <nl> + InstLoc , Val , Field , SILType : : getPrimitiveAddressType ( ResultTy ) ) ; <nl> + else <nl> + ResultVal = B . createTupleExtract ( <nl> + InstLoc , Val , Field , SILType : : getPrimitiveObjectType ( ResultTy ) ) ; <nl> + break ; <nl> + } <nl> + case SILInstructionKind : : ReturnInst : { <nl> + if ( parseTypedValueRef ( Val , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> - values . push_back ( Val ) ; <nl> + ResultVal = B . createReturn ( InstLoc , Val ) ; <nl> + break ; <nl> + } <nl> + case SILInstructionKind : : ThrowInst : { <nl> + if ( parseTypedValueRef ( Val , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + ResultVal = B . createThrow ( InstLoc , Val ) ; <nl> + break ; <nl> + } <nl> + case SILInstructionKind : : UnwindInst : { <nl> + if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + ResultVal = B . createUnwind ( InstLoc ) ; <nl> + break ; <nl> } <nl> + case SILInstructionKind : : YieldInst : { <nl> + SmallVector < SILValue , 6 > values ; <nl> <nl> - Identifier resumeName , unwindName ; <nl> - SourceLoc resumeLoc , unwindLoc ; <nl> - if ( P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseVerbatim ( \" resume \" ) | | <nl> - parseSILIdentifier ( resumeName , resumeLoc , <nl> - diag : : expected_sil_block_name ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseVerbatim ( \" unwind \" ) | | <nl> - parseSILIdentifier ( unwindName , unwindLoc , <nl> - diag : : expected_sil_block_name ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> + / / Parse a parenthesized ( unless length - 1 ) , comma - separated list <nl> + / / of yielded values . <nl> + if ( P . consumeIf ( tok : : l_paren ) ) { <nl> + if ( ! P . Tok . is ( tok : : r_paren ) ) { <nl> + do { <nl> + if ( parseTypedValueRef ( Val , B ) ) <nl> + return true ; <nl> + values . push_back ( Val ) ; <nl> + } while ( P . consumeIf ( tok : : comma ) ) ; <nl> + } <nl> <nl> - auto resumeBB = getBBForReference ( resumeName , resumeLoc ) ; <nl> - auto unwindBB = getBBForReference ( unwindName , unwindLoc ) ; <nl> - ResultVal = B . createYield ( InstLoc , values , resumeBB , unwindBB ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : BranchInst : { <nl> - Identifier BBName ; <nl> - SourceLoc NameLoc ; <nl> - if ( parseSILIdentifier ( BBName , NameLoc , diag : : expected_sil_block_name ) ) <nl> - return true ; <nl> + if ( P . parseToken ( tok : : r_paren , diag : : expected_tok_in_sil_instr , \" ) \" ) ) <nl> + return true ; <nl> <nl> - SmallVector < SILValue , 6 > Args ; <nl> - if ( parseSILBBArgsAtBranch ( Args , B ) ) <nl> - return true ; <nl> + } else { <nl> + if ( parseTypedValueRef ( Val , B ) ) <nl> + return true ; <nl> + values . push_back ( Val ) ; <nl> + } <nl> <nl> - if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> + Identifier resumeName , unwindName ; <nl> + SourceLoc resumeLoc , unwindLoc ; <nl> + if ( P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseVerbatim ( \" resume \" ) | | <nl> + parseSILIdentifier ( resumeName , resumeLoc , <nl> + diag : : expected_sil_block_name ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseVerbatim ( \" unwind \" ) | | <nl> + parseSILIdentifier ( unwindName , unwindLoc , <nl> + diag : : expected_sil_block_name ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> <nl> - / / Note , the basic block here could be a reference to an undefined <nl> - / / basic block , which will be parsed later on . <nl> - ResultVal = B . createBranch ( InstLoc , getBBForReference ( BBName , NameLoc ) , <nl> - Args ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : CondBranchInst : { <nl> - UnresolvedValueName Cond ; <nl> - Identifier BBName , BBName2 ; <nl> - SourceLoc NameLoc , NameLoc2 ; <nl> - SmallVector < SILValue , 6 > Args , Args2 ; <nl> - if ( parseValueName ( Cond ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILIdentifier ( BBName , NameLoc , diag : : expected_sil_block_name ) | | <nl> - parseSILBBArgsAtBranch ( Args , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILIdentifier ( BBName2 , NameLoc2 , <nl> - diag : : expected_sil_block_name ) | | <nl> - parseSILBBArgsAtBranch ( Args2 , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> + auto resumeBB = getBBForReference ( resumeName , resumeLoc ) ; <nl> + auto unwindBB = getBBForReference ( unwindName , unwindLoc ) ; <nl> + ResultVal = B . createYield ( InstLoc , values , resumeBB , unwindBB ) ; <nl> + break ; <nl> + } <nl> + case SILInstructionKind : : BranchInst : { <nl> + Identifier BBName ; <nl> + SourceLoc NameLoc ; <nl> + if ( parseSILIdentifier ( BBName , NameLoc , diag : : expected_sil_block_name ) ) <nl> + return true ; <nl> <nl> - auto I1Ty = <nl> - SILType : : getBuiltinIntegerType ( 1 , SILMod . getASTContext ( ) ) ; <nl> - SILValue CondVal = getLocalValue ( Cond , I1Ty , InstLoc , B ) ; <nl> - ResultVal = B . createCondBranch ( InstLoc , CondVal , <nl> - getBBForReference ( BBName , NameLoc ) , <nl> - Args , <nl> - getBBForReference ( BBName2 , NameLoc2 ) , <nl> - Args2 ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : UnreachableInst : <nl> - if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - ResultVal = B . createUnreachable ( InstLoc ) ; <nl> - break ; <nl> - <nl> - case SILInstructionKind : : ClassMethodInst : <nl> - case SILInstructionKind : : SuperMethodInst : <nl> - case SILInstructionKind : : ObjCMethodInst : <nl> - case SILInstructionKind : : ObjCSuperMethodInst : { <nl> - SILDeclRef Member ; <nl> - SILType MethodTy ; <nl> - SourceLoc TyLoc ; <nl> - SmallVector < ValueDecl * , 4 > values ; <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) ) <nl> - return true ; <nl> + SmallVector < SILValue , 6 > Args ; <nl> + if ( parseSILBBArgsAtBranch ( Args , B ) ) <nl> + return true ; <nl> <nl> - if ( parseSILDeclRef ( Member , true ) ) <nl> - return true ; <nl> + if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> <nl> - if ( P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILType ( MethodTy , TyLoc ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> + / / Note , the basic block here could be a reference to an undefined <nl> + / / basic block , which will be parsed later on . <nl> + ResultVal = <nl> + B . createBranch ( InstLoc , getBBForReference ( BBName , NameLoc ) , Args ) ; <nl> + break ; <nl> + } <nl> + case SILInstructionKind : : CondBranchInst : { <nl> + UnresolvedValueName Cond ; <nl> + Identifier BBName , BBName2 ; <nl> + SourceLoc NameLoc , NameLoc2 ; <nl> + SmallVector < SILValue , 6 > Args , Args2 ; <nl> + if ( parseValueName ( Cond ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILIdentifier ( BBName , NameLoc , diag : : expected_sil_block_name ) | | <nl> + parseSILBBArgsAtBranch ( Args , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILIdentifier ( BBName2 , NameLoc2 , <nl> + diag : : expected_sil_block_name ) | | <nl> + parseSILBBArgsAtBranch ( Args2 , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> <nl> - switch ( Opcode ) { <nl> - default : llvm_unreachable ( \" Out of sync with parent switch \" ) ; <nl> - case SILInstructionKind : : ClassMethodInst : <nl> - ResultVal = B . createClassMethod ( InstLoc , Val , Member , MethodTy ) ; <nl> + auto I1Ty = SILType : : getBuiltinIntegerType ( 1 , SILMod . getASTContext ( ) ) ; <nl> + SILValue CondVal = getLocalValue ( Cond , I1Ty , InstLoc , B ) ; <nl> + ResultVal = B . createCondBranch ( <nl> + InstLoc , CondVal , getBBForReference ( BBName , NameLoc ) , Args , <nl> + getBBForReference ( BBName2 , NameLoc2 ) , Args2 ) ; <nl> break ; <nl> - case SILInstructionKind : : SuperMethodInst : <nl> - ResultVal = B . createSuperMethod ( InstLoc , Val , Member , MethodTy ) ; <nl> + } <nl> + case SILInstructionKind : : UnreachableInst : <nl> + if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + ResultVal = B . createUnreachable ( InstLoc ) ; <nl> break ; <nl> + <nl> + case SILInstructionKind : : ClassMethodInst : <nl> + case SILInstructionKind : : SuperMethodInst : <nl> case SILInstructionKind : : ObjCMethodInst : <nl> - ResultVal = B . createObjCMethod ( InstLoc , Val , Member , MethodTy ) ; <nl> - break ; <nl> - case SILInstructionKind : : ObjCSuperMethodInst : <nl> - ResultVal = B . createObjCSuperMethod ( InstLoc , Val , Member , MethodTy ) ; <nl> + case SILInstructionKind : : ObjCSuperMethodInst : { <nl> + SILDeclRef Member ; <nl> + SILType MethodTy ; <nl> + SourceLoc TyLoc ; <nl> + SmallVector < ValueDecl * , 4 > values ; <nl> + if ( parseTypedValueRef ( Val , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) ) <nl> + return true ; <nl> + <nl> + if ( parseSILDeclRef ( Member , true ) ) <nl> + return true ; <nl> + <nl> + if ( P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILType ( MethodTy , TyLoc ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + <nl> + switch ( Opcode ) { <nl> + default : <nl> + llvm_unreachable ( \" Out of sync with parent switch \" ) ; <nl> + case SILInstructionKind : : ClassMethodInst : <nl> + ResultVal = B . createClassMethod ( InstLoc , Val , Member , MethodTy ) ; <nl> + break ; <nl> + case SILInstructionKind : : SuperMethodInst : <nl> + ResultVal = B . createSuperMethod ( InstLoc , Val , Member , MethodTy ) ; <nl> + break ; <nl> + case SILInstructionKind : : ObjCMethodInst : <nl> + ResultVal = B . createObjCMethod ( InstLoc , Val , Member , MethodTy ) ; <nl> + break ; <nl> + case SILInstructionKind : : ObjCSuperMethodInst : <nl> + ResultVal = B . createObjCSuperMethod ( InstLoc , Val , Member , MethodTy ) ; <nl> + break ; <nl> + } <nl> break ; <nl> } <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : WitnessMethodInst : { <nl> - CanType LookupTy ; <nl> - SILDeclRef Member ; <nl> - SILType MethodTy ; <nl> - SourceLoc TyLoc ; <nl> - if ( P . parseToken ( tok : : sil_dollar , diag : : expected_tok_in_sil_instr , \" $ \" ) | | <nl> - parseASTType ( LookupTy ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) ) <nl> - return true ; <nl> - if ( parseSILDeclRef ( Member , true ) ) <nl> - return true ; <nl> - / / Optional operand . <nl> - SILValue Operand ; <nl> - if ( P . Tok . is ( tok : : comma ) ) { <nl> - P . consumeToken ( tok : : comma ) ; <nl> - if ( parseTypedValueRef ( Operand , B ) ) <nl> + case SILInstructionKind : : WitnessMethodInst : { <nl> + CanType LookupTy ; <nl> + SILDeclRef Member ; <nl> + SILType MethodTy ; <nl> + SourceLoc TyLoc ; <nl> + if ( P . parseToken ( tok : : sil_dollar , diag : : expected_tok_in_sil_instr , \" $ \" ) | | <nl> + parseASTType ( LookupTy ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) ) <nl> + return true ; <nl> + if ( parseSILDeclRef ( Member , true ) ) <nl> + return true ; <nl> + / / Optional operand . <nl> + SILValue Operand ; <nl> + if ( P . Tok . is ( tok : : comma ) ) { <nl> + P . consumeToken ( tok : : comma ) ; <nl> + if ( parseTypedValueRef ( Operand , B ) ) <nl> + return true ; <nl> + } <nl> + if ( P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) | | <nl> + parseSILType ( MethodTy , TyLoc ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> return true ; <nl> - } <nl> - if ( P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) | | <nl> - parseSILType ( MethodTy , TyLoc ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> <nl> - / / If LookupTy is a non - archetype , look up its conformance . <nl> - ProtocolDecl * proto <nl> - = dyn_cast < ProtocolDecl > ( Member . getDecl ( ) - > getDeclContext ( ) ) ; <nl> - if ( ! proto ) { <nl> - P . diagnose ( TyLoc , diag : : sil_witness_method_not_protocol ) ; <nl> - return true ; <nl> - } <nl> - auto conformance = P . SF . getParentModule ( ) - > lookupConformance ( LookupTy , proto ) ; <nl> - if ( conformance . isInvalid ( ) ) { <nl> - P . diagnose ( TyLoc , diag : : sil_witness_method_type_does_not_conform ) ; <nl> - return true ; <nl> + / / If LookupTy is a non - archetype , look up its conformance . <nl> + ProtocolDecl * proto = <nl> + dyn_cast < ProtocolDecl > ( Member . getDecl ( ) - > getDeclContext ( ) ) ; <nl> + if ( ! proto ) { <nl> + P . diagnose ( TyLoc , diag : : sil_witness_method_not_protocol ) ; <nl> + return true ; <nl> + } <nl> + auto conformance = <nl> + P . SF . getParentModule ( ) - > lookupConformance ( LookupTy , proto ) ; <nl> + if ( conformance . isInvalid ( ) ) { <nl> + P . diagnose ( TyLoc , diag : : sil_witness_method_type_does_not_conform ) ; <nl> + return true ; <nl> + } <nl> + <nl> + ResultVal = B . createWitnessMethod ( InstLoc , LookupTy , conformance , Member , <nl> + MethodTy ) ; <nl> + break ; <nl> } <nl> + case SILInstructionKind : : CopyAddrInst : { <nl> + bool IsTake = false , IsInit = false ; <nl> + UnresolvedValueName SrcLName ; <nl> + SILValue DestLVal ; <nl> + SourceLoc ToLoc , DestLoc ; <nl> + Identifier ToToken ; <nl> + if ( parseSILOptional ( IsTake , * this , \" take \" ) | | parseValueName ( SrcLName ) | | <nl> + parseSILIdentifier ( ToToken , ToLoc , diag : : expected_tok_in_sil_instr , <nl> + \" to \" ) | | <nl> + parseSILOptional ( IsInit , * this , \" initialization \" ) | | <nl> + parseTypedValueRef ( DestLVal , DestLoc , B ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> <nl> - ResultVal = <nl> - B . createWitnessMethod ( InstLoc , LookupTy , conformance , Member , MethodTy ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : CopyAddrInst : { <nl> - bool IsTake = false , IsInit = false ; <nl> - UnresolvedValueName SrcLName ; <nl> - SILValue DestLVal ; <nl> - SourceLoc ToLoc , DestLoc ; <nl> - Identifier ToToken ; <nl> - if ( parseSILOptional ( IsTake , * this , \" take \" ) | | parseValueName ( SrcLName ) | | <nl> - parseSILIdentifier ( ToToken , ToLoc , <nl> - diag : : expected_tok_in_sil_instr , \" to \" ) | | <nl> - parseSILOptional ( IsInit , * this , \" initialization \" ) | | <nl> - parseTypedValueRef ( DestLVal , DestLoc , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> + if ( ToToken . str ( ) ! = \" to \" ) { <nl> + P . diagnose ( ToLoc , diag : : expected_tok_in_sil_instr , \" to \" ) ; <nl> + return true ; <nl> + } <nl> <nl> - if ( ToToken . str ( ) ! = \" to \" ) { <nl> - P . diagnose ( ToLoc , diag : : expected_tok_in_sil_instr , \" to \" ) ; <nl> - return true ; <nl> - } <nl> + if ( ! DestLVal - > getType ( ) . isAddress ( ) ) { <nl> + P . diagnose ( DestLoc , diag : : sil_invalid_instr_operands ) ; <nl> + return true ; <nl> + } <nl> <nl> - if ( ! DestLVal - > getType ( ) . isAddress ( ) ) { <nl> - P . diagnose ( DestLoc , diag : : sil_invalid_instr_operands ) ; <nl> - return true ; <nl> + SILValue SrcLVal = <nl> + getLocalValue ( SrcLName , DestLVal - > getType ( ) , InstLoc , B ) ; <nl> + ResultVal = B . createCopyAddr ( InstLoc , SrcLVal , DestLVal , IsTake_t ( IsTake ) , <nl> + IsInitialization_t ( IsInit ) ) ; <nl> + break ; <nl> } <nl> + case SILInstructionKind : : BindMemoryInst : { <nl> + SILValue IndexVal ; <nl> + Identifier ToToken ; <nl> + SourceLoc ToLoc ; <nl> + SILType EltTy ; <nl> + if ( parseTypedValueRef ( Val , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseTypedValueRef ( IndexVal , B ) | | <nl> + parseSILIdentifier ( ToToken , ToLoc , diag : : expected_tok_in_sil_instr , <nl> + \" to \" ) | | <nl> + parseSILType ( EltTy ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> <nl> - SILValue SrcLVal = getLocalValue ( SrcLName , DestLVal - > getType ( ) , InstLoc , B ) ; <nl> - ResultVal = B . createCopyAddr ( InstLoc , SrcLVal , DestLVal , <nl> - IsTake_t ( IsTake ) , <nl> - IsInitialization_t ( IsInit ) ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : BindMemoryInst : { <nl> - SILValue IndexVal ; <nl> - Identifier ToToken ; <nl> - SourceLoc ToLoc ; <nl> - SILType EltTy ; <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseTypedValueRef ( IndexVal , B ) | | <nl> - parseSILIdentifier ( ToToken , ToLoc , <nl> - diag : : expected_tok_in_sil_instr , \" to \" ) | | <nl> - parseSILType ( EltTy ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - <nl> - if ( ToToken . str ( ) ! = \" to \" ) { <nl> - P . diagnose ( ToLoc , diag : : expected_tok_in_sil_instr , \" to \" ) ; <nl> - return true ; <nl> + if ( ToToken . str ( ) ! = \" to \" ) { <nl> + P . diagnose ( ToLoc , diag : : expected_tok_in_sil_instr , \" to \" ) ; <nl> + return true ; <nl> + } <nl> + ResultVal = B . createBindMemory ( InstLoc , Val , IndexVal , EltTy ) ; <nl> + break ; <nl> } <nl> - ResultVal = B . createBindMemory ( InstLoc , Val , IndexVal , EltTy ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : ObjectInst : <nl> - case SILInstructionKind : : StructInst : { <nl> - SILType Ty ; <nl> - if ( parseSILType ( Ty ) | | <nl> - P . parseToken ( tok : : l_paren , diag : : expected_tok_in_sil_instr , \" ( \" ) ) <nl> - return true ; <nl> + case SILInstructionKind : : ObjectInst : <nl> + case SILInstructionKind : : StructInst : { <nl> + SILType Ty ; <nl> + if ( parseSILType ( Ty ) | | <nl> + P . parseToken ( tok : : l_paren , diag : : expected_tok_in_sil_instr , \" ( \" ) ) <nl> + return true ; <nl> <nl> - / / Parse a list of SILValue . <nl> - bool OpsAreTailElems = false ; <nl> - unsigned NumBaseElems = 0 ; <nl> - if ( P . Tok . isNot ( tok : : r_paren ) ) { <nl> - do { <nl> - if ( Opcode = = SILInstructionKind : : ObjectInst ) { <nl> - if ( parseSILOptional ( OpsAreTailElems , * this , \" tail_elems \" ) ) <nl> + / / Parse a list of SILValue . <nl> + bool OpsAreTailElems = false ; <nl> + unsigned NumBaseElems = 0 ; <nl> + if ( P . Tok . isNot ( tok : : r_paren ) ) { <nl> + do { <nl> + if ( Opcode = = SILInstructionKind : : ObjectInst ) { <nl> + if ( parseSILOptional ( OpsAreTailElems , * this , \" tail_elems \" ) ) <nl> + return true ; <nl> + } <nl> + if ( parseTypedValueRef ( Val , B ) ) <nl> return true ; <nl> - } <nl> - if ( parseTypedValueRef ( Val , B ) ) return true ; <nl> - OpList . push_back ( Val ) ; <nl> - if ( ! OpsAreTailElems ) <nl> - NumBaseElems = OpList . size ( ) ; <nl> - } while ( P . consumeIf ( tok : : comma ) ) ; <nl> - } <nl> - if ( P . parseToken ( tok : : r_paren , <nl> - diag : : expected_tok_in_sil_instr , \" ) \" ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> + OpList . push_back ( Val ) ; <nl> + if ( ! OpsAreTailElems ) <nl> + NumBaseElems = OpList . size ( ) ; <nl> + } while ( P . consumeIf ( tok : : comma ) ) ; <nl> + } <nl> + if ( P . parseToken ( tok : : r_paren , diag : : expected_tok_in_sil_instr , \" ) \" ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> <nl> - if ( Opcode = = SILInstructionKind : : StructInst ) { <nl> - ResultVal = B . createStruct ( InstLoc , Ty , OpList ) ; <nl> - } else { <nl> - ResultVal = B . createObject ( InstLoc , Ty , OpList , NumBaseElems ) ; <nl> + if ( Opcode = = SILInstructionKind : : StructInst ) { <nl> + ResultVal = B . createStruct ( InstLoc , Ty , OpList ) ; <nl> + } else { <nl> + ResultVal = B . createObject ( InstLoc , Ty , OpList , NumBaseElems ) ; <nl> + } <nl> + break ; <nl> } <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : StructElementAddrInst : <nl> - case SILInstructionKind : : StructExtractInst : { <nl> - ValueDecl * FieldV ; <nl> - SourceLoc NameLoc = P . Tok . getLoc ( ) ; <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILDottedPath ( FieldV ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - if ( ! FieldV | | ! isa < VarDecl > ( FieldV ) ) { <nl> - P . diagnose ( NameLoc , diag : : sil_struct_inst_wrong_field ) ; <nl> - return true ; <nl> + case SILInstructionKind : : StructElementAddrInst : <nl> + case SILInstructionKind : : StructExtractInst : { <nl> + ValueDecl * FieldV ; <nl> + SourceLoc NameLoc = P . Tok . getLoc ( ) ; <nl> + if ( parseTypedValueRef ( Val , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILDottedPath ( FieldV ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + if ( ! FieldV | | ! isa < VarDecl > ( FieldV ) ) { <nl> + P . diagnose ( NameLoc , diag : : sil_struct_inst_wrong_field ) ; <nl> + return true ; <nl> + } <nl> + VarDecl * Field = cast < VarDecl > ( FieldV ) ; <nl> + <nl> + / / FIXME : substitution means this type should be explicit to improve <nl> + / / performance . <nl> + auto ResultTy = Val - > getType ( ) . getFieldType ( Field , SILMod , <nl> + B . getTypeExpansionContext ( ) ) ; <nl> + if ( Opcode = = SILInstructionKind : : StructElementAddrInst ) <nl> + ResultVal = B . createStructElementAddr ( InstLoc , Val , Field , <nl> + ResultTy . getAddressType ( ) ) ; <nl> + else <nl> + ResultVal = B . createStructExtract ( InstLoc , Val , Field , <nl> + ResultTy . getObjectType ( ) ) ; <nl> + break ; <nl> } <nl> - VarDecl * Field = cast < VarDecl > ( FieldV ) ; <nl> - <nl> - / / FIXME : substitution means this type should be explicit to improve <nl> - / / performance . <nl> - auto ResultTy = <nl> - Val - > getType ( ) . getFieldType ( Field , SILMod , B . getTypeExpansionContext ( ) ) ; <nl> - if ( Opcode = = SILInstructionKind : : StructElementAddrInst ) <nl> - ResultVal = B . createStructElementAddr ( InstLoc , Val , Field , <nl> - ResultTy . getAddressType ( ) ) ; <nl> - else <nl> - ResultVal = B . createStructExtract ( InstLoc , Val , Field , <nl> - ResultTy . getObjectType ( ) ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : RefElementAddrInst : { <nl> - ValueDecl * FieldV ; <nl> - SourceLoc NameLoc ; <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILDottedPath ( FieldV ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - if ( ! FieldV | | ! isa < VarDecl > ( FieldV ) ) { <nl> - P . diagnose ( NameLoc , diag : : sil_ref_inst_wrong_field ) ; <nl> - return true ; <nl> + case SILInstructionKind : : RefElementAddrInst : { <nl> + ValueDecl * FieldV ; <nl> + SourceLoc NameLoc ; <nl> + if ( parseTypedValueRef ( Val , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILDottedPath ( FieldV ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + if ( ! FieldV | | ! isa < VarDecl > ( FieldV ) ) { <nl> + P . diagnose ( NameLoc , diag : : sil_ref_inst_wrong_field ) ; <nl> + return true ; <nl> + } <nl> + VarDecl * Field = cast < VarDecl > ( FieldV ) ; <nl> + auto ResultTy = Val - > getType ( ) . getFieldType ( Field , SILMod , <nl> + B . getTypeExpansionContext ( ) ) ; <nl> + ResultVal = B . createRefElementAddr ( InstLoc , Val , Field , ResultTy ) ; <nl> + break ; <nl> } <nl> - VarDecl * Field = cast < VarDecl > ( FieldV ) ; <nl> - auto ResultTy = <nl> - Val - > getType ( ) . getFieldType ( Field , SILMod , B . getTypeExpansionContext ( ) ) ; <nl> - ResultVal = B . createRefElementAddr ( InstLoc , Val , Field , ResultTy ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : RefTailAddrInst : { <nl> - SourceLoc NameLoc ; <nl> - SILType ResultObjTy ; <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILType ( ResultObjTy ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - SILType ResultTy = ResultObjTy . getAddressType ( ) ; <nl> - ResultVal = B . createRefTailAddr ( InstLoc , Val , ResultTy ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : IndexAddrInst : { <nl> - SILValue IndexVal ; <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseTypedValueRef ( IndexVal , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - ResultVal = B . createIndexAddr ( InstLoc , Val , IndexVal ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : TailAddrInst : { <nl> - SILValue IndexVal ; <nl> - SILType ResultObjTy ; <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseTypedValueRef ( IndexVal , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILType ( ResultObjTy ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - SILType ResultTy = ResultObjTy . getAddressType ( ) ; <nl> - ResultVal = B . createTailAddr ( InstLoc , Val , IndexVal , ResultTy ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : IndexRawPointerInst : { <nl> - SILValue IndexVal ; <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseTypedValueRef ( IndexVal , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - ResultVal = B . createIndexRawPointer ( InstLoc , Val , IndexVal ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : ObjCProtocolInst : { <nl> - Identifier ProtocolName ; <nl> - SILType Ty ; <nl> - if ( P . parseToken ( tok : : pound , diag : : expected_sil_constant ) | | <nl> - parseSILIdentifier ( ProtocolName , diag : : expected_sil_constant ) | | <nl> - P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) | | <nl> - parseSILType ( Ty ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - / / Find the decl for the protocol name . <nl> - ValueDecl * VD ; <nl> - SmallVector < ValueDecl * , 4 > CurModuleResults ; <nl> - / / Perform a module level lookup on the first component of the <nl> - / / fully - qualified name . <nl> - P . SF . getParentModule ( ) - > lookupValue ( ProtocolName , <nl> - NLKind : : UnqualifiedLookup , <nl> - CurModuleResults ) ; <nl> - assert ( CurModuleResults . size ( ) = = 1 ) ; <nl> - VD = CurModuleResults [ 0 ] ; <nl> - ResultVal = B . createObjCProtocol ( InstLoc , cast < ProtocolDecl > ( VD ) , Ty ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : AllocGlobalInst : { <nl> - Identifier GlobalName ; <nl> - SourceLoc IdLoc ; <nl> - if ( P . parseToken ( tok : : at_sign , diag : : expected_sil_value_name ) | | <nl> - parseSILIdentifier ( GlobalName , IdLoc , diag : : expected_sil_value_name ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - <nl> - / / Go through list of global variables in the SILModule . <nl> - SILGlobalVariable * global = SILMod . lookUpGlobalVariable ( GlobalName . str ( ) ) ; <nl> - if ( ! global ) { <nl> - P . diagnose ( IdLoc , diag : : sil_global_variable_not_found , GlobalName ) ; <nl> - return true ; <nl> + case SILInstructionKind : : RefTailAddrInst : { <nl> + SourceLoc NameLoc ; <nl> + SILType ResultObjTy ; <nl> + if ( parseTypedValueRef ( Val , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILType ( ResultObjTy ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + SILType ResultTy = ResultObjTy . getAddressType ( ) ; <nl> + ResultVal = B . createRefTailAddr ( InstLoc , Val , ResultTy ) ; <nl> + break ; <nl> } <nl> - <nl> - ResultVal = B . createAllocGlobal ( InstLoc , global ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : GlobalAddrInst : <nl> - case SILInstructionKind : : GlobalValueInst : { <nl> - Identifier GlobalName ; <nl> - SourceLoc IdLoc ; <nl> - SILType Ty ; <nl> - if ( P . parseToken ( tok : : at_sign , diag : : expected_sil_value_name ) | | <nl> - parseSILIdentifier ( GlobalName , IdLoc , diag : : expected_sil_value_name ) | | <nl> - P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) | | <nl> - parseSILType ( Ty ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - <nl> - / / Go through list of global variables in the SILModule . <nl> - SILGlobalVariable * global = SILMod . lookUpGlobalVariable ( GlobalName . str ( ) ) ; <nl> - if ( ! global ) { <nl> - P . diagnose ( IdLoc , diag : : sil_global_variable_not_found , GlobalName ) ; <nl> - return true ; <nl> + case SILInstructionKind : : IndexAddrInst : { <nl> + SILValue IndexVal ; <nl> + if ( parseTypedValueRef ( Val , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseTypedValueRef ( IndexVal , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + ResultVal = B . createIndexAddr ( InstLoc , Val , IndexVal ) ; <nl> + break ; <nl> } <nl> - <nl> - SILType expectedType = ( Opcode = = SILInstructionKind : : GlobalAddrInst ? <nl> - global - > getLoweredType ( ) . getAddressType ( ) : <nl> - global - > getLoweredType ( ) ) ; <nl> - if ( expectedType ! = Ty ) { <nl> - P . diagnose ( IdLoc , diag : : sil_value_use_type_mismatch , GlobalName . str ( ) , <nl> - global - > getLoweredType ( ) . getASTType ( ) , <nl> - Ty . getASTType ( ) ) ; <nl> - return true ; <nl> + case SILInstructionKind : : TailAddrInst : { <nl> + SILValue IndexVal ; <nl> + SILType ResultObjTy ; <nl> + if ( parseTypedValueRef ( Val , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseTypedValueRef ( IndexVal , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILType ( ResultObjTy ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + SILType ResultTy = ResultObjTy . getAddressType ( ) ; <nl> + ResultVal = B . createTailAddr ( InstLoc , Val , IndexVal , ResultTy ) ; <nl> + break ; <nl> } <nl> + case SILInstructionKind : : IndexRawPointerInst : { <nl> + SILValue IndexVal ; <nl> + if ( parseTypedValueRef ( Val , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseTypedValueRef ( IndexVal , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + ResultVal = B . createIndexRawPointer ( InstLoc , Val , IndexVal ) ; <nl> + break ; <nl> + } <nl> + case SILInstructionKind : : ObjCProtocolInst : { <nl> + Identifier ProtocolName ; <nl> + SILType Ty ; <nl> + if ( P . parseToken ( tok : : pound , diag : : expected_sil_constant ) | | <nl> + parseSILIdentifier ( ProtocolName , diag : : expected_sil_constant ) | | <nl> + P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) | | <nl> + parseSILType ( Ty ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + / / Find the decl for the protocol name . <nl> + ValueDecl * VD ; <nl> + SmallVector < ValueDecl * , 4 > CurModuleResults ; <nl> + / / Perform a module level lookup on the first component of the <nl> + / / fully - qualified name . <nl> + P . SF . getParentModule ( ) - > lookupValue ( <nl> + ProtocolName , NLKind : : UnqualifiedLookup , CurModuleResults ) ; <nl> + assert ( CurModuleResults . size ( ) = = 1 ) ; <nl> + VD = CurModuleResults [ 0 ] ; <nl> + ResultVal = B . createObjCProtocol ( InstLoc , cast < ProtocolDecl > ( VD ) , Ty ) ; <nl> + break ; <nl> + } <nl> + case SILInstructionKind : : AllocGlobalInst : { <nl> + Identifier GlobalName ; <nl> + SourceLoc IdLoc ; <nl> + if ( P . parseToken ( tok : : at_sign , diag : : expected_sil_value_name ) | | <nl> + parseSILIdentifier ( GlobalName , IdLoc , <nl> + diag : : expected_sil_value_name ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> <nl> - if ( Opcode = = SILInstructionKind : : GlobalAddrInst ) { <nl> - ResultVal = B . createGlobalAddr ( InstLoc , global ) ; <nl> - } else { <nl> - ResultVal = B . createGlobalValue ( InstLoc , global ) ; <nl> + / / Go through list of global variables in the SILModule . <nl> + SILGlobalVariable * global = SILMod . lookUpGlobalVariable ( GlobalName . str ( ) ) ; <nl> + if ( ! global ) { <nl> + P . diagnose ( IdLoc , diag : : sil_global_variable_not_found , GlobalName ) ; <nl> + return true ; <nl> + } <nl> + <nl> + ResultVal = B . createAllocGlobal ( InstLoc , global ) ; <nl> + break ; <nl> } <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : SelectEnumInst : <nl> - case SILInstructionKind : : SelectEnumAddrInst : { <nl> - if ( parseTypedValueRef ( Val , B ) ) <nl> - return true ; <nl> + case SILInstructionKind : : GlobalAddrInst : <nl> + case SILInstructionKind : : GlobalValueInst : { <nl> + Identifier GlobalName ; <nl> + SourceLoc IdLoc ; <nl> + SILType Ty ; <nl> + if ( P . parseToken ( tok : : at_sign , diag : : expected_sil_value_name ) | | <nl> + parseSILIdentifier ( GlobalName , IdLoc , <nl> + diag : : expected_sil_value_name ) | | <nl> + P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) | | <nl> + parseSILType ( Ty ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> <nl> - SmallVector < std : : pair < EnumElementDecl * , UnresolvedValueName > , 4 > <nl> - CaseValueNames ; <nl> - Optional < UnresolvedValueName > DefaultValueName ; <nl> - while ( P . consumeIf ( tok : : comma ) ) { <nl> - Identifier BBName ; <nl> - SourceLoc BBLoc ; <nl> - / / Parse ' default ' sil - value . <nl> - UnresolvedValueName tmp ; <nl> - if ( P . consumeIf ( tok : : kw_default ) ) { <nl> - if ( parseValueName ( tmp ) ) <nl> - return true ; <nl> - DefaultValueName = tmp ; <nl> - break ; <nl> + / / Go through list of global variables in the SILModule . <nl> + SILGlobalVariable * global = SILMod . lookUpGlobalVariable ( GlobalName . str ( ) ) ; <nl> + if ( ! global ) { <nl> + P . diagnose ( IdLoc , diag : : sil_global_variable_not_found , GlobalName ) ; <nl> + return true ; <nl> } <nl> <nl> - / / Parse ' case ' sil - decl - ref ' : ' sil - value . <nl> - if ( P . consumeIf ( tok : : kw_case ) ) { <nl> - SILDeclRef ElemRef ; <nl> - if ( parseSILDeclRef ( ElemRef ) ) <nl> - return true ; <nl> - assert ( ElemRef . hasDecl ( ) & & isa < EnumElementDecl > ( ElemRef . getDecl ( ) ) ) ; <nl> - P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) ; <nl> - parseValueName ( tmp ) ; <nl> - CaseValueNames . push_back ( std : : make_pair ( <nl> - cast < EnumElementDecl > ( ElemRef . getDecl ( ) ) , <nl> - tmp ) ) ; <nl> - continue ; <nl> + SILType expectedType = ( Opcode = = SILInstructionKind : : GlobalAddrInst <nl> + ? global - > getLoweredType ( ) . getAddressType ( ) <nl> + : global - > getLoweredType ( ) ) ; <nl> + if ( expectedType ! = Ty ) { <nl> + P . diagnose ( IdLoc , diag : : sil_value_use_type_mismatch , GlobalName . str ( ) , <nl> + global - > getLoweredType ( ) . getASTType ( ) , Ty . getASTType ( ) ) ; <nl> + return true ; <nl> } <nl> <nl> - P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" case or default \" ) ; <nl> - return true ; <nl> + if ( Opcode = = SILInstructionKind : : GlobalAddrInst ) { <nl> + ResultVal = B . createGlobalAddr ( InstLoc , global ) ; <nl> + } else { <nl> + ResultVal = B . createGlobalValue ( InstLoc , global ) ; <nl> + } <nl> + break ; <nl> } <nl> - <nl> - / / Parse the type of the result operands . <nl> - SILType ResultType ; <nl> - if ( P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) <nl> - | | parseSILType ( ResultType ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - <nl> - / / Resolve the results . <nl> - SmallVector < std : : pair < EnumElementDecl * , SILValue > , 4 > CaseValues ; <nl> - SILValue DefaultValue ; <nl> - if ( DefaultValueName ) <nl> - DefaultValue = getLocalValue ( * DefaultValueName , ResultType , InstLoc , B ) ; <nl> - for ( auto & caseName : CaseValueNames ) <nl> - CaseValues . push_back ( std : : make_pair ( <nl> - caseName . first , <nl> - getLocalValue ( caseName . second , ResultType , InstLoc , B ) ) ) ; <nl> - <nl> - if ( Opcode = = SILInstructionKind : : SelectEnumInst ) <nl> - ResultVal = B . createSelectEnum ( InstLoc , Val , ResultType , <nl> - DefaultValue , CaseValues ) ; <nl> - else <nl> - ResultVal = B . createSelectEnumAddr ( InstLoc , Val , ResultType , <nl> - DefaultValue , CaseValues ) ; <nl> - break ; <nl> - } <nl> - <nl> - case SILInstructionKind : : SwitchEnumInst : <nl> - case SILInstructionKind : : SwitchEnumAddrInst : { <nl> - if ( parseTypedValueRef ( Val , B ) ) <nl> - return true ; <nl> + case SILInstructionKind : : SelectEnumInst : <nl> + case SILInstructionKind : : SelectEnumAddrInst : { <nl> + if ( parseTypedValueRef ( Val , B ) ) <nl> + return true ; <nl> <nl> - SmallVector < std : : pair < EnumElementDecl * , SILBasicBlock * > , 4 > CaseBBs ; <nl> - SILBasicBlock * DefaultBB = nullptr ; <nl> - while ( ! peekSILDebugLocation ( P ) & & P . consumeIf ( tok : : comma ) ) { <nl> - Identifier BBName ; <nl> - SourceLoc BBLoc ; <nl> - / / Parse ' default ' sil - identifier . <nl> - if ( P . consumeIf ( tok : : kw_default ) ) { <nl> - parseSILIdentifier ( BBName , BBLoc , diag : : expected_sil_block_name ) ; <nl> - DefaultBB = getBBForReference ( BBName , BBLoc ) ; <nl> - break ; <nl> - } <nl> + SmallVector < std : : pair < EnumElementDecl * , UnresolvedValueName > , 4 > <nl> + CaseValueNames ; <nl> + Optional < UnresolvedValueName > DefaultValueName ; <nl> + while ( P . consumeIf ( tok : : comma ) ) { <nl> + Identifier BBName ; <nl> + SourceLoc BBLoc ; <nl> + / / Parse ' default ' sil - value . <nl> + UnresolvedValueName tmp ; <nl> + if ( P . consumeIf ( tok : : kw_default ) ) { <nl> + if ( parseValueName ( tmp ) ) <nl> + return true ; <nl> + DefaultValueName = tmp ; <nl> + break ; <nl> + } <nl> <nl> - / / Parse ' case ' sil - decl - ref ' : ' sil - identifier . <nl> - if ( P . consumeIf ( tok : : kw_case ) ) { <nl> - SILDeclRef ElemRef ; <nl> - if ( parseSILDeclRef ( ElemRef ) ) <nl> - return true ; <nl> - assert ( ElemRef . hasDecl ( ) & & isa < EnumElementDecl > ( ElemRef . getDecl ( ) ) ) ; <nl> - P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) ; <nl> - parseSILIdentifier ( BBName , BBLoc , diag : : expected_sil_block_name ) ; <nl> - CaseBBs . push_back ( { cast < EnumElementDecl > ( ElemRef . getDecl ( ) ) , <nl> - getBBForReference ( BBName , BBLoc ) } ) ; <nl> - continue ; <nl> + / / Parse ' case ' sil - decl - ref ' : ' sil - value . <nl> + if ( P . consumeIf ( tok : : kw_case ) ) { <nl> + SILDeclRef ElemRef ; <nl> + if ( parseSILDeclRef ( ElemRef ) ) <nl> + return true ; <nl> + assert ( ElemRef . hasDecl ( ) & & isa < EnumElementDecl > ( ElemRef . getDecl ( ) ) ) ; <nl> + P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) ; <nl> + parseValueName ( tmp ) ; <nl> + CaseValueNames . push_back ( <nl> + std : : make_pair ( cast < EnumElementDecl > ( ElemRef . getDecl ( ) ) , tmp ) ) ; <nl> + continue ; <nl> + } <nl> + <nl> + P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" case or default \" ) ; <nl> + return true ; <nl> } <nl> <nl> - P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" case or default \" ) ; <nl> - return true ; <nl> + / / Parse the type of the result operands . <nl> + SILType ResultType ; <nl> + if ( P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) | | <nl> + parseSILType ( ResultType ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + <nl> + / / Resolve the results . <nl> + SmallVector < std : : pair < EnumElementDecl * , SILValue > , 4 > CaseValues ; <nl> + SILValue DefaultValue ; <nl> + if ( DefaultValueName ) <nl> + DefaultValue = getLocalValue ( * DefaultValueName , ResultType , InstLoc , B ) ; <nl> + for ( auto & caseName : CaseValueNames ) <nl> + CaseValues . push_back ( std : : make_pair ( <nl> + caseName . first , <nl> + getLocalValue ( caseName . second , ResultType , InstLoc , B ) ) ) ; <nl> + <nl> + if ( Opcode = = SILInstructionKind : : SelectEnumInst ) <nl> + ResultVal = B . createSelectEnum ( InstLoc , Val , ResultType , DefaultValue , <nl> + CaseValues ) ; <nl> + else <nl> + ResultVal = B . createSelectEnumAddr ( InstLoc , Val , ResultType , <nl> + DefaultValue , CaseValues ) ; <nl> + break ; <nl> } <nl> - if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - if ( Opcode = = SILInstructionKind : : SwitchEnumInst ) <nl> - ResultVal = B . createSwitchEnum ( InstLoc , Val , DefaultBB , CaseBBs ) ; <nl> - else <nl> - ResultVal = B . createSwitchEnumAddr ( InstLoc , Val , DefaultBB , CaseBBs ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : SwitchValueInst : { <nl> - if ( parseTypedValueRef ( Val , B ) ) <nl> - return true ; <nl> <nl> - SmallVector < std : : pair < SILValue , SILBasicBlock * > , 4 > CaseBBs ; <nl> - SILBasicBlock * DefaultBB = nullptr ; <nl> - while ( ! peekSILDebugLocation ( P ) & & P . consumeIf ( tok : : comma ) ) { <nl> - Identifier BBName ; <nl> - SourceLoc BBLoc ; <nl> - SILValue CaseVal ; <nl> - <nl> - / / Parse ' default ' sil - identifier . <nl> - if ( P . consumeIf ( tok : : kw_default ) ) { <nl> - parseSILIdentifier ( BBName , BBLoc , diag : : expected_sil_block_name ) ; <nl> - DefaultBB = getBBForReference ( BBName , BBLoc ) ; <nl> - break ; <nl> - } <nl> + case SILInstructionKind : : SwitchEnumInst : <nl> + case SILInstructionKind : : SwitchEnumAddrInst : { <nl> + if ( parseTypedValueRef ( Val , B ) ) <nl> + return true ; <nl> <nl> - / / Parse ' case ' value - ref ' : ' sil - identifier . <nl> - if ( P . consumeIf ( tok : : kw_case ) ) { <nl> - if ( parseValueRef ( CaseVal , Val - > getType ( ) , <nl> - RegularLocation ( P . Tok . getLoc ( ) ) , B ) ) { <nl> - / / TODO : Issue a proper error message here <nl> - P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" reference to a value \" ) ; <nl> - return true ; <nl> + SmallVector < std : : pair < EnumElementDecl * , SILBasicBlock * > , 4 > CaseBBs ; <nl> + SILBasicBlock * DefaultBB = nullptr ; <nl> + while ( ! peekSILDebugLocation ( P ) & & P . consumeIf ( tok : : comma ) ) { <nl> + Identifier BBName ; <nl> + SourceLoc BBLoc ; <nl> + / / Parse ' default ' sil - identifier . <nl> + if ( P . consumeIf ( tok : : kw_default ) ) { <nl> + parseSILIdentifier ( BBName , BBLoc , diag : : expected_sil_block_name ) ; <nl> + DefaultBB = getBBForReference ( BBName , BBLoc ) ; <nl> + break ; <nl> } <nl> <nl> - auto intTy = Val - > getType ( ) . getAs < BuiltinIntegerType > ( ) ; <nl> - auto functionTy = Val - > getType ( ) . getAs < SILFunctionType > ( ) ; <nl> - if ( ! intTy & & ! functionTy ) { <nl> - P . diagnose ( P . Tok , diag : : sil_integer_literal_not_integer_type ) ; <nl> - return true ; <nl> + / / Parse ' case ' sil - decl - ref ' : ' sil - identifier . <nl> + if ( P . consumeIf ( tok : : kw_case ) ) { <nl> + SILDeclRef ElemRef ; <nl> + if ( parseSILDeclRef ( ElemRef ) ) <nl> + return true ; <nl> + assert ( ElemRef . hasDecl ( ) & & isa < EnumElementDecl > ( ElemRef . getDecl ( ) ) ) ; <nl> + P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) ; <nl> + parseSILIdentifier ( BBName , BBLoc , diag : : expected_sil_block_name ) ; <nl> + CaseBBs . push_back ( { cast < EnumElementDecl > ( ElemRef . getDecl ( ) ) , <nl> + getBBForReference ( BBName , BBLoc ) } ) ; <nl> + continue ; <nl> } <nl> <nl> - if ( intTy ) { <nl> - / / If it is a switch on an integer type , check that all case values <nl> - / / are integer literals or undef . <nl> - if ( ! isa < SILUndef > ( CaseVal ) ) { <nl> - auto * IL = dyn_cast < IntegerLiteralInst > ( CaseVal ) ; <nl> - if ( ! IL ) { <nl> - P . diagnose ( P . Tok , diag : : sil_integer_literal_not_integer_type ) ; <nl> - return true ; <nl> - } <nl> - APInt CaseValue = IL - > getValue ( ) ; <nl> + P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" case or default \" ) ; <nl> + return true ; <nl> + } <nl> + if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + if ( Opcode = = SILInstructionKind : : SwitchEnumInst ) <nl> + ResultVal = B . createSwitchEnum ( InstLoc , Val , DefaultBB , CaseBBs ) ; <nl> + else <nl> + ResultVal = B . createSwitchEnumAddr ( InstLoc , Val , DefaultBB , CaseBBs ) ; <nl> + break ; <nl> + } <nl> + case SILInstructionKind : : SwitchValueInst : { <nl> + if ( parseTypedValueRef ( Val , B ) ) <nl> + return true ; <nl> <nl> - if ( CaseValue . getBitWidth ( ) ! = intTy - > getGreatestWidth ( ) ) <nl> - CaseVal = B . createIntegerLiteral ( <nl> - IL - > getLoc ( ) , Val - > getType ( ) , <nl> - CaseValue . zextOrTrunc ( intTy - > getGreatestWidth ( ) ) ) ; <nl> - } <nl> + SmallVector < std : : pair < SILValue , SILBasicBlock * > , 4 > CaseBBs ; <nl> + SILBasicBlock * DefaultBB = nullptr ; <nl> + while ( ! peekSILDebugLocation ( P ) & & P . consumeIf ( tok : : comma ) ) { <nl> + Identifier BBName ; <nl> + SourceLoc BBLoc ; <nl> + SILValue CaseVal ; <nl> + <nl> + / / Parse ' default ' sil - identifier . <nl> + if ( P . consumeIf ( tok : : kw_default ) ) { <nl> + parseSILIdentifier ( BBName , BBLoc , diag : : expected_sil_block_name ) ; <nl> + DefaultBB = getBBForReference ( BBName , BBLoc ) ; <nl> + break ; <nl> } <nl> <nl> - if ( functionTy ) { <nl> - / / If it is a switch on a function type , check that all case values <nl> - / / are function references or undef . <nl> - if ( ! isa < SILUndef > ( CaseVal ) ) { <nl> - auto * FR = dyn_cast < FunctionRefInst > ( CaseVal ) ; <nl> - if ( ! FR ) { <nl> - if ( auto * CF = dyn_cast < ConvertFunctionInst > ( CaseVal ) ) { <nl> - FR = dyn_cast < FunctionRefInst > ( CF - > getOperand ( ) ) ; <nl> + / / Parse ' case ' value - ref ' : ' sil - identifier . <nl> + if ( P . consumeIf ( tok : : kw_case ) ) { <nl> + if ( parseValueRef ( CaseVal , Val - > getType ( ) , <nl> + RegularLocation ( P . Tok . getLoc ( ) ) , B ) ) { <nl> + / / TODO : Issue a proper error message here <nl> + P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , <nl> + \" reference to a value \" ) ; <nl> + return true ; <nl> + } <nl> + <nl> + auto intTy = Val - > getType ( ) . getAs < BuiltinIntegerType > ( ) ; <nl> + auto functionTy = Val - > getType ( ) . getAs < SILFunctionType > ( ) ; <nl> + if ( ! intTy & & ! functionTy ) { <nl> + P . diagnose ( P . Tok , diag : : sil_integer_literal_not_integer_type ) ; <nl> + return true ; <nl> + } <nl> + <nl> + if ( intTy ) { <nl> + / / If it is a switch on an integer type , check that all case values <nl> + / / are integer literals or undef . <nl> + if ( ! isa < SILUndef > ( CaseVal ) ) { <nl> + auto * IL = dyn_cast < IntegerLiteralInst > ( CaseVal ) ; <nl> + if ( ! IL ) { <nl> + P . diagnose ( P . Tok , diag : : sil_integer_literal_not_integer_type ) ; <nl> + return true ; <nl> } <nl> + APInt CaseValue = IL - > getValue ( ) ; <nl> + <nl> + if ( CaseValue . getBitWidth ( ) ! = intTy - > getGreatestWidth ( ) ) <nl> + CaseVal = B . createIntegerLiteral ( <nl> + IL - > getLoc ( ) , Val - > getType ( ) , <nl> + CaseValue . zextOrTrunc ( intTy - > getGreatestWidth ( ) ) ) ; <nl> } <nl> - if ( ! FR ) { <nl> - P . diagnose ( P . Tok , diag : : sil_integer_literal_not_integer_type ) ; <nl> - return true ; <nl> + } <nl> + <nl> + if ( functionTy ) { <nl> + / / If it is a switch on a function type , check that all case values <nl> + / / are function references or undef . <nl> + if ( ! isa < SILUndef > ( CaseVal ) ) { <nl> + auto * FR = dyn_cast < FunctionRefInst > ( CaseVal ) ; <nl> + if ( ! FR ) { <nl> + if ( auto * CF = dyn_cast < ConvertFunctionInst > ( CaseVal ) ) { <nl> + FR = dyn_cast < FunctionRefInst > ( CF - > getOperand ( ) ) ; <nl> + } <nl> + } <nl> + if ( ! FR ) { <nl> + P . diagnose ( P . Tok , diag : : sil_integer_literal_not_integer_type ) ; <nl> + return true ; <nl> + } <nl> } <nl> } <nl> + <nl> + P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) ; <nl> + parseSILIdentifier ( BBName , BBLoc , diag : : expected_sil_block_name ) ; <nl> + CaseBBs . push_back ( { CaseVal , getBBForReference ( BBName , BBLoc ) } ) ; <nl> + continue ; <nl> } <nl> <nl> - P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) ; <nl> - parseSILIdentifier ( BBName , BBLoc , diag : : expected_sil_block_name ) ; <nl> - CaseBBs . push_back ( { CaseVal , getBBForReference ( BBName , BBLoc ) } ) ; <nl> - continue ; <nl> + P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" case or default \" ) ; <nl> + return true ; <nl> } <nl> - <nl> - P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" case or default \" ) ; <nl> - return true ; <nl> + if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + ResultVal = B . createSwitchValue ( InstLoc , Val , DefaultBB , CaseBBs ) ; <nl> + break ; <nl> } <nl> - if ( parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - ResultVal = B . createSwitchValue ( InstLoc , Val , DefaultBB , CaseBBs ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : SelectValueInst : { <nl> - if ( parseTypedValueRef ( Val , B ) ) <nl> - return true ; <nl> + case SILInstructionKind : : SelectValueInst : { <nl> + if ( parseTypedValueRef ( Val , B ) ) <nl> + return true ; <nl> <nl> - SmallVector < std : : pair < UnresolvedValueName , UnresolvedValueName > , 4 > <nl> - CaseValueAndResultNames ; <nl> - Optional < UnresolvedValueName > DefaultResultName ; <nl> - while ( P . consumeIf ( tok : : comma ) ) { <nl> - Identifier BBName ; <nl> - SourceLoc BBLoc ; <nl> - / / Parse ' default ' sil - value . <nl> - UnresolvedValueName tmp ; <nl> - if ( P . consumeIf ( tok : : kw_default ) ) { <nl> - if ( parseValueName ( tmp ) ) <nl> - return true ; <nl> - DefaultResultName = tmp ; <nl> - break ; <nl> + SmallVector < std : : pair < UnresolvedValueName , UnresolvedValueName > , 4 > <nl> + CaseValueAndResultNames ; <nl> + Optional < UnresolvedValueName > DefaultResultName ; <nl> + while ( P . consumeIf ( tok : : comma ) ) { <nl> + Identifier BBName ; <nl> + SourceLoc BBLoc ; <nl> + / / Parse ' default ' sil - value . <nl> + UnresolvedValueName tmp ; <nl> + if ( P . consumeIf ( tok : : kw_default ) ) { <nl> + if ( parseValueName ( tmp ) ) <nl> + return true ; <nl> + DefaultResultName = tmp ; <nl> + break ; <nl> + } <nl> + <nl> + / / Parse ' case ' sil - decl - ref ' : ' sil - value . <nl> + if ( P . consumeIf ( tok : : kw_case ) ) { <nl> + UnresolvedValueName casevalue ; <nl> + parseValueName ( casevalue ) ; <nl> + P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) ; <nl> + parseValueName ( tmp ) ; <nl> + CaseValueAndResultNames . push_back ( std : : make_pair ( casevalue , tmp ) ) ; <nl> + continue ; <nl> + } <nl> + <nl> + P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" case or default \" ) ; <nl> + return true ; <nl> } <nl> <nl> - / / Parse ' case ' sil - decl - ref ' : ' sil - value . <nl> - if ( P . consumeIf ( tok : : kw_case ) ) { <nl> - UnresolvedValueName casevalue ; <nl> - parseValueName ( casevalue ) ; <nl> - P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) ; <nl> - parseValueName ( tmp ) ; <nl> - CaseValueAndResultNames . push_back ( std : : make_pair ( <nl> - casevalue , <nl> - tmp ) ) ; <nl> - continue ; <nl> + if ( ! DefaultResultName ) { <nl> + P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" default \" ) ; <nl> + return true ; <nl> } <nl> <nl> - P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" case or default \" ) ; <nl> - return true ; <nl> + / / Parse the type of the result operands . <nl> + SILType ResultType ; <nl> + if ( P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) | | <nl> + parseSILType ( ResultType ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + <nl> + / / Resolve the results . <nl> + SmallVector < std : : pair < SILValue , SILValue > , 4 > CaseValues ; <nl> + SILValue DefaultValue ; <nl> + if ( DefaultResultName ) <nl> + DefaultValue = <nl> + getLocalValue ( * DefaultResultName , ResultType , InstLoc , B ) ; <nl> + SILType ValType = Val - > getType ( ) ; <nl> + for ( auto & caseName : CaseValueAndResultNames ) <nl> + CaseValues . push_back ( std : : make_pair ( <nl> + getLocalValue ( caseName . first , ValType , InstLoc , B ) , <nl> + getLocalValue ( caseName . second , ResultType , InstLoc , B ) ) ) ; <nl> + <nl> + ResultVal = B . createSelectValue ( InstLoc , Val , ResultType , DefaultValue , <nl> + CaseValues ) ; <nl> + break ; <nl> + } <nl> + case SILInstructionKind : : DeinitExistentialAddrInst : { <nl> + if ( parseTypedValueRef ( Val , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + ResultVal = B . createDeinitExistentialAddr ( InstLoc , Val ) ; <nl> + break ; <nl> } <nl> + case SILInstructionKind : : DeinitExistentialValueInst : { <nl> + if ( parseTypedValueRef ( Val , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + ResultVal = B . createDeinitExistentialValue ( InstLoc , Val ) ; <nl> + break ; <nl> + } <nl> + case SILInstructionKind : : InitExistentialAddrInst : { <nl> + CanType Ty ; <nl> + SourceLoc TyLoc ; <nl> + if ( parseTypedValueRef ( Val , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + P . parseToken ( tok : : sil_dollar , diag : : expected_tok_in_sil_instr , \" $ \" ) | | <nl> + parseASTType ( Ty , TyLoc ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> <nl> - if ( ! DefaultResultName ) { <nl> - P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" default \" ) ; <nl> - return true ; <nl> + / / Lower the type at the abstraction level of the existential . <nl> + auto archetype = OpenedArchetypeType : : get ( Val - > getType ( ) . getASTType ( ) ) <nl> + - > getCanonicalType ( ) ; <nl> + <nl> + auto & F = B . getFunction ( ) ; <nl> + SILType LoweredTy = <nl> + F . getLoweredType ( Lowering : : AbstractionPattern ( archetype ) , Ty ) <nl> + . getAddressType ( ) ; <nl> + <nl> + / / Collect conformances for the type . <nl> + ArrayRef < ProtocolConformanceRef > conformances = <nl> + collectExistentialConformances ( P , Ty , TyLoc , <nl> + Val - > getType ( ) . getASTType ( ) ) ; <nl> + <nl> + ResultVal = B . createInitExistentialAddr ( InstLoc , Val , Ty , LoweredTy , <nl> + conformances ) ; <nl> + break ; <nl> } <nl> + case SILInstructionKind : : InitExistentialValueInst : { <nl> + CanType FormalConcreteTy ; <nl> + SILType ExistentialTy ; <nl> + SourceLoc TyLoc ; <nl> + <nl> + if ( parseTypedValueRef ( Val , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + P . parseToken ( tok : : sil_dollar , diag : : expected_tok_in_sil_instr , \" $ \" ) | | <nl> + parseASTType ( FormalConcreteTy , TyLoc ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILType ( ExistentialTy ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> <nl> - / / Parse the type of the result operands . <nl> - SILType ResultType ; <nl> - if ( P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) | | <nl> - parseSILType ( ResultType ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> + ArrayRef < ProtocolConformanceRef > conformances = <nl> + collectExistentialConformances ( P , FormalConcreteTy , TyLoc , <nl> + ExistentialTy . getASTType ( ) ) ; <nl> <nl> - / / Resolve the results . <nl> - SmallVector < std : : pair < SILValue , SILValue > , 4 > CaseValues ; <nl> - SILValue DefaultValue ; <nl> - if ( DefaultResultName ) <nl> - DefaultValue = getLocalValue ( * DefaultResultName , ResultType , InstLoc , B ) ; <nl> - SILType ValType = Val - > getType ( ) ; <nl> - for ( auto & caseName : CaseValueAndResultNames ) <nl> - CaseValues . push_back ( std : : make_pair ( <nl> - getLocalValue ( caseName . first , ValType , InstLoc , B ) , <nl> - getLocalValue ( caseName . second , ResultType , InstLoc , B ) ) ) ; <nl> + ResultVal = B . createInitExistentialValue ( <nl> + InstLoc , ExistentialTy , FormalConcreteTy , Val , conformances ) ; <nl> + break ; <nl> + } <nl> + case SILInstructionKind : : AllocExistentialBoxInst : { <nl> + SILType ExistentialTy ; <nl> + CanType ConcreteFormalTy ; <nl> + SourceLoc TyLoc ; <nl> <nl> - ResultVal = B . createSelectValue ( InstLoc , Val , ResultType , <nl> - DefaultValue , CaseValues ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : DeinitExistentialAddrInst : { <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - ResultVal = B . createDeinitExistentialAddr ( InstLoc , Val ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : DeinitExistentialValueInst : { <nl> - if ( parseTypedValueRef ( Val , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - ResultVal = B . createDeinitExistentialValue ( InstLoc , Val ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : InitExistentialAddrInst : { <nl> - CanType Ty ; <nl> - SourceLoc TyLoc ; <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - P . parseToken ( tok : : sil_dollar , diag : : expected_tok_in_sil_instr , \" $ \" ) | | <nl> - parseASTType ( Ty , TyLoc ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - <nl> - / / Lower the type at the abstraction level of the existential . <nl> - auto archetype <nl> - = OpenedArchetypeType : : get ( Val - > getType ( ) . getASTType ( ) ) <nl> - - > getCanonicalType ( ) ; <nl> - <nl> - auto & F = B . getFunction ( ) ; <nl> - SILType LoweredTy = F . getLoweredType ( <nl> - Lowering : : AbstractionPattern ( archetype ) , Ty ) <nl> - . getAddressType ( ) ; <nl> - <nl> - / / Collect conformances for the type . <nl> - ArrayRef < ProtocolConformanceRef > conformances <nl> - = collectExistentialConformances ( P , Ty , TyLoc , <nl> - Val - > getType ( ) . getASTType ( ) ) ; <nl> - <nl> - ResultVal = B . createInitExistentialAddr ( InstLoc , Val , Ty , LoweredTy , <nl> - conformances ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : InitExistentialValueInst : { <nl> - CanType FormalConcreteTy ; <nl> - SILType ExistentialTy ; <nl> - SourceLoc TyLoc ; <nl> + if ( parseSILType ( ExistentialTy ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + P . parseToken ( tok : : sil_dollar , diag : : expected_tok_in_sil_instr , \" $ \" ) | | <nl> + parseASTType ( ConcreteFormalTy , TyLoc ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - P . parseToken ( tok : : sil_dollar , diag : : expected_tok_in_sil_instr , \" $ \" ) | | <nl> - parseASTType ( FormalConcreteTy , TyLoc ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILType ( ExistentialTy ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> + / / Collect conformances for the type . <nl> + ArrayRef < ProtocolConformanceRef > conformances = <nl> + collectExistentialConformances ( P , ConcreteFormalTy , TyLoc , <nl> + ExistentialTy . getASTType ( ) ) ; <nl> <nl> - ArrayRef < ProtocolConformanceRef > conformances = <nl> - collectExistentialConformances ( P , FormalConcreteTy , TyLoc , <nl> - ExistentialTy . getASTType ( ) ) ; <nl> + ResultVal = B . createAllocExistentialBox ( InstLoc , ExistentialTy , <nl> + ConcreteFormalTy , conformances ) ; <nl> <nl> - ResultVal = B . createInitExistentialValue ( <nl> - InstLoc , ExistentialTy , FormalConcreteTy , Val , conformances ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : AllocExistentialBoxInst : { <nl> - SILType ExistentialTy ; <nl> - CanType ConcreteFormalTy ; <nl> - SourceLoc TyLoc ; <nl> - <nl> - if ( parseSILType ( ExistentialTy ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - P . parseToken ( tok : : sil_dollar , diag : : expected_tok_in_sil_instr , \" $ \" ) | | <nl> - parseASTType ( ConcreteFormalTy , TyLoc ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - <nl> - / / Collect conformances for the type . <nl> - ArrayRef < ProtocolConformanceRef > conformances <nl> - = collectExistentialConformances ( P , ConcreteFormalTy , TyLoc , <nl> - ExistentialTy . getASTType ( ) ) ; <nl> - <nl> - ResultVal = B . createAllocExistentialBox ( InstLoc , ExistentialTy , <nl> - ConcreteFormalTy , conformances ) ; <nl> - <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : InitExistentialRefInst : { <nl> - CanType FormalConcreteTy ; <nl> - SILType ExistentialTy ; <nl> - SourceLoc TyLoc ; <nl> + break ; <nl> + } <nl> + case SILInstructionKind : : InitExistentialRefInst : { <nl> + CanType FormalConcreteTy ; <nl> + SILType ExistentialTy ; <nl> + SourceLoc TyLoc ; <nl> + <nl> + if ( parseTypedValueRef ( Val , B ) | | <nl> + P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) | | <nl> + P . parseToken ( tok : : sil_dollar , diag : : expected_tok_in_sil_instr , \" $ \" ) | | <nl> + parseASTType ( FormalConcreteTy , TyLoc ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILType ( ExistentialTy ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) | | <nl> - P . parseToken ( tok : : sil_dollar , diag : : expected_tok_in_sil_instr , \" $ \" ) | | <nl> - parseASTType ( FormalConcreteTy , TyLoc ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILType ( ExistentialTy ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - <nl> - ArrayRef < ProtocolConformanceRef > conformances <nl> - = collectExistentialConformances ( P , FormalConcreteTy , TyLoc , <nl> - ExistentialTy . getASTType ( ) ) ; <nl> - <nl> - / / FIXME : Conformances in InitExistentialRefInst is currently not included <nl> - / / in SIL . rst . <nl> - ResultVal = B . createInitExistentialRef ( InstLoc , ExistentialTy , <nl> - FormalConcreteTy , Val , <nl> - conformances ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : InitExistentialMetatypeInst : { <nl> - SourceLoc TyLoc ; <nl> - SILType ExistentialTy ; <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILType ( ExistentialTy , TyLoc ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> + ArrayRef < ProtocolConformanceRef > conformances = <nl> + collectExistentialConformances ( P , FormalConcreteTy , TyLoc , <nl> + ExistentialTy . getASTType ( ) ) ; <nl> <nl> - auto baseExType = ExistentialTy . getASTType ( ) ; <nl> - auto formalConcreteType = Val - > getType ( ) . getASTType ( ) ; <nl> - while ( auto instExType = dyn_cast < ExistentialMetatypeType > ( baseExType ) ) { <nl> - baseExType = instExType . getInstanceType ( ) ; <nl> - formalConcreteType = <nl> - cast < MetatypeType > ( formalConcreteType ) . getInstanceType ( ) ; <nl> + / / FIXME : Conformances in InitExistentialRefInst is currently not included <nl> + / / in SIL . rst . <nl> + ResultVal = B . createInitExistentialRef ( <nl> + InstLoc , ExistentialTy , FormalConcreteTy , Val , conformances ) ; <nl> + break ; <nl> } <nl> + case SILInstructionKind : : InitExistentialMetatypeInst : { <nl> + SourceLoc TyLoc ; <nl> + SILType ExistentialTy ; <nl> + if ( parseTypedValueRef ( Val , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILType ( ExistentialTy , TyLoc ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> <nl> - ArrayRef < ProtocolConformanceRef > conformances <nl> - = collectExistentialConformances ( P , formalConcreteType , TyLoc , <nl> - baseExType ) ; <nl> - <nl> - ResultVal = B . createInitExistentialMetatype ( InstLoc , Val , ExistentialTy , <nl> - conformances ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : DynamicMethodBranchInst : { <nl> - SILDeclRef Member ; <nl> - Identifier BBName , BBName2 ; <nl> - SourceLoc NameLoc , NameLoc2 ; <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILDeclRef ( Member ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILIdentifier ( BBName , NameLoc , diag : : expected_sil_block_name ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILIdentifier ( BBName2 , NameLoc2 , <nl> - diag : : expected_sil_block_name ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> + auto baseExType = ExistentialTy . getASTType ( ) ; <nl> + auto formalConcreteType = Val - > getType ( ) . getASTType ( ) ; <nl> + while ( auto instExType = dyn_cast < ExistentialMetatypeType > ( baseExType ) ) { <nl> + baseExType = instExType . getInstanceType ( ) ; <nl> + formalConcreteType = <nl> + cast < MetatypeType > ( formalConcreteType ) . getInstanceType ( ) ; <nl> + } <nl> <nl> - ResultVal = B . createDynamicMethodBranch ( InstLoc , Val , Member , <nl> - getBBForReference ( BBName , NameLoc ) , <nl> - getBBForReference ( BBName2 , <nl> - NameLoc2 ) ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : ProjectBlockStorageInst : { <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - <nl> - ResultVal = B . createProjectBlockStorage ( InstLoc , Val ) ; <nl> - break ; <nl> - } <nl> - case SILInstructionKind : : InitBlockStorageHeaderInst : { <nl> - Identifier invoke , type ; <nl> - SourceLoc invokeLoc , typeLoc ; <nl> - <nl> - UnresolvedValueName invokeName ; <nl> - SILType invokeTy ; <nl> - GenericEnvironment * invokeGenericEnv ; <nl> - <nl> - SILType blockType ; <nl> - SmallVector < ParsedSubstitution , 4 > parsedSubs ; <nl> + ArrayRef < ProtocolConformanceRef > conformances = <nl> + collectExistentialConformances ( P , formalConcreteType , TyLoc , <nl> + baseExType ) ; <nl> <nl> - <nl> - if ( parseTypedValueRef ( Val , B ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILIdentifier ( invoke , invokeLoc , <nl> - diag : : expected_tok_in_sil_instr , \" invoke \" ) | | <nl> - parseValueName ( invokeName ) | | <nl> - parseSubstitutions ( parsedSubs ) | | <nl> - P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) | | <nl> - parseSILType ( invokeTy , invokeGenericEnv ) | | <nl> - P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> - parseSILIdentifier ( type , typeLoc , <nl> - diag : : expected_tok_in_sil_instr , \" type \" ) | | <nl> - parseSILType ( blockType ) | | <nl> - parseSILDebugLocation ( InstLoc , B ) ) <nl> - return true ; <nl> - <nl> - if ( invoke . str ( ) ! = \" invoke \" ) { <nl> - P . diagnose ( invokeLoc , diag : : expected_tok_in_sil_instr , \" invoke \" ) ; <nl> - return true ; <nl> + ResultVal = B . createInitExistentialMetatype ( InstLoc , Val , ExistentialTy , <nl> + conformances ) ; <nl> + break ; <nl> } <nl> - if ( type . str ( ) ! = \" type \" ) { <nl> - P . diagnose ( invokeLoc , diag : : expected_tok_in_sil_instr , \" type \" ) ; <nl> - return true ; <nl> + case SILInstructionKind : : DynamicMethodBranchInst : { <nl> + SILDeclRef Member ; <nl> + Identifier BBName , BBName2 ; <nl> + SourceLoc NameLoc , NameLoc2 ; <nl> + if ( parseTypedValueRef ( Val , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILDeclRef ( Member ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILIdentifier ( BBName , NameLoc , diag : : expected_sil_block_name ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILIdentifier ( BBName2 , NameLoc2 , <nl> + diag : : expected_sil_block_name ) | | <nl> + parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + <nl> + ResultVal = B . createDynamicMethodBranch ( <nl> + InstLoc , Val , Member , getBBForReference ( BBName , NameLoc ) , <nl> + getBBForReference ( BBName2 , NameLoc2 ) ) ; <nl> + break ; <nl> } <nl> - <nl> - auto invokeVal = getLocalValue ( invokeName , invokeTy , InstLoc , B ) ; <nl> + case SILInstructionKind : : ProjectBlockStorageInst : { <nl> + if ( parseTypedValueRef ( Val , B ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> <nl> - SubstitutionMap subMap ; <nl> - if ( ! parsedSubs . empty ( ) ) { <nl> - if ( ! invokeGenericEnv ) { <nl> - P . diagnose ( typeLoc , diag : : sil_substitutions_on_non_polymorphic_type ) ; <nl> + ResultVal = B . createProjectBlockStorage ( InstLoc , Val ) ; <nl> + break ; <nl> + } <nl> + case SILInstructionKind : : InitBlockStorageHeaderInst : { <nl> + Identifier invoke , type ; <nl> + SourceLoc invokeLoc , typeLoc ; <nl> + <nl> + UnresolvedValueName invokeName ; <nl> + SILType invokeTy ; <nl> + GenericEnvironment * invokeGenericEnv ; <nl> + <nl> + SILType blockType ; <nl> + SmallVector < ParsedSubstitution , 4 > parsedSubs ; <nl> + <nl> + if ( parseTypedValueRef ( Val , B ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILIdentifier ( invoke , invokeLoc , diag : : expected_tok_in_sil_instr , <nl> + \" invoke \" ) | | <nl> + parseValueName ( invokeName ) | | parseSubstitutions ( parsedSubs ) | | <nl> + P . parseToken ( tok : : colon , diag : : expected_tok_in_sil_instr , \" : \" ) | | <nl> + parseSILType ( invokeTy , invokeGenericEnv ) | | <nl> + P . parseToken ( tok : : comma , diag : : expected_tok_in_sil_instr , \" , \" ) | | <nl> + parseSILIdentifier ( type , typeLoc , diag : : expected_tok_in_sil_instr , <nl> + \" type \" ) | | <nl> + parseSILType ( blockType ) | | parseSILDebugLocation ( InstLoc , B ) ) <nl> + return true ; <nl> + <nl> + if ( invoke . str ( ) ! = \" invoke \" ) { <nl> + P . diagnose ( invokeLoc , diag : : expected_tok_in_sil_instr , \" invoke \" ) ; <nl> + return true ; <nl> + } <nl> + if ( type . str ( ) ! = \" type \" ) { <nl> + P . diagnose ( invokeLoc , diag : : expected_tok_in_sil_instr , \" type \" ) ; <nl> return true ; <nl> } <nl> <nl> - subMap = getApplySubstitutionsFromParsed ( * this , invokeGenericEnv , <nl> - parsedSubs ) ; <nl> - if ( ! subMap ) <nl> + auto invokeVal = getLocalValue ( invokeName , invokeTy , InstLoc , B ) ; <nl> + <nl> + SubstitutionMap subMap ; <nl> + if ( ! parsedSubs . empty ( ) ) { <nl> + if ( ! invokeGenericEnv ) { <nl> + P . diagnose ( typeLoc , diag : : sil_substitutions_on_non_polymorphic_type ) ; <nl> + return true ; <nl> + } <nl> + <nl> + subMap = getApplySubstitutionsFromParsed ( * this , invokeGenericEnv , <nl> + parsedSubs ) ; <nl> + if ( ! subMap ) <nl> + return true ; <nl> + } <nl> + <nl> + ResultVal = B . createInitBlockStorageHeader ( InstLoc , Val , invokeVal , <nl> + blockType , subMap ) ; <nl> + break ; <nl> + } <nl> + } <nl> + <nl> + return false ; <nl> + } <nl> + <nl> + / / / sil - instruction - result : : = sil - value - name ' = ' <nl> + / / / sil - instruction - result : : = ' ( ' sil - value - name ? ' ) ' <nl> + / / / sil - instruction - result : : = ' ( ' sil - value - name ( ' , ' sil - value - name ) * ' ) ' <nl> + / / / sil - instruction - source - info : : = ( ' , ' sil - scope - ref ) ? ( ' , ' sil - loc ) ? <nl> + / / / sil - instruction - def : : = <nl> + / / / ( sil - instruction - result ' = ' ) ? sil - instruction sil - instruction - source - info <nl> + bool SILParser : : parseSILInstruction ( SILBuilder & B ) { <nl> + / / We require SIL instructions to be at the start of a line to assist <nl> + / / recovery . <nl> + if ( ! P . Tok . isAtStartOfLine ( ) ) { <nl> + P . diagnose ( P . Tok , diag : : expected_sil_instr_start_of_line ) ; <nl> + return true ; <nl> + } <nl> + <nl> + SmallVector < Located < StringRef > , 4 > resultNames ; <nl> + SourceLoc resultClauseBegin ; <nl> + <nl> + / / If the instruction has a name ' % foo = ' , parse it . <nl> + if ( P . Tok . is ( tok : : sil_local_name ) ) { <nl> + resultClauseBegin = P . Tok . getLoc ( ) ; <nl> + resultNames . push_back ( { P . Tok . getText ( ) , P . Tok . getLoc ( ) } ) ; <nl> + P . consumeToken ( tok : : sil_local_name ) ; <nl> + <nl> + / / If the instruction has a ' ( % foo , % bar ) = ' , parse it . <nl> + } else if ( P . consumeIf ( tok : : l_paren ) ) { <nl> + resultClauseBegin = P . PreviousLoc ; <nl> + <nl> + if ( ! P . consumeIf ( tok : : r_paren ) ) { <nl> + while ( true ) { <nl> + if ( ! P . Tok . is ( tok : : sil_local_name ) ) { <nl> + P . diagnose ( P . Tok , diag : : expected_sil_value_name ) ; <nl> + return true ; <nl> + } <nl> + <nl> + resultNames . push_back ( { P . Tok . getText ( ) , P . Tok . getLoc ( ) } ) ; <nl> + P . consumeToken ( tok : : sil_local_name ) ; <nl> + <nl> + if ( P . consumeIf ( tok : : comma ) ) <nl> + continue ; <nl> + if ( P . consumeIf ( tok : : r_paren ) ) <nl> + break ; <nl> + <nl> + P . diagnose ( P . Tok , diag : : expected_tok_in_sil_instr , \" , \" ) ; <nl> return true ; <nl> + } <nl> } <nl> - <nl> - ResultVal = B . createInitBlockStorageHeader ( InstLoc , Val , invokeVal , <nl> - blockType , subMap ) ; <nl> - break ; <nl> } <nl> + <nl> + if ( resultClauseBegin . isValid ( ) ) { <nl> + if ( P . parseToken ( tok : : equal , diag : : expected_equal_in_sil_instr ) ) <nl> + return true ; <nl> } <nl> <nl> + SILInstructionKind Opcode ; <nl> + SourceLoc OpcodeLoc ; <nl> + StringRef OpcodeName ; <nl> + <nl> + / / Parse the opcode name . <nl> + if ( parseSILOpcode ( Opcode , OpcodeLoc , OpcodeName ) ) <nl> + return true ; <nl> + <nl> + / / Perform opcode specific parsing . <nl> + SILInstruction * ResultVal ; <nl> + if ( parseSpecificSILInstruction ( B , Opcode , OpcodeLoc , OpcodeName , ResultVal ) ) <nl> + return true ; <nl> + <nl> / / Match the results clause if we had one . <nl> if ( resultClauseBegin . isValid ( ) ) { <nl> auto results = ResultVal - > getResults ( ) ; <nl>\n", "msg": "Merge remote - tracking branch ' origin / master ' into master - next\n"}
{"diff_id": 14102, "repo": "telegramdesktop/tdesktop\n", "sha": "4a20a4d739363793750cd72dd51e9490467bec37\n", "time": "2020-12-02T21:16:26Z\n", "diff": "mmm a / Telegram / SourceFiles / ui / effects / send_action_animations . cpp <nl> ppp b / Telegram / SourceFiles / ui / effects / send_action_animations . cpp <nl> class SpeakingAnimation : public SendActionAnimation : : Impl { <nl> } <nl> <nl> int width ( ) const override { <nl> - return 4 * ( st : : dialogsSpeakingStrokeNumerator / st : : dialogsSpeakingDenominator ) ; <nl> + const auto & numerator = st : : dialogsSpeakingStrokeNumerator ; <nl> + const auto & denominator = st : : dialogsSpeakingDenominator ; <nl> + return 4 * ( numerator / denominator ) ; <nl> } <nl> <nl> void restartedAt ( crl : : time now ) override ; <nl> bool finishNow ( ) override ; <nl> <nl> - static void PaintIdle ( Painter & p , style : : color color , int x , int y , int outerWidth ) ; <nl> + static void PaintIdle ( <nl> + Painter & p , <nl> + style : : color color , <nl> + int x , <nl> + int y , <nl> + int outerWidth ) ; <nl> <nl> - void paint ( Painter & p , style : : color color , int x , int y , int outerWidth , crl : : time now ) override ; <nl> + void paint ( <nl> + Painter & p , <nl> + style : : color color , <nl> + int x , <nl> + int y , <nl> + int outerWidth , <nl> + crl : : time now ) override ; <nl> <nl> private : <nl> - static void PaintFrame ( Painter & p , style : : color color , int x , int y , int outerWidth , int frameMs , float64 started ) ; <nl> + static void PaintFrame ( <nl> + Painter & p , <nl> + style : : color color , <nl> + int x , <nl> + int y , <nl> + int outerWidth , <nl> + int frameMs , <nl> + float64 started ) ; <nl> <nl> crl : : time _startStarted = 0 ; <nl> crl : : time _finishStarted = 0 ; <nl> <nl> } ; <nl> <nl> - const SpeakingAnimation : : MetaData SpeakingAnimation : : kMeta = { 0 , & SpeakingAnimation : : create } ; <nl> + const SpeakingAnimation : : MetaData SpeakingAnimation : : kMeta = { <nl> + 0 , <nl> + & SpeakingAnimation : : create } ; <nl> <nl> SpeakingAnimation : : SpeakingAnimation ( ) <nl> : Impl ( kSpeakingDuration ) <nl> bool SpeakingAnimation : : finishNow ( ) { <nl> return false ; <nl> } <nl> <nl> - void SpeakingAnimation : : PaintIdle ( Painter & p , style : : color color , int x , int y , int outerWidth ) { <nl> + void SpeakingAnimation : : PaintIdle ( <nl> + Painter & p , <nl> + style : : color color , <nl> + int x , <nl> + int y , <nl> + int outerWidth ) { <nl> PaintFrame ( p , color , x , y , outerWidth , 0 , 0 . ) ; <nl> - PainterHighQualityEnabler hq ( p ) ; <nl> - <nl> - const auto line = st : : dialogsSpeakingStrokeNumerator / ( 2 * st : : dialogsSpeakingDenominator ) ; <nl> - <nl> - p . setPen ( Qt : : NoPen ) ; <nl> - p . setBrush ( color ) ; <nl> - <nl> - const auto half = st : : dialogsCallBadgeSize / 2 . ; <nl> - const auto center = QPointF ( x + half , y + half ) ; <nl> - auto middleSize = line ; <nl> - auto sideSize = line ; <nl> - <nl> - auto left = center . x ( ) - 4 * line ; <nl> - p . drawRoundedRect ( left , center . y ( ) - line * 2 , 2 * line , 4 * line , line , line ) ; <nl> - left + = 3 * line ; <nl> - p . drawRoundedRect ( left , center . y ( ) - line * 2 , 2 * line , 4 * line , line , line ) ; <nl> - left + = 3 * line ; <nl> - p . drawRoundedRect ( left , center . y ( ) - line * 2 , 2 * line , 4 * line , line , line ) ; <nl> } <nl> <nl> - void SpeakingAnimation : : paint ( Painter & p , style : : color color , int x , int y , int outerWidth , crl : : time now ) { <nl> + void SpeakingAnimation : : paint ( <nl> + Painter & p , <nl> + style : : color color , <nl> + int x , <nl> + int y , <nl> + int outerWidth , <nl> + crl : : time now ) { <nl> const auto started = _finishStarted <nl> ? ( 1 . - ( ( now - _finishStarted ) / float64 ( kSpeakingFadeDuration ) ) ) <nl> : ( now - _startStarted ) / float64 ( kSpeakingFadeDuration ) ; <nl> - PaintFrame ( p , color , x , y , outerWidth , frameTime ( now ) , std : : clamp ( started , 0 . , 1 . ) ) ; <nl> + const auto progress = std : : clamp ( started , 0 . , 1 . ) ; <nl> + PaintFrame ( p , color , x , y , outerWidth , frameTime ( now ) , progress ) ; <nl> } <nl> <nl> - void SpeakingAnimation : : PaintFrame ( Painter & p , style : : color color , int x , int y , int outerWidth , int frameMs , float64 started ) { <nl> + void SpeakingAnimation : : PaintFrame ( <nl> + Painter & p , <nl> + style : : color color , <nl> + int x , <nl> + int y , <nl> + int outerWidth , <nl> + int frameMs , <nl> + float64 started ) { <nl> PainterHighQualityEnabler hq ( p ) ; <nl> <nl> - const auto line = st : : dialogsSpeakingStrokeNumerator / ( 2 * st : : dialogsSpeakingDenominator ) ; <nl> + const auto line = st : : dialogsSpeakingStrokeNumerator <nl> + / ( 2 * st : : dialogsSpeakingDenominator ) ; <nl> <nl> p . setPen ( Qt : : NoPen ) ; <nl> p . setBrush ( color ) ; <nl> void SpeakingAnimation : : PaintFrame ( Painter & p , style : : color color , int x , int y , <nl> const auto stageDuration = duration / 8 ; <nl> const auto fullprogress = frameMs ; <nl> const auto stage = fullprogress / stageDuration ; <nl> - const auto progress = ( fullprogress - stage * stageDuration ) / float64 ( stageDuration ) ; <nl> + const auto progress = ( fullprogress - stage * stageDuration ) <nl> + / float64 ( stageDuration ) ; <nl> const auto half = st : : dialogsCallBadgeSize / 2 . ; <nl> const auto center = QPointF ( x + half , y + half ) ; <nl> const auto middleSize = [ & ] { <nl> void SpeakingAnimation : : PaintFrame ( Painter & p , style : : color color , int x , int y , <nl> : ( started * result ) + ( ( 1 . - started ) * 2 * line ) ; <nl> } ( ) ; <nl> <nl> + const auto drawRoundedRect = [ & ] ( float left , float size ) { <nl> + const auto top = center . y ( ) - size ; <nl> + const auto w = 2 * line ; <nl> + const auto h = 2 * size ; <nl> + <nl> + if ( left = = ( int ) left ) { <nl> + p . drawRoundedRect ( left , top , w , h , line , line ) ; <nl> + } else { <nl> + p . drawRoundedRect ( QRectF ( left , top , w , h ) , line , line ) ; <nl> + } <nl> + } ; <nl> + <nl> auto left = center . x ( ) - 4 * line ; <nl> - p . drawRoundedRect ( left , center . y ( ) - sideSize , 2 * line , 2 * sideSize , line , line ) ; <nl> + drawRoundedRect ( left , sideSize ) ; <nl> left + = 3 * line ; <nl> - p . drawRoundedRect ( left , center . y ( ) - middleSize , 2 * line , 2 * middleSize , line , line ) ; <nl> + drawRoundedRect ( left , middleSize ) ; <nl> left + = 3 * line ; <nl> - p . drawRoundedRect ( left , center . y ( ) - sideSize , 2 * line , 2 * sideSize , line , line ) ; <nl> + drawRoundedRect ( left , sideSize ) ; <nl> } <nl> <nl> void CreateImplementationsMap ( ) { <nl>\n", "msg": "Fixed drawing of voice chat indicator for non - default scales .\n"}
{"diff_id": 14114, "repo": "godotengine/godot\n", "sha": "ab1e460f539dea93ff14b250b0c3b76262ff343d\n", "time": "2018-08-14T13:11:19Z\n", "diff": "mmm a / drivers / gles2 / rasterizer_scene_gles2 . cpp <nl> ppp b / drivers / gles2 / rasterizer_scene_gles2 . cpp <nl> void RasterizerSceneGLES2 : : render_scene ( const Transform & p_cam_transform , const <nl> } break ; <nl> <nl> default : { <nl> - print_line ( \" uhm \" ) ; <nl> + / / FIXME : implement other background modes <nl> } break ; <nl> } <nl> } <nl>\n", "msg": "Reduce verbosity for unsupported GLES2 bg modes\n", "score": 1}
{"diff_id": 14126, "repo": "godotengine/godot\n", "sha": "509064de0f030beac426e8b72bffe716ff9bf214\n", "time": "2019-12-06T10:30:52Z\n", "diff": "mmm a / platform / iphone / export / export . cpp <nl> ppp b / platform / iphone / export / export . cpp <nl> <nl> / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / <nl> <nl> # include \" export . h \" <nl> + # include \" core / io / image_loader . h \" <nl> # include \" core / io / marshalls . h \" <nl> # include \" core / io / resource_saver . h \" <nl> # include \" core / io / zip_io . h \" <nl> <nl> # include \" editor / editor_export . h \" <nl> # include \" editor / editor_node . h \" <nl> # include \" editor / editor_settings . h \" <nl> + # include \" main / splash . gen . h \" <nl> # include \" platform / iphone / logo . gen . h \" <nl> # include \" string . h \" <nl> <nl> class EditorExportPlatformIOS : public EditorExportPlatform { <nl> typedef Error ( * FileHandler ) ( String p_file , void * p_userdata ) ; <nl> static Error _walk_dir_recursive ( DirAccess * p_da , FileHandler p_handler , void * p_userdata ) ; <nl> static Error _codesign ( String p_file , void * p_userdata ) ; <nl> + void _blend_and_rotate ( Ref < Image > & p_dst , Ref < Image > & p_src , bool p_rot ) ; <nl> <nl> struct IOSConfigData { <nl> String pkg_name ; <nl> Vector < EditorExportPlatformIOS : : ExportArchitecture > EditorExportPlatformIOS : : _ge <nl> struct LoadingScreenInfo { <nl> const char * preset_key ; <nl> const char * export_name ; <nl> + int width ; <nl> + int height ; <nl> + bool rotate ; <nl> } ; <nl> <nl> static const LoadingScreenInfo loading_screen_infos [ ] = { <nl> - { \" landscape_launch_screens / iphone_2436x1125 \" , \" Default - Landscape - X . png \" } , <nl> - { \" landscape_launch_screens / iphone_2208x1242 \" , \" Default - Landscape - 736h @ 3x . png \" } , <nl> - { \" landscape_launch_screens / ipad_1024x768 \" , \" Default - Landscape . png \" } , <nl> - { \" landscape_launch_screens / ipad_2048x1536 \" , \" Default - Landscape @ 2x . png \" } , <nl> - <nl> - { \" portrait_launch_screens / iphone_640x960 \" , \" Default - 480h @ 2x . png \" } , <nl> - { \" portrait_launch_screens / iphone_640x1136 \" , \" Default - 568h @ 2x . png \" } , <nl> - { \" portrait_launch_screens / iphone_750x1334 \" , \" Default - 667h @ 2x . png \" } , <nl> - { \" portrait_launch_screens / iphone_1125x2436 \" , \" Default - Portrait - X . png \" } , <nl> - { \" portrait_launch_screens / ipad_768x1024 \" , \" Default - Portrait . png \" } , <nl> - { \" portrait_launch_screens / ipad_1536x2048 \" , \" Default - Portrait @ 2x . png \" } , <nl> - { \" portrait_launch_screens / iphone_1242x2208 \" , \" Default - Portrait - 736h @ 3x . png \" } <nl> + { \" landscape_launch_screens / iphone_2436x1125 \" , \" Default - Landscape - X . png \" , 2436 , 1125 , false } , <nl> + { \" landscape_launch_screens / iphone_2208x1242 \" , \" Default - Landscape - 736h @ 3x . png \" , 2208 , 1242 , false } , <nl> + { \" landscape_launch_screens / ipad_1024x768 \" , \" Default - Landscape . png \" , 1024 , 768 , false } , <nl> + { \" landscape_launch_screens / ipad_2048x1536 \" , \" Default - Landscape @ 2x . png \" , 2048 , 1536 , false } , <nl> + <nl> + { \" portrait_launch_screens / iphone_640x960 \" , \" Default - 480h @ 2x . png \" , 640 , 960 , true } , <nl> + { \" portrait_launch_screens / iphone_640x1136 \" , \" Default - 568h @ 2x . png \" , 640 , 1136 , true } , <nl> + { \" portrait_launch_screens / iphone_750x1334 \" , \" Default - 667h @ 2x . png \" , 750 , 1334 , true } , <nl> + { \" portrait_launch_screens / iphone_1125x2436 \" , \" Default - Portrait - X . png \" , 1125 , 2436 , true } , <nl> + { \" portrait_launch_screens / ipad_768x1024 \" , \" Default - Portrait . png \" , 768 , 1024 , true } , <nl> + { \" portrait_launch_screens / ipad_1536x2048 \" , \" Default - Portrait @ 2x . png \" , 1536 , 2048 , true } , <nl> + { \" portrait_launch_screens / iphone_1242x2208 \" , \" Default - Portrait - 736h @ 3x . png \" , 1242 , 2208 , true } <nl> } ; <nl> <nl> void EditorExportPlatformIOS : : get_export_options ( List < ExportOption > * r_options ) { <nl> void EditorExportPlatformIOS : : get_export_options ( List < ExportOption > * r_options ) <nl> r_options - > push_back ( ExportOption ( PropertyInfo ( Variant : : BOOL , \" orientation / landscape_right \" ) , true ) ) ; <nl> r_options - > push_back ( ExportOption ( PropertyInfo ( Variant : : BOOL , \" orientation / portrait_upside_down \" ) , true ) ) ; <nl> <nl> + r_options - > push_back ( ExportOption ( PropertyInfo ( Variant : : BOOL , \" icons / generate_missing \" ) , false ) ) ; <nl> + <nl> r_options - > push_back ( ExportOption ( PropertyInfo ( Variant : : STRING , \" required_icons / iphone_120x120 \" , PROPERTY_HINT_FILE , \" * . png \" ) , \" \" ) ) ; / / Home screen on iPhone / iPod Touch with retina display <nl> r_options - > push_back ( ExportOption ( PropertyInfo ( Variant : : STRING , \" required_icons / ipad_76x76 \" , PROPERTY_HINT_FILE , \" * . png \" ) , \" \" ) ) ; / / Home screen on iPad <nl> r_options - > push_back ( ExportOption ( PropertyInfo ( Variant : : STRING , \" required_icons / app_store_1024x1024 \" , PROPERTY_HINT_FILE , \" * . png \" ) , \" \" ) ) ; / / App Store <nl> void EditorExportPlatformIOS : : get_export_options ( List < ExportOption > * r_options ) <nl> r_options - > push_back ( ExportOption ( PropertyInfo ( Variant : : STRING , \" optional_icons / spotlight_40x40 \" , PROPERTY_HINT_FILE , \" * . png \" ) , \" \" ) ) ; / / Spotlight <nl> r_options - > push_back ( ExportOption ( PropertyInfo ( Variant : : STRING , \" optional_icons / spotlight_80x80 \" , PROPERTY_HINT_FILE , \" * . png \" ) , \" \" ) ) ; / / Spotlight on devices with retina display <nl> <nl> + r_options - > push_back ( ExportOption ( PropertyInfo ( Variant : : BOOL , \" launch_screens / generate_missing \" ) , false ) ) ; <nl> + <nl> for ( uint64_t i = 0 ; i < sizeof ( loading_screen_infos ) / sizeof ( loading_screen_infos [ 0 ] ) ; + + i ) { <nl> r_options - > push_back ( ExportOption ( PropertyInfo ( Variant : : STRING , loading_screen_infos [ i ] . preset_key , PROPERTY_HINT_FILE , \" * . png \" ) , \" \" ) ) ; <nl> } <nl> String EditorExportPlatformIOS : : _get_cpp_code ( ) { <nl> return result ; <nl> } <nl> <nl> + void EditorExportPlatformIOS : : _blend_and_rotate ( Ref < Image > & p_dst , Ref < Image > & p_src , bool p_rot ) { <nl> + <nl> + ERR_FAIL_COND ( p_dst . is_null ( ) ) ; <nl> + ERR_FAIL_COND ( p_src . is_null ( ) ) ; <nl> + <nl> + p_dst - > lock ( ) ; <nl> + p_src - > lock ( ) ; <nl> + <nl> + int sw = p_rot ? p_src - > get_height ( ) : p_src - > get_width ( ) ; <nl> + int sh = p_rot ? p_src - > get_width ( ) : p_src - > get_height ( ) ; <nl> + <nl> + int x_pos = ( p_dst - > get_width ( ) - sw ) / 2 ; <nl> + int y_pos = ( p_dst - > get_height ( ) - sh ) / 2 ; <nl> + <nl> + int xs = ( x_pos > = 0 ) ? 0 : - x_pos ; <nl> + int ys = ( y_pos > = 0 ) ? 0 : - y_pos ; <nl> + <nl> + if ( sw + x_pos > p_dst - > get_width ( ) ) sw = p_dst - > get_width ( ) - x_pos ; <nl> + if ( sh + y_pos > p_dst - > get_height ( ) ) sh = p_dst - > get_height ( ) - y_pos ; <nl> + <nl> + for ( int y = ys ; y < sh ; y + + ) { <nl> + for ( int x = xs ; x < sw ; x + + ) { <nl> + Color sc = p_rot ? p_src - > get_pixel ( p_src - > get_width ( ) - y - 1 , x ) : p_src - > get_pixel ( x , y ) ; <nl> + Color dc = p_dst - > get_pixel ( x_pos + x , y_pos + y ) ; <nl> + dc . r = ( double ) ( sc . a * sc . r + dc . a * ( 1 . 0 - sc . a ) * dc . r ) ; <nl> + dc . g = ( double ) ( sc . a * sc . g + dc . a * ( 1 . 0 - sc . a ) * dc . g ) ; <nl> + dc . b = ( double ) ( sc . a * sc . b + dc . a * ( 1 . 0 - sc . a ) * dc . b ) ; <nl> + dc . a = ( double ) ( sc . a + dc . a * ( 1 . 0 - sc . a ) ) ; <nl> + p_dst - > set_pixel ( x_pos + x , y_pos + y , dc ) ; <nl> + } <nl> + } <nl> + <nl> + p_dst - > unlock ( ) ; <nl> + p_src - > unlock ( ) ; <nl> + } <nl> + <nl> struct IconInfo { <nl> const char * preset_key ; <nl> const char * idiom ; <nl> static const IconInfo icon_infos [ ] = { <nl> { \" required_icons / iphone_120x120 \" , \" iphone \" , \" Icon - 120 . png \" , \" 120 \" , \" 2x \" , \" 60x60 \" , true } , <nl> { \" required_icons / iphone_120x120 \" , \" iphone \" , \" Icon - 120 . png \" , \" 120 \" , \" 3x \" , \" 40x40 \" , true } , <nl> <nl> - { \" required_icons / ipad_76x76 \" , \" ipad \" , \" Icon - 76 . png \" , \" 76 \" , \" 1x \" , \" 76x76 \" , false } , <nl> - { \" required_icons / app_store_1024x1024 \" , \" ios - marketing \" , \" Icon - 1024 . png \" , \" 1024 \" , \" 1x \" , \" 1024x1024 \" , false } , <nl> + { \" required_icons / ipad_76x76 \" , \" ipad \" , \" Icon - 76 . png \" , \" 76 \" , \" 1x \" , \" 76x76 \" , true } , <nl> + { \" required_icons / app_store_1024x1024 \" , \" ios - marketing \" , \" Icon - 1024 . png \" , \" 1024 \" , \" 1x \" , \" 1024x1024 \" , true } , <nl> <nl> { \" optional_icons / iphone_180x180 \" , \" iphone \" , \" Icon - 180 . png \" , \" 180 \" , \" 3x \" , \" 60x60 \" , false } , <nl> <nl> Error EditorExportPlatformIOS : : _export_icons ( const Ref < EditorExportPreset > & p_pr <nl> <nl> for ( uint64_t i = 0 ; i < ( sizeof ( icon_infos ) / sizeof ( icon_infos [ 0 ] ) ) ; + + i ) { <nl> IconInfo info = icon_infos [ i ] ; <nl> + int side_size = String ( info . actual_size_side ) . to_int ( ) ; <nl> String icon_path = p_preset - > get ( info . preset_key ) ; <nl> if ( icon_path . length ( ) = = 0 ) { <nl> - if ( info . is_required ) { <nl> - ERR_PRINT ( \" Required icon is not specified in the preset \" ) ; <nl> + if ( ( bool ) p_preset - > get ( \" icons / generate_missing \" ) ) { <nl> + / / Resize main app icon <nl> + icon_path = ProjectSettings : : get_singleton ( ) - > get ( \" application / config / icon \" ) ; <nl> + Ref < Image > img = memnew ( Image ) ; <nl> + Error err = ImageLoader : : load_image ( icon_path , img ) ; <nl> + if ( err ! = OK ) { <nl> + ERR_PRINT ( \" Invalid icon ( \" + String ( info . preset_key ) + \" ) : ' \" + icon_path + \" ' . \" ) ; <nl> + return ERR_UNCONFIGURED ; <nl> + } <nl> + img - > resize ( side_size , side_size ) ; <nl> + err = img - > save_png ( p_iconset_dir + info . export_name ) ; <nl> + if ( err ) { <nl> + String err_str = String ( \" Failed to export icon ( \" + String ( info . preset_key ) + \" ) : ' \" + icon_path + \" ' . \" ) ; <nl> + ERR_PRINT ( err_str . utf8 ( ) . get_data ( ) ) ; <nl> + return err ; <nl> + } <nl> + } else { <nl> + if ( info . is_required ) { <nl> + String err_str = String ( \" Required icon ( \" ) + info . preset_key + \" ) is not specified in the preset . \" ; <nl> + ERR_PRINT ( err_str ) ; <nl> + return ERR_UNCONFIGURED ; <nl> + } else { <nl> + String err_str = String ( \" Icon ( \" ) + info . preset_key + \" ) is not specified in the preset . \" ; <nl> + WARN_PRINT ( err_str ) ; <nl> + } <nl> + continue ; <nl> + } <nl> + } else { <nl> + / / Load custom icon <nl> + Ref < Image > img = memnew ( Image ) ; <nl> + Error err = ImageLoader : : load_image ( icon_path , img ) ; <nl> + if ( err ! = OK ) { <nl> + ERR_PRINT ( \" Invalid icon ( \" + String ( info . preset_key ) + \" ) : ' \" + icon_path + \" ' . \" ) ; <nl> return ERR_UNCONFIGURED ; <nl> } <nl> - continue ; <nl> - } <nl> - Error err = da - > copy ( icon_path , p_iconset_dir + info . export_name ) ; <nl> - if ( err ) { <nl> - memdelete ( da ) ; <nl> - String err_str = String ( \" Failed to export icon : \" ) + icon_path ; <nl> - ERR_PRINT ( err_str . utf8 ( ) . get_data ( ) ) ; <nl> - return err ; <nl> + if ( img - > get_width ( ) ! = side_size | | img - > get_height ( ) ! = side_size ) { <nl> + ERR_PRINT ( \" Invalid icon size ( \" + String ( info . preset_key ) + \" ) : ' \" + icon_path + \" ' . \" ) ; <nl> + return ERR_UNCONFIGURED ; <nl> + } <nl> + <nl> + err = da - > copy ( icon_path , p_iconset_dir + info . export_name ) ; <nl> + if ( err ) { <nl> + memdelete ( da ) ; <nl> + String err_str = String ( \" Failed to export icon ( \" + String ( info . preset_key ) + \" ) : ' \" + icon_path + \" ' . \" ) ; <nl> + ERR_PRINT ( err_str . utf8 ( ) . get_data ( ) ) ; <nl> + return err ; <nl> + } <nl> } <nl> sizes + = String ( info . actual_size_side ) + \" \\ n \" ; <nl> if ( i > 0 ) { <nl> Error EditorExportPlatformIOS : : _export_loading_screens ( const Ref < EditorExportPre <nl> LoadingScreenInfo info = loading_screen_infos [ i ] ; <nl> String loading_screen_file = p_preset - > get ( info . preset_key ) ; <nl> if ( loading_screen_file . size ( ) > 0 ) { <nl> - Error err = da - > copy ( loading_screen_file , p_dest_dir + info . export_name ) ; <nl> + / / Load custom loading screens <nl> + Ref < Image > img = memnew ( Image ) ; <nl> + Error err = ImageLoader : : load_image ( loading_screen_file , img ) ; <nl> + if ( err ! = OK ) { <nl> + ERR_PRINT ( \" Invalid loading screen ( \" + String ( info . preset_key ) + \" ) : ' \" + loading_screen_file + \" ' . \" ) ; <nl> + return ERR_UNCONFIGURED ; <nl> + } <nl> + if ( img - > get_width ( ) ! = info . width | | img - > get_height ( ) ! = info . height ) { <nl> + ERR_PRINT ( \" Invalid loading screen size ( \" + String ( info . preset_key ) + \" ) : ' \" + loading_screen_file + \" ' . \" ) ; <nl> + return ERR_UNCONFIGURED ; <nl> + } <nl> + err = da - > copy ( loading_screen_file , p_dest_dir + info . export_name ) ; <nl> if ( err ) { <nl> memdelete ( da ) ; <nl> String err_str = String ( \" Failed to export loading screen ( \" ) + info . preset_key + \" ) from path ' \" + loading_screen_file + \" ' . \" ; <nl> ERR_PRINT ( err_str . utf8 ( ) . get_data ( ) ) ; <nl> return err ; <nl> } <nl> + } else if ( ( bool ) p_preset - > get ( \" launch_screens / generate_missing \" ) ) { <nl> + / / Generate loading screen from the splash screen <nl> + Color boot_bg_color = ProjectSettings : : get_singleton ( ) - > get ( \" application / boot_splash / bg_color \" ) ; <nl> + String boot_logo_path = ProjectSettings : : get_singleton ( ) - > get ( \" application / boot_splash / image \" ) ; <nl> + bool boot_logo_scale = ProjectSettings : : get_singleton ( ) - > get ( \" application / boot_splash / fullsize \" ) ; <nl> + <nl> + Ref < Image > img = memnew ( Image ) ; <nl> + img - > create ( info . width , info . height , false , Image : : FORMAT_RGBA8 ) ; <nl> + img - > fill ( boot_bg_color ) ; <nl> + <nl> + Ref < Image > img_bs ; <nl> + <nl> + if ( boot_logo_path . length ( ) > 0 ) { <nl> + img_bs = Ref < Image > ( memnew ( Image ) ) ; <nl> + ImageLoader : : load_image ( boot_logo_path , img_bs ) ; <nl> + } <nl> + if ( ! img_bs . is_valid ( ) ) { <nl> + img_bs = Ref < Image > ( memnew ( Image ( boot_splash_png ) ) ) ; <nl> + } <nl> + if ( img_bs . is_valid ( ) ) { <nl> + float aspect_ratio = ( float ) img_bs - > get_width ( ) / ( float ) img_bs - > get_height ( ) ; <nl> + if ( info . rotate ) { <nl> + if ( boot_logo_scale ) { <nl> + if ( info . width * aspect_ratio < = info . height ) { <nl> + img_bs - > resize ( info . width * aspect_ratio , info . width ) ; <nl> + } else { <nl> + img_bs - > resize ( info . height , info . height / aspect_ratio ) ; <nl> + } <nl> + } <nl> + } else { <nl> + if ( boot_logo_scale ) { <nl> + if ( info . height * aspect_ratio < = info . width ) { <nl> + img_bs - > resize ( info . height * aspect_ratio , info . height ) ; <nl> + } else { <nl> + img_bs - > resize ( info . width , info . width / aspect_ratio ) ; <nl> + } <nl> + } <nl> + } <nl> + _blend_and_rotate ( img , img_bs , info . rotate ) ; <nl> + } <nl> + Error err = img - > save_png ( p_dest_dir + info . export_name ) ; <nl> + if ( err ) { <nl> + String err_str = String ( \" Failed to export loading screen ( \" ) + info . preset_key + \" ) from splash screen . \" ; <nl> + WARN_PRINT ( err_str . utf8 ( ) . get_data ( ) ) ; <nl> + } <nl> + } else { <nl> + String err_str = String ( \" No loading screen ( \" ) + info . preset_key + \" ) specified . \" ; <nl> + WARN_PRINT ( err_str . utf8 ( ) . get_data ( ) ) ; <nl> } <nl> } <nl> memdelete ( da ) ; <nl>\n", "msg": "[ iOS ] Adds export options to automatically generate iOS icons and launch screens from the project icon and boot splash .\n", "score": 1}
{"diff_id": 14160, "msg": "Minor visual improvements to the \" Batch Rename \" dialog\n", "msgGPT": "added missing colons to the label texts in the rename dialog.", "METEOR Score": "28.629603317608403", "BLEU Score": "0.41001650683486834", "ROUGE-L Score": "0.42105262659279785", "score": 1, "repo": "godotengine/godot\n", "sha": "25d18e34916ab4a2a5a1281b42549b11cdc8d29c\n", "time": "2020-08-14T18:57:07Z\n", "diff": "mmm a / editor / rename_dialog . cpp <nl> ppp b / editor / rename_dialog . cpp <nl> RenameDialog : : RenameDialog ( SceneTreeEditor * p_scene_tree_editor , UndoRedo * p_und <nl> / / mmm - 1st & 2nd row <nl> <nl> Label * lbl_search = memnew ( Label ) ; <nl> - lbl_search - > set_text ( TTR ( \" Search \" ) ) ; <nl> + lbl_search - > set_text ( TTR ( \" Search : \" ) ) ; <nl> <nl> lne_search = memnew ( LineEdit ) ; <nl> - lne_search - > set_placeholder ( TTR ( \" Search \" ) ) ; <nl> lne_search - > set_name ( \" lne_search \" ) ; <nl> lne_search - > set_h_size_flags ( Control : : SIZE_EXPAND_FILL ) ; <nl> <nl> Label * lbl_replace = memnew ( Label ) ; <nl> - lbl_replace - > set_text ( TTR ( \" Replace \" ) ) ; <nl> + lbl_replace - > set_text ( TTR ( \" Replace : \" ) ) ; <nl> <nl> lne_replace = memnew ( LineEdit ) ; <nl> - lne_replace - > set_placeholder ( TTR ( \" Replace \" ) ) ; <nl> lne_replace - > set_name ( \" lne_replace \" ) ; <nl> lne_replace - > set_h_size_flags ( Control : : SIZE_EXPAND_FILL ) ; <nl> <nl> RenameDialog : : RenameDialog ( SceneTreeEditor * p_scene_tree_editor , UndoRedo * p_und <nl> / / mmm - 3rd & 4th row <nl> <nl> Label * lbl_prefix = memnew ( Label ) ; <nl> - lbl_prefix - > set_text ( TTR ( \" Prefix \" ) ) ; <nl> + lbl_prefix - > set_text ( TTR ( \" Prefix : \" ) ) ; <nl> <nl> lne_prefix = memnew ( LineEdit ) ; <nl> - lne_prefix - > set_placeholder ( TTR ( \" Prefix \" ) ) ; <nl> lne_prefix - > set_name ( \" lne_prefix \" ) ; <nl> lne_prefix - > set_h_size_flags ( Control : : SIZE_EXPAND_FILL ) ; <nl> <nl> Label * lbl_suffix = memnew ( Label ) ; <nl> - lbl_suffix - > set_text ( TTR ( \" Suffix \" ) ) ; <nl> + lbl_suffix - > set_text ( TTR ( \" Suffix : \" ) ) ; <nl> <nl> lne_suffix = memnew ( LineEdit ) ; <nl> - lne_suffix - > set_placeholder ( TTR ( \" Suffix \" ) ) ; <nl> lne_suffix - > set_name ( \" lne_suffix \" ) ; <nl> lne_suffix - > set_h_size_flags ( Control : : SIZE_EXPAND_FILL ) ; <nl> <nl> RenameDialog : : RenameDialog ( SceneTreeEditor * p_scene_tree_editor , UndoRedo * p_und <nl> <nl> / / - - Feature Tabs <nl> <nl> - const int feature_min_height = 160 * EDSCALE ; <nl> - <nl> cbut_regex = memnew ( CheckButton ) ; <nl> cbut_regex - > set_text ( TTR ( \" Use Regular Expressions \" ) ) ; <nl> vbc - > add_child ( cbut_regex ) ; <nl> RenameDialog : : RenameDialog ( SceneTreeEditor * p_scene_tree_editor , UndoRedo * p_und <nl> <nl> tabc_features = memnew ( TabContainer ) ; <nl> tabc_features - > set_tab_align ( TabContainer : : ALIGN_LEFT ) ; <nl> + tabc_features - > set_use_hidden_tabs_for_min_size ( true ) ; <nl> vbc - > add_child ( tabc_features ) ; <nl> <nl> / / mmm - Tab Substitute <nl> <nl> VBoxContainer * vbc_substitute = memnew ( VBoxContainer ) ; <nl> vbc_substitute - > set_h_size_flags ( Control : : SIZE_EXPAND_FILL ) ; <nl> - vbc_substitute - > set_custom_minimum_size ( Size2 ( 0 , feature_min_height ) ) ; <nl> <nl> vbc_substitute - > set_name ( TTR ( \" Substitute \" ) ) ; <nl> tabc_features - > add_child ( vbc_substitute ) ; <nl> RenameDialog : : RenameDialog ( SceneTreeEditor * p_scene_tree_editor , UndoRedo * p_und <nl> <nl> chk_per_level_counter = memnew ( CheckBox ) ; <nl> chk_per_level_counter - > set_text ( TTR ( \" Per - level Counter \" ) ) ; <nl> - chk_per_level_counter - > set_tooltip ( TTR ( \" If set the counter restarts for each group of child nodes . \" ) ) ; <nl> + chk_per_level_counter - > set_tooltip ( TTR ( \" If set , the counter restarts for each group of child nodes . \" ) ) ; <nl> vbc_substitute - > add_child ( chk_per_level_counter ) ; <nl> <nl> HBoxContainer * hbc_count_options = memnew ( HBoxContainer ) ; <nl> RenameDialog : : RenameDialog ( SceneTreeEditor * p_scene_tree_editor , UndoRedo * p_und <nl> VBoxContainer * vbc_process = memnew ( VBoxContainer ) ; <nl> vbc_process - > set_h_size_flags ( Control : : SIZE_EXPAND_FILL ) ; <nl> vbc_process - > set_name ( TTR ( \" Post - Process \" ) ) ; <nl> - vbc_process - > set_custom_minimum_size ( Size2 ( 0 , feature_min_height ) ) ; <nl> tabc_features - > add_child ( vbc_process ) ; <nl> <nl> cbut_process = memnew ( CheckBox ) ; <nl> RenameDialog : : RenameDialog ( SceneTreeEditor * p_scene_tree_editor , UndoRedo * p_und <nl> vbc - > add_child ( sep_preview ) ; <nl> <nl> lbl_preview_title = memnew ( Label ) ; <nl> - lbl_preview_title - > set_text ( TTR ( \" Preview \" ) ) ; <nl> vbc - > add_child ( lbl_preview_title ) ; <nl> <nl> lbl_preview = memnew ( Label ) ; <nl> - lbl_preview - > set_text ( \" \" ) ; <nl> - lbl_preview - > add_theme_color_override ( \" font_color \" , EditorNode : : get_singleton ( ) - > get_gui_base ( ) - > get_theme_color ( \" error_color \" , \" Editor \" ) ) ; <nl> vbc - > add_child ( lbl_preview ) ; <nl> <nl> / / mmm - Dialog related <nl> <nl> set_min_size ( Size2 ( 383 , 0 ) ) ; <nl> - / / set_as_toplevel ( true ) ; <nl> get_ok ( ) - > set_text ( TTR ( \" Rename \" ) ) ; <nl> Button * but_reset = add_button ( TTR ( \" Reset \" ) ) ; <nl> <nl> RenameDialog : : RenameDialog ( SceneTreeEditor * p_scene_tree_editor , UndoRedo * p_und <nl> <nl> cbut_collapse_features - > connect ( \" toggled \" , callable_mp ( this , & RenameDialog : : _features_toggled ) ) ; <nl> <nl> - / / Substitite Buttons <nl> + / / Substitute Buttons <nl> <nl> lne_search - > connect ( \" focus_entered \" , callable_mp ( this , & RenameDialog : : _update_substitute ) ) ; <nl> lne_search - > connect ( \" focus_exited \" , callable_mp ( this , & RenameDialog : : _update_substitute ) ) ; <nl> void RenameDialog : : _update_preview ( String new_text ) { <nl> String new_name = _apply_rename ( preview_node , spn_count_start - > get_value ( ) ) ; <nl> <nl> if ( ! has_errors ) { <nl> - lbl_preview_title - > set_text ( TTR ( \" Preview \" ) ) ; <nl> + lbl_preview_title - > set_text ( TTR ( \" Preview : \" ) ) ; <nl> lbl_preview - > set_text ( new_name ) ; <nl> <nl> if ( new_name = = preview_node - > get_name ( ) ) { <nl> void RenameDialog : : _error_handler ( void * p_self , const char * p_func , const char * <nl> } <nl> <nl> self - > has_errors = true ; <nl> - self - > lbl_preview_title - > set_text ( TTR ( \" Regular Expression Error \" ) ) ; <nl> + self - > lbl_preview_title - > set_text ( TTR ( \" Regular Expression Error : \" ) ) ; <nl> self - > lbl_preview - > add_theme_color_override ( \" font_color \" , EditorNode : : get_singleton ( ) - > get_gui_base ( ) - > get_theme_color ( \" error_color \" , \" Editor \" ) ) ; <nl> self - > lbl_preview - > set_text ( vformat ( TTR ( \" At character % s \" ) , err_str ) ) ; <nl> } <nl>\n"}
{"diff_id": 14186, "repo": "bitcoin/bitcoin\n", "sha": "5d35ae3326624da3fe5dcb4047c9a7cec6665cab\n", "time": "2019-03-23T20:35:24Z\n", "diff": "mmm a / src / util / system . cpp <nl> ppp b / src / util / system . cpp <nl> void AllocateFileRange ( FILE * file , unsigned int offset , unsigned int length ) { <nl> fcntl ( fileno ( file ) , F_PREALLOCATE , & fst ) ; <nl> } <nl> ftruncate ( fileno ( file ) , fst . fst_length ) ; <nl> - # elif defined ( __linux__ ) <nl> + # else <nl> + # if defined ( __linux__ ) <nl> / / Version using posix_fallocate <nl> off_t nEndPos = ( off_t ) offset + length ; <nl> - posix_fallocate ( fileno ( file ) , 0 , nEndPos ) ; <nl> - # else <nl> + if ( 0 = = posix_fallocate ( fileno ( file ) , 0 , nEndPos ) ) return ; <nl> + # endif <nl> / / Fallback version <nl> / / TODO : just write one byte per block <nl> static const char buf [ 65536 ] = { } ; <nl>\n", "msg": "Handle the result of posix_fallocate system call\n"}
{"diff_id": 14306, "repo": "notepad-plus-plus/notepad-plus-plus\n", "sha": "9443e2e8f221e565f46423df099f56bec14c3ed2\n", "time": "2019-04-02T21:30:49Z\n", "diff": "mmm a / PowerEditor / src / NppIO . cpp <nl> ppp b / PowerEditor / src / NppIO . cpp <nl> bool Notepad_plus : : loadSession ( Session & session , bool isSnapshotMode ) <nl> } <nl> buf - > setLangType ( typeToSet , pLn ) ; <nl> buf - > setEncoding ( session . _subViewFiles [ k ] . _encoding ) ; <nl> - buf - > setUserReadOnly ( session . _mainViewFiles [ k ] . _isUserReadOnly ) ; <nl> + buf - > setUserReadOnly ( session . _subViewFiles [ k ] . _isUserReadOnly ) ; <nl> <nl> if ( isSnapshotMode & & session . _subViewFiles [ k ] . _backupFilePath ! = TEXT ( \" \" ) & & PathFileExists ( session . _subViewFiles [ k ] . _backupFilePath . c_str ( ) ) ) <nl> buf - > setDirty ( true ) ; <nl>\n", "msg": "Fix a crash issue due to cfa702a8a87272c276e4cb46c8979f2418ef25e2\n"}
{"diff_id": 14324, "repo": "apple/swift\n", "sha": "73adca7d2cf2c2ec5ba6c763500cb11c64355649\n", "time": "2015-12-29T00:15:57Z\n", "diff": "mmm a / lib / SIL / SILValueProjection . cpp <nl> ppp b / lib / SIL / SILValueProjection . cpp <nl> bool LSLocation : : isNonEscapingLocalLSLocation ( SILFunction * Fn , <nl> / / An alloc_stack is definitely dead at the end of the function . <nl> if ( isa < AllocStackInst > ( Base ) ) <nl> return true ; <nl> + / / For other allocations we ask escape analysis . <nl> + auto * ConGraph = EA - > getConnectionGraph ( Fn ) ; <nl> + if ( isa < AllocationInst > ( Base ) ) { <nl> + auto * Node = ConGraph - > getNodeOrNull ( Base , EA ) ; <nl> + if ( Node & & ! Node - > escapes ( ) ) { <nl> + return true ; <nl> + } <nl> + } <nl> return false ; <nl> } <nl> <nl>\n", "msg": "After looking at the commit at which the test case broke . I do not think the\n"}
{"diff_id": 14381, "repo": "apple/swift\n", "sha": "b6f39e3132de823f3ddf51d77fd45308c039f3b4\n", "time": "2017-10-27T17:42:59Z\n", "diff": "mmm a / lib / IRGen / GenBuiltin . cpp <nl> ppp b / lib / IRGen / GenBuiltin . cpp <nl> void irgen : : emitBuiltinCall ( IRGenFunction & IGF , Identifier FnId , <nl> return out . add ( v ) ; \\ <nl> } <nl> <nl> - # define BUILTIN_RUNTIME_CALL ( id , name , attrs ) \\ <nl> - if ( Builtin . ID = = BuiltinValueKind : : id ) { \\ <nl> - llvm : : CallInst * call = IGF . Builder . CreateCall ( IGF . IGM . get # # id # # Fn ( ) , \\ <nl> - args . claimNext ( ) ) ; \\ <nl> - call - > setCallingConv ( IGF . IGM . DefaultCC ) ; \\ <nl> - call - > setDoesNotThrow ( ) ; \\ <nl> - return out . add ( call ) ; \\ <nl> - } <nl> + # define BUILTIN_RUNTIME_CALL ( id , name , attrs ) \\ <nl> + if ( Builtin . ID = = BuiltinValueKind : : id ) { \\ <nl> + auto * fn = cast < llvm : : Function > ( IGF . IGM . get # # id # # Fn ( ) ) ; \\ <nl> + llvm : : CallInst * call = IGF . Builder . CreateCall ( fn , args . claimNext ( ) ) ; \\ <nl> + call - > setCallingConv ( fn - > getCallingConv ( ) ) ; \\ <nl> + call - > setAttributes ( fn - > getAttributes ( ) ) ; \\ <nl> + return out . add ( call ) ; \\ <nl> + } <nl> <nl> # define BUILTIN_BINARY_OPERATION_WITH_OVERFLOW ( id , name , uncheckedID , attrs , overload ) \\ <nl> if ( Builtin . ID = = BuiltinValueKind : : id ) { \\ <nl>\n", "msg": "IRGen : Whe emitting a call to a builtin runtime function transfer the\n", "score": 1}
{"diff_id": 14418, "repo": "godotengine/godot\n", "sha": "3a0f665c90ea645eaf56397dd873e2b8f0bcc38a\n", "time": "2015-01-13T09:16:56Z\n", "diff": "mmm a / scene / gui / text_edit . cpp <nl> ppp b / scene / gui / text_edit . cpp <nl> void TextEdit : : _update_scrollbars ( ) { <nl> <nl> int hscroll_rows = ( ( hmin . height - 1 ) / get_row_height ( ) ) + 1 ; <nl> int visible_rows = get_visible_rows ( ) ; <nl> - int total_rows = text . size ( ) * cache . line_spacing ; <nl> + int total_rows = text . size ( ) ; <nl> <nl> int vscroll_pixels = v_scroll - > get_combined_minimum_size ( ) . width ; <nl> int visible_width = size . width - cache . style_normal - > get_minimum_size ( ) . width ; <nl>\n", "msg": "Total rows of text edit was calculated wrong , fixed issue\n"}
{"diff_id": 14436, "repo": "ClickHouse/ClickHouse\n", "sha": "cb7a458ac4e30cc9105a3b1a6fbcb9b7affd9c7b\n", "time": "2016-08-07T11:12:55Z\n", "diff": "mmm a / dbms / src / Storages / StorageMergeTree . cpp <nl> ppp b / dbms / src / Storages / StorageMergeTree . cpp <nl> void StorageMergeTree : : alter ( <nl> if ( primary_key_is_modified & & data . merging_params . mode = = MergeTreeData : : MergingParams : : Unsorted ) <nl> throw Exception ( \" UnsortedMergeTree cannot have primary key \" , ErrorCodes : : BAD_ARGUMENTS ) ; <nl> <nl> + if ( primary_key_is_modified & & supportsSampling ( ) ) <nl> + throw Exception ( \" MODIFY PRIMARY KEY only supported for tables without sampling key \" , ErrorCodes : : BAD_ARGUMENTS ) ; <nl> + <nl> MergeTreeData : : DataParts parts = data . getAllDataParts ( ) ; <nl> for ( const MergeTreeData : : DataPartPtr & part : parts ) <nl> if ( auto transaction = data . alterDataPart ( part , columns_for_parts , new_primary_key_ast , false ) ) <nl>\n", "msg": "Added check [ # METR - 22325 ] .\n"}
{"diff_id": 14462, "repo": "xbmc/xbmc\n", "sha": "1c8dbe9f926871c86298782c343f017f3142a5b0\n", "time": "2010-07-03T03:18:29Z\n", "diff": "mmm a / xbmc / cores / dvdplayer / DVDCodecs / Video / CrystalHD . cpp <nl> ppp b / xbmc / cores / dvdplayer / DVDCodecs / Video / CrystalHD . cpp <nl> void CCrystalHD : : OpenDevice ( ) <nl> # ifdef USE_CHD_SINGLE_THREADED_API <nl> BCM : : DTS_SINGLE_THREADED_MODE | <nl> # endif <nl> - / * BCM : : DTS_SKIP_TX_CHK_CPB | * / <nl> - / * BCM : : DTS_PLAYBACK_DROP_RPT_MODE | * / <nl> + BCM : : DTS_SKIP_TX_CHK_CPB | <nl> + BCM : : DTS_PLAYBACK_DROP_RPT_MODE | <nl> / / DTS_DFLT_RESOLUTION ( BCM : : vdecRESOLUTION_CUSTOM ) ; <nl> DTS_DFLT_RESOLUTION ( BCM : : vdecRESOLUTION_720p23_976 ) ; <nl> <nl> bool CCrystalHD : : OpenDecoder ( CRYSTALHD_CODEC_TYPE codec_type , int extradata_size <nl> # if ( HAVE_LIBCRYSTALHD = = 2 ) <nl> if ( m_has_bcm70015 ) <nl> { <nl> - int start_code_size = 0 ; <nl> + int start_code_size = 4 ; <nl> uint8_t * meta_data = NULL ; <nl> uint32_t meta_data_size = 0 ; <nl> BCM : : BC_INPUT_FORMAT bcm_input_format ; <nl> bool CCrystalHD : : GetPicture ( DVDVideoPicture * pDvdVideoPicture ) <nl> <nl> void CCrystalHD : : SetDropState ( bool bDrop ) <nl> { <nl> - if ( m_reset ) <nl> - { <nl> - if ( m_drop_state ! = bDrop ) <nl> - m_drop_state = bDrop ; <nl> + if ( ! m_has_bcm70015 ) <nl> + { <nl> + if ( m_reset ) <nl> + { <nl> + if ( m_drop_state ! = bDrop ) <nl> + m_drop_state = bDrop ; <nl> <nl> - m_reset - - ; <nl> - if ( ! m_reset ) <nl> - m_dll - > DtsSetSkipPictureMode ( m_device , 0 ) ; <nl> + m_reset - - ; <nl> + if ( ! m_reset ) <nl> + m_dll - > DtsSetSkipPictureMode ( m_device , 0 ) ; <nl> <nl> - return ; <nl> - } <nl> + return ; <nl> + } <nl> <nl> - if ( m_drop_state ! = bDrop ) <nl> - { <nl> - m_drop_state = bDrop ; <nl> - if ( m_drop_state ) <nl> - m_dll - > DtsSetSkipPictureMode ( m_device , 1 ) ; <nl> - else <nl> - m_dll - > DtsSetSkipPictureMode ( m_device , 0 ) ; <nl> + if ( m_drop_state ! = bDrop ) <nl> + { <nl> + m_drop_state = bDrop ; <nl> + if ( m_drop_state ) <nl> + m_dll - > DtsSetSkipPictureMode ( m_device , 1 ) ; <nl> + else <nl> + m_dll - > DtsSetSkipPictureMode ( m_device , 0 ) ; <nl> + } <nl> } <nl> / * <nl> if ( m_drop_state ) <nl>\n", "msg": "[ chd ] ignore drops with bcm70015\n"}
{"diff_id": 14515, "repo": "EOSIO/eos\n", "sha": "3cf414ee5d1a3d8584bb7bc9864b1b4b167c16b5\n", "time": "2018-05-09T19:06:06Z\n", "diff": "mmm a / unittests / api_tests . cpp <nl> ppp b / unittests / api_tests . cpp <nl> BOOST_FIXTURE_TEST_CASE ( deferred_transaction_tests , TESTER ) { try { <nl> / / schedule <nl> { <nl> transaction_trace_ptr trace ; <nl> - control - > applied_transaction . connect ( [ & ] ( const transaction_trace_ptr & t ) { if ( t - > scheduled ) { trace = t ; } } ) ; <nl> + auto c = control - > applied_transaction . connect ( [ & ] ( const transaction_trace_ptr & t ) { if ( t - > scheduled ) { trace = t ; } } ) ; <nl> CALL_TEST_FUNCTION ( * this , \" test_transaction \" , \" send_deferred_transaction \" , { } ) ; <nl> / / check that it doesn ' t get executed immediately <nl> control - > push_next_scheduled_transaction ( ) ; <nl> BOOST_FIXTURE_TEST_CASE ( deferred_transaction_tests , TESTER ) { try { <nl> / / confirm printed message <nl> BOOST_TEST ( ! trace - > action_traces . empty ( ) ) ; <nl> BOOST_TEST ( trace - > action_traces . back ( ) . console = = \" deferred executed \\ n \" ) ; <nl> + c . disconnect ( ) ; <nl> } <nl> <nl> produce_blocks ( 10 ) ; <nl>\n", "msg": "Remove callback to prevent accessing no longer existing stack objects .\n"}
{"diff_id": 14584, "repo": "EOSIO/eos\n", "sha": "88e5db9c041480bd04015bf4666ff623b527cdb8\n", "time": "2018-09-14T17:16:56Z\n", "diff": "mmm a / libraries / chain / controller . cpp <nl> ppp b / libraries / chain / controller . cpp <nl> struct controller_impl { <nl> bool trust = ! conf . force_all_checks & & ( s = = controller : : block_status : : irreversible | | s = = controller : : block_status : : validated ) ; <nl> auto new_header_state = fork_db . add ( b , trust ) ; <nl> emit ( self . accepted_block_header , new_header_state ) ; <nl> - / / on replay irreversible is not emitted by fork database , so emit it explicitly here <nl> - if ( s = = controller : : block_status : : irreversible ) <nl> - emit ( self . irreversible_block , new_header_state ) ; <nl> <nl> if ( read_mode ! = db_read_mode : : IRREVERSIBLE ) { <nl> maybe_switch_forks ( s ) ; <nl> } <nl> + <nl> + / / on replay irreversible is not emitted by fork database , so emit it explicitly here <nl> + if ( s = = controller : : block_status : : irreversible ) <nl> + emit ( self . irreversible_block , new_header_state ) ; <nl> + <nl> } FC_LOG_AND_RETHROW ( ) <nl> } <nl> <nl>\n", "msg": "avoid plugin through irreversible_block signal change block , so that apply_block faild . andkeep signal according to the order of accepted_transaction , applied_transaction and irreversible_block .\n", "score": 1}
{"diff_id": 14649, "repo": "godotengine/godot\n", "sha": "251f43d79e7c0f06591003a9a41102717cf2c72c\n", "time": "2020-06-19T19:16:51Z\n", "diff": "mmm a / editor / project_settings_editor . cpp <nl> ppp b / editor / project_settings_editor . cpp <nl> ProjectSettingsEditor : : ProjectSettingsEditor ( EditorData * p_data ) { <nl> restart_icon - > set_v_size_flags ( Control : : SIZE_SHRINK_CENTER ) ; <nl> restart_hb - > add_child ( restart_icon ) ; <nl> restart_label = memnew ( Label ) ; <nl> - restart_label - > set_text ( TTR ( \" The editor must be restarted for changes to take effect . \" ) ) ; <nl> + restart_label - > set_text ( TTR ( \" Changed settings will be applied to the editor after restarting . \" ) ) ; <nl> restart_hb - > add_child ( restart_label ) ; <nl> restart_hb - > add_spacer ( ) ; <nl> Button * restart_button = memnew ( Button ) ; <nl>\n", "msg": "Project Settings ' restart ' message put focus on editor rather than project itself\n"}
{"diff_id": 14741, "repo": "Tencent/ncnn\n", "sha": "68f016936d995d6b1096a10e3c2ab60e22165e21\n", "time": "2018-03-03T06:46:06Z\n", "diff": "mmm a / tools / onnx / onnx2ncnn . cpp <nl> ppp b / tools / onnx / onnx2ncnn . cpp <nl> int main ( int argc , char * * argv ) <nl> } <nl> } <nl> <nl> + if ( op = = \" Dropout \" ) <nl> + { <nl> + const std : : string & output_name = node . output ( 0 ) ; <nl> + blob_names . insert ( output_name ) ; <nl> + continue ; <nl> + } <nl> + <nl> for ( int j = 0 ; j < ( int ) node . output_size ( ) ; j + + ) <nl> { <nl> const std : : string & output_name = node . output ( j ) ; <nl> int main ( int argc , char * * argv ) <nl> else if ( op = = \" Dropout \" ) <nl> { <nl> fprintf ( pp , \" % - 16s \" , \" Dropout \" ) ; <nl> + output_size = 1 ; <nl> } <nl> else if ( op = = \" Gemm \" ) <nl> { <nl> - fprintf ( pp , \" % - 16s \" , \" Innerproduct \" ) ; <nl> + float alpha = get_node_attr_f ( node , \" alpha \" , 1 . f ) ; <nl> + float beta = get_node_attr_f ( node , \" beta \" , 1 . f ) ; <nl> + int broadcast = get_node_attr_i ( node , \" broadcast \" , 0 ) ; <nl> + int transA = get_node_attr_i ( node , \" transA \" , 0 ) ; <nl> + int transB = get_node_attr_i ( node , \" transB \" , 0 ) ; <nl> + <nl> + if ( alpha = = 1 . f & & beta = = 1 . f ) <nl> + { <nl> + / / InnerProduct - like A * B + C <nl> + if ( transA = = 0 & & transB = = 1 & & broadcast = = 1 ) <nl> + { <nl> + fprintf ( pp , \" % - 16s \" , \" InnerProduct \" ) ; <nl> + } <nl> + } <nl> + <nl> + / / TODO <nl> } <nl> else if ( op = = \" GlobalAveragePool \" ) <nl> { <nl> int main ( int argc , char * * argv ) <nl> { <nl> fprintf ( pp , \" % - 16s \" , \" Softmax \" ) ; <nl> } <nl> + else if ( op = = \" Sum \" ) <nl> + { <nl> + fprintf ( pp , \" % - 16s \" , \" Eltwise \" ) ; <nl> + } <nl> else if ( op = = \" Transpose \" ) <nl> { <nl> fprintf ( pp , \" % - 16s \" , \" Permute \" ) ; <nl> int main ( int argc , char * * argv ) <nl> fprintf ( pp , \" % s \" , input_name . c_str ( ) ) ; <nl> } <nl> <nl> - for ( int j = 0 ; j < node . output_size ( ) ; j + + ) <nl> + for ( int j = 0 ; j < output_size ; j + + ) <nl> { <nl> const std : : string & output_name = node . output ( j ) ; <nl> <nl> int main ( int argc , char * * argv ) <nl> } else if ( pads . size ( ) = = 4 ) { <nl> fprintf ( pp , \" 3 = % d \" , pads [ 1 ] ) ; <nl> fprintf ( pp , \" 13 = % d \" , pads [ 0 ] ) ; <nl> - / / TODO hpad2 = pads [ 2 ] wpad2 = pads [ 3 ] <nl> + fprintf ( pp , \" 14 = % d \" , pads [ 3 ] ) ; <nl> + fprintf ( pp , \" 15 = % d \" , pads [ 2 ] ) ; <nl> } <nl> <nl> fprintf ( pp , \" 5 = % d \" , pad_mode ) ; <nl> int main ( int argc , char * * argv ) <nl> <nl> if ( alpha = = 1 . f & & beta = = 1 . f ) <nl> { <nl> - / / A * B + C <nl> + / / InnerProduct - like A * B + C <nl> if ( transA = = 0 & & transB = = 1 & & broadcast = = 1 ) <nl> { <nl> const onnx : : TensorProto & B = graph . initializer ( weight_nodes [ node . input ( 1 ) ] ) ; <nl> const onnx : : TensorProto & C = graph . initializer ( weight_nodes [ node . input ( 2 ) ] ) ; <nl> <nl> + fprintf ( pp , \" 0 = % d \" , get_tensor_proto_data_size ( C ) ) ; <nl> + fprintf ( pp , \" 1 = 1 \" ) ; <nl> + fprintf ( pp , \" 2 = % d \" , get_tensor_proto_data_size ( B ) ) ; <nl> + <nl> + int quantize_tag = 0 ; <nl> + fwrite ( & quantize_tag , sizeof ( int ) , 1 , bp ) ; <nl> + <nl> fwrite_tensor_proto_data ( B , bp ) ; <nl> fwrite_tensor_proto_data ( C , bp ) ; <nl> } <nl> int main ( int argc , char * * argv ) <nl> int axis = get_node_attr_i ( node , \" axis \" , 1 ) ; <nl> fprintf ( pp , \" 0 = % d \" , axis - 1 ) ; <nl> } <nl> + else if ( op = = \" Sum \" ) <nl> + { <nl> + int op_type = 1 ; <nl> + fprintf ( pp , \" 0 = % d \" , op_type ) ; <nl> + } <nl> else if ( op = = \" Transpose \" ) <nl> { <nl> std : : vector < int > perm = get_node_attr_ai ( node , \" perm \" ) ; <nl>\n", "msg": "convert Dropout Sum and InnerProduct - like Gemm , inception_v1 works : P\n"}
{"diff_id": 14813, "repo": "CRYTEK/CRYENGINE\n", "sha": "f58c92e9b5c62480d87601d94a5f724fbfda2338\n", "time": "2018-11-29T11:52:54Z\n", "diff": "mmm a / Code / CryEngine / RenderDll / XRenderD3D9 / PipelineProfiler . cpp <nl> ppp b / Code / CryEngine / RenderDll / XRenderD3D9 / PipelineProfiler . cpp <nl> CRenderPipelineProfiler : : CRenderPipelineProfiler ( ) <nl> <nl> m_avgFrameTime = 0 ; <nl> m_enabled = false ; <nl> + m_paused = false ; <nl> m_recordData = false ; <nl> <nl> m_stack . reserve ( 8 ) ; <nl>\n", "msg": "! B ( Renderer ) Prevent pipeline - profiler to indefinitely pause when splash - screen doesn ' t happen\n", "score": 1}
{"diff_id": 14908, "repo": "cocos2d/cocos2d-x\n", "sha": "955ddaafb77fc9f5f107c657905fabe5218b3f0c\n", "time": "2015-11-27T02:20:04Z\n", "diff": "mmm a / tests / js - tests / project / Classes / js_Effect3D_bindings . cpp <nl> ppp b / tests / js - tests / project / Classes / js_Effect3D_bindings . cpp <nl> bool js_cocos2dx_EffectSprite3D_setEffect3D ( JSContext * cx , uint32_t argc , jsval <nl> do { <nl> if ( ! args . get ( 0 ) . isObject ( ) ) { ok = false ; break ; } <nl> js_proxy_t * jsProxy ; <nl> - JSObject * tmpObj = args . get ( 0 ) . toObjectOrNull ( ) ; <nl> + JS : : RootedObject tmpObj ( cx , args . get ( 0 ) . toObjectOrNull ( ) ) ; <nl> jsProxy = jsb_get_js_proxy ( tmpObj ) ; <nl> arg0 = ( Effect3D * ) ( jsProxy ? jsProxy - > ptr : NULL ) ; <nl> JSB_PRECONDITION2 ( arg0 , cx , false , \" Invalid Native Object \" ) ; <nl> bool js_cocos2dx_EffectSprite3D_addEffect ( JSContext * cx , uint32_t argc , jsval * v <nl> do { <nl> if ( ! args . get ( 0 ) . isObject ( ) ) { ok = false ; break ; } <nl> js_proxy_t * jsProxy ; <nl> - JSObject * tmpObj = args . get ( 0 ) . toObjectOrNull ( ) ; <nl> + JS : : RootedObject tmpObj ( cx , args . get ( 0 ) . toObjectOrNull ( ) ) ; <nl> jsProxy = jsb_get_js_proxy ( tmpObj ) ; <nl> arg0 = ( Effect3DOutline * ) ( jsProxy ? jsProxy - > ptr : NULL ) ; <nl> JSB_PRECONDITION2 ( arg0 , cx , false , \" Invalid Native Object \" ) ; <nl>\n", "msg": "Use rooted object for js_proxy new and get ( missed )\n", "score": 1}
{"diff_id": 14946, "repo": "xbmc/xbmc\n", "sha": "a70ba860c210608e7ccf77b8744d3620ada55a80\n", "time": "2016-07-28T19:48:13Z\n", "diff": "mmm a / xbmc / listproviders / DirectoryProvider . cpp <nl> ppp b / xbmc / listproviders / DirectoryProvider . cpp <nl> <nl> # include \" settings / Settings . h \" <nl> # include \" threads / SingleLock . h \" <nl> # include \" utils / JobManager . h \" <nl> + # include \" utils / log . h \" <nl> # include \" utils / SortUtils . h \" <nl> # include \" utils / URIUtils . h \" <nl> # include \" utils / Variant . h \" <nl> bool CDirectoryProvider : : Update ( bool forceRefresh ) <nl> fireJob | = UpdateSort ( ) ; <nl> fireJob | = UpdateLimit ( ) ; <nl> if ( fireJob ) <nl> + { <nl> + { <nl> + CSingleLock lock ( m_section ) ; <nl> + CLog : : Log ( LOGDEBUG , \" CDirectoryProvider [ % s ] : refreshing . . \" , m_currentUrl . c_str ( ) ) ; <nl> + } <nl> FireJob ( ) ; <nl> + } <nl> <nl> for ( std : : vector < CGUIStaticItemPtr > : : iterator i = m_items . begin ( ) ; i ! = m_items . end ( ) ; + + i ) <nl> changed | = ( * i ) - > UpdateVisibility ( m_parentID ) ; <nl>\n", "msg": "[ listprovider ] add trace logging for refresh\n"}
{"diff_id": 15086, "repo": "google/filament\n", "sha": "16088760c8a5ae658a83fdd71ca06ec8e3fd2004\n", "time": "2019-02-02T01:10:45Z\n", "diff": "mmm a / filament / src / driver / vulkan / VulkanHandles . cpp <nl> ppp b / filament / src / driver / vulkan / VulkanHandles . cpp <nl> VulkanTexture : : VulkanTexture ( VulkanContext & context , SamplerType target , uint8_t <nl> imageInfo . usage | = VK_IMAGE_USAGE_DEPTH_STENCIL_ATTACHMENT_BIT ; <nl> } <nl> if ( usage & TextureUsage : : UPLOADABLE ) { <nl> - imageInfo . usage | = VK_IMAGE_USAGE_TRANSFER_DST_BIT ; <nl> + / / Uploadable textures can be used as a blit source ( e . g . for mipmap generation ) <nl> + / / therefore we must set both the TRANSFER_DST and TRANSFER_SRC flags . <nl> + imageInfo . usage | = VK_IMAGE_USAGE_TRANSFER_DST_BIT | VK_IMAGE_USAGE_TRANSFER_SRC_BIT ; <nl> } <nl> if ( usage & TextureUsage : : DEPTH_ATTACHMENT ) { <nl> imageInfo . usage | = VK_IMAGE_USAGE_DEPTH_STENCIL_ATTACHMENT_BIT ; <nl> - } else { <nl> - / / If it ' s a not an FBO target or a depth attachment , then it ' s safe to assume that it will <nl> - / / need to be uploaded or blitted to , so we should set USAGE_TRANSFER_DST . Also , since we <nl> - / / need to support GenerateMipmaps , it can be a blit source ; ergo we set USAGE_TRANSFER_SRC . <nl> - imageInfo . usage | = VK_IMAGE_USAGE_TRANSFER_DST_BIT | VK_IMAGE_USAGE_TRANSFER_SRC_BIT ; <nl> } <nl> <nl> VkResult error = vkCreateImage ( context . device , & imageInfo , VKALLOC , & textureImage ) ; <nl>\n", "msg": "Update VulkanTexture constructor for TextureUsage .\n"}
{"diff_id": 15359, "repo": "opencv/opencv\n", "sha": "55f8310cacebb1072d9f2880f7eb5a1be25264bc\n", "time": "2012-08-09T08:37:35Z\n", "diff": "mmm a / modules / video / src / bgfg_gmg . cpp <nl> ppp b / modules / video / src / bgfg_gmg . cpp <nl> namespace <nl> public : <nl> GMG_LoopBody ( const cv : : Mat & frame , const cv : : Mat & fgmask , const cv : : Mat_ < int > & nfeatures , const cv : : Mat_ < int > & colors , const cv : : Mat_ < float > & weights , <nl> int maxFeatures , double learningRate , int numInitializationFrames , int quantizationLevels , double backgroundPrior , double decisionThreshold , <nl> - double maxVal , double minVal , size_t frameNum ) : <nl> + double maxVal , double minVal , int frameNum ) : <nl> frame_ ( frame ) , fgmask_ ( fgmask ) , nfeatures_ ( nfeatures ) , colors_ ( colors ) , weights_ ( weights ) , <nl> maxFeatures_ ( maxFeatures ) , learningRate_ ( learningRate ) , numInitializationFrames_ ( numInitializationFrames ) , <nl> quantizationLevels_ ( quantizationLevels ) , backgroundPrior_ ( backgroundPrior ) , decisionThreshold_ ( decisionThreshold ) , <nl> namespace <nl> <nl> double maxVal_ ; <nl> double minVal_ ; <nl> - size_t frameNum_ ; <nl> + int frameNum_ ; <nl> } ; <nl> <nl> void GMG_LoopBody : : operator ( ) ( const cv : : Range & range ) const <nl> namespace <nl> <nl> bool isForeground = false ; <nl> <nl> - if ( frameNum_ > numInitializationFrames_ ) <nl> + if ( frameNum_ > = numInitializationFrames_ ) <nl> { <nl> / / typical operation <nl> <nl> namespace <nl> const double posterior = ( weight * backgroundPrior_ ) / ( weight * backgroundPrior_ + ( 1 . 0 - weight ) * ( 1 . 0 - backgroundPrior_ ) ) ; <nl> <nl> isForeground = ( ( 1 . 0 - posterior ) > decisionThreshold_ ) ; <nl> - } <nl> <nl> - fgmask_row [ x ] = ( uchar ) ( - isForeground ) ; <nl> + / / update histogram . <nl> <nl> - if ( frameNum_ < = numInitializationFrames_ + 1 ) <nl> - { <nl> - / / training - mode update <nl> + for ( int i = 0 ; i < nfeatures ; + + i ) <nl> + weights [ i ] * = 1 . 0f - learningRate_ ; <nl> <nl> - insertFeature ( newFeatureColor , 1 . 0f , colors , weights , nfeatures , maxFeatures_ ) ; <nl> + bool inserted = insertFeature ( newFeatureColor , learningRate_ , colors , weights , nfeatures , maxFeatures_ ) ; <nl> <nl> - if ( frameNum_ = = numInitializationFrames_ + 1 ) <nl> + if ( inserted ) <nl> + { <nl> normalizeHistogram ( weights , nfeatures ) ; <nl> + nfeatures_row [ x ] = nfeatures ; <nl> + } <nl> } <nl> else <nl> { <nl> - / / update histogram . <nl> - <nl> - for ( int i = 0 ; i < nfeatures ; + + i ) <nl> - weights [ i ] * = 1 . 0f - learningRate_ ; <nl> + / / training - mode update <nl> <nl> - bool inserted = insertFeature ( newFeatureColor , learningRate_ , colors , weights , nfeatures , maxFeatures_ ) ; <nl> + insertFeature ( newFeatureColor , 1 . 0f , colors , weights , nfeatures , maxFeatures_ ) ; <nl> <nl> - if ( inserted ) <nl> + if ( frameNum_ = = numInitializationFrames_ - 1 ) <nl> normalizeHistogram ( weights , nfeatures ) ; <nl> } <nl> <nl> - nfeatures_row [ x ] = nfeatures ; <nl> + fgmask_row [ x ] = ( uchar ) ( - isForeground ) ; <nl> } <nl> } <nl> } <nl>\n", "msg": "fixed number of training mode operation\n"}
{"diff_id": 15433, "repo": "ocornut/imgui\n", "sha": "5525c2356ab9bfeb3840fa80741f50f6e7013365\n", "time": "2016-06-29T08:30:42Z\n", "diff": "mmm a / imgui . cpp <nl> ppp b / imgui . cpp <nl> ImVec2 ImGui : : GetCursorPos ( ) <nl> <nl> float ImGui : : GetCursorPosX ( ) <nl> { <nl> - ImGuiWindow * window = GetCurrentWindow ( ) ; <nl> + ImGuiWindow * window = GetCurrentWindowRead ( ) ; <nl> return window - > DC . CursorPos . x - window - > Pos . x + window - > Scroll . x ; <nl> } <nl> <nl> float ImGui : : GetCursorPosY ( ) <nl> { <nl> - ImGuiWindow * window = GetCurrentWindow ( ) ; <nl> + ImGuiWindow * window = GetCurrentWindowRead ( ) ; <nl> return window - > DC . CursorPos . y - window - > Pos . y + window - > Scroll . y ; <nl> } <nl> <nl>\n", "msg": "Using GetCurrentWindowRead ( ) instead of GetCurrentWindow ( )\n"}
{"diff_id": 15505, "repo": "opencv/opencv\n", "sha": "8c7d29e52642cf8e256ae657c5b98befb0c748e2\n", "time": "2017-03-09T17:08:34Z\n", "diff": "mmm a / modules / imgproc / src / drawing . cpp <nl> ppp b / modules / imgproc / src / drawing . cpp <nl> static inline uint16_t opencvLittleToHost16 ( const uchar * p ) { <nl> # endif <nl> } <nl> <nl> + / * <nl> static inline uint16_t opencvLittleToHost16 ( uint16_t x ) { <nl> # if OPENCV_LITTLEENDIAN <nl> return x ; <nl> # else <nl> - return opencvLittleToHost16 ( ( uchar * ) & x ) ; <nl> + return opencvLittleToHost16 ( ( const uchar * ) & x ) ; <nl> # endif <nl> } <nl> + * / <nl> <nl> static inline uint32_t opencvLittleToHost32 ( const uchar * p ) { <nl> # if OPENCV_BYTEORDER = = 1234 <nl> static inline uint32_t opencvLittleToHost32 ( uint32_t x ) { <nl> # if OPENCV_LITTLEENDIAN <nl> return x ; <nl> # else <nl> - return opencvLittleToHost32 ( ( uchar * ) & x ) ; <nl> + return opencvLittleToHost32 ( ( const uchar * ) & x ) ; <nl> # endif <nl> } <nl> <nl> static inline void ICV_HLINE_2 ( uchar * ptr , int xl , int xr , const uchar * color ) <nl> { <nl> if ( is_aligned ( ( ( uchar * ) ( ptr ) + ( xl ) * 2 ) , 0x2 ) ) <nl> { <nl> - uint16_t c = opencvLittleToHost16 ( ( uchar * ) ( color ) ) ; <nl> + uint16_t c = opencvLittleToHost16 ( color ) ; <nl> uint16_t * hline_ptr = ( uint16_t * ) ( ptr ) + xl ; <nl> uint16_t * hline_max_ptr = ( uint16_t * ) ( ptr ) + xr ; <nl> for ( ; hline_ptr < = hline_max_ptr ; ) <nl> static inline void ICV_HLINE_4 ( uchar * ptr , int xl , int xr , const uchar * color ) <nl> { <nl> if ( is_aligned ( ( ( uchar * ) ( ptr ) + ( xl ) * 4 ) , 0x4 ) ) <nl> { <nl> - uint32_t c = opencvLittleToHost32 ( ( uchar * ) ( color ) ) ; <nl> + uint32_t c = opencvLittleToHost32 ( color ) ; <nl> uint32_t * hline_ptr = ( uint32_t * ) ( ptr ) + xl ; <nl> uint32_t * hline_max_ptr = ( uint32_t * ) ( ptr ) + xr ; <nl> for ( ; hline_ptr < = hline_max_ptr ; ) <nl> static inline void ICV_HLINE_8 ( uchar * ptr , int xl , int xr , const uchar * color ) <nl> } <nl> else if ( is_aligned ( ( ( uchar * ) ( ptr ) + ( xl ) * 8 ) , 0x4 ) ) <nl> { <nl> - uint32_t c [ 2 ] = { opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x00 ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x04 ) } ; <nl> + uint32_t c [ 2 ] = { opencvLittleToHost32 ( color + 0x00 ) , <nl> + opencvLittleToHost32 ( color + 0x04 ) } ; <nl> uint32_t * hline_ptr = ( uint32_t * ) ( ( uchar * ) ( ptr ) + ( xl ) * ( 8 ) ) ; <nl> uint32_t * hline_max_ptr = ( uint32_t * ) ( ( uchar * ) ( ptr ) + ( xr ) * ( 8 ) ) ; <nl> for ( ; hline_ptr < = hline_max_ptr ; ) <nl> static inline void ICV_HLINE_8 ( uchar * ptr , int xl , int xr , const uchar * color ) <nl> } <nl> / / end ICV_HLINE_8 ( ) <nl> <nl> + / * <nl> static inline void ICV_HLINE_12 ( uchar * ptr , int xl , int xr , const uchar * color ) <nl> { <nl> if ( is_aligned ( ( ( uchar * ) ( ptr ) + ( xl ) * 12 ) , 0x4 ) ) <nl> { <nl> - uint32_t c [ 3 ] = { opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x00 ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x04 ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x08 ) } ; <nl> + uint32_t c [ 3 ] = { opencvLittleToHost32 ( color + 0x00 ) , <nl> + opencvLittleToHost32 ( color + 0x04 ) , <nl> + opencvLittleToHost32 ( color + 0x08 ) } ; <nl> uint32_t * hline_ptr = ( uint32_t * ) ( ( uchar * ) ( ptr ) + ( xl ) * ( 12 ) ) ; <nl> uint32_t * hline_max_ptr = ( uint32_t * ) ( ( uchar * ) ( ptr ) + ( xr ) * ( 12 ) ) ; <nl> for ( ; hline_ptr < = hline_max_ptr ; ) <nl> static inline void ICV_HLINE_16 ( uchar * ptr , int xl , int xr , const uchar * color ) <nl> } <nl> else if ( is_aligned ( ( ( uchar * ) ( ptr ) + ( xl ) * 16 ) , 0x4 ) ) <nl> { <nl> - uint32_t c [ 4 ] = { opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x00 ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x04 ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x08 ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x0C ) } ; <nl> + uint32_t c [ 4 ] = { opencvLittleToHost32 ( color + 0x00 ) , <nl> + opencvLittleToHost32 ( color + 0x04 ) , <nl> + opencvLittleToHost32 ( color + 0x08 ) , <nl> + opencvLittleToHost32 ( color + 0x0C ) } ; <nl> uint32_t * hline_ptr = ( uint32_t * ) ( ( uchar * ) ( ptr ) + ( xl ) * ( 16 ) ) ; <nl> uint32_t * hline_max_ptr = ( uint32_t * ) ( ( uchar * ) ( ptr ) + ( xr ) * ( 16 ) ) ; <nl> for ( ; hline_ptr < = hline_max_ptr ; ) <nl> static inline void ICV_HLINE_24 ( uchar * ptr , int xl , int xr , const uchar * color ) <nl> } <nl> else if ( is_aligned ( ( ( uchar * ) ( ptr ) + ( xl ) * 24 ) , 0x4 ) ) <nl> { <nl> - uint32_t c [ 6 ] = { opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x00 ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x04 ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x08 ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x0C ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x10 ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x14 ) } ; <nl> + uint32_t c [ 6 ] = { opencvLittleToHost32 ( color + 0x00 ) , <nl> + opencvLittleToHost32 ( color + 0x04 ) , <nl> + opencvLittleToHost32 ( color + 0x08 ) , <nl> + opencvLittleToHost32 ( color + 0x0C ) , <nl> + opencvLittleToHost32 ( color + 0x10 ) , <nl> + opencvLittleToHost32 ( color + 0x14 ) } ; <nl> uint32_t * hline_ptr = ( uint32_t * ) ( ( uchar * ) ( ptr ) + ( xl ) * ( 24 ) ) ; <nl> uint32_t * hline_max_ptr = ( uint32_t * ) ( ( uchar * ) ( ptr ) + ( xr ) * ( 24 ) ) ; <nl> for ( ; hline_ptr < = hline_max_ptr ; ) <nl> static inline void ICV_HLINE_32 ( uchar * ptr , int xl , int xr , const uchar * color ) <nl> } <nl> else if ( is_aligned ( ( ( uchar * ) ( ptr ) + ( xl ) * 2324 ) , 0x4 ) ) <nl> { <nl> - uint32_t c [ 8 ] = { opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x00 ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x04 ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x08 ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x0C ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x10 ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x14 ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x18 ) , <nl> - opencvLittleToHost32 ( ( uchar * ) ( color ) + 0x1C ) } ; <nl> + uint32_t c [ 8 ] = { opencvLittleToHost32 ( color + 0x00 ) , <nl> + opencvLittleToHost32 ( color + 0x04 ) , <nl> + opencvLittleToHost32 ( color + 0x08 ) , <nl> + opencvLittleToHost32 ( color + 0x0C ) , <nl> + opencvLittleToHost32 ( color + 0x10 ) , <nl> + opencvLittleToHost32 ( color + 0x14 ) , <nl> + opencvLittleToHost32 ( color + 0x18 ) , <nl> + opencvLittleToHost32 ( color + 0x1C ) } ; <nl> uint32_t * hline_ptr = ( uint32_t * ) ( ( uchar * ) ( ptr ) + ( xl ) * ( 32 ) ) ; <nl> uint32_t * hline_max_ptr = ( uint32_t * ) ( ( uchar * ) ( ptr ) + ( xr ) * ( 32 ) ) ; <nl> for ( ; hline_ptr < = hline_max_ptr ; ) <nl> static inline void ICV_HLINE_32 ( uchar * ptr , int xl , int xr , const uchar * color ) <nl> } <nl> } <nl> / / end ICV_HLINE_32 ( ) <nl> + * / <nl> <nl> static const bool ICV_HLINE_OPTIMIZATION = true ; <nl> static inline void ICV_HLINE ( uchar * ptr , int xl , int xr , const void * color , int pix_size ) <nl>\n", "msg": "more minor changes to fix - Wunused - function warning on Apple platforms\n"}
{"diff_id": 15525, "repo": "bitcoin/bitcoin\n", "sha": "80be6e69a92130175da623fbb75552a04d3ff4f8\n", "time": "2011-01-07T19:10:08Z\n", "diff": "mmm a / rpc . cpp <nl> ppp b / rpc . cpp <nl> Value listreceivedbyaccount ( const Array & params , bool fHelp ) <nl> return ListReceived ( params , true ) ; <nl> } <nl> <nl> - void ListTransactions ( const CWalletTx & wtx , const string & strAccount , int nMinDepth , Array & ret ) <nl> + void ListTransactions ( const CWalletTx & wtx , const string & strAccount , int nMinDepth , bool fLong , Array & ret ) <nl> { <nl> int64 nGenerated , nFee ; <nl> string strSentAccount ; <nl> void ListTransactions ( const CWalletTx & wtx , const string & strAccount , int nMinDe <nl> entry . push_back ( Pair ( \" account \" , string ( \" \" ) ) ) ; <nl> entry . push_back ( Pair ( \" category \" , \" generate \" ) ) ; <nl> entry . push_back ( Pair ( \" amount \" , ValueFromAmount ( nGenerated ) ) ) ; <nl> - WalletTxToJSON ( wtx , entry ) ; <nl> + if ( fLong ) <nl> + WalletTxToJSON ( wtx , entry ) ; <nl> ret . push_back ( entry ) ; <nl> } <nl> <nl> void ListTransactions ( const CWalletTx & wtx , const string & strAccount , int nMinDe <nl> entry . push_back ( Pair ( \" category \" , \" send \" ) ) ; <nl> entry . push_back ( Pair ( \" amount \" , ValueFromAmount ( - s . second ) ) ) ; <nl> entry . push_back ( Pair ( \" fee \" , ValueFromAmount ( - nFee ) ) ) ; <nl> - WalletTxToJSON ( wtx , entry ) ; <nl> + if ( fLong ) <nl> + WalletTxToJSON ( wtx , entry ) ; <nl> ret . push_back ( entry ) ; <nl> } <nl> } <nl> void ListTransactions ( const CWalletTx & wtx , const string & strAccount , int nMinDe <nl> entry . push_back ( Pair ( \" address \" , r . first ) ) ; <nl> entry . push_back ( Pair ( \" category \" , \" receive \" ) ) ; <nl> entry . push_back ( Pair ( \" amount \" , ValueFromAmount ( r . second ) ) ) ; <nl> - WalletTxToJSON ( wtx , entry ) ; <nl> + if ( fLong ) <nl> + WalletTxToJSON ( wtx , entry ) ; <nl> ret . push_back ( entry ) ; <nl> } <nl> } <nl> Value listtransactions ( const Array & params , bool fHelp ) <nl> { <nl> CWalletTx * const pwtx = ( * it ) . second . first ; <nl> if ( pwtx ! = 0 ) <nl> - ListTransactions ( * pwtx , strAccount , 0 , ret ) ; <nl> + ListTransactions ( * pwtx , strAccount , 0 , true , ret ) ; <nl> CAccountingEntry * const pacentry = ( * it ) . second . second ; <nl> if ( pacentry ! = 0 ) <nl> AcentryToJSON ( * pacentry , strAccount , ret ) ; <nl> Value gettransaction ( const Array & params , bool fHelp ) <nl> CRITICAL_BLOCK ( cs_mapWallet ) <nl> { <nl> if ( ! mapWallet . count ( hash ) ) <nl> - throw JSONRPCError ( - 5 , \" Invalid transaction id \" ) ; <nl> + throw JSONRPCError ( - 5 , \" Invalid or non - wallet transaction id \" ) ; <nl> const CWalletTx & wtx = mapWallet [ hash ] ; <nl> <nl> int64 nCredit = wtx . GetCredit ( ) ; <nl> Value gettransaction ( const Array & params , bool fHelp ) <nl> entry . push_back ( Pair ( \" amount \" , ValueFromAmount ( nNet - nFee ) ) ) ; <nl> if ( wtx . IsFromMe ( ) ) <nl> entry . push_back ( Pair ( \" fee \" , ValueFromAmount ( nFee ) ) ) ; <nl> + <nl> WalletTxToJSON ( mapWallet [ hash ] , entry ) ; <nl> + <nl> + Array details ; <nl> + ListTransactions ( mapWallet [ hash ] , \" * \" , 0 , false , details ) ; <nl> + entry . push_back ( Pair ( \" details \" , details ) ) ; <nl> } <nl> <nl> return entry ; <nl>\n", "msg": "Add account / address details to gettransaction output\n"}
{"diff_id": 15599, "repo": "apple/swift\n", "sha": "683cf5258c25350125f839553452164e154a52b4\n", "time": "2013-08-26T14:59:59Z\n", "diff": "mmm a / lib / Sema / TypeCheckDecl . cpp <nl> ppp b / lib / Sema / TypeCheckDecl . cpp <nl> class DeclChecker : public DeclVisitor < DeclChecker > { <nl> Expr * initializer = nullptr ; <nl> if ( isPatternProperty ( PBD - > getPattern ( ) ) ) { <nl> / / Properties don ' t have initializers . <nl> - } else if ( TC . Context . LangOpts . UseDefiniteInit ) { <nl> + } else if ( TC . Context . LangOpts . UseDefiniteInit & & <nl> + ! isa < TopLevelCodeDecl > ( PBD - > getDeclContext ( ) ) ) { <nl> / / If we are using the new definite initialization rules , we don ' t <nl> - / / default initialize anything ! <nl> + / / default initialize local variables , only globals . <nl> } else if ( ! TC . isDefaultInitializable ( ty , & initializer ) ) { <nl> / / FIXME : Better diagnostics here . <nl> TC . diagnose ( PBD , diag : : decl_no_default_init , ty ) ; <nl>\n", "msg": "Global variables must have an initializer or be default constructible , even\n"}
{"diff_id": 15619, "repo": "bitcoin/bitcoin\n", "sha": "4b189c13401bcd350c05cf8194beaeb3d18b3ebc\n", "time": "2017-01-26T17:03:47Z\n", "diff": "mmm a / src / wallet / rpcwallet . cpp <nl> ppp b / src / wallet / rpcwallet . cpp <nl> UniValue bumpfee ( const JSONRPCRequest & request ) <nl> \" \\ nResult : \\ n \" <nl> \" { \\ n \" <nl> \" \\ \" txid \\ \" : \\ \" value \\ \" , ( string ) The id of the new transaction \\ n \" <nl> - \" \\ \" oldfee \\ \" : n , ( numeric ) Fee of the replaced transaction \\ n \" <nl> - \" \\ \" fee \\ \" : n , ( numeric ) Fee of the new transaction \\ n \" <nl> + \" \\ \" origfee \\ \" : n , ( numeric ) Fee of the replaced transaction \\ n \" <nl> + \" \\ \" fee \\ \" : n , ( numeric ) Fee of the new transaction \\ n \" <nl> \" } \\ n \" <nl> \" \\ nExamples : \\ n \" <nl> \" \\ nBump the fee , get the new transaction \\ ' s txid \\ n \" + <nl> UniValue bumpfee ( const JSONRPCRequest & request ) <nl> <nl> UniValue result ( UniValue : : VOBJ ) ; <nl> result . push_back ( Pair ( \" txid \" , wtxBumped . GetHash ( ) . GetHex ( ) ) ) ; <nl> - result . push_back ( Pair ( \" oldfee \" , ValueFromAmount ( nOldFee ) ) ) ; <nl> + result . push_back ( Pair ( \" origfee \" , ValueFromAmount ( nOldFee ) ) ) ; <nl> result . push_back ( Pair ( \" fee \" , ValueFromAmount ( nNewFee ) ) ) ; <nl> <nl> return result ; <nl>\n", "msg": "Change bumpfee result value from ' oldfee ' to ' origfee ' .\n"}
{"diff_id": 15695, "repo": "facebook/folly\n", "sha": "879a247afb1b651c8e8aff9ac19435360ed67d3e\n", "time": "2017-12-05T00:39:49Z\n", "diff": "mmm a / folly / detail / MemoryIdler . cpp <nl> ppp b / folly / detail / MemoryIdler . cpp <nl> <nl> # include < folly / portability / PThread . h > <nl> # include < folly / portability / SysMman . h > <nl> # include < folly / portability / Unistd . h > <nl> + # include < folly / synchronization / CallOnce . h > <nl> <nl> # include < limits . h > <nl> # include < stdio . h > <nl> static size_t pageSize ( ) { <nl> } <nl> <nl> static void fetchStackLimits ( ) { <nl> + int err ; <nl> pthread_attr_t attr ; <nl> - pthread_getattr_np ( pthread_self ( ) , & attr ) ; <nl> + if ( ( err = pthread_getattr_np ( pthread_self ( ) , & attr ) ) ) { <nl> + / / some restricted environments can ' t access / proc <nl> + static folly : : once_flag flag ; <nl> + folly : : call_once ( flag , [ err ] ( ) { <nl> + LOG ( WARNING ) < < \" pthread_getaddr_np failed errno = \" < < err ; <nl> + } ) ; <nl> + <nl> + tls_stackSize = 1 ; <nl> + return ; <nl> + } <nl> SCOPE_EXIT { pthread_attr_destroy ( & attr ) ; } ; <nl> <nl> void * addr ; <nl> size_t rawSize ; <nl> - int err ; <nl> if ( ( err = pthread_attr_getstack ( & attr , & addr , & rawSize ) ) ) { <nl> / / unexpected , but it is better to continue in prod than do nothing <nl> FB_LOG_EVERY_MS ( ERROR , 10000 ) < < \" pthread_attr_getstack error \" < < err ; <nl>\n", "msg": "better error handling in MemoryIdler for inside jails\n"}
{"diff_id": 15777, "repo": "catchorg/Catch2\n", "sha": "9bc15939a5cf7f0f6702bff218401acdc3b5d353\n", "time": "2018-12-18T19:19:39Z\n", "diff": "mmm a / include / internal / catch_exception_translator_registry . cpp <nl> ppp b / include / internal / catch_exception_translator_registry . cpp <nl> namespace Catch { <nl> } <nl> } <nl> <nl> + std : : string ExceptionTranslatorRegistry : : tryTranslators ( ) const { <nl> + if ( m_translators . empty ( ) ) { <nl> + std : : rethrow_exception ( std : : current_exception ( ) ) ; <nl> + } else { <nl> + return m_translators [ 0 ] - > translate ( m_translators . begin ( ) + 1 , m_translators . end ( ) ) ; <nl> + } <nl> + } <nl> + <nl> # else / / ^ ^ Exceptions are enabled / / Exceptions are disabled vv <nl> std : : string ExceptionTranslatorRegistry : : translateActiveException ( ) const { <nl> CATCH_INTERNAL_ERROR ( \" Attempted to translate active exception under CATCH_CONFIG_DISABLE_EXCEPTIONS ! \" ) ; <nl> } <nl> - # endif <nl> - <nl> <nl> std : : string ExceptionTranslatorRegistry : : tryTranslators ( ) const { <nl> - if ( m_translators . empty ( ) ) <nl> - std : : rethrow_exception ( std : : current_exception ( ) ) ; <nl> - else <nl> - return m_translators [ 0 ] - > translate ( m_translators . begin ( ) + 1 , m_translators . end ( ) ) ; <nl> + CATCH_INTERNAL_ERROR ( \" Attempted to use exception translators under CATCH_CONFIG_DISABLE_EXCEPTIONS ! \" ) ; <nl> } <nl> + # endif <nl> + <nl> + <nl> } <nl>\n", "msg": "Don ' t use exception - related std : : functions with - fno - exceptions\n"}
{"diff_id": 15899, "repo": "xbmc/xbmc\n", "sha": "e61a4391d4dbed7d3093244b0f3f89fb7d9b9532\n", "time": "2015-02-21T07:10:07Z\n", "diff": "mmm a / xbmc / guilib / GUIControlFactory . cpp <nl> ppp b / xbmc / guilib / GUIControlFactory . cpp <nl> CGUIControl * CGUIControlFactory : : Create ( int parentID , const CRect & rect , TiXmlEl <nl> / / <nl> <nl> CGUIControl * control = NULL ; <nl> - if ( type = = CGUIControl : : GUICONTROL_GROUP ) <nl> + switch ( type ) <nl> { <nl> - if ( insideContainer ) <nl> + case CGUIControl : : GUICONTROL_GROUP : <nl> { <nl> - control = new CGUIListGroup ( parentID , id , posX , posY , width , height ) ; <nl> + if ( insideContainer ) <nl> + { <nl> + control = new CGUIListGroup ( parentID , id , posX , posY , width , height ) ; <nl> + } <nl> + else <nl> + { <nl> + control = new CGUIControlGroup ( <nl> + parentID , id , posX , posY , width , height ) ; <nl> + ( ( CGUIControlGroup * ) control ) - > SetDefaultControl ( defaultControl , defaultAlways ) ; <nl> + ( ( CGUIControlGroup * ) control ) - > SetRenderFocusedLast ( renderFocusedLast ) ; <nl> + } <nl> } <nl> - else <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_GROUPLIST : <nl> { <nl> - control = new CGUIControlGroup ( <nl> - parentID , id , posX , posY , width , height ) ; <nl> - ( ( CGUIControlGroup * ) control ) - > SetDefaultControl ( defaultControl , defaultAlways ) ; <nl> + CScroller scroller ; <nl> + GetScroller ( pControlNode , \" scrolltime \" , scroller ) ; <nl> + <nl> + control = new CGUIControlGroupList ( <nl> + parentID , id , posX , posY , width , height , buttonGap , pageControl , orientation , useControlCoords , labelInfo . align , scroller ) ; <nl> ( ( CGUIControlGroup * ) control ) - > SetRenderFocusedLast ( renderFocusedLast ) ; <nl> + ( ( CGUIControlGroupList * ) control ) - > SetMinSize ( minWidth , minHeight ) ; <nl> } <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_GROUPLIST ) <nl> - { <nl> - CScroller scroller ; <nl> - GetScroller ( pControlNode , \" scrolltime \" , scroller ) ; <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_LABEL : <nl> + { <nl> + const CGUIInfoLabel & content = ( infoLabels . size ( ) ) ? infoLabels [ 0 ] : CGUIInfoLabel ( \" \" ) ; <nl> + if ( insideContainer ) <nl> + { / / inside lists we use CGUIListLabel <nl> + control = new CGUIListLabel ( parentID , id , posX , posY , width , height , labelInfo , content , scrollValue ) ; <nl> + } <nl> + else <nl> + { <nl> + control = new CGUILabelControl ( <nl> + parentID , id , posX , posY , width , height , <nl> + labelInfo , wrapMultiLine , bHasPath ) ; <nl> + ( ( CGUILabelControl * ) control ) - > SetInfo ( content ) ; <nl> + ( ( CGUILabelControl * ) control ) - > SetWidthControl ( minWidth , ( scrollValue = = CGUIControl : : ALWAYS ) ? true : false ) ; <nl> + } <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_EDIT : <nl> + { <nl> + control = new CGUIEditControl ( <nl> + parentID , id , posX , posY , width , height , textureFocus , textureNoFocus , <nl> + labelInfo , strLabel ) ; <nl> <nl> - control = new CGUIControlGroupList ( <nl> - parentID , id , posX , posY , width , height , buttonGap , pageControl , orientation , useControlCoords , labelInfo . align , scroller ) ; <nl> - ( ( CGUIControlGroup * ) control ) - > SetRenderFocusedLast ( renderFocusedLast ) ; <nl> - ( ( CGUIControlGroupList * ) control ) - > SetMinSize ( minWidth , minHeight ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_LABEL ) <nl> - { <nl> - const CGUIInfoLabel & content = ( infoLabels . size ( ) ) ? infoLabels [ 0 ] : CGUIInfoLabel ( \" \" ) ; <nl> - if ( insideContainer ) <nl> - { / / inside lists we use CGUIListLabel <nl> - control = new CGUIListLabel ( parentID , id , posX , posY , width , height , labelInfo , content , scrollValue ) ; <nl> + CGUIInfoLabel hint_text ; <nl> + GetInfoLabel ( pControlNode , \" hinttext \" , hint_text , parentID ) ; <nl> + ( ( CGUIEditControl * ) control ) - > SetHint ( hint_text ) ; <nl> + <nl> + if ( bPassword ) <nl> + ( ( CGUIEditControl * ) control ) - > SetInputType ( CGUIEditControl : : INPUT_TYPE_PASSWORD , 0 ) ; <nl> + ( ( CGUIEditControl * ) control ) - > SetTextChangeActions ( textChangeActions ) ; <nl> } <nl> - else <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_VIDEO : <nl> + { <nl> + control = new CGUIVideoControl ( <nl> + parentID , id , posX , posY , width , height ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_FADELABEL : <nl> { <nl> - control = new CGUILabelControl ( <nl> + control = new CGUIFadeLabelControl ( <nl> parentID , id , posX , posY , width , height , <nl> - labelInfo , wrapMultiLine , bHasPath ) ; <nl> - ( ( CGUILabelControl * ) control ) - > SetInfo ( content ) ; <nl> - ( ( CGUILabelControl * ) control ) - > SetWidthControl ( minWidth , ( scrollValue = = CGUIControl : : ALWAYS ) ? true : false ) ; <nl> + labelInfo , scrollOut , timeToPauseAtEnd , resetOnLabelChange ) ; <nl> + <nl> + ( ( CGUIFadeLabelControl * ) control ) - > SetInfo ( infoLabels ) ; <nl> } <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_EDIT ) <nl> - { <nl> - control = new CGUIEditControl ( <nl> - parentID , id , posX , posY , width , height , textureFocus , textureNoFocus , <nl> - labelInfo , strLabel ) ; <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_RSS : <nl> + { <nl> + control = new CGUIRSSControl ( <nl> + parentID , id , posX , posY , width , height , <nl> + labelInfo , textColor3 , headlineColor , strRSSTags ) ; <nl> + RssUrls : : const_iterator iter = CRssManager : : Get ( ) . GetUrls ( ) . find ( iUrlSet ) ; <nl> + if ( iter ! = CRssManager : : Get ( ) . GetUrls ( ) . end ( ) ) <nl> + ( ( CGUIRSSControl * ) control ) - > SetUrlSet ( iUrlSet ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_BUTTON : <nl> + { <nl> + control = new CGUIButtonControl ( <nl> + parentID , id , posX , posY , width , height , <nl> + textureFocus , textureNoFocus , <nl> + labelInfo ) ; <nl> + <nl> + ( ( CGUIButtonControl * ) control ) - > SetLabel ( strLabel ) ; <nl> + ( ( CGUIButtonControl * ) control ) - > SetLabel2 ( strLabel2 ) ; <nl> + ( ( CGUIButtonControl * ) control ) - > SetClickActions ( clickActions ) ; <nl> + ( ( CGUIButtonControl * ) control ) - > SetFocusActions ( focusActions ) ; <nl> + ( ( CGUIButtonControl * ) control ) - > SetUnFocusActions ( unfocusActions ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_TOGGLEBUTTON : <nl> + { <nl> + control = new CGUIToggleButtonControl ( <nl> + parentID , id , posX , posY , width , height , <nl> + textureFocus , textureNoFocus , <nl> + textureAltFocus , textureAltNoFocus , labelInfo ) ; <nl> + <nl> + ( ( CGUIToggleButtonControl * ) control ) - > SetLabel ( strLabel ) ; <nl> + ( ( CGUIToggleButtonControl * ) control ) - > SetAltLabel ( altLabel ) ; <nl> + ( ( CGUIToggleButtonControl * ) control ) - > SetClickActions ( clickActions ) ; <nl> + ( ( CGUIToggleButtonControl * ) control ) - > SetAltClickActions ( altclickActions ) ; <nl> + ( ( CGUIToggleButtonControl * ) control ) - > SetFocusActions ( focusActions ) ; <nl> + ( ( CGUIToggleButtonControl * ) control ) - > SetUnFocusActions ( unfocusActions ) ; <nl> + ( ( CGUIToggleButtonControl * ) control ) - > SetToggleSelect ( toggleSelect ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_CHECKMARK : <nl> + { <nl> + control = new CGUICheckMarkControl ( <nl> + parentID , id , posX , posY , width , height , <nl> + textureCheckMark , textureCheckMarkNF , <nl> + checkWidth , checkHeight , labelInfo ) ; <nl> <nl> - CGUIInfoLabel hint_text ; <nl> - GetInfoLabel ( pControlNode , \" hinttext \" , hint_text , parentID ) ; <nl> - ( ( CGUIEditControl * ) control ) - > SetHint ( hint_text ) ; <nl> + ( ( CGUICheckMarkControl * ) control ) - > SetLabel ( strLabel ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_RADIO : <nl> + { <nl> + control = new CGUIRadioButtonControl ( <nl> + parentID , id , posX , posY , width , height , <nl> + textureFocus , textureNoFocus , <nl> + labelInfo , <nl> + textureRadioOnFocus , textureRadioOnNoFocus , textureRadioOffFocus , textureRadioOffNoFocus ) ; <nl> + <nl> + ( ( CGUIRadioButtonControl * ) control ) - > SetLabel ( strLabel ) ; <nl> + ( ( CGUIRadioButtonControl * ) control ) - > SetRadioDimensions ( radioPosX , radioPosY , radioWidth , radioHeight ) ; <nl> + ( ( CGUIRadioButtonControl * ) control ) - > SetToggleSelect ( toggleSelect ) ; <nl> + ( ( CGUIRadioButtonControl * ) control ) - > SetClickActions ( clickActions ) ; <nl> + ( ( CGUIRadioButtonControl * ) control ) - > SetFocusActions ( focusActions ) ; <nl> + ( ( CGUIRadioButtonControl * ) control ) - > SetUnFocusActions ( unfocusActions ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_MULTISELECT : <nl> + { <nl> + CGUIInfoLabel label ; <nl> + if ( infoLabels . size ( ) ) <nl> + label = infoLabels [ 0 ] ; <nl> + control = new CGUIMultiSelectTextControl ( <nl> + parentID , id , posX , posY , width , height , <nl> + textureFocus , textureNoFocus , labelInfo , label ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_SPIN : <nl> + { <nl> + control = new CGUISpinControl ( <nl> + parentID , id , posX , posY , width , height , <nl> + textureUp , textureDown , textureUpFocus , textureDownFocus , <nl> + labelInfo , iType ) ; <nl> <nl> - if ( bPassword ) <nl> - ( ( CGUIEditControl * ) control ) - > SetInputType ( CGUIEditControl : : INPUT_TYPE_PASSWORD , 0 ) ; <nl> - ( ( CGUIEditControl * ) control ) - > SetTextChangeActions ( textChangeActions ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_VIDEO ) <nl> - { <nl> - control = new CGUIVideoControl ( <nl> - parentID , id , posX , posY , width , height ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_FADELABEL ) <nl> - { <nl> - control = new CGUIFadeLabelControl ( <nl> - parentID , id , posX , posY , width , height , <nl> - labelInfo , scrollOut , timeToPauseAtEnd , resetOnLabelChange ) ; <nl> + ( ( CGUISpinControl * ) control ) - > SetReverse ( bReverse ) ; <nl> <nl> - ( ( CGUIFadeLabelControl * ) control ) - > SetInfo ( infoLabels ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_RSS ) <nl> - { <nl> - control = new CGUIRSSControl ( <nl> - parentID , id , posX , posY , width , height , <nl> - labelInfo , textColor3 , headlineColor , strRSSTags ) ; <nl> - RssUrls : : const_iterator iter = CRssManager : : Get ( ) . GetUrls ( ) . find ( iUrlSet ) ; <nl> - if ( iter ! = CRssManager : : Get ( ) . GetUrls ( ) . end ( ) ) <nl> - ( ( CGUIRSSControl * ) control ) - > SetUrlSet ( iUrlSet ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_BUTTON ) <nl> - { <nl> - control = new CGUIButtonControl ( <nl> - parentID , id , posX , posY , width , height , <nl> - textureFocus , textureNoFocus , <nl> - labelInfo ) ; <nl> - <nl> - ( ( CGUIButtonControl * ) control ) - > SetLabel ( strLabel ) ; <nl> - ( ( CGUIButtonControl * ) control ) - > SetLabel2 ( strLabel2 ) ; <nl> - ( ( CGUIButtonControl * ) control ) - > SetClickActions ( clickActions ) ; <nl> - ( ( CGUIButtonControl * ) control ) - > SetFocusActions ( focusActions ) ; <nl> - ( ( CGUIButtonControl * ) control ) - > SetUnFocusActions ( unfocusActions ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_TOGGLEBUTTON ) <nl> - { <nl> - control = new CGUIToggleButtonControl ( <nl> - parentID , id , posX , posY , width , height , <nl> - textureFocus , textureNoFocus , <nl> - textureAltFocus , textureAltNoFocus , labelInfo ) ; <nl> - <nl> - ( ( CGUIToggleButtonControl * ) control ) - > SetLabel ( strLabel ) ; <nl> - ( ( CGUIToggleButtonControl * ) control ) - > SetAltLabel ( altLabel ) ; <nl> - ( ( CGUIToggleButtonControl * ) control ) - > SetClickActions ( clickActions ) ; <nl> - ( ( CGUIToggleButtonControl * ) control ) - > SetAltClickActions ( altclickActions ) ; <nl> - ( ( CGUIToggleButtonControl * ) control ) - > SetFocusActions ( focusActions ) ; <nl> - ( ( CGUIToggleButtonControl * ) control ) - > SetUnFocusActions ( unfocusActions ) ; <nl> - ( ( CGUIToggleButtonControl * ) control ) - > SetToggleSelect ( toggleSelect ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_CHECKMARK ) <nl> - { <nl> - control = new CGUICheckMarkControl ( <nl> - parentID , id , posX , posY , width , height , <nl> - textureCheckMark , textureCheckMarkNF , <nl> - checkWidth , checkHeight , labelInfo ) ; <nl> + if ( iType = = SPIN_CONTROL_TYPE_INT ) <nl> + { <nl> + ( ( CGUISpinControl * ) control ) - > SetRange ( iMin , iMax ) ; <nl> + } <nl> + else if ( iType = = SPIN_CONTROL_TYPE_PAGE ) <nl> + { <nl> + ( ( CGUISpinControl * ) control ) - > SetRange ( iMin , iMax ) ; <nl> + ( ( CGUISpinControl * ) control ) - > SetShowRange ( true ) ; <nl> + ( ( CGUISpinControl * ) control ) - > SetReverse ( false ) ; <nl> + ( ( CGUISpinControl * ) control ) - > SetShowOnePage ( showOnePage ) ; <nl> + } <nl> + else if ( iType = = SPIN_CONTROL_TYPE_FLOAT ) <nl> + { <nl> + ( ( CGUISpinControl * ) control ) - > SetFloatRange ( fMin , fMax ) ; <nl> + ( ( CGUISpinControl * ) control ) - > SetFloatInterval ( fInterval ) ; <nl> + } <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_SLIDER : <nl> + { <nl> + control = new CGUISliderControl ( <nl> + parentID , id , posX , posY , width , height , <nl> + textureBar , textureNib , textureNibFocus , SLIDER_CONTROL_TYPE_PERCENTAGE ) ; <nl> <nl> - ( ( CGUICheckMarkControl * ) control ) - > SetLabel ( strLabel ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_RADIO ) <nl> - { <nl> - control = new CGUIRadioButtonControl ( <nl> - parentID , id , posX , posY , width , height , <nl> - textureFocus , textureNoFocus , <nl> - labelInfo , <nl> - textureRadioOnFocus , textureRadioOnNoFocus , textureRadioOffFocus , textureRadioOffNoFocus ) ; <nl> - <nl> - ( ( CGUIRadioButtonControl * ) control ) - > SetLabel ( strLabel ) ; <nl> - ( ( CGUIRadioButtonControl * ) control ) - > SetRadioDimensions ( radioPosX , radioPosY , radioWidth , radioHeight ) ; <nl> - ( ( CGUIRadioButtonControl * ) control ) - > SetToggleSelect ( toggleSelect ) ; <nl> - ( ( CGUIRadioButtonControl * ) control ) - > SetClickActions ( clickActions ) ; <nl> - ( ( CGUIRadioButtonControl * ) control ) - > SetFocusActions ( focusActions ) ; <nl> - ( ( CGUIRadioButtonControl * ) control ) - > SetUnFocusActions ( unfocusActions ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_MULTISELECT ) <nl> - { <nl> - CGUIInfoLabel label ; <nl> - if ( infoLabels . size ( ) ) <nl> - label = infoLabels [ 0 ] ; <nl> - control = new CGUIMultiSelectTextControl ( <nl> - parentID , id , posX , posY , width , height , <nl> - textureFocus , textureNoFocus , labelInfo , label ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_SPIN ) <nl> - { <nl> - control = new CGUISpinControl ( <nl> - parentID , id , posX , posY , width , height , <nl> - textureUp , textureDown , textureUpFocus , textureDownFocus , <nl> - labelInfo , iType ) ; <nl> + ( ( CGUISliderControl * ) control ) - > SetInfo ( singleInfo ) ; <nl> + ( ( CGUISliderControl * ) control ) - > SetAction ( action ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_SETTINGS_SLIDER : <nl> + { <nl> + control = new CGUISettingsSliderControl ( <nl> + parentID , id , posX , posY , width , height , sliderWidth , sliderHeight , textureFocus , textureNoFocus , <nl> + textureBar , textureNib , textureNibFocus , labelInfo , SLIDER_CONTROL_TYPE_PERCENTAGE ) ; <nl> <nl> - ( ( CGUISpinControl * ) control ) - > SetReverse ( bReverse ) ; <nl> + ( ( CGUISettingsSliderControl * ) control ) - > SetText ( strLabel ) ; <nl> + ( ( CGUISettingsSliderControl * ) control ) - > SetInfo ( singleInfo ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_SCROLLBAR : <nl> + { <nl> + control = new CGUIScrollBar ( <nl> + parentID , id , posX , posY , width , height , <nl> + textureBackground , textureBar , textureBarFocus , textureNib , textureNibFocus , orientation , showOnePage ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_PROGRESS : <nl> + { <nl> + control = new CGUIProgressControl ( <nl> + parentID , id , posX , posY , width , height , <nl> + textureBackground , textureLeft , textureMid , textureRight , <nl> + textureOverlay , bReveal ) ; <nl> <nl> - if ( iType = = SPIN_CONTROL_TYPE_INT ) <nl> + ( ( CGUIProgressControl * ) control ) - > SetInfo ( singleInfo ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_IMAGE : <nl> { <nl> - ( ( CGUISpinControl * ) control ) - > SetRange ( iMin , iMax ) ; <nl> + if ( strType = = \" largeimage \" ) <nl> + texture . useLarge = true ; <nl> + <nl> + / / use a bordered texture if we have < bordersize > or < bordertexture > specified . <nl> + if ( borderTexture . filename . empty ( ) & & borderStr . empty ( ) ) <nl> + control = new CGUIImage ( <nl> + parentID , id , posX , posY , width , height , texture ) ; <nl> + else <nl> + control = new CGUIBorderedImage ( <nl> + parentID , id , posX , posY , width , height , texture , borderTexture , borderSize ) ; <nl> + ( ( CGUIImage * ) control ) - > SetInfo ( textureFile ) ; <nl> + ( ( CGUIImage * ) control ) - > SetAspectRatio ( aspect ) ; <nl> + ( ( CGUIImage * ) control ) - > SetCrossFade ( fadeTime ) ; <nl> } <nl> - else if ( iType = = SPIN_CONTROL_TYPE_PAGE ) <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_MULTI_IMAGE : <nl> { <nl> - ( ( CGUISpinControl * ) control ) - > SetRange ( iMin , iMax ) ; <nl> - ( ( CGUISpinControl * ) control ) - > SetShowRange ( true ) ; <nl> - ( ( CGUISpinControl * ) control ) - > SetReverse ( false ) ; <nl> - ( ( CGUISpinControl * ) control ) - > SetShowOnePage ( showOnePage ) ; <nl> + control = new CGUIMultiImage ( <nl> + parentID , id , posX , posY , width , height , texture , timePerImage , fadeTime , randomized , loop , timeToPauseAtEnd ) ; <nl> + ( ( CGUIMultiImage * ) control ) - > SetInfo ( texturePath ) ; <nl> + ( ( CGUIMultiImage * ) control ) - > SetAspectRatio ( aspect ) ; <nl> } <nl> - else if ( iType = = SPIN_CONTROL_TYPE_FLOAT ) <nl> + break ; <nl> + case CGUIControl : : GUICONTAINER_LIST : <nl> { <nl> - ( ( CGUISpinControl * ) control ) - > SetFloatRange ( fMin , fMax ) ; <nl> - ( ( CGUISpinControl * ) control ) - > SetFloatInterval ( fInterval ) ; <nl> + CScroller scroller ; <nl> + GetScroller ( pControlNode , \" scrolltime \" , scroller ) ; <nl> + <nl> + control = new CGUIListContainer ( parentID , id , posX , posY , width , height , orientation , scroller , preloadItems ) ; <nl> + ( ( CGUIListContainer * ) control ) - > LoadLayout ( pControlNode ) ; <nl> + ( ( CGUIListContainer * ) control ) - > LoadListProvider ( pControlNode , defaultControl , defaultAlways ) ; <nl> + ( ( CGUIListContainer * ) control ) - > SetType ( viewType , viewLabel ) ; <nl> + ( ( CGUIListContainer * ) control ) - > SetPageControl ( pageControl ) ; <nl> + ( ( CGUIListContainer * ) control ) - > SetRenderOffset ( offset ) ; <nl> + ( ( CGUIListContainer * ) control ) - > SetAutoScrolling ( pControlNode ) ; <nl> } <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_SLIDER ) <nl> - { <nl> - control = new CGUISliderControl ( <nl> - parentID , id , posX , posY , width , height , <nl> - textureBar , textureNib , textureNibFocus , SLIDER_CONTROL_TYPE_PERCENTAGE ) ; <nl> - <nl> - ( ( CGUISliderControl * ) control ) - > SetInfo ( singleInfo ) ; <nl> - ( ( CGUISliderControl * ) control ) - > SetAction ( action ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_SETTINGS_SLIDER ) <nl> - { <nl> - control = new CGUISettingsSliderControl ( <nl> - parentID , id , posX , posY , width , height , sliderWidth , sliderHeight , textureFocus , textureNoFocus , <nl> - textureBar , textureNib , textureNibFocus , labelInfo , SLIDER_CONTROL_TYPE_PERCENTAGE ) ; <nl> - <nl> - ( ( CGUISettingsSliderControl * ) control ) - > SetText ( strLabel ) ; <nl> - ( ( CGUISettingsSliderControl * ) control ) - > SetInfo ( singleInfo ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_SCROLLBAR ) <nl> - { <nl> - control = new CGUIScrollBar ( <nl> - parentID , id , posX , posY , width , height , <nl> - textureBackground , textureBar , textureBarFocus , textureNib , textureNibFocus , orientation , showOnePage ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_PROGRESS ) <nl> - { <nl> - control = new CGUIProgressControl ( <nl> - parentID , id , posX , posY , width , height , <nl> - textureBackground , textureLeft , textureMid , textureRight , <nl> - textureOverlay , bReveal ) ; <nl> - <nl> - ( ( CGUIProgressControl * ) control ) - > SetInfo ( singleInfo ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_IMAGE ) <nl> - { <nl> - if ( strType = = \" largeimage \" ) <nl> - texture . useLarge = true ; <nl> - <nl> - / / use a bordered texture if we have < bordersize > or < bordertexture > specified . <nl> - if ( borderTexture . filename . empty ( ) & & borderStr . empty ( ) ) <nl> - control = new CGUIImage ( <nl> - parentID , id , posX , posY , width , height , texture ) ; <nl> - else <nl> - control = new CGUIBorderedImage ( <nl> - parentID , id , posX , posY , width , height , texture , borderTexture , borderSize ) ; <nl> - ( ( CGUIImage * ) control ) - > SetInfo ( textureFile ) ; <nl> - ( ( CGUIImage * ) control ) - > SetAspectRatio ( aspect ) ; <nl> - ( ( CGUIImage * ) control ) - > SetCrossFade ( fadeTime ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_MULTI_IMAGE ) <nl> - { <nl> - control = new CGUIMultiImage ( <nl> - parentID , id , posX , posY , width , height , texture , timePerImage , fadeTime , randomized , loop , timeToPauseAtEnd ) ; <nl> - ( ( CGUIMultiImage * ) control ) - > SetInfo ( texturePath ) ; <nl> - ( ( CGUIMultiImage * ) control ) - > SetAspectRatio ( aspect ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTAINER_LIST ) <nl> - { <nl> - CScroller scroller ; <nl> - GetScroller ( pControlNode , \" scrolltime \" , scroller ) ; <nl> - <nl> - control = new CGUIListContainer ( parentID , id , posX , posY , width , height , orientation , scroller , preloadItems ) ; <nl> - ( ( CGUIListContainer * ) control ) - > LoadLayout ( pControlNode ) ; <nl> - ( ( CGUIListContainer * ) control ) - > LoadListProvider ( pControlNode , defaultControl , defaultAlways ) ; <nl> - ( ( CGUIListContainer * ) control ) - > SetType ( viewType , viewLabel ) ; <nl> - ( ( CGUIListContainer * ) control ) - > SetPageControl ( pageControl ) ; <nl> - ( ( CGUIListContainer * ) control ) - > SetRenderOffset ( offset ) ; <nl> - ( ( CGUIListContainer * ) control ) - > SetAutoScrolling ( pControlNode ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTAINER_WRAPLIST ) <nl> - { <nl> - CScroller scroller ; <nl> - GetScroller ( pControlNode , \" scrolltime \" , scroller ) ; <nl> - <nl> - control = new CGUIWrappingListContainer ( parentID , id , posX , posY , width , height , orientation , scroller , preloadItems , focusPosition ) ; <nl> - ( ( CGUIWrappingListContainer * ) control ) - > LoadLayout ( pControlNode ) ; <nl> - ( ( CGUIWrappingListContainer * ) control ) - > LoadListProvider ( pControlNode , defaultControl , defaultAlways ) ; <nl> - ( ( CGUIWrappingListContainer * ) control ) - > SetType ( viewType , viewLabel ) ; <nl> - ( ( CGUIWrappingListContainer * ) control ) - > SetPageControl ( pageControl ) ; <nl> - ( ( CGUIWrappingListContainer * ) control ) - > SetRenderOffset ( offset ) ; <nl> - ( ( CGUIWrappingListContainer * ) control ) - > SetAutoScrolling ( pControlNode ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTAINER_EPGGRID ) <nl> - { <nl> - control = new CGUIEPGGridContainer ( parentID , id , posX , posY , width , height , scrollTime , preloadItems , timeBlocks , rulerUnit , textureProgressIndicator ) ; <nl> - ( ( CGUIEPGGridContainer * ) control ) - > LoadLayout ( pControlNode ) ; <nl> - ( ( CGUIEPGGridContainer * ) control ) - > SetRenderOffset ( offset ) ; <nl> - ( ( CGUIEPGGridContainer * ) control ) - > SetType ( viewType , viewLabel ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTAINER_FIXEDLIST ) <nl> - { <nl> - CScroller scroller ; <nl> - GetScroller ( pControlNode , \" scrolltime \" , scroller ) ; <nl> - <nl> - control = new CGUIFixedListContainer ( parentID , id , posX , posY , width , height , orientation , scroller , preloadItems , focusPosition , iMovementRange ) ; <nl> - ( ( CGUIFixedListContainer * ) control ) - > LoadLayout ( pControlNode ) ; <nl> - ( ( CGUIFixedListContainer * ) control ) - > LoadListProvider ( pControlNode , defaultControl , defaultAlways ) ; <nl> - ( ( CGUIFixedListContainer * ) control ) - > SetType ( viewType , viewLabel ) ; <nl> - ( ( CGUIFixedListContainer * ) control ) - > SetPageControl ( pageControl ) ; <nl> - ( ( CGUIFixedListContainer * ) control ) - > SetRenderOffset ( offset ) ; <nl> - ( ( CGUIFixedListContainer * ) control ) - > SetAutoScrolling ( pControlNode ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTAINER_PANEL ) <nl> - { <nl> - CScroller scroller ; <nl> - GetScroller ( pControlNode , \" scrolltime \" , scroller ) ; <nl> - <nl> - control = new CGUIPanelContainer ( parentID , id , posX , posY , width , height , orientation , scroller , preloadItems ) ; <nl> - ( ( CGUIPanelContainer * ) control ) - > LoadLayout ( pControlNode ) ; <nl> - ( ( CGUIPanelContainer * ) control ) - > LoadListProvider ( pControlNode , defaultControl , defaultAlways ) ; <nl> - ( ( CGUIPanelContainer * ) control ) - > SetType ( viewType , viewLabel ) ; <nl> - ( ( CGUIPanelContainer * ) control ) - > SetPageControl ( pageControl ) ; <nl> - ( ( CGUIPanelContainer * ) control ) - > SetRenderOffset ( offset ) ; <nl> - ( ( CGUIPanelContainer * ) control ) - > SetAutoScrolling ( pControlNode ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_TEXTBOX ) <nl> - { <nl> - control = new CGUITextBox ( <nl> - parentID , id , posX , posY , width , height , <nl> - labelInfo , scrollTime ) ; <nl> + break ; <nl> + case CGUIControl : : GUICONTAINER_WRAPLIST : <nl> + { <nl> + CScroller scroller ; <nl> + GetScroller ( pControlNode , \" scrolltime \" , scroller ) ; <nl> + <nl> + control = new CGUIWrappingListContainer ( parentID , id , posX , posY , width , height , orientation , scroller , preloadItems , focusPosition ) ; <nl> + ( ( CGUIWrappingListContainer * ) control ) - > LoadLayout ( pControlNode ) ; <nl> + ( ( CGUIWrappingListContainer * ) control ) - > LoadListProvider ( pControlNode , defaultControl , defaultAlways ) ; <nl> + ( ( CGUIWrappingListContainer * ) control ) - > SetType ( viewType , viewLabel ) ; <nl> + ( ( CGUIWrappingListContainer * ) control ) - > SetPageControl ( pageControl ) ; <nl> + ( ( CGUIWrappingListContainer * ) control ) - > SetRenderOffset ( offset ) ; <nl> + ( ( CGUIWrappingListContainer * ) control ) - > SetAutoScrolling ( pControlNode ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTAINER_EPGGRID : <nl> + { <nl> + control = new CGUIEPGGridContainer ( parentID , id , posX , posY , width , height , scrollTime , preloadItems , timeBlocks , rulerUnit , textureProgressIndicator ) ; <nl> + ( ( CGUIEPGGridContainer * ) control ) - > LoadLayout ( pControlNode ) ; <nl> + ( ( CGUIEPGGridContainer * ) control ) - > SetRenderOffset ( offset ) ; <nl> + ( ( CGUIEPGGridContainer * ) control ) - > SetType ( viewType , viewLabel ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTAINER_FIXEDLIST : <nl> + { <nl> + CScroller scroller ; <nl> + GetScroller ( pControlNode , \" scrolltime \" , scroller ) ; <nl> + <nl> + control = new CGUIFixedListContainer ( parentID , id , posX , posY , width , height , orientation , scroller , preloadItems , focusPosition , iMovementRange ) ; <nl> + ( ( CGUIFixedListContainer * ) control ) - > LoadLayout ( pControlNode ) ; <nl> + ( ( CGUIFixedListContainer * ) control ) - > LoadListProvider ( pControlNode , defaultControl , defaultAlways ) ; <nl> + ( ( CGUIFixedListContainer * ) control ) - > SetType ( viewType , viewLabel ) ; <nl> + ( ( CGUIFixedListContainer * ) control ) - > SetPageControl ( pageControl ) ; <nl> + ( ( CGUIFixedListContainer * ) control ) - > SetRenderOffset ( offset ) ; <nl> + ( ( CGUIFixedListContainer * ) control ) - > SetAutoScrolling ( pControlNode ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTAINER_PANEL : <nl> + { <nl> + CScroller scroller ; <nl> + GetScroller ( pControlNode , \" scrolltime \" , scroller ) ; <nl> + <nl> + control = new CGUIPanelContainer ( parentID , id , posX , posY , width , height , orientation , scroller , preloadItems ) ; <nl> + ( ( CGUIPanelContainer * ) control ) - > LoadLayout ( pControlNode ) ; <nl> + ( ( CGUIPanelContainer * ) control ) - > LoadListProvider ( pControlNode , defaultControl , defaultAlways ) ; <nl> + ( ( CGUIPanelContainer * ) control ) - > SetType ( viewType , viewLabel ) ; <nl> + ( ( CGUIPanelContainer * ) control ) - > SetPageControl ( pageControl ) ; <nl> + ( ( CGUIPanelContainer * ) control ) - > SetRenderOffset ( offset ) ; <nl> + ( ( CGUIPanelContainer * ) control ) - > SetAutoScrolling ( pControlNode ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_TEXTBOX : <nl> + { <nl> + control = new CGUITextBox ( <nl> + parentID , id , posX , posY , width , height , <nl> + labelInfo , scrollTime ) ; <nl> <nl> - ( ( CGUITextBox * ) control ) - > SetPageControl ( pageControl ) ; <nl> - if ( infoLabels . size ( ) ) <nl> - ( ( CGUITextBox * ) control ) - > SetInfo ( infoLabels [ 0 ] ) ; <nl> - ( ( CGUITextBox * ) control ) - > SetAutoScrolling ( pControlNode ) ; <nl> - ( ( CGUITextBox * ) control ) - > SetMinHeight ( minHeight ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_SELECTBUTTON ) <nl> - { <nl> - control = new CGUISelectButtonControl ( <nl> - parentID , id , posX , posY , <nl> - width , height , textureFocus , textureNoFocus , <nl> - labelInfo , <nl> - textureBackground , textureLeft , textureLeftFocus , textureRight , textureRightFocus ) ; <nl> + ( ( CGUITextBox * ) control ) - > SetPageControl ( pageControl ) ; <nl> + if ( infoLabels . size ( ) ) <nl> + ( ( CGUITextBox * ) control ) - > SetInfo ( infoLabels [ 0 ] ) ; <nl> + ( ( CGUITextBox * ) control ) - > SetAutoScrolling ( pControlNode ) ; <nl> + ( ( CGUITextBox * ) control ) - > SetMinHeight ( minHeight ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_SELECTBUTTON : <nl> + { <nl> + control = new CGUISelectButtonControl ( <nl> + parentID , id , posX , posY , <nl> + width , height , textureFocus , textureNoFocus , <nl> + labelInfo , <nl> + textureBackground , textureLeft , textureLeftFocus , textureRight , textureRightFocus ) ; <nl> <nl> - ( ( CGUISelectButtonControl * ) control ) - > SetLabel ( strLabel ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_MOVER ) <nl> - { <nl> - control = new CGUIMoverControl ( <nl> - parentID , id , posX , posY , width , height , <nl> - textureFocus , textureNoFocus ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_RESIZE ) <nl> - { <nl> - control = new CGUIResizeControl ( <nl> - parentID , id , posX , posY , width , height , <nl> - textureFocus , textureNoFocus ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_SPINEX ) <nl> - { <nl> - control = new CGUISpinControlEx ( <nl> - parentID , id , posX , posY , width , height , spinWidth , spinHeight , <nl> - labelInfo , textureFocus , textureNoFocus , textureUp , textureDown , textureUpFocus , textureDownFocus , <nl> - labelInfo , iType ) ; <nl> - <nl> - ( ( CGUISpinControlEx * ) control ) - > SetSpinPosition ( spinPosX ) ; <nl> - ( ( CGUISpinControlEx * ) control ) - > SetText ( strLabel ) ; <nl> - ( ( CGUISpinControlEx * ) control ) - > SetReverse ( bReverse ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_VISUALISATION ) <nl> - { <nl> + ( ( CGUISelectButtonControl * ) control ) - > SetLabel ( strLabel ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_MOVER : <nl> + { <nl> + control = new CGUIMoverControl ( <nl> + parentID , id , posX , posY , width , height , <nl> + textureFocus , textureNoFocus ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_RESIZE : <nl> + { <nl> + control = new CGUIResizeControl ( <nl> + parentID , id , posX , posY , width , height , <nl> + textureFocus , textureNoFocus ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_SPINEX : <nl> + { <nl> + control = new CGUISpinControlEx ( <nl> + parentID , id , posX , posY , width , height , spinWidth , spinHeight , <nl> + labelInfo , textureFocus , textureNoFocus , textureUp , textureDown , textureUpFocus , textureDownFocus , <nl> + labelInfo , iType ) ; <nl> + <nl> + ( ( CGUISpinControlEx * ) control ) - > SetSpinPosition ( spinPosX ) ; <nl> + ( ( CGUISpinControlEx * ) control ) - > SetText ( strLabel ) ; <nl> + ( ( CGUISpinControlEx * ) control ) - > SetReverse ( bReverse ) ; <nl> + } <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_VISUALISATION : <nl> control = new CGUIVisualisationControl ( parentID , id , posX , posY , width , height ) ; <nl> - } <nl> - else if ( type = = CGUIControl : : GUICONTROL_RENDERADDON ) <nl> - { <nl> + break ; <nl> + case CGUIControl : : GUICONTROL_RENDERADDON : <nl> control = new CGUIRenderingControl ( parentID , id , posX , posY , width , height ) ; <nl> + break ; <nl> + default : <nl> + break ; <nl> } <nl> <nl> / / things that apply to all controls <nl>\n", "msg": "[ gui ] Improve CGUIControlFactory : : Create to use ' switch ' instead of ' if '\n"}
{"diff_id": 15930, "repo": "tensorflow/tensorflow\n", "sha": "ad9bc85a49f4a89c3eb7c9d2463f925719429cda\n", "time": "2019-05-06T15:23:04Z\n", "diff": "mmm a / tools / mlir - translate / mlir - translate . cpp <nl> ppp b / tools / mlir - translate / mlir - translate . cpp <nl> static llvm : : SmallVector < TranslateFunction , 16 > wrapperStorage ; <nl> struct TranslationParser : public llvm : : cl : : parser < const TranslateFunction * > { <nl> TranslationParser ( llvm : : cl : : Option & opt ) <nl> : llvm : : cl : : parser < const TranslateFunction * > ( opt ) { <nl> - for ( const auto & kv : getTranslationToMLIRRegistry ( ) ) { <nl> + const auto & toMLIRRegistry = getTranslationToMLIRRegistry ( ) ; <nl> + const auto & fromMLIRRegistry = getTranslationFromMLIRRegistry ( ) ; <nl> + <nl> + / / Reserve the required capacity upfront so that pointers are not <nl> + / / invalidated on reallocation . <nl> + wrapperStorage . reserve ( toMLIRRegistry . size ( ) + fromMLIRRegistry . size ( ) ) ; <nl> + for ( const auto & kv : toMLIRRegistry ) { <nl> TranslateToMLIRFunction function = kv . second ; <nl> TranslateFunction wrapper = [ function ] ( StringRef inputFilename , <nl> StringRef outputFilename , <nl> struct TranslationParser : public llvm : : cl : : parser < const TranslateFunction * > { <nl> <nl> addLiteralOption ( kv . first ( ) , & wrapperStorage . back ( ) , kv . first ( ) ) ; <nl> } <nl> - for ( const auto & kv : getTranslationFromMLIRRegistry ( ) ) { <nl> + for ( const auto & kv : fromMLIRRegistry ) { <nl> TranslateFromMLIRFunction function = kv . second ; <nl> TranslateFunction wrapper = [ function ] ( StringRef inputFilename , <nl> StringRef outputFilename , <nl>\n", "msg": "Reserve the required capacity to avoid pointer invalidations for translation functions\n", "score": 1}
{"diff_id": 16338, "repo": "pytorch/pytorch\n", "sha": "5823cc419a9ecb99822a8a6f509d86f6f79c04f9\n", "time": "2017-09-05T21:48:55Z\n", "diff": "mmm a / torch / csrc / toffee / export . cpp <nl> ppp b / torch / csrc / toffee / export . cpp <nl> std : : string ExportGraph ( std : : unique_ptr < Graph > & g ) { <nl> } <nl> if ( node - > type ( ) - > kind ( ) = = TypeKind : : MultiType ) { <nl> for ( auto u : node - > uses ( ) ) { <nl> + JIT_ASSERT ( u . user - > kind ( ) = = kSelect ) ; <nl> + / / Python operators whose backwards are not traceable will have <nl> + / / handle outputs ; at the moment ToffeeIR export only supports <nl> + / / forwards only , so these will be unused <nl> + if ( u . user - > type ( ) - > kind ( ) = = TypeKind : : HandleType ) { <nl> + JIT_ASSERT ( u . user - > uses ( ) . empty ( ) ) ; <nl> + continue ; <nl> + } <nl> p_n - > add_output ( node_name ( u . user ) ) ; <nl> } <nl> } else { <nl>\n", "msg": "Ignore Handle when exporting to ToffeeIR .\n"}
{"diff_id": 16490, "repo": "telegramdesktop/tdesktop\n", "sha": "3a45957ceb2f90407070a57ea37832976e0fa356\n", "time": "2020-11-09T08:19:03Z\n", "diff": "mmm a / Telegram / SourceFiles / platform / linux / specific_linux . cpp <nl> ppp b / Telegram / SourceFiles / platform / linux / specific_linux . cpp <nl> For license and copyright information please follow this link : <nl> # include \" storage / localstorage . h \" <nl> # include \" core / crash_reports . h \" <nl> # include \" core / update_checker . h \" <nl> + # include \" window / window_controller . h \" <nl> + # include \" core / application . h \" <nl> <nl> # include < QtWidgets / QApplication > <nl> # include < QtWidgets / QDesktopWidget > <nl> void PortalAutostart ( bool autostart , bool silent = false ) { <nl> qsl ( \" org . freedesktop . portal . Background \" ) , <nl> qsl ( \" RequestBackground \" ) ) ; <nl> <nl> + const auto parentWindowId = [ & ] { <nl> + if ( const auto activeWindow = Core : : App ( ) . activeWindow ( ) ) { <nl> + if ( ! IsWayland ( ) ) { <nl> + return qsl ( \" x11 : % 1 \" ) . arg ( QString : : number ( <nl> + activeWindow - > widget ( ) . get ( ) - > windowHandle ( ) - > winId ( ) , <nl> + 16 ) ) ; <nl> + } <nl> + } <nl> + return QString ( ) ; <nl> + } ( ) ; <nl> + <nl> message . setArguments ( { <nl> - QString ( ) , <nl> + parentWindowId , <nl> options <nl> } ) ; <nl> <nl>\n", "msg": "Set parent window ID for portal autostart dialog\n"}
{"diff_id": 16492, "repo": "apple/swift\n", "sha": "2f9bd597bbee7bd3215e96957489d00dabfe3fb4\n", "time": "2017-02-07T00:14:07Z\n", "diff": "mmm a / lib / AST / GenericSignature . cpp <nl> ppp b / lib / AST / GenericSignature . cpp <nl> bool GenericSignature : : enumeratePairedRequirements ( <nl> return enumerateGenericParamsUpToDependentType ( CanType ( ) ) ; <nl> } <nl> <nl> - void <nl> - GenericSignature : : getSubstitutionMap ( ArrayRef < Substitution > subs , <nl> - SubstitutionMap & result ) const { <nl> - / / An empty parameter list gives an empty map . <nl> - if ( subs . empty ( ) ) <nl> - assert ( getGenericParams ( ) . empty ( ) | | areAllParamsConcrete ( ) ) ; <nl> - <nl> - for ( auto depTy : getAllDependentTypes ( ) ) { <nl> - auto sub = subs . front ( ) ; <nl> - subs = subs . slice ( 1 ) ; <nl> - <nl> - auto canTy = depTy - > getCanonicalType ( ) ; <nl> - if ( isa < SubstitutableType > ( canTy ) ) <nl> - result . addSubstitution ( cast < SubstitutableType > ( canTy ) , <nl> - sub . getReplacement ( ) ) ; <nl> - for ( auto conformance : sub . getConformances ( ) ) <nl> - result . addConformance ( canTy , conformance ) ; <nl> - } <nl> - <nl> - for ( auto reqt : getRequirements ( ) ) { <nl> + static void populateParentMap ( const GenericSignature * sig , <nl> + SubstitutionMap & subMap ) { <nl> + for ( auto reqt : sig - > getRequirements ( ) ) { <nl> if ( reqt . getKind ( ) ! = RequirementKind : : SameType ) <nl> continue ; <nl> <nl> GenericSignature : : getSubstitutionMap ( ArrayRef < Substitution > subs , <nl> continue ; <nl> <nl> if ( auto * firstMemTy = first - > getAs < DependentMemberType > ( ) ) { <nl> - result . addParent ( second - > getCanonicalType ( ) , <nl> + subMap . addParent ( second - > getCanonicalType ( ) , <nl> firstMemTy - > getBase ( ) - > getCanonicalType ( ) , <nl> firstMemTy - > getAssocType ( ) ) ; <nl> } <nl> <nl> if ( auto * secondMemTy = second - > getAs < DependentMemberType > ( ) ) { <nl> - result . addParent ( first - > getCanonicalType ( ) , <nl> + subMap . addParent ( first - > getCanonicalType ( ) , <nl> secondMemTy - > getBase ( ) - > getCanonicalType ( ) , <nl> secondMemTy - > getAssocType ( ) ) ; <nl> } <nl> } <nl> + } <nl> + <nl> + void <nl> + GenericSignature : : getSubstitutionMap ( ArrayRef < Substitution > subs , <nl> + SubstitutionMap & result ) const { <nl> + / / An empty parameter list gives an empty map . <nl> + if ( subs . empty ( ) ) <nl> + assert ( getGenericParams ( ) . empty ( ) | | areAllParamsConcrete ( ) ) ; <nl> + <nl> + for ( auto depTy : getAllDependentTypes ( ) ) { <nl> + auto sub = subs . front ( ) ; <nl> + subs = subs . slice ( 1 ) ; <nl> + <nl> + auto canTy = depTy - > getCanonicalType ( ) ; <nl> + if ( isa < SubstitutableType > ( canTy ) ) <nl> + result . addSubstitution ( cast < SubstitutableType > ( canTy ) , <nl> + sub . getReplacement ( ) ) ; <nl> + for ( auto conformance : sub . getConformances ( ) ) <nl> + result . addConformance ( canTy , conformance ) ; <nl> + } <nl> <nl> assert ( subs . empty ( ) & & \" did not use all substitutions ? ! \" ) ; <nl> + populateParentMap ( this , result ) ; <nl> } <nl> <nl> SubstitutionMap <nl> getSubstitutionMap ( TypeSubstitutionFn subs , <nl> return false ; <nl> } ) ; <nl> <nl> - for ( auto reqt : getRequirements ( ) ) { <nl> - if ( reqt . getKind ( ) ! = RequirementKind : : SameType ) <nl> - continue ; <nl> - <nl> - auto first = reqt . getFirstType ( ) ; <nl> - auto second = reqt . getSecondType ( ) ; <nl> - <nl> - if ( ! first - > isTypeParameter ( ) | | ! second - > isTypeParameter ( ) ) <nl> - continue ; <nl> - <nl> - if ( auto * firstMemTy = first - > getAs < DependentMemberType > ( ) ) { <nl> - subMap . addParent ( second - > getCanonicalType ( ) , <nl> - firstMemTy - > getBase ( ) - > getCanonicalType ( ) , <nl> - firstMemTy - > getAssocType ( ) ) ; <nl> - } <nl> - <nl> - if ( auto * secondMemTy = second - > getAs < DependentMemberType > ( ) ) { <nl> - subMap . addParent ( first - > getCanonicalType ( ) , <nl> - secondMemTy - > getBase ( ) - > getCanonicalType ( ) , <nl> - secondMemTy - > getAssocType ( ) ) ; <nl> - } <nl> - } <nl> - <nl> + populateParentMap ( this , subMap ) ; <nl> return subMap ; <nl> } <nl> <nl>\n", "msg": "AST : Clean up duplicated code in GenericSignature . cpp\n"}
{"diff_id": 16532, "repo": "CRYTEK/CRYENGINE\n", "sha": "30f9f90446ef70ba44f21c64035adf5c0b878c44\n", "time": "2017-06-27T12:58:25Z\n", "diff": "mmm a / Code / CryPlugins / CrySensorSystem / Module / SchematycEntitySensorVolumeComponent . cpp <nl> ppp b / Code / CryPlugins / CrySensorSystem / Module / SchematycEntitySensorVolumeComponent . cpp <nl> void CSchematycEntitySensorVolumeComponent : : OnSensorEvent ( const SSensorEvent & ev <nl> { <nl> case ESensorEventType : : Entering : <nl> { <nl> - GetEntity ( ) - > GetSchematycObject ( ) - > ProcessSignal ( SEnteringSignal ( otherVolumeParams . entityId ) ) ; <nl> + GetEntity ( ) - > GetSchematycObject ( ) - > ProcessSignal ( SEnteringSignal ( otherVolumeParams . entityId ) , GetGUID ( ) ) ; <nl> break ; <nl> } <nl> case ESensorEventType : : Leaving : <nl> { <nl> - GetEntity ( ) - > GetSchematycObject ( ) - > ProcessSignal ( SLeavingSignal ( otherVolumeParams . entityId ) ) ; <nl> + GetEntity ( ) - > GetSchematycObject ( ) - > ProcessSignal ( SLeavingSignal ( otherVolumeParams . entityId ) , GetGUID ( ) ) ; <nl> break ; <nl> } <nl> } <nl>\n", "msg": "! XB ( CE - 12954 ) ( CrySensorSystem ) Fixed sensor component event processing .\n"}
{"diff_id": 16603, "repo": "xbmc/xbmc\n", "sha": "08c9469bdbba3744b86beeeafa276788a4e51381\n", "time": "2020-08-14T06:55:49Z\n", "diff": "mmm a / xbmc / pvr / guilib / guiinfo / PVRGUIInfo . cpp <nl> ppp b / xbmc / pvr / guilib / guiinfo / PVRGUIInfo . cpp <nl> bool CPVRGUIInfo : : GetListItemAndPlayerLabel ( const CFileItem * item , const CGUIInf <nl> case LISTITEM_PREMIERED : <nl> if ( recording - > FirstAired ( ) . IsValid ( ) ) <nl> { <nl> - strValue = recording - > FirstAired ( ) . GetAsLocalizedDate ( true ) ; <nl> + strValue = recording - > FirstAired ( ) . GetAsLocalizedDate ( ) ; <nl> return true ; <nl> } <nl> else if ( recording - > HasYear ( ) ) <nl> bool CPVRGUIInfo : : GetListItemAndPlayerLabel ( const CFileItem * item , const CGUIInf <nl> case LISTITEM_PREMIERED : <nl> if ( epgTag - > FirstAired ( ) . IsValid ( ) ) <nl> { <nl> - strValue = epgTag - > FirstAired ( ) . GetAsLocalizedDate ( true ) ; <nl> + strValue = epgTag - > FirstAired ( ) . GetAsLocalizedDate ( ) ; <nl> return true ; <nl> } <nl> else if ( epgTag - > Year ( ) > 0 ) <nl>\n", "msg": "[ PVR ] Fix date format for ListItem . Premiered and VideoPlayer . Premiered guiinfo labels .\n"}
{"diff_id": 16727, "repo": "apple/swift\n", "sha": "2302e323d74096461a467f48aab6a5b7b4399a21\n", "time": "2014-01-13T21:23:45Z\n", "diff": "mmm a / lib / IRGen / GenClass . cpp <nl> ppp b / lib / IRGen / GenClass . cpp <nl> namespace { <nl> } <nl> <nl> void addIVarInitializer ( ) { <nl> - if ( auto entry = emitObjCIVarInitDestroyDescriptor ( IGM , getClass ( ) , false ) ) <nl> + if ( auto entry = emitObjCIVarInitDestroyDescriptor ( IGM , getClass ( ) , <nl> + false ) ) { <nl> InstanceMethods . push_back ( * entry ) ; <nl> + <nl> + HasNonTrivialConstructor = true ; <nl> + } <nl> } <nl> <nl> void addIVarDestroyer ( ) { <nl> - if ( auto entry = emitObjCIVarInitDestroyDescriptor ( IGM , getClass ( ) , true ) ) <nl> + if ( auto entry = emitObjCIVarInitDestroyDescriptor ( IGM , getClass ( ) , <nl> + true ) ) { <nl> InstanceMethods . push_back ( * entry ) ; <nl> + <nl> + HasNonTrivialDestructor = true ; <nl> + } <nl> } <nl> <nl> private : <nl> namespace { <nl> SILType fieldType = <nl> IGM . getLoweredType ( AbstractionPattern ( var - > getType ( ) ) , var - > getType ( ) ) ; <nl> Ivars . push_back ( buildIvar ( var , fieldType ) ) ; <nl> - if ( ! IGM . isPOD ( fieldType , ResilienceScope : : Local ) ) { <nl> - HasNonTrivialDestructor = true ; <nl> - } <nl> <nl> / / Build property accessors for the ivar if necessary . <nl> visitProperty ( var ) ; <nl>\n", "msg": "Set Objective - C class metadata bits to indicate presence of . cxx_construct / . cxx_destruct .\n"}
{"diff_id": 16815, "repo": "yuzu-emu/yuzu\n", "sha": "b4242633ad542f1f442e825c7ad426f05d703e40\n", "time": "2018-12-31T02:29:38Z\n", "diff": "mmm a / src / core / hle / kernel / svc . cpp <nl> ppp b / src / core / hle / kernel / svc . cpp <nl> static ResultCode CreateThread ( Handle * out_handle , VAddr entry_point , u64 arg , V <nl> } <nl> <nl> if ( priority > THREADPRIO_LOWEST ) { <nl> - LOG_ERROR ( Kernel_SVC , \" An invalid priority was specified , expected { } but got { } \" , <nl> - THREADPRIO_LOWEST , priority ) ; <nl> + LOG_ERROR ( Kernel_SVC , <nl> + \" Invalid thread priority specified ( { } ) . Must be within the range 0 - 64 \" , <nl> + priority ) ; <nl> return ERR_INVALID_THREAD_PRIORITY ; <nl> } <nl> <nl>\n", "msg": "kernel / svc : Correct misleading error message within CreateThread ( )\n"}
{"diff_id": 16824, "repo": "xbmc/xbmc\n", "sha": "cec6c703005f73d4f0d9173c54fbceedd0704193\n", "time": "2013-11-05T19:04:01Z\n", "diff": "mmm a / xbmc / settings / SettingsManager . cpp <nl> ppp b / xbmc / settings / SettingsManager . cpp <nl> void CSettingsManager : : RegisterSettingsHandler ( ISettingsHandler * settingsHandler <nl> return ; <nl> <nl> CExclusiveLock lock ( m_critical ) ; <nl> - if ( find ( m_settingsHandlers . begin ( ) , m_settingsHandlers . end ( ) , settingsHandler ) > = m_settingsHandlers . end ( ) ) <nl> + if ( find ( m_settingsHandlers . begin ( ) , m_settingsHandlers . end ( ) , settingsHandler ) = = m_settingsHandlers . end ( ) ) <nl> m_settingsHandlers . push_back ( settingsHandler ) ; <nl> } <nl> <nl>\n", "msg": "settings : cosmetic on iterator comparison\n"}
{"diff_id": 16836, "repo": "EOSIO/eos\n", "sha": "05b927612b8fe3757c0385d655fb70762e605b5b\n", "time": "2018-07-05T13:12:26Z\n", "diff": "mmm a / plugins / mongo_db_plugin / mongo_db_plugin . cpp <nl> ppp b / plugins / mongo_db_plugin / mongo_db_plugin . cpp <nl> const std : : string mongo_db_plugin_impl : : trans_traces_col = \" transaction_traces \" ; <nl> const std : : string mongo_db_plugin_impl : : actions_col = \" actions \" ; <nl> const std : : string mongo_db_plugin_impl : : accounts_col = \" accounts \" ; <nl> <nl> + namespace { <nl> + <nl> + template < typename Queue , typename Entry > <nl> + void queue ( boost : : mutex & mtx , boost : : condition_variable & condition , Queue & queue , const Entry & e , size_t queue_size ) { <nl> + int sleep_time = 100 ; <nl> + size_t last_queue_size = 0 ; <nl> + boost : : mutex : : scoped_lock lock ( mtx ) ; <nl> + if ( queue . size ( ) > queue_size ) { <nl> + lock . unlock ( ) ; <nl> + condition . notify_one ( ) ; <nl> + if ( last_queue_size < queue . size ( ) ) { <nl> + sleep_time + = 100 ; <nl> + } else { <nl> + sleep_time - = 100 ; <nl> + if ( sleep_time < 0 ) sleep_time = 100 ; <nl> + } <nl> + last_queue_size = queue . size ( ) ; <nl> + boost : : this_thread : : sleep_for ( boost : : chrono : : milliseconds ( sleep_time ) ) ; <nl> + lock . lock ( ) ; <nl> + } <nl> + queue . emplace_back ( e ) ; <nl> + lock . unlock ( ) ; <nl> + condition . notify_one ( ) ; <nl> + } <nl> + <nl> + } <nl> <nl> void mongo_db_plugin_impl : : accepted_transaction ( const chain : : transaction_metadata_ptr & t ) { <nl> try { <nl> void mongo_db_plugin_impl : : accepted_transaction ( const chain : : transaction_metada <nl> / / on startup we don ' t want to queue , instead push back on caller <nl> process_accepted_transaction ( t ) ; <nl> } else { <nl> - boost : : mutex : : scoped_lock lock ( mtx ) ; <nl> - if ( transaction_metadata_queue . size ( ) > queue_size ) { <nl> - lock . unlock ( ) ; <nl> - condition . notify_one ( ) ; <nl> - boost : : this_thread : : sleep_for ( boost : : chrono : : milliseconds ( 100 ) ) ; <nl> - lock . lock ( ) ; <nl> - } <nl> - transaction_metadata_queue . emplace_back ( t ) ; <nl> - lock . unlock ( ) ; <nl> - condition . notify_one ( ) ; <nl> + queue ( mtx , condition , transaction_metadata_queue , t , queue_size ) ; <nl> } <nl> } catch ( fc : : exception & e ) { <nl> elog ( \" FC Exception while accepted_transaction $ { e } \" , ( \" e \" , e . to_string ( ) ) ) ; <nl> void mongo_db_plugin_impl : : applied_transaction ( const chain : : transaction_trace_p <nl> / / on startup we don ' t want to queue , instead push back on caller <nl> process_applied_transaction ( t ) ; <nl> } else { <nl> - boost : : mutex : : scoped_lock lock ( mtx ) ; <nl> - if ( transaction_trace_queue . size ( ) > queue_size ) { <nl> - lock . unlock ( ) ; <nl> - condition . notify_one ( ) ; <nl> - boost : : this_thread : : sleep_for ( boost : : chrono : : milliseconds ( 100 ) ) ; <nl> - lock . lock ( ) ; <nl> - } <nl> - transaction_trace_queue . emplace_back ( t ) ; <nl> - lock . unlock ( ) ; <nl> - condition . notify_one ( ) ; <nl> + queue ( mtx , condition , transaction_trace_queue , t , queue_size ) ; <nl> } <nl> } catch ( fc : : exception & e ) { <nl> elog ( \" FC Exception while applied_transaction $ { e } \" , ( \" e \" , e . to_string ( ) ) ) ; <nl> void mongo_db_plugin_impl : : applied_irreversible_block ( const chain : : block_state_ <nl> / / on startup we don ' t want to queue , instead push back on caller <nl> process_irreversible_block ( bs ) ; <nl> } else { <nl> - boost : : mutex : : scoped_lock lock ( mtx ) ; <nl> - if ( irreversible_block_state_queue . size ( ) > queue_size ) { <nl> - lock . unlock ( ) ; <nl> - condition . notify_one ( ) ; <nl> - boost : : this_thread : : sleep_for ( boost : : chrono : : milliseconds ( 100 ) ) ; <nl> - lock . lock ( ) ; <nl> - } <nl> - irreversible_block_state_queue . push_back ( bs ) ; <nl> - lock . unlock ( ) ; <nl> - condition . notify_one ( ) ; <nl> + queue ( mtx , condition , irreversible_block_state_queue , bs , queue_size ) ; <nl> } <nl> } catch ( fc : : exception & e ) { <nl> elog ( \" FC Exception while applied_irreversible_block $ { e } \" , ( \" e \" , e . to_string ( ) ) ) ; <nl> void mongo_db_plugin_impl : : accepted_block ( const chain : : block_state_ptr & bs ) { <nl> / / on startup we don ' t want to queue , instead push back on caller <nl> process_block ( bs ) ; <nl> } else { <nl> - boost : : mutex : : scoped_lock lock ( mtx ) ; <nl> - if ( block_state_queue . size ( ) > queue_size ) { <nl> - lock . unlock ( ) ; <nl> - condition . notify_one ( ) ; <nl> - boost : : this_thread : : sleep_for ( boost : : chrono : : milliseconds ( 100 ) ) ; <nl> - lock . lock ( ) ; <nl> - } <nl> - block_state_queue . emplace_back ( bs ) ; <nl> - lock . unlock ( ) ; <nl> - condition . notify_one ( ) ; <nl> + queue ( mtx , condition , block_state_queue , bs , queue_size ) ; <nl> } <nl> } catch ( fc : : exception & e ) { <nl> elog ( \" FC Exception while accepted_block $ { e } \" , ( \" e \" , e . to_string ( ) ) ) ; <nl> void mongo_db_plugin : : set_program_options ( options_description & cli , options_desc <nl> { <nl> cfg . add_options ( ) <nl> ( \" mongodb - queue - size , q \" , bpo : : value < uint > ( ) - > default_value ( 256 ) , <nl> - \" The queue size between nodeos and MongoDB plugin thread . \" ) <nl> + \" The target queue size between nodeos and MongoDB plugin thread . \" ) <nl> + ( \" mongodb - wipe \" , bpo : : bool_switch ( ) - > default_value ( false ) , <nl> + \" Required with - - replay - blockchain , - - hard - replay - blockchain , or - - delete - all - blocks to wipe mongo db . \" <nl> + \" This option required to prevent accidental wipe of mongo db . \" ) <nl> + ( \" mongodb - hot - start \" , bpo : : bool_switch ( ) - > default_value ( false ) , <nl> + \" Start \" ) <nl> ( \" mongodb - uri , m \" , bpo : : value < std : : string > ( ) , <nl> \" MongoDB URI connection string , see : https : / / docs . mongodb . com / master / reference / connection - string / . \" <nl> - \" If not specified then plugin is disabled . Default database ' EOS ' is used if not specified in URI . \" ) <nl> + \" If not specified then plugin is disabled . Default database ' EOS ' is used if not specified in URI . \" <nl> + \" Example : mongodb : / / 127 . 0 . 0 . 1 : 27017 / EOS \" ) <nl> ; <nl> } <nl> <nl> void mongo_db_plugin : : plugin_initialize ( const variables_map & options ) <nl> { <nl> - if ( options . count ( \" mongodb - uri \" ) ) { <nl> - ilog ( \" initializing mongo_db_plugin \" ) ; <nl> - my - > configured = true ; <nl> - <nl> - if ( options . at ( \" replay - blockchain \" ) . as < bool > ( ) | | options . at ( \" hard - replay - blockchain \" ) . as < bool > ( ) ) { <nl> - ilog ( \" Replay requested : wiping mongo database on startup \" ) ; <nl> - my - > wipe_database_on_startup = true ; <nl> - } <nl> - if ( options . at ( \" delete - all - blocks \" ) . as < bool > ( ) ) { <nl> - ilog ( \" Resync requested : wiping mongo database on startup \" ) ; <nl> - my - > wipe_database_on_startup = true ; <nl> - } <nl> - <nl> - if ( options . count ( \" mongodb - queue - size \" ) ) { <nl> - auto size = options . at ( \" mongodb - queue - size \" ) . as < uint > ( ) ; <nl> - my - > queue_size = size ; <nl> - } <nl> + try { <nl> + if ( options . count ( \" mongodb - uri \" ) ) { <nl> + ilog ( \" initializing mongo_db_plugin \" ) ; <nl> + my - > configured = true ; <nl> + <nl> + if ( options . at ( \" replay - blockchain \" ) . as < bool > ( ) | | options . at ( \" hard - replay - blockchain \" ) . as < bool > ( ) | | options . at ( \" delete - all - blocks \" ) . as < bool > ( ) ) { <nl> + if ( options . at ( \" mongodb - wipe \" ) . as < bool > ( ) ) { <nl> + ilog ( \" Wiping mongo database on startup \" ) ; <nl> + my - > wipe_database_on_startup = true ; <nl> + } else { <nl> + FC_ASSERT ( false , \" - - mongodb - wipe required with - - replay - blockchain , - - hard - replay - blockchain , or - - delete - all - blocks \" <nl> + \" - - mongodb - wipe will remove all EOS collections from mongodb . \" ) ; <nl> + } <nl> + } <nl> <nl> - std : : string uri_str = options . at ( \" mongodb - uri \" ) . as < std : : string > ( ) ; <nl> - ilog ( \" connecting to $ { u } \" , ( \" u \" , uri_str ) ) ; <nl> - mongocxx : : uri uri = mongocxx : : uri { uri_str } ; <nl> - my - > db_name = uri . database ( ) ; <nl> - if ( my - > db_name . empty ( ) ) <nl> - my - > db_name = \" EOS \" ; <nl> - my - > mongo_conn = mongocxx : : client { uri } ; <nl> - <nl> - / / hook up to signals on controller <nl> - chain_plugin * chain_plug = app ( ) . find_plugin < chain_plugin > ( ) ; <nl> - FC_ASSERT ( chain_plug ) ; <nl> - auto & chain = chain_plug - > chain ( ) ; <nl> - my - > chain_id . emplace ( chain . get_chain_id ( ) ) ; <nl> - <nl> - my - > accepted_block_connection . emplace ( chain . accepted_block . connect ( [ & ] ( const chain : : block_state_ptr & bs ) { <nl> - my - > accepted_block ( bs ) ; <nl> - } ) ) ; <nl> - my - > irreversible_block_connection . emplace ( chain . irreversible_block . connect ( [ & ] ( const chain : : block_state_ptr & bs ) { <nl> - my - > applied_irreversible_block ( bs ) ; <nl> - } ) ) ; <nl> - my - > accepted_transaction_connection . emplace ( chain . accepted_transaction . connect ( [ & ] ( const chain : : transaction_metadata_ptr & t ) { <nl> - my - > accepted_transaction ( t ) ; <nl> - } ) ) ; <nl> - my - > applied_transaction_connection . emplace ( chain . applied_transaction . connect ( [ & ] ( const chain : : transaction_trace_ptr & t ) { <nl> - my - > applied_transaction ( t ) ; <nl> - } ) ) ; <nl> + if ( options . count ( \" mongodb - queue - size \" ) ) { <nl> + auto size = options . at ( \" mongodb - queue - size \" ) . as < uint > ( ) ; <nl> + my - > queue_size = size ; <nl> + } <nl> <nl> - if ( my - > wipe_database_on_startup ) { <nl> - my - > wipe_database ( ) ; <nl> + std : : string uri_str = options . at ( \" mongodb - uri \" ) . as < std : : string > ( ) ; <nl> + ilog ( \" connecting to $ { u } \" , ( \" u \" , uri_str ) ) ; <nl> + mongocxx : : uri uri = mongocxx : : uri { uri_str } ; <nl> + my - > db_name = uri . database ( ) ; <nl> + if ( my - > db_name . empty ( ) ) <nl> + my - > db_name = \" EOS \" ; <nl> + my - > mongo_conn = mongocxx : : client { uri } ; <nl> + <nl> + / / hook up to signals on controller <nl> + chain_plugin * chain_plug = app ( ) . find_plugin < chain_plugin > ( ) ; <nl> + FC_ASSERT ( chain_plug ) ; <nl> + auto & chain = chain_plug - > chain ( ) ; <nl> + my - > chain_id . emplace ( chain . get_chain_id ( ) ) ; <nl> + <nl> + my - > accepted_block_connection . emplace ( chain . accepted_block . connect ( [ & ] ( const chain : : block_state_ptr & bs ) { <nl> + my - > accepted_block ( bs ) ; <nl> + } ) ) ; <nl> + my - > irreversible_block_connection . emplace ( <nl> + chain . irreversible_block . connect ( [ & ] ( const chain : : block_state_ptr & bs ) { <nl> + my - > applied_irreversible_block ( bs ) ; <nl> + } ) ) ; <nl> + my - > accepted_transaction_connection . emplace ( <nl> + chain . accepted_transaction . connect ( [ & ] ( const chain : : transaction_metadata_ptr & t ) { <nl> + my - > accepted_transaction ( t ) ; <nl> + } ) ) ; <nl> + my - > applied_transaction_connection . emplace ( <nl> + chain . applied_transaction . connect ( [ & ] ( const chain : : transaction_trace_ptr & t ) { <nl> + my - > applied_transaction ( t ) ; <nl> + } ) ) ; <nl> + <nl> + if ( my - > wipe_database_on_startup ) { <nl> + my - > wipe_database ( ) ; <nl> + } <nl> + my - > init ( ) ; <nl> + } else { <nl> + wlog ( \" eosio : : mongo_db_plugin configured , but no - - mongodb - uri specified . \" ) ; <nl> + wlog ( \" mongo_db_plugin disabled . \" ) ; <nl> } <nl> - my - > init ( ) ; <nl> - } else { <nl> - wlog ( \" eosio : : mongo_db_plugin configured , but no - - mongodb - uri specified . \" ) ; <nl> - wlog ( \" mongo_db_plugin disabled . \" ) ; <nl> - } <nl> + } FC_LOG_AND_RETHROW ( ) <nl> } <nl> <nl> void mongo_db_plugin : : plugin_startup ( ) <nl>\n", "msg": "Modify sleep time as queue size changes . Added - - mongodb - wipe option to prevent accidental mongodb wipe .\n"}
{"diff_id": 16843, "repo": "tensorflow/tensorflow\n", "sha": "320fc8311fd8e320d27f8e8335a3bdae86599c07\n", "time": "2019-10-22T14:31:48Z\n", "diff": "mmm a / bindings / python / pybind . cpp <nl> ppp b / bindings / python / pybind . cpp <nl> <nl> # include \" mlir / EDSC / Helpers . h \" <nl> # include \" mlir / EDSC / Intrinsics . h \" <nl> # include \" mlir / ExecutionEngine / ExecutionEngine . h \" <nl> + # include \" mlir / ExecutionEngine / OptUtils . h \" <nl> # include \" mlir / IR / Attributes . h \" <nl> # include \" mlir / IR / Function . h \" <nl> # include \" mlir / IR / Module . h \" <nl> struct PythonMLIRModule { <nl> / / Create a boolean attribute . <nl> PythonAttribute boolAttr ( bool value ) ; <nl> <nl> - void compile ( ) { <nl> + / / Compile the module save the execution engine . \" optLevel \" and <nl> + / / \" codegenOptLevel \" contain the levels of optimization to run ( 0 to 3 ) for <nl> + / / transformations and codegen . - 1 means ExecutionEngine default . <nl> + void compile ( int optLevel , int codegenOptLevel ) { <nl> PassManager manager ( module - > getContext ( ) ) ; <nl> manager . addPass ( mlir : : createCanonicalizerPass ( ) ) ; <nl> manager . addPass ( mlir : : createCSEPass ( ) ) ; <nl> struct PythonMLIRModule { <nl> return ; <nl> } <nl> <nl> - auto created = mlir : : ExecutionEngine : : create ( * module ) ; <nl> + / / Make sure the executione engine runs LLVM passes for the specified <nl> + / / optimization level . <nl> + auto tmBuilderOrError = llvm : : orc : : JITTargetMachineBuilder : : detectHost ( ) ; <nl> + assert ( tmBuilderOrError ) ; <nl> + auto tmOrError = tmBuilderOrError - > createTargetMachine ( ) ; <nl> + assert ( tmOrError ) ; <nl> + targetMachine = std : : move ( tmOrError . get ( ) ) ; <nl> + auto transformer = mlir : : makeLLVMPassesTransformer ( <nl> + / * llvmPasses = * / { } , <nl> + optLevel = = - 1 ? llvm : : Optional < unsigned > ( ) : optLevel , <nl> + targetMachine . get ( ) , <nl> + / * optPassesInsertPos = * / 0 ) ; <nl> + <nl> + auto created = mlir : : ExecutionEngine : : create ( <nl> + * module , transformer , <nl> + codegenOptLevel = = - 1 <nl> + ? llvm : : Optional < llvm : : CodeGenOpt : : Level > ( ) <nl> + : static_cast < llvm : : CodeGenOpt : : Level > ( codegenOptLevel ) ) ; <nl> llvm : : handleAllErrors ( created . takeError ( ) , <nl> [ ] ( const llvm : : ErrorInfoBase & b ) { <nl> b . log ( llvm : : errs ( ) ) ; <nl> struct PythonMLIRModule { <nl> / / One single module in a python - exposed MLIRContext for now . <nl> mlir : : OwningModuleRef module ; <nl> mlir : : ModuleManager moduleManager ; <nl> + <nl> + / / An execution engine and an associated target machine . The latter must <nl> + / / outlive the former since it may be used by the transformation layers . <nl> std : : unique_ptr < mlir : : ExecutionEngine > engine ; <nl> + std : : unique_ptr < llvm : : TargetMachine > targetMachine ; <nl> } ; <nl> <nl> struct PythonFunctionContext { <nl> PYBIND11_MODULE ( pybind , m ) { <nl> \" Returns an mlir : : Type defined by the IR passed in as the argument . \" ) <nl> . def ( \" compile \" , & PythonMLIRModule : : compile , <nl> \" Compiles the mlir : : ModuleOp to LLVMIR a creates new opaque \" <nl> - \" ExecutionEngine backed by the ORC JIT . \" ) <nl> + \" ExecutionEngine backed by the ORC JIT . The arguments , if present , \" <nl> + \" indicates the level of LLVM optimizations to run ( similar to - O ? ) . \" , <nl> + py : : arg ( \" optLevel \" ) = - 1 , py : : arg ( \" codegenOptLevel \" ) = - 1 ) <nl> . def ( \" get_ir \" , & PythonMLIRModule : : getIR , <nl> \" Returns a dump of the MLIR representation of the module . This is \" <nl> \" used for serde to support out - of - process execution as well as \" <nl>\n", "msg": "Expose optimizations flags in Python bindings\n"}
{"diff_id": 17047, "repo": "mongodb/mongo\n", "sha": "f7d1dbff85b54014ead2d5859228fd16b072b9db\n", "time": "2011-01-26T18:34:43Z\n", "diff": "mmm a / s / commands_public . cpp <nl> ppp b / s / commands_public . cpp <nl> namespace mongo { <nl> / / so we allocate them in our thread <nl> / / and hand off <nl> <nl> - list < shared_ptr < ShardConnection > > shardConns ; <nl> + vector < shared_ptr < ShardConnection > > shardConns ; <nl> <nl> list < shared_ptr < Future : : CommandResult > > futures ; <nl> <nl> for ( set < Shard > : : iterator i = shards . begin ( ) , end = shards . end ( ) ; i ! = end ; i + + ) { <nl> shared_ptr < ShardConnection > temp ( new ShardConnection ( i - > getConnString ( ) , fullns ) ) ; <nl> + assert ( temp - > get ( ) ) ; <nl> futures . push_back ( Future : : spawnCommand ( i - > getConnString ( ) , dbName , shardedCommand , temp - > get ( ) ) ) ; <nl> shardConns . push_back ( temp ) ; <nl> } <nl> namespace mongo { <nl> } <nl> shardresults . append ( res - > getServer ( ) , res - > result ( ) ) ; <nl> } <nl> - <nl> + <nl> + for ( unsigned i = 0 ; i < shardConns . size ( ) ; i + + ) <nl> + shardConns [ i ] - > done ( ) ; <nl> + <nl> if ( failed ) <nl> return 0 ; <nl> <nl>\n", "msg": "release ShardConnection when done in sharded / mr\n"}
{"diff_id": 17049, "repo": "google/filament\n", "sha": "f96501215bcdd747f14459e8492fe1afb516e029\n", "time": "2019-01-10T02:47:30Z\n", "diff": "mmm a / samples / app / MeshAssimp . cpp <nl> ppp b / samples / app / MeshAssimp . cpp <nl> std : : string shaderFromConfig ( MaterialConfig config ) { <nl> <nl> if ( ! config . unlit ) { <nl> shader + = R \" SHADER ( <nl> - material . roughness = materialParams . roughnessFactor * texture ( materialParams_metallicRoughnessMap , metallicRoughnessUV ) . g ; <nl> - material . metallic = materialParams . metallicFactor * texture ( materialParams_metallicRoughnessMap , metallicRoughnessUV ) . b ; <nl> + vec4 metallicRoughness = texture ( materialParams_metallicRoughnessMap , metallicRoughnessUV ) ; <nl> + material . roughness = materialParams . roughnessFactor * metallicRoughness . g ; <nl> + material . metallic = materialParams . metallicFactor * metallicRoughness . b ; <nl> material . ambientOcclusion = texture ( materialParams_aoMap , aoUV ) . r ; <nl> material . emissive = texture ( materialParams_emissiveMap , emissiveUV ) ; <nl> material . emissive . rgb * = materialParams . emissiveFactor . rgb ; <nl> bool MeshAssimp : : setFromFile ( Asset & asset , std : : map < std : : string , MaterialInstanc <nl> <nl> asset . snormUV0 = minUV0 . x > = - 1 . 0f & & minUV0 . x < = 1 . 0f & & maxUV0 . x > = - 1 . 0f & & maxUV0 . x < = 1 . 0f & & <nl> minUV0 . y > = - 1 . 0f & & minUV0 . y < = 1 . 0f & & maxUV0 . y > = - 1 . 0f & & maxUV0 . y < = 1 . 0f ; <nl> - <nl> + <nl> asset . snormUV1 = minUV1 . x > = - 1 . 0f & & minUV1 . x < = 1 . 0f & & maxUV1 . x > = - 1 . 0f & & maxUV1 . x < = 1 . 0f & & <nl> minUV1 . y > = - 1 . 0f & & minUV1 . y < = 1 . 0f & & maxUV1 . y > = - 1 . 0f & & maxUV1 . y < = 1 . 0f ; <nl> <nl>\n", "msg": "Reduce number of texture lookups in gltf_viewer .\n"}
{"diff_id": 17076, "repo": "godotengine/godot\n", "sha": "2115bced93dc85ea04d5d5b51d022063a05c4c2f\n", "time": "2019-09-25T07:08:08Z\n", "diff": "mmm a / editor / scene_tree_dock . cpp <nl> ppp b / editor / scene_tree_dock . cpp <nl> void SceneTreeDock : : _replace_with_branch_scene ( const String & p_file , Node * base ) <nl> return ; <nl> } <nl> <nl> + UndoRedo * undo_redo = editor - > get_undo_redo ( ) ; <nl> + undo_redo - > create_action ( TTR ( \" Replace with Branch Scene \" ) ) ; <nl> + <nl> Node * parent = base - > get_parent ( ) ; <nl> int pos = base - > get_index ( ) ; <nl> - parent - > remove_child ( base ) ; <nl> - parent - > add_child ( instanced_scene ) ; <nl> - parent - > move_child ( instanced_scene , pos ) ; <nl> - instanced_scene - > set_owner ( edited_scene ) ; <nl> - editor_selection - > clear ( ) ; <nl> - editor_selection - > add_node ( instanced_scene ) ; <nl> - scene_tree - > set_selected ( instanced_scene ) ; <nl> - <nl> - / / Delete the node as late as possible because before another one is selected <nl> - / / an editor plugin could be referencing it to do something with it before <nl> - / / switching to another ( or to none ) ; and since some steps of changing the <nl> - / / editor state are deferred , the safest thing is to do this is as the last <nl> - / / step of this function and also by enqueing instead of memdelete ( ) - ing it here <nl> - base - > queue_delete ( ) ; <nl> + undo_redo - > add_do_method ( parent , \" remove_child \" , base ) ; <nl> + undo_redo - > add_undo_method ( parent , \" remove_child \" , instanced_scene ) ; <nl> + undo_redo - > add_do_method ( parent , \" add_child \" , instanced_scene ) ; <nl> + undo_redo - > add_undo_method ( parent , \" add_child \" , base ) ; <nl> + undo_redo - > add_do_method ( parent , \" move_child \" , instanced_scene , pos ) ; <nl> + undo_redo - > add_undo_method ( parent , \" move_child \" , base , pos ) ; <nl> + <nl> + List < Node * > owned ; <nl> + base - > get_owned_by ( base - > get_owner ( ) , & owned ) ; <nl> + Array owners ; <nl> + for ( List < Node * > : : Element * F = owned . front ( ) ; F ; F = F - > next ( ) ) { <nl> + owners . push_back ( F - > get ( ) ) ; <nl> + } <nl> + undo_redo - > add_do_method ( instanced_scene , \" set_owner \" , edited_scene ) ; <nl> + undo_redo - > add_undo_method ( this , \" _set_owners \" , edited_scene , owners ) ; <nl> + <nl> + undo_redo - > add_do_method ( editor_selection , \" clear \" ) ; <nl> + undo_redo - > add_undo_method ( editor_selection , \" clear \" ) ; <nl> + undo_redo - > add_do_method ( editor_selection , \" add_node \" , instanced_scene ) ; <nl> + undo_redo - > add_undo_method ( editor_selection , \" add_node \" , base ) ; <nl> + undo_redo - > add_do_property ( scene_tree , \" set_selected \" , instanced_scene ) ; <nl> + undo_redo - > add_undo_property ( scene_tree , \" set_selected \" , base ) ; <nl> + <nl> + undo_redo - > add_do_reference ( instanced_scene ) ; <nl> + undo_redo - > add_undo_reference ( base ) ; <nl> + undo_redo - > commit_action ( ) ; <nl> } <nl> <nl> bool SceneTreeDock : : _cyclical_dependency_exists ( const String & p_target_scene_path , Node * p_desired_node ) { <nl>\n", "msg": "' Save Branch as Scene ' adds to undo history\n"}
{"diff_id": 17086, "repo": "facebook/folly\n", "sha": "b837180a88e62576ab8cd4b85ee67f91771d945f\n", "time": "2016-08-04T23:08:32Z\n", "diff": "mmm a / folly / test / AtomicHashArrayTest . cpp <nl> ppp b / folly / test / AtomicHashArrayTest . cpp <nl> class MmapAllocator { <nl> <nl> T * allocate ( size_t n ) { <nl> void * p = mmap ( nullptr , n * sizeof ( T ) , PROT_READ | PROT_WRITE , <nl> - MAP_SHARED | MAP_ANONYMOUS , - 1 , 0 ) ; <nl> + MAP_PRIVATE | MAP_ANONYMOUS , - 1 , 0 ) ; <nl> if ( p = = MAP_FAILED ) throw std : : bad_alloc ( ) ; <nl> return ( T * ) p ; <nl> } <nl>\n", "msg": "Don ' t attempt to mmap an anonymous shared piece of memory\n"}
{"diff_id": 17174, "repo": "ClickHouse/ClickHouse\n", "sha": "40ef75399220c674d6fa6fe6f3b176fbe909f1db\n", "time": "2018-02-12T21:13:50Z\n", "diff": "mmm a / dbms / src / Storages / MergeTree / registerStorageMergeTree . cpp <nl> ppp b / dbms / src / Storages / MergeTree / registerStorageMergeTree . cpp <nl> MergeTrees are different in two ways : <nl> - they may be replicated and non - replicated ; <nl> - they may do different actions on merge : nothing ; sign collapse ; sum ; apply aggregete functions . <nl> <nl> - So we have 12 combinations : <nl> - MergeTree , CollapsingMergeTree , SummingMergeTree , AggregatingMergeTree , ReplacingMergeTree , GraphiteMergeTree <nl> - ReplicatedMergeTree , ReplicatedCollapsingMergeTree , ReplicatedSummingMergeTree , ReplicatedAggregatingMergeTree , ReplicatedReplacingMergeTree , ReplicatedGraphiteMergeTree <nl> + So we have 14 combinations : <nl> + MergeTree , CollapsingMergeTree , SummingMergeTree , AggregatingMergeTree , ReplacingMergeTree , GraphiteMergeTree , VersionedCollapsingMergeTree <nl> + ReplicatedMergeTree , ReplicatedCollapsingMergeTree , ReplicatedSummingMergeTree , ReplicatedAggregatingMergeTree , ReplicatedReplacingMergeTree , ReplicatedGraphiteMergeTree , ReplicatedVersionedCollapsingMergeTree <nl> <nl> In most of cases , you need MergeTree or ReplicatedMergeTree . <nl> <nl> For the Summing mode , the optional last parameter is a list of columns to sum wh <nl> If this parameter is omitted , the storage will sum all numeric columns except columns participating in the primary key . <nl> <nl> For the Replacing mode , the optional last parameter is the name of a ' version ' column . While merging , for all rows with the same primary key , only one row is selected : the last row , if the version column was not specified , or the last row with the maximum version value , if specified . <nl> + <nl> + For VersionedCollapsing mode , the last 2 parameters are the name of a sign column and the name of a ' version ' column . Version column must be in primary key . While merging , a pair of rows with the same primary key and different sign may collapse . <nl> ) \" ; <nl> <nl> if ( is_extended_syntax ) <nl> void registerStorageMergeTree ( StorageFactory & factory ) <nl> factory . registerStorage ( \" AggregatingMergeTree \" , create ) ; <nl> factory . registerStorage ( \" SummingMergeTree \" , create ) ; <nl> factory . registerStorage ( \" GraphiteMergeTree \" , create ) ; <nl> - factory . registerStorage ( \" MultiversionMergeTree \" , create ) ; <nl> + factory . registerStorage ( \" VersionedCollapsingMergeTree \" , create ) ; <nl> <nl> factory . registerStorage ( \" ReplicatedMergeTree \" , create ) ; <nl> factory . registerStorage ( \" ReplicatedCollapsingMergeTree \" , create ) ; <nl> void registerStorageMergeTree ( StorageFactory & factory ) <nl> factory . registerStorage ( \" ReplicatedAggregatingMergeTree \" , create ) ; <nl> factory . registerStorage ( \" ReplicatedSummingMergeTree \" , create ) ; <nl> factory . registerStorage ( \" ReplicatedGraphiteMergeTree \" , create ) ; <nl> - factory . registerStorage ( \" ReplicatedMultiversionMergeTree \" , create ) ; <nl> + factory . registerStorage ( \" ReplicatedVersionedCollapsingMergeTree \" , create ) ; <nl> } <nl> <nl> } <nl>\n", "msg": "added VersionedCollapsingMergeTree to help message [ # CLICKHOUSE - 3479 ]\n", "score": 1}
{"diff_id": 17525, "repo": "aseprite/aseprite\n", "sha": "7f4871c2fb53922ad1f4325323932bafedc3fffa\n", "time": "2010-07-05T02:17:01Z\n", "diff": "mmm a / src / commands / cmd_about . cpp <nl> ppp b / src / commands / cmd_about . cpp <nl> AboutCommand : : AboutCommand ( ) <nl> <nl> void AboutCommand : : execute ( Context * context ) <nl> { <nl> - JWidget box1 , label1 , label2 , separator1 ; <nl> - JWidget textbox , view , separator2 ; <nl> - JWidget label3 , label4 , box2 , box3 , box4 , button1 ; <nl> - <nl> - FramePtr window ( new Frame ( false , _ ( \" About \" PACKAGE ) ) ) ; <nl> - <nl> - box1 = jbox_new ( JI_VERTICAL ) ; <nl> - label1 = new Label ( PACKAGE \" | Allegro Sprite Editor v \" VERSION ) ; <nl> - label2 = new Label ( _ ( \" A pixel art program \" ) ) ; <nl> - separator1 = ji_separator_new ( NULL , JI_HORIZONTAL ) ; <nl> - <nl> - label3 = new Label ( COPYRIGHT ) ; <nl> - label4 = new LinkLabel ( WEBSITE ) ; <nl> - textbox = jtextbox_new ( \" Authors : \\ n \\ n \" <nl> - \" David Capello \\ n \" <nl> - \" - Project leader and developer \\ n \\ n \" <nl> - \" Ilija Melentijevic \\ n \" <nl> - \" - ASE skin and pixel art expert \\ n \\ n \" <nl> - \" Trent Gamblin \\ n \" <nl> - \" - Mac OS X builds \\ n \" , 0 ) ; <nl> - box2 = jbox_new ( JI_HORIZONTAL ) ; <nl> - box3 = jbox_new ( JI_HORIZONTAL ) ; <nl> - box4 = jbox_new ( JI_HORIZONTAL ) ; <nl> - button1 = jbutton_new ( _ ( \" & Close \" ) ) ; <nl> + FramePtr frame ( new Frame ( false , _ ( \" About \" PACKAGE ) ) ) ; <nl> + Widget * box1 = jbox_new ( JI_VERTICAL ) ; <nl> + Widget * grid = jgrid_new ( 2 , false ) ; <nl> + Label * title = new Label ( PACKAGE \" | Allegro Sprite Editor v \" VERSION ) ; <nl> + Label * subtitle = new Label ( _ ( \" A pixel art program \" ) ) ; <nl> + Widget * authors_separator1 = ji_separator_new ( \" Authors : \" , JI_HORIZONTAL | JI_TOP ) ; <nl> + Widget * authors_separator2 = ji_separator_new ( NULL , JI_HORIZONTAL ) ; <nl> + Label * author1 = new LinkLabel ( \" http : / / www . davidcapello . com . ar / \" , \" David Capello \" ) ; <nl> + Label * author1_desc = new Label ( \" | Programming \" ) ; <nl> + Label * author2 = new LinkLabel ( \" http : / / ilkke . blogspot . com / \" , \" Ilija Melentijevic \" ) ; <nl> + Label * author2_desc = new Label ( \" | Skin and Graphics \" ) ; <nl> + Label * author3 = new Label ( \" Trent Gamblin \" ) ; <nl> + Label * author3_desc = new Label ( \" | MAC OS X builds \" ) ; <nl> + Widget * bottom_box1 = jbox_new ( JI_HORIZONTAL ) ; <nl> + Widget * bottom_box2 = jbox_new ( JI_HORIZONTAL ) ; <nl> + Widget * bottom_box3 = jbox_new ( JI_HORIZONTAL ) ; <nl> + Label * copyright = new Label ( COPYRIGHT ) ; <nl> + Label * website = new LinkLabel ( WEBSITE ) ; <nl> + Widget * close_button = jbutton_new ( _ ( \" & Close \" ) ) ; <nl> + <nl> + jgrid_add_child ( grid , title , 2 , 1 , 0 ) ; <nl> + jgrid_add_child ( grid , subtitle , 2 , 1 , 0 ) ; <nl> + jgrid_add_child ( grid , authors_separator1 , 2 , 1 , 0 ) ; <nl> + jgrid_add_child ( grid , author1 , 1 , 1 , 0 ) ; <nl> + jgrid_add_child ( grid , author1_desc , 1 , 1 , 0 ) ; <nl> + jgrid_add_child ( grid , author2 , 1 , 1 , 0 ) ; <nl> + jgrid_add_child ( grid , author2_desc , 1 , 1 , 0 ) ; <nl> + jgrid_add_child ( grid , author3 , 1 , 1 , 0 ) ; <nl> + jgrid_add_child ( grid , author3_desc , 1 , 1 , 0 ) ; <nl> + jgrid_add_child ( grid , authors_separator2 , 2 , 1 , 0 ) ; <nl> + jgrid_add_child ( grid , copyright , 2 , 1 , 0 ) ; <nl> + jgrid_add_child ( grid , website , 2 , 1 , 0 ) ; <nl> + jgrid_add_child ( grid , bottom_box1 , 2 , 1 , 0 ) ; <nl> <nl> - jwidget_magnetic ( button1 , true ) ; <nl> + jwidget_magnetic ( close_button , true ) ; <nl> <nl> - jwidget_set_border ( box1 , 4 * jguiscale ( ) ) ; <nl> - jwidget_add_children ( box1 , label1 , label2 , separator1 , NULL ) ; <nl> + jwidget_expansive ( bottom_box2 , true ) ; <nl> + jwidget_expansive ( bottom_box3 , true ) ; <nl> <nl> - if ( textbox ) { <nl> - view = jview_new ( ) ; <nl> - separator2 = ji_separator_new ( NULL , JI_HORIZONTAL ) ; <nl> + jwidget_add_children ( bottom_box1 , bottom_box2 , close_button , bottom_box3 , NULL ) ; <nl> + jwidget_add_child ( box1 , grid ) ; <nl> + jwidget_add_child ( frame , box1 ) ; <nl> <nl> - jview_attach ( view , textbox ) ; <nl> - jview_maxsize ( view ) ; <nl> - jwidget_expansive ( view , true ) ; <nl> - jwidget_add_children ( box1 , view , separator2 , NULL ) ; <nl> - } <nl> + jwidget_set_border ( close_button , <nl> + close_button - > border_width . l + 16 * jguiscale ( ) , <nl> + close_button - > border_width . t , <nl> + close_button - > border_width . r + 16 * jguiscale ( ) , <nl> + close_button - > border_width . b ) ; <nl> <nl> - jwidget_expansive ( box3 , true ) ; <nl> - jwidget_expansive ( box4 , true ) ; <nl> - jwidget_add_children ( box2 , box3 , button1 , box4 , NULL ) ; <nl> - <nl> - jwidget_add_children ( box1 , label3 , label4 , NULL ) ; <nl> - jwidget_add_child ( box1 , box2 ) ; <nl> - jwidget_add_child ( window , box1 ) ; <nl> - <nl> - jwidget_set_border ( button1 , <nl> - button1 - > border_width . l + 16 * jguiscale ( ) , <nl> - button1 - > border_width . t , <nl> - button1 - > border_width . r + 16 * jguiscale ( ) , <nl> - button1 - > border_width . b ) ; <nl> - <nl> - window - > open_window_fg ( ) ; <nl> + frame - > open_window_fg ( ) ; <nl> } <nl> <nl> / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / <nl>\n", "msg": "Modified about command to show links to authors ' home page .\n", "score": 1}
{"diff_id": 17531, "repo": "apple/swift\n", "sha": "50fd6eae97a19bb5c72e176facdff841475fb301\n", "time": "2019-07-04T02:16:35Z\n", "diff": "mmm a / lib / Immediate / Immediate . cpp <nl> ppp b / lib / Immediate / Immediate . cpp <nl> static void * loadRuntimeLib ( StringRef sharedLibName , <nl> <nl> void * swift : : immediate : : loadSwiftRuntime ( ArrayRef < std : : string > <nl> runtimeLibPaths ) { <nl> + # if defined ( _WIN32 ) <nl> + return loadRuntimeLib ( \" swiftCore \" LTDL_SHLIB_EXT , runtimeLibPaths ) ; <nl> + # else <nl> return loadRuntimeLib ( \" libswiftCore \" LTDL_SHLIB_EXT , runtimeLibPaths ) ; <nl> + # endif <nl> } <nl> <nl> static bool tryLoadLibrary ( LinkLibrary linkLib , <nl>\n", "msg": "[ windows ] Use unprefixed library name for immediate mode .\n", "score": 1}
{"diff_id": 17587, "repo": "facebook/hhvm\n", "sha": "16e221b73806961c4f83dc1228ca9137114c54b9\n", "time": "2019-03-12T14:30:37Z\n", "diff": "mmm a / hphp / hhbbc / dce . cpp <nl> ppp b / hphp / hhbbc / dce . cpp <nl> template < typename Op > <nl> void dce_slot_default ( Env & , const Op & , int ) { } <nl> <nl> template < class Op > <nl> - void dce ( Env & env , const Op & op ) { <nl> + void dce_default ( Env & env , const Op & op ) { <nl> addLocGenSet ( env , env . flags . mayReadLocalSet ) ; <nl> push_outputs ( env , op . numPush ( ) ) ; <nl> pop_inputs ( env , op . numPop ( ) ) ; <nl> dce_slot_default ( env , op , true ) ; <nl> } <nl> <nl> + void dce ( Env & env , const bc : : Add & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : AddElemV & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : AddNewElemC & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : AddNewElemV & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : AddO & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : AliasCls & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : AssertRATL & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : AssertRATStk & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : AsTypeStructC & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Await & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : AwaitAll & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : BaseGL & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : BaseH & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : BaseL & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : BindG & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : BindL & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : BindS & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : BitAnd & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : BitNot & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : BitOr & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : BitXor & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Box & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : BreakTraceHint & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CastArray & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CastBool & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CastDArray & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CastDict & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CastDouble & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CastInt & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CastKeyset & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CastObject & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CastString & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CastVArray & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CastVec & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Catch & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CGetCUNop & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CGetG & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CGetQuietG & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CGetS & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ChainFaults & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CheckReifiedGenericMismatch & op ) { <nl> + dce_default ( env , op ) ; <nl> + } <nl> + void dce ( Env & env , const bc : : CheckThis & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Clone & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ClsCns & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ClsCnsD & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ClsRefGetTS & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Cmp & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Cns & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CnsE & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CnsU & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CnsUE & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Concat & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ConcatN & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ContAssignDelegate & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ContCheck & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ContCurrent & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ContEnter & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ContEnterDelegate & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ContGetReturn & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ContKey & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ContRaise & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ContUnsetDelegate & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ContValid & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CreateCl & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : CreateCont & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : DblAsBits & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : DefCls & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : DefClsNop & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : DefCns & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : DefTypeAlias & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Div & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : EmptyG & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : EmptyL & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : EmptyS & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : EntryNop & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Eq & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Eval & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : FCall & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : FCallBuiltin & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : FPushClsMethod & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : FPushClsMethodD & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : FPushClsMethodS & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : FPushClsMethodSD & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : FPushCtor & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : FPushFunc & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : FPushFuncD & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : FPushFuncU & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : FPushObjMethod & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : FPushObjMethodD & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : GetMemoKeyL & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Gt & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Gte & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : IncDecG & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : IncDecS & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Incl & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : InclOnce & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : InitProp & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : InstanceOf & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : InstanceOfD & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : IssetG & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : IssetL & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : IssetS & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : IterBreak & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : IterFree & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : IterInit & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : IterInitK & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : IterNext & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : IterNextK & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Jmp & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : JmpNS & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : JmpNZ & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : JmpZ & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : LIterFree & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : LIterInit & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : LIterInitK & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : LIterNext & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : LIterNextK & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Lt & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Lte & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : MemoGet & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : MemoGetEager & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : MemoSet & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : MemoSetEager & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Method & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Mod & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Mul & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : MulO & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : NativeImpl & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Neq & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : NewLikeArrayL & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : NewObj & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : NewObjD & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : NewObjI & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : NewObjS & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Nop & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Not & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : NSame & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : OODeclExists & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Pow & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Print & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : RecordReifiedGeneric & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Req & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ReqDoc & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ReqOnce & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ResolveClsMethod & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ResolveFunc & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : ResolveObjMethod & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : RetM & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Same & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Select & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : SetG & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : SetOpG & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : SetOpS & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : SetRangeM & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : SetS & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Shl & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Shr & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Silence & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : SSwitch & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : StaticLocCheck & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : StaticLocDef & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : StaticLocInit & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Sub & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : SubO & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Switch & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : This & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : UGetCUNop & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Unbox & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : UnsetG & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Unwind & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : VerifyOutType & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : VerifyParamType & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : VerifyParamTypeTS & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : VerifyRetNonNullC & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : VerifyRetTypeC & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : VerifyRetTypeTS & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : VGetG & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : VGetL & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : VGetS & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : WHResult & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Xor & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : Yield & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : YieldFromDelegate & op ) { dce_default ( env , op ) ; } <nl> + void dce ( Env & env , const bc : : YieldK & op ) { dce_default ( env , op ) ; } <nl> + <nl> / * <nl> * The minstr instructions can read a cell from the stack without <nl> * popping it . They need special handling . <nl> void minstr_touch ( Env & env , int32_t depth ) { <nl> <nl> template < class Op > <nl> void minstr_base ( Env & env , const Op & op , int32_t ix ) { <nl> - dce < Op > ( env , op ) ; <nl> + dce_default ( env , op ) ; <nl> minstr_touch ( env , ix ) ; <nl> } <nl> <nl> template < class Op > <nl> void minstr_dim ( Env & env , const Op & op ) { <nl> - dce < Op > ( env , op ) ; <nl> + dce_default ( env , op ) ; <nl> if ( op . mkey . mcode = = MEC | | op . mkey . mcode = = MPC ) { <nl> minstr_touch ( env , op . mkey . idx ) ; <nl> } <nl>\n", "msg": "Explicitly implement all opcodes in DCE\n"}
{"diff_id": 17709, "msg": "AddTeamsBestOf : Build more teams than desired\n", "msgGPT": "refactor team building logic to achieve a more balanced number of teams per server.", "METEOR Score": "20.612098513326295", "BLEU Score": "0.28763031326032396", "ROUGE-L Score": "0.1739130387145559", "score": 1, "repo": "apple/foundationdb\n", "sha": "7461c87ae6e7a12d577767183a24d4b869640483\n", "time": "2019-07-03T00:40:37Z\n", "diff": "mmm a / fdbserver / DataDistribution . actor . cpp <nl> ppp b / fdbserver / DataDistribution . actor . cpp <nl> struct DDTeamCollection : ReferenceCounted < DDTeamCollection > { <nl> <nl> / / If there are too few machines to even build teams or there are too few represented datacenters , build no new teams <nl> if ( uniqueMachines > = self - > configuration . storageTeamSize ) { <nl> - desiredTeams = SERVER_KNOBS - > DESIRED_TEAMS_PER_SERVER * serverCount ; <nl> - int maxTeams = SERVER_KNOBS - > MAX_TEAMS_PER_SERVER * serverCount ; <nl> + / / We build more teams than we finally want so that we can use serverTeamRemover ( ) actor to remove the teams <nl> + / / whose member belong to too many teams . This allows us to get a more balanced number of teams per server . <nl> + / / The numTeamsPerServerFactor is calculated as <nl> + / / ( SERVER_KNOBS - > DESIRED_TEAMS_PER_SERVER + ideal_num_of_teams_per_server ) / 2 <nl> + / / ideal_num_of_teams_per_server is ( # teams * storageTeamSize ) / # servers , which is <nl> + / / ( # servers * DESIRED_TEAMS_PER_SERVER * storageTeamSize ) / # servers . <nl> + int numTeamsPerServerFactor = ( SERVER_KNOBS - > DESIRED_TEAMS_PER_SERVER + SERVER_KNOBS - > DESIRED_TEAMS_PER_SERVER * self - > configuration . storageTeamSize ) / 2 ; <nl> + ASSERT ( SERVER_KNOBS - > DESIRED_TEAMS_PER_SERVER > = 1 & & self - > configuration . storageTeamSize > = 1 ) ; <nl> + ASSERT ( numTeamsPerServerFactor > 0 ) ; <nl> + desiredTeams = numTeamsPerServerFactor * serverCount ; <nl> + int maxTeams = numTeamsPerServerFactor * serverCount ; <nl> <nl> / / Exclude teams who have members in the wrong configuration , since we don ' t want these teams <nl> int teamCount = 0 ; <nl>\n"}
{"diff_id": 17822, "repo": "xbmc/xbmc\n", "sha": "b93a152c7c4dcdd2936711b59b5c209bc51d3f13\n", "time": "2013-03-20T21:40:58Z\n", "diff": "mmm a / xbmc / network / AirPlayServer . cpp <nl> ppp b / xbmc / network / AirPlayServer . cpp <nl> int CAirPlayServer : : CTCPClient : : ProcessRequest ( CStdString & responseHeader , <nl> CStdString authorization = m_httpParser - > getValue ( \" authorization \" ) ; <nl> int status = AIRPLAY_STATUS_OK ; <nl> bool needAuth = false ; <nl> + <nl> + if ( m_sessionId . IsEmpty ( ) ) <nl> + m_sessionId = \" 00000000 - 0000 - 0000 - 0000 - 000000000000 \" ; <nl> <nl> if ( ServerInstance - > m_usePassword & & ! m_bAuthenticated ) <nl> { <nl>\n", "msg": "[ airplay ] - handle empty session ids from itunes\n"}
{"diff_id": 17954, "repo": "microsoft/CNTK\n", "sha": "82fd2d863808ce8330e27ff956486990204f79d3\n", "time": "2015-05-28T18:49:11Z\n", "diff": "mmm a / MachineLearning / CNTK / CNTK . cpp <nl> ppp b / MachineLearning / CNTK / CNTK . cpp <nl> void DoWriteWordAndClassInfo ( const ConfigParameters & config ) <nl> ofvocab . close ( ) ; <nl> if ( nbrCls > 0 ) <nl> { <nl> - / / / write the outputs <nl> + / / / write the outputs <nl> + msra : : files : : make_intermediate_dirs ( s2ws ( outputWord2Cls ) ) ; <nl> ofstream ofp ( outputWord2Cls . c_str ( ) ) ; <nl> if ( ! ofp ) <nl> - RuntimeError ( \" cannot write to % s \" , outputWord2Cls . c_str ( ) ) ; <nl> - for ( size_t r = 0 ; r < wrd2cls . GetNumRows ( ) ; r + + ) <nl> + RuntimeError ( \" cannot write to % s \" , outputWord2Cls . c_str ( ) ) ; <nl> + for ( size_t r = 0 ; r < wrd2cls . GetNumRows ( ) ; r + + ) <nl> ofp < < ( int ) wrd2cls ( r , 0 ) < < endl ; <nl> ofp . close ( ) ; <nl> <nl> + msra : : files : : make_intermediate_dirs ( s2ws ( outputCls2Index ) ) ; <nl> ofp . open ( outputCls2Index . c_str ( ) ) ; <nl> if ( ! ofp ) <nl> - RuntimeError ( \" cannot write to % s \" , outputCls2Index . c_str ( ) ) ; <nl> - for ( size_t r = 0 ; r < cls2idx . GetNumRows ( ) ; r + + ) <nl> + RuntimeError ( \" cannot write to % s \" , outputCls2Index . c_str ( ) ) ; <nl> + for ( size_t r = 0 ; r < cls2idx . GetNumRows ( ) ; r + + ) <nl> ofp < < ( int ) cls2idx ( r , 0 ) < < endl ; <nl> ofp . close ( ) ; <nl> } <nl>\n", "msg": "add directory creation in when writing clusters\n"}
{"diff_id": 17969, "repo": "facebook/hhvm\n", "sha": "075f4e57d8f89121924e221310e23cea4f6a8c2a\n", "time": "2014-05-28T19:22:21Z\n", "diff": "mmm a / hphp / runtime / vm / jit / xls . cpp <nl> ppp b / hphp / runtime / vm / jit / xls . cpp <nl> struct Interval { <nl> / / data structures we use during the algorithm so we don ' t have <nl> / / to pass them around everywhere . <nl> struct XLS { <nl> + typedef smart : : vector < Interval * > IntervalList ; <nl> XLS ( IRUnit & unit , RegAllocInfo & regs , const Abi & ) ; <nl> ~ XLS ( ) ; <nl> void allocate ( ) ; <nl> struct XLS { <nl> Use coalesceSrc ( unsigned pos , const IRInstruction & , unsigned i ) ; <nl> Use coalesceDst ( unsigned pos , const IRInstruction & , unsigned i ) ; <nl> RegPair firstHint ( Interval * , const RegPositions & ) ; <nl> + static void erase ( IntervalList & list , IntervalList : : iterator it ) ; <nl> / / debugging <nl> void print ( const char * caption ) ; <nl> void dumpIntervals ( ) ; <nl> struct XLS { <nl> PhysReg : : Map < Interval > m_blocked ; <nl> StateVector < Block , LiveSet > m_liveIn ; <nl> smart : : priority_queue < Interval * , Compare > m_pending ; <nl> - smart : : vector < Interval * > m_active ; <nl> - smart : : vector < Interval * > m_inactive ; <nl> + IntervalList m_active ; <nl> + IntervalList m_inactive ; <nl> StateVector < Block , std : : pair < IRInstruction * , IRInstruction * > > m_edgeCopies ; <nl> unsigned m_frontier { 0 } ; / / debug_only to detect backtracking <nl> unsigned m_orig { 0 } ; <nl> void XLS : : spill ( Interval * ivl ) { <nl> if ( ! isDefConst ( ivl ) ) assignSpill ( ivl ) ; <nl> } <nl> <nl> + / / remove the element at list [ i ] by moving the last element down . <nl> + void XLS : : erase ( IntervalList & list , IntervalList : : iterator i ) { <nl> + * i = list . back ( ) ; <nl> + list . pop_back ( ) ; <nl> + } <nl> + <nl> / / Split and spill other intervals that conflict with current for <nl> / / register r , at current - > start ( ) . If necessary , split the victims <nl> / / again before their first use position that requires a register . <nl> void XLS : : spillOthers ( Interval * current , RegPair r ) { <nl> if ( other - > scratch | | ! conflict ( r , other - > regs ( ) ) ) { <nl> i + + ; continue ; <nl> } <nl> - i = m_active . erase ( i ) ; <nl> + erase ( m_active , i ) ; <nl> spillAfter ( other , cur_start ) ; <nl> } <nl> for ( auto i = m_inactive . begin ( ) ; i ! = m_inactive . end ( ) ; ) { <nl> void XLS : : spillOthers ( Interval * current , RegPair r ) { <nl> if ( intersect > = current - > end ( ) ) { <nl> i + + ; continue ; <nl> } <nl> - i = m_inactive . erase ( i ) ; <nl> + erase ( m_inactive , i ) ; <nl> spillAfter ( other , cur_start ) ; <nl> } <nl> } <nl> void XLS : : update ( unsigned pos ) { <nl> auto ivl = * i ; <nl> if ( ivl - > end ( ) < = pos ) { <nl> / / done with ivl ; remove interval from active list <nl> - * i = m_active . back ( ) ; <nl> - m_active . pop_back ( ) ; <nl> + erase ( m_active , i ) ; <nl> } else if ( ! ivl - > covers ( pos ) ) { <nl> / / move ivl from active to inactive <nl> - * i = m_active . back ( ) ; <nl> - m_active . pop_back ( ) ; <nl> + erase ( m_active , i ) ; <nl> m_inactive . push_back ( ivl ) ; <nl> } else { <nl> i + + ; <nl> void XLS : : update ( unsigned pos ) { <nl> auto ivl = * i ; <nl> if ( ivl - > end ( ) < = pos ) { <nl> / / done with ivl ; remove interval from inactive list <nl> - * i = m_inactive . back ( ) ; <nl> - m_inactive . pop_back ( ) ; <nl> + erase ( m_inactive , i ) ; <nl> } else if ( ivl - > covers ( pos ) ) { <nl> / / move ivl from inactive to active <nl> - * i = m_inactive . back ( ) ; <nl> - m_inactive . pop_back ( ) ; <nl> + erase ( m_inactive , i ) ; <nl> m_active . push_back ( ivl ) ; <nl> } else { <nl> i + + ; <nl>\n", "msg": "Two more instances making erase faster .\n"}
{"diff_id": 18064, "repo": "apple/swift\n", "sha": "b65b3174c27aa6512ec54745b167115166dd5675\n", "time": "2019-12-13T16:53:12Z\n", "diff": "mmm a / lib / SILOptimizer / IPO / GlobalOpt . cpp <nl> ppp b / lib / SILOptimizer / IPO / GlobalOpt . cpp <nl> void SILGlobalOpt : : optimizeInitializer ( SILFunction * AddrF , <nl> HasChanged = true ; <nl> } <nl> <nl> - bool SILGlobalOpt : : tryRemoveGlobalAlloc ( SILGlobalVariable * global , <nl> - AllocGlobalInst * alloc ) { <nl> - if ( GlobalAddrMap [ global ] . size ( ) ) <nl> - return false ; <nl> - <nl> - InstToRemove . push_back ( alloc ) ; <nl> - <nl> - return true ; <nl> - } <nl> - <nl> static bool canBeChangedExternally ( SILGlobalVariable * SILG ) { <nl> / / Don ' t assume anything about globals which are imported from other modules . <nl> if ( isAvailableExternally ( SILG - > getLinkage ( ) ) ) <nl> static bool isSafeToRemove ( SILGlobalVariable * global ) { <nl> return global - > getDecl ( ) & & ! canBeUsedOrChangedExternally ( global ) ; <nl> } <nl> <nl> + bool SILGlobalOpt : : tryRemoveGlobalAlloc ( SILGlobalVariable * global , <nl> + AllocGlobalInst * alloc ) { <nl> + if ( ! isSafeToRemove ( global ) ) return false ; <nl> + <nl> + if ( GlobalAddrMap [ global ] . size ( ) ) <nl> + return false ; <nl> + <nl> + InstToRemove . push_back ( alloc ) ; <nl> + <nl> + return true ; <nl> + } <nl> + <nl> / / / If there are no loads or accesses of a given global , then remove its <nl> / / / associated global addr and all asssociated instructions . <nl> bool SILGlobalOpt : : tryRemoveGlobalAddr ( SILGlobalVariable * global ) { <nl> static LoadInst * getValidLoad ( SILInstruction * I , SILValue V ) { <nl> <nl> / / / If this is a read from a global let variable , map it . <nl> void SILGlobalOpt : : collectGlobalAccess ( GlobalAddrInst * GAI ) { <nl> + GAI - > dump ( ) ; <nl> auto * SILG = GAI - > getReferencedGlobal ( ) ; <nl> if ( ! SILG ) <nl> return ; <nl>\n", "msg": "Check global can be used before removing alloc\n"}
{"diff_id": 18193, "repo": "aseprite/aseprite\n", "sha": "fa760d8a2124e3a3fedc4c628702ecd50d7afc32\n", "time": "2014-07-07T00:29:36Z\n", "diff": "mmm a / src / app / commands / cmd_save_file . cpp <nl> ppp b / src / app / commands / cmd_save_file . cpp <nl> class SaveFileBaseCommand : public Command { <nl> { <nl> ContextWriter writer ( reader ) ; <nl> Document * documentWriter = writer . document ( ) ; <nl> + std : : string oldFilename = documentWriter - > getFilename ( ) ; <nl> <nl> / / Change the document file name <nl> documentWriter - > setFilename ( filename . c_str ( ) ) ; <nl> class SaveFileBaseCommand : public Command { <nl> / / Save the document <nl> save_document_in_background ( documentWriter , markAsSaved ) ; <nl> <nl> + if ( documentWriter - > isModified ( ) ) <nl> + documentWriter - > setFilename ( oldFilename ) ; <nl> + <nl> update_screen_for_document ( documentWriter ) ; <nl> } <nl> } <nl>\n", "msg": "Restore filename if \" save as \" fails\n"}
{"diff_id": 18200, "repo": "microsoft/vcpkg\n", "sha": "5bd45366fb0558616a6cb46cdbca6810da5afa4c\n", "time": "2019-08-09T22:15:22Z\n", "diff": "mmm a / toolsrc / src / vcpkg / build . cpp <nl> ppp b / toolsrc / src / vcpkg / build . cpp <nl> namespace vcpkg : : Build <nl> const std : : string features = Strings : : join ( \" ; \" , config . feature_list ) ; <nl> abi_tag_entries . emplace_back ( AbiEntry { \" features \" , features } ) ; <nl> <nl> + if ( pre_build_info . public_abi_override ) <nl> + { <nl> + abi_tag_entries . emplace_back ( <nl> + AbiEntry { <nl> + \" public_abi_override \" , <nl> + pre_build_info . public_abi_override . value_or_exit ( VCPKG_LINE_INFO ) <nl> + } ) ; <nl> + } <nl> + <nl> if ( config . build_package_options . use_head_version = = UseHeadVersion : : YES ) <nl> abi_tag_entries . emplace_back ( AbiEntry { \" head \" , \" \" } ) ; <nl> <nl>\n", "msg": "Add public abi override into the private abi\n"}
{"diff_id": 18246, "repo": "CRYTEK/CRYENGINE\n", "sha": "e004b4bb83804e019fb467b61cf8a21be3383a51\n", "time": "2019-07-04T10:03:01Z\n", "diff": "mmm a / Code / CryEngine / CryAction / GameVolumes / GameVolumesManager . cpp <nl> ppp b / Code / CryEngine / CryAction / GameVolumes / GameVolumesManager . cpp <nl> void CGameVolumesManager : : ResolveEntityIdsFromGUIDs ( ) <nl> for ( uint32 index = 0 ; index < count ; + + index ) <nl> { <nl> const EntityId entityId = gEnv - > pEntitySystem - > FindEntityByGuid ( m_volumesData [ index ] . entityGUID ) ; <nl> - CRY_ASSERT ( entityId ! = INVALID_ENTITYID ) ; <nl> + <nl> + / / This is a valid case for some volumes which are baked ( e . g . CLedgeObjectStatic ) and not spawned as entity . <nl> + if ( entityId = = INVALID_ENTITYID ) <nl> + continue ; <nl> + <nl> m_entityToIndexMap [ entityId ] = index ; <nl> } <nl> } <nl>\n", "msg": "! B ( CryAction ) ( CE - 17447 ) Fixed game volume manager not considering baked objects for entity id resolving .\n", "score": 1}
{"diff_id": 18369, "repo": "opencv/opencv\n", "sha": "72d90ba8d297bf9834848551d236081d3cbe20cb\n", "time": "2015-01-16T22:57:11Z\n", "diff": "mmm a / modules / highgui / src / window_QT . cpp <nl> ppp b / modules / highgui / src / window_QT . cpp <nl> CV_IMPL void cvAddText ( const CvArr * img , const char * text , CvPoint org , CvFont * <nl> \" putText \" , <nl> autoBlockingConnection ( ) , <nl> Q_ARG ( void * , ( void * ) img ) , <nl> - Q_ARG ( QString , QString ( text ) ) , <nl> + Q_ARG ( QString , QString : : fromUtf8 ( text ) ) , <nl> Q_ARG ( QPoint , QPoint ( org . x , org . y ) ) , <nl> Q_ARG ( void * , ( void * ) font ) ) ; <nl> } <nl>\n", "msg": "In cvAddText , construct QString from \" text \" using fromUtf8 .\n"}
{"diff_id": 18385, "repo": "notepad-plus-plus/notepad-plus-plus\n", "sha": "8ceabd7850ff5da0c961a250279576731be6dde7\n", "time": "2014-11-14T22:14:43Z\n", "diff": "mmm a / PowerEditor / src / Notepad_plus . cpp <nl> ppp b / PowerEditor / src / Notepad_plus . cpp <nl> bool Notepad_plus : : isConditionExprLine ( int lineNumber ) <nl> <nl> void Notepad_plus : : maintainIndentation ( TCHAR ch ) <nl> { <nl> - / * <nl> - int eolMode = int ( _pEditView - > execute ( SCI_GETEOLMODE ) ) ; <nl> - int curLine = int ( _pEditView - > getCurrentLineNumber ( ) ) ; <nl> - int prevLine = curLine - 1 ; <nl> - int indentAmount = 0 ; <nl> - <nl> - if ( ( ( eolMode = = SC_EOL_CRLF | | eolMode = = SC_EOL_LF ) & & ch = = ' \\ n ' ) | | <nl> - ( eolMode = = SC_EOL_CR & & ch = = ' \\ r ' ) ) <nl> - { <nl> - / / Search the non - empty previous line <nl> - while ( prevLine > = 0 & & _pEditView - > getLineLength ( prevLine ) = = 0 ) <nl> - prevLine - - ; <nl> - <nl> - if ( prevLine > = 0 ) { <nl> - indentAmount = _pEditView - > getLineIndent ( prevLine ) ; <nl> - } <nl> - if ( indentAmount > 0 ) { <nl> - _pEditView - > setLineIndent ( curLine , indentAmount ) ; <nl> - } <nl> - } <nl> - * / <nl> int eolMode = int ( _pEditView - > execute ( SCI_GETEOLMODE ) ) ; <nl> int curLine = int ( _pEditView - > getCurrentLineNumber ( ) ) ; <nl> int prevLine = curLine - 1 ; <nl> int indentAmountPrevLine = 0 ; <nl> + int tabWidth = _pEditView - > execute ( SCI_GETTABWIDTH ) ; <nl> <nl> if ( ( ( eolMode = = SC_EOL_CRLF | | eolMode = = SC_EOL_LF ) & & ch = = ' \\ n ' ) | | <nl> ( eolMode = = SC_EOL_CR & & ch = = ' \\ r ' ) ) <nl> void Notepad_plus : : maintainIndentation ( TCHAR ch ) <nl> / / get previous char from current line <nl> int prevPos = _pEditView - > execute ( SCI_GETCURRENTPOS ) - ( eolMode = = SC_EOL_CRLF ? 3 : 2 ) ; <nl> UCHAR prevChar = ( UCHAR ) _pEditView - > execute ( SCI_GETCHARAT , prevPos ) ; <nl> - int tabWidth = _pEditView - > execute ( SCI_GETTABWIDTH ) ; <nl> <nl> if ( prevChar = = ' { ' ) / / & & c + + java , c # js php ) <nl> { <nl> void Notepad_plus : : maintainIndentation ( TCHAR ch ) <nl> } <nl> } <nl> } <nl> + else if ( ch = = ' { ' ) <nl> + { <nl> + / / if no character in front of { , aligned with prev line ' s indentation <nl> + int startPos = _pEditView - > execute ( SCI_POSITIONFROMLINE , curLine ) ; <nl> + int endPos = _pEditView - > execute ( SCI_GETCURRENTPOS ) ; <nl> <nl> + for ( int i = endPos - 2 ; i > 0 & & i > startPos ; - - i ) <nl> + { <nl> + UCHAR aChar = ( UCHAR ) _pEditView - > execute ( SCI_GETCHARAT , i ) ; <nl> + if ( aChar ! = ' ' & & aChar ! = ' \\ t ' ) <nl> + return ; <nl> + } <nl> + <nl> + / / Search the non - empty previous line <nl> + while ( prevLine > = 0 & & _pEditView - > getLineLength ( prevLine ) = = 0 ) <nl> + prevLine - - ; <nl> + <nl> + / / Get previous line ' s Indent <nl> + if ( prevLine > = 0 ) <nl> + { <nl> + indentAmountPrevLine = _pEditView - > getLineIndent ( prevLine ) ; <nl> + } <nl> + _pEditView - > setLineIndent ( curLine , indentAmountPrevLine ) ; <nl> + } <nl> + else if ( ch = = ' } ' ) <nl> + { <nl> + / / Look backward for the pair { <nl> + int startPos = _pEditView - > execute ( SCI_GETCURRENTPOS ) ; <nl> + int endPos = 0 ; <nl> + _pEditView - > execute ( SCI_SETSEARCHFLAGS , SCFIND_REGEXP | SCFIND_POSIX ) ; <nl> + _pEditView - > execute ( SCI_SETTARGETSTART , startPos ) ; <nl> + _pEditView - > execute ( SCI_SETTARGETEND , endPos ) ; <nl> + <nl> + const char expr [ ] = \" { \" ; <nl> + <nl> + int posFound = _pEditView - > execute ( SCI_SEARCHINTARGET , strlen ( expr ) , ( LPARAM ) expr ) ; <nl> + <nl> + / / if no { found , do nothing <nl> + if ( posFound = = - 1 | | posFound = = - 2 ) <nl> + return ; <nl> + <nl> + / / if { is in the same line , do nothing <nl> + int matchedPairLine = _pEditView - > execute ( SCI_LINEFROMPOSITION , posFound ) ; <nl> + if ( matchedPairLine = = curLine ) <nl> + return ; <nl> + <nl> + / / { is in another line , get its indentation <nl> + indentAmountPrevLine = _pEditView - > getLineIndent ( matchedPairLine ) ; <nl> + <nl> + / / aligned } indent with { <nl> + _pEditView - > setLineIndent ( curLine , indentAmountPrevLine ) ; <nl> + <nl> + / / indent lines from { to } <nl> + for ( int i = matchedPairLine + 1 ; i < curLine ; + + i ) <nl> + _pEditView - > setLineIndent ( i , indentAmountPrevLine + tabWidth ) ; <nl> + } <nl> } <nl> <nl> void Notepad_plus : : specialCmd ( int id ) <nl>\n", "msg": "[ NEW_FEATURE ] Smart Indent ( in progress ) .\n"}
{"diff_id": 18438, "repo": "MarlinFirmware/Marlin\n", "sha": "46d3ef222368c032ca75dc11c13f6ae249ea53be\n", "time": "2016-06-18T22:38:23Z\n", "diff": "mmm a / Marlin / Marlin_main . cpp <nl> ppp b / Marlin / Marlin_main . cpp <nl> inline void gcode_M42 ( ) { <nl> / * * <nl> * We don ' t really have to do this move , but if we don ' t we can see a <nl> * funny shift in the Z Height because the user might not have the <nl> - * Z_RAISE_BEFORE_PROBING height identical to the Z_RAISE_BETWEEN_PROBING <nl> + * Z_RAISE_BEFORE_PROBING height identical to the Z_RAISE_BETWEEN_PROBINGS <nl> * height . This gets us back to the probe location at the same height that <nl> * we have been running around the circle at . <nl> * / <nl> + bool last_probe = ( n = = n_samples - 1 ) ; <nl> do_blocking_move_to_xy ( X_probe_location - ( X_PROBE_OFFSET_FROM_EXTRUDER ) , Y_probe_location - ( Y_PROBE_OFFSET_FROM_EXTRUDER ) ) ; <nl> - if ( deploy_probe_for_each_reading ) <nl> - sample_set [ n ] = probe_pt ( X_probe_location , Y_probe_location , Z_RAISE_BEFORE_PROBING , ProbeDeployAndStow , verbose_level ) ; <nl> - else { <nl> - if ( n = = n_samples - 1 ) <nl> - sample_set [ n ] = probe_pt ( X_probe_location , Y_probe_location , Z_RAISE_BEFORE_PROBING , ProbeStow , verbose_level ) ; else <nl> - sample_set [ n ] = probe_pt ( X_probe_location , Y_probe_location , Z_RAISE_BEFORE_PROBING , ProbeStay , verbose_level ) ; <nl> - } <nl> + sample_set [ n ] = probe_pt ( <nl> + X_probe_location , Y_probe_location , <nl> + Z_RAISE_BEFORE_PROBING , <nl> + deploy_probe_for_each_reading ? ProbeDeployAndStow : last_probe ? ProbeStow : ProbeStay , <nl> + verbose_level <nl> + ) ; <nl> <nl> / * * <nl> * Get the current mean for the data points we have so far <nl> inline void gcode_M42 ( ) { <nl> } <nl> if ( verbose_level > 0 ) SERIAL_EOL ; <nl> delay ( 50 ) ; <nl> - do_blocking_move_to_z ( current_position [ Z_AXIS ] + Z_RAISE_BETWEEN_PROBINGS ) ; <nl> + do_blocking_move_to_z ( current_position [ Z_AXIS ] + ( last_probe ? Z_RAISE_AFTER_PROBING : Z_RAISE_BETWEEN_PROBINGS ) ) ; <nl> } / / End of probe loop code <nl> <nl> if ( verbose_level > 0 ) { <nl>\n", "msg": "Simplify sample_set probe_pt call in M48\n"}
{"diff_id": 18742, "repo": "godotengine/godot\n", "sha": "701335e845166acb2a386778a70476ee57f33919\n", "time": "2015-04-18T20:55:04Z\n", "diff": "mmm a / modules / gdscript / gd_compiler . cpp <nl> ppp b / modules / gdscript / gd_compiler . cpp <nl> int GDCompiler : : _parse_expression ( CodeGen & codegen , const GDParser : : Node * p_expre <nl> <nl> int index ; <nl> if ( named ) { <nl> + # ifdef DEBUG_ENABLED <nl> + if ( on - > arguments [ 0 ] - > type = = GDParser : : Node : : TYPE_SELF & & codegen . script & & codegen . function_node & & ! codegen . function_node - > _static ) { <nl> <nl> + const Map < StringName , GDScript : : MemberInfo > : : Element * MI = codegen . script - > member_indices . find ( static_cast < GDParser : : IdentifierNode * > ( on - > arguments [ 1 ] ) - > name ) ; <nl> + if ( MI & & MI - > get ( ) . getter = = codegen . function_node - > name ) { <nl> + String n = static_cast < GDParser : : IdentifierNode * > ( on - > arguments [ 1 ] ) - > name ; <nl> + _set_error ( \" Must use ' \" + n + \" ' instead of ' self . \" + n + \" ' in getter . \" , on ) ; <nl> + return - 1 ; <nl> + } <nl> + } <nl> + # endif <nl> index = codegen . get_name_map_pos ( static_cast < GDParser : : IdentifierNode * > ( on - > arguments [ 1 ] ) - > name ) ; <nl> <nl> } else { <nl> int GDCompiler : : _parse_expression ( CodeGen & codegen , const GDParser : : Node * p_expre <nl> if ( on - > arguments [ 0 ] - > type = = GDParser : : Node : : TYPE_OPERATOR & & ( static_cast < GDParser : : OperatorNode * > ( on - > arguments [ 0 ] ) - > op = = GDParser : : OperatorNode : : OP_INDEX | | static_cast < GDParser : : OperatorNode * > ( on - > arguments [ 0 ] ) - > op = = GDParser : : OperatorNode : : OP_INDEX_NAMED ) ) { <nl> / / SET ( chained ) MODE ! ! <nl> <nl> + <nl> + # ifdef DEBUG_ENABLED <nl> + if ( static_cast < GDParser : : OperatorNode * > ( on - > arguments [ 0 ] ) - > op = = GDParser : : OperatorNode : : OP_INDEX_NAMED ) { <nl> + const GDParser : : OperatorNode * inon = static_cast < GDParser : : OperatorNode * > ( on - > arguments [ 0 ] ) ; <nl> + <nl> + <nl> + if ( inon - > arguments [ 0 ] - > type = = GDParser : : Node : : TYPE_SELF & & codegen . script & & codegen . function_node & & ! codegen . function_node - > _static ) { <nl> + <nl> + const Map < StringName , GDScript : : MemberInfo > : : Element * MI = codegen . script - > member_indices . find ( static_cast < GDParser : : IdentifierNode * > ( inon - > arguments [ 1 ] ) - > name ) ; <nl> + if ( MI & & MI - > get ( ) . setter = = codegen . function_node - > name ) { <nl> + String n = static_cast < GDParser : : IdentifierNode * > ( inon - > arguments [ 1 ] ) - > name ; <nl> + _set_error ( \" Must use ' \" + n + \" ' instead of ' self . \" + n + \" ' in setter . \" , inon ) ; <nl> + return - 1 ; <nl> + } <nl> + } <nl> + } <nl> + # endif <nl> + <nl> + <nl> int slevel = p_stack_level ; <nl> <nl> GDParser : : OperatorNode * op = static_cast < GDParser : : OperatorNode * > ( on - > arguments [ 0 ] ) ; <nl>\n", "msg": "- Throw error if setter and getter reference their member variable with self . , fixes\n", "score": 1}
{"diff_id": 18767, "repo": "yuzu-emu/yuzu\n", "sha": "331ce2942c4906945b4d42f1ebe8b9b6e453c6ee\n", "time": "2018-10-14T00:58:00Z\n", "diff": "mmm a / src / video_core / textures / decoders . cpp <nl> ppp b / src / video_core / textures / decoders . cpp <nl> constexpr auto fast_swizzle_table = SwizzleTable < 8 , 4 , 16 > ( ) ; <nl> * Instead of going gob by gob , we map the coordinates inside a block and manage from <nl> * those . Block_Width is assumed to be 1 . <nl> * / <nl> - void Precise3DProcessBlock ( u8 * swizzled_data , u8 * unswizzled_data , const bool unswizzle , <nl> - const u32 x_start , const u32 y_start , const u32 z_start , const u32 x_end , <nl> - const u32 y_end , const u32 z_end , const u32 tile_offset , <nl> - const u32 xy_block_size , const u32 layer_z , const u32 stride_x , <nl> - const u32 bytes_per_pixel , const u32 out_bytes_per_pixel ) { <nl> + void PreciseProcessBlock ( u8 * swizzled_data , u8 * unswizzled_data , const bool unswizzle , <nl> + const u32 x_start , const u32 y_start , const u32 z_start , const u32 x_end , <nl> + const u32 y_end , const u32 z_end , const u32 tile_offset , <nl> + const u32 xy_block_size , const u32 layer_z , const u32 stride_x , <nl> + const u32 bytes_per_pixel , const u32 out_bytes_per_pixel ) { <nl> std : : array < u8 * , 2 > data_ptrs ; <nl> u32 z_address = tile_offset ; <nl> const u32 gob_size_x = 64 ; <nl> void Precise3DProcessBlock ( u8 * swizzled_data , u8 * unswizzled_data , const bool un <nl> } <nl> } <nl> <nl> - / * * <nl> - * This function unswizzles or swizzles a texture by mapping Linear to BlockLinear Textue . <nl> - * The body of this function takes care of splitting the swizzled texture into blocks , <nl> - * and managing the extents of it . Once all the parameters of a single block are obtained , <nl> - * the function calls ' 3DProcessBlock ' to process that particular Block . <nl> - * <nl> - * Documentation for the memory layout and decoding can be found at : <nl> - * https : / / envytools . readthedocs . io / en / latest / hw / memory / g80 - surface . html # blocklinear - surfaces <nl> - * / <nl> - void Precise3DSwizzledData ( u8 * swizzled_data , u8 * unswizzled_data , const bool unswizzle , <nl> - const u32 width , const u32 height , const u32 depth , <nl> - const u32 bytes_per_pixel , const u32 out_bytes_per_pixel , <nl> - const u32 block_height , const u32 block_depth ) { <nl> - auto div_ceil = [ ] ( const u32 x , const u32 y ) { return ( ( x + y - 1 ) / y ) ; } ; <nl> - const u32 stride_x = width * out_bytes_per_pixel ; <nl> - const u32 layer_z = height * stride_x ; <nl> - const u32 gob_x_bytes = 64 ; <nl> - const u32 gob_elements_x = gob_x_bytes / bytes_per_pixel ; <nl> - const u32 gob_elements_y = 8 ; <nl> - const u32 gob_elements_z = 1 ; <nl> - const u32 block_x_elements = gob_elements_x ; <nl> - const u32 block_y_elements = gob_elements_y * block_height ; <nl> - const u32 block_z_elements = gob_elements_z * block_depth ; <nl> - const u32 blocks_on_x = div_ceil ( width , block_x_elements ) ; <nl> - const u32 blocks_on_y = div_ceil ( height , block_y_elements ) ; <nl> - const u32 blocks_on_z = div_ceil ( depth , block_z_elements ) ; <nl> - const u32 blocks = blocks_on_x * blocks_on_y * blocks_on_z ; <nl> - const u32 gob_size = gob_x_bytes * gob_elements_y * gob_elements_z ; <nl> - const u32 xy_block_size = gob_size * block_height ; <nl> - const u32 block_size = xy_block_size * block_depth ; <nl> - u32 tile_offset = 0 ; <nl> - for ( u32 zb = 0 ; zb < blocks_on_z ; zb + + ) { <nl> - const u32 z_start = zb * block_z_elements ; <nl> - const u32 z_end = std : : min ( depth , z_start + block_z_elements ) ; <nl> - for ( u32 yb = 0 ; yb < blocks_on_y ; yb + + ) { <nl> - const u32 y_start = yb * block_y_elements ; <nl> - const u32 y_end = std : : min ( height , y_start + block_y_elements ) ; <nl> - for ( u32 xb = 0 ; xb < blocks_on_x ; xb + + ) { <nl> - const u32 x_start = xb * block_x_elements ; <nl> - const u32 x_end = std : : min ( width , x_start + block_x_elements ) ; <nl> - Precise3DProcessBlock ( swizzled_data , unswizzled_data , unswizzle , x_start , y_start , <nl> - z_start , x_end , y_end , z_end , tile_offset , xy_block_size , <nl> - layer_z , stride_x , bytes_per_pixel , out_bytes_per_pixel ) ; <nl> - tile_offset + = block_size ; <nl> - } <nl> - } <nl> - } <nl> - } <nl> - <nl> / * * <nl> * This function manages ALL the GOBs ( Group of Bytes ) Inside a single block . <nl> * Instead of going gob by gob , we map the coordinates inside a block and manage from <nl> * those . Block_Width is assumed to be 1 . <nl> * / <nl> - void Fast3DProcessBlock ( u8 * swizzled_data , u8 * unswizzled_data , const bool unswizzle , <nl> - const u32 x_start , const u32 y_start , const u32 z_start , const u32 x_end , <nl> - const u32 y_end , const u32 z_end , const u32 tile_offset , <nl> - const u32 xy_block_size , const u32 layer_z , const u32 stride_x , <nl> - const u32 bytes_per_pixel , const u32 out_bytes_per_pixel ) { <nl> + void FastProcessBlock ( u8 * swizzled_data , u8 * unswizzled_data , const bool unswizzle , <nl> + const u32 x_start , const u32 y_start , const u32 z_start , const u32 x_end , <nl> + const u32 y_end , const u32 z_end , const u32 tile_offset , <nl> + const u32 xy_block_size , const u32 layer_z , const u32 stride_x , <nl> + const u32 bytes_per_pixel , const u32 out_bytes_per_pixel ) { <nl> std : : array < u8 * , 2 > data_ptrs ; <nl> u32 z_address = tile_offset ; <nl> const u32 x_startb = x_start * bytes_per_pixel ; <nl> void Fast3DProcessBlock ( u8 * swizzled_data , u8 * unswizzled_data , const bool unswi <nl> * This function unswizzles or swizzles a texture by mapping Linear to BlockLinear Textue . <nl> * The body of this function takes care of splitting the swizzled texture into blocks , <nl> * and managing the extents of it . Once all the parameters of a single block are obtained , <nl> - * the function calls ' 3DProcessBlock ' to process that particular Block . <nl> + * the function calls ' ProcessBlock ' to process that particular Block . <nl> * <nl> * Documentation for the memory layout and decoding can be found at : <nl> * https : / / envytools . readthedocs . io / en / latest / hw / memory / g80 - surface . html # blocklinear - surfaces <nl> * / <nl> - void Fast3DSwizzledData ( u8 * swizzled_data , u8 * unswizzled_data , const bool unswizzle , <nl> - const u32 width , const u32 height , const u32 depth , <nl> - const u32 bytes_per_pixel , const u32 out_bytes_per_pixel , <nl> - const u32 block_height , const u32 block_depth ) { <nl> + template < bool fast > <nl> + void SwizzledData ( u8 * swizzled_data , u8 * unswizzled_data , const bool unswizzle , const u32 width , <nl> + const u32 height , const u32 depth , const u32 bytes_per_pixel , <nl> + const u32 out_bytes_per_pixel , const u32 block_height , const u32 block_depth ) { <nl> auto div_ceil = [ ] ( const u32 x , const u32 y ) { return ( ( x + y - 1 ) / y ) ; } ; <nl> const u32 stride_x = width * out_bytes_per_pixel ; <nl> const u32 layer_z = height * stride_x ; <nl> void Fast3DSwizzledData ( u8 * swizzled_data , u8 * unswizzled_data , const bool unswi <nl> for ( u32 xb = 0 ; xb < blocks_on_x ; xb + + ) { <nl> const u32 x_start = xb * block_x_elements ; <nl> const u32 x_end = std : : min ( width , x_start + block_x_elements ) ; <nl> - Fast3DProcessBlock ( swizzled_data , unswizzled_data , unswizzle , x_start , y_start , <nl> - z_start , x_end , y_end , z_end , tile_offset , xy_block_size , <nl> - layer_z , stride_x , bytes_per_pixel , out_bytes_per_pixel ) ; <nl> + if ( fast ) { <nl> + FastProcessBlock ( swizzled_data , unswizzled_data , unswizzle , x_start , y_start , <nl> + z_start , x_end , y_end , z_end , tile_offset , xy_block_size , <nl> + layer_z , stride_x , bytes_per_pixel , out_bytes_per_pixel ) ; <nl> + } else { <nl> + PreciseProcessBlock ( swizzled_data , unswizzled_data , unswizzle , x_start , y_start , <nl> + z_start , x_end , y_end , z_end , tile_offset , xy_block_size , <nl> + layer_z , stride_x , bytes_per_pixel , out_bytes_per_pixel ) ; <nl> + } <nl> tile_offset + = block_size ; <nl> } <nl> } <nl> void CopySwizzledData ( u32 width , u32 height , u32 depth , u32 bytes_per_pixel , <nl> u32 out_bytes_per_pixel , u8 * swizzled_data , u8 * unswizzled_data , <nl> bool unswizzle , u32 block_height , u32 block_depth ) { <nl> if ( bytes_per_pixel % 3 ! = 0 & & ( width * bytes_per_pixel ) % 16 = = 0 ) { <nl> - Fast3DSwizzledData ( swizzled_data , unswizzled_data , unswizzle , width , height , depth , <nl> + SwizzledData < true > ( swizzled_data , unswizzled_data , unswizzle , width , height , depth , <nl> bytes_per_pixel , out_bytes_per_pixel , block_height , block_depth ) ; <nl> } else { <nl> - Precise3DSwizzledData ( swizzled_data , unswizzled_data , unswizzle , width , height , depth , <nl> - bytes_per_pixel , out_bytes_per_pixel , block_height , block_depth ) ; <nl> + SwizzledData < false > ( swizzled_data , unswizzled_data , unswizzle , width , height , depth , <nl> + bytes_per_pixel , out_bytes_per_pixel , block_height , block_depth ) ; <nl> } <nl> } <nl> <nl>\n", "msg": "Shorten the implementation of 3D swizzle to only 3 functions\n"}
{"diff_id": 18873, "repo": "apple/swift\n", "sha": "621f89d26797c728bee92aa1bd3c83c0764c771e\n", "time": "2014-04-29T05:01:59Z\n", "diff": "mmm a / lib / SILPasses / GenericSpecializer . cpp <nl> ppp b / lib / SILPasses / GenericSpecializer . cpp <nl> class TypeSubCloner : public SILCloner < TypeSubCloner > { <nl> case CheckedCastKind : : ConcreteToUnrelatedExistential : <nl> SILCloner < TypeSubCloner > : : visitCheckedCastBranchInst ( Inst ) ; <nl> return ; <nl> - case CheckedCastKind : : SuperToArchetype : <nl> - / / Stub implementation . <nl> - SILCloner < TypeSubCloner > : : visitCheckedCastBranchInst ( Inst ) ; <nl> + case CheckedCastKind : : SuperToArchetype : { <nl> + / / Just change the type of cast to a checked_cast_br downcast <nl> + SILLocation OpLoc = getOpLocation ( Inst - > getLoc ( ) ) ; <nl> + SILValue OpValue = getOpValue ( Inst - > getOperand ( ) ) ; <nl> + SILType OpType = getOpType ( Inst - > getCastType ( ) ) ; <nl> + SILBasicBlock * OpSuccBB = getOpBasicBlock ( Inst - > getSuccessBB ( ) ) ; <nl> + SILBasicBlock * OpFailBB = getOpBasicBlock ( Inst - > getFailureBB ( ) ) ; <nl> + CheckedCastKind OpCastKind = CheckedCastKind : : Downcast ; <nl> + doPostProcess ( Inst , <nl> + getBuilder ( ) . createCheckedCastBranch ( OpLoc , <nl> + OpCastKind , <nl> + OpValue , <nl> + OpType , <nl> + OpSuccBB , <nl> + OpFailBB ) ) ; <nl> return ; <nl> + } <nl> case CheckedCastKind : : ArchetypeToArchetype : <nl> - visitCheckedCastBrArchToArchCast ( Inst ) ; <nl> - return ; <nl> case CheckedCastKind : : ArchetypeToConcrete : <nl> - / / Stub implementation . <nl> - SILCloner < TypeSubCloner > : : visitCheckedCastBranchInst ( Inst ) ; <nl> - return ; <nl> - case CheckedCastKind : : ExistentialToArchetype : <nl> - / / Stub implementation . <nl> - SILCloner < TypeSubCloner > : : visitCheckedCastBranchInst ( Inst ) ; <nl> - return ; <nl> case CheckedCastKind : : ConcreteToArchetype : <nl> - / / Stub implementation . <nl> - SILCloner < TypeSubCloner > : : visitCheckedCastBranchInst ( Inst ) ; <nl> + visitCheckedCastBrArchToArchCast ( Inst ) ; <nl> return ; <nl> + case CheckedCastKind : : ExistentialToArchetype : { <nl> + / / Just convert to ExistentialToConcrete . <nl> + / / Just change the type of cast to a checked_cast_br downcast <nl> + SILLocation OpLoc = getOpLocation ( Inst - > getLoc ( ) ) ; <nl> + SILValue OpValue = getOpValue ( Inst - > getOperand ( ) ) ; <nl> + SILType OpType = getOpType ( Inst - > getCastType ( ) ) ; <nl> + SILBasicBlock * OpSuccBB = getOpBasicBlock ( Inst - > getSuccessBB ( ) ) ; <nl> + SILBasicBlock * OpFailBB = getOpBasicBlock ( Inst - > getFailureBB ( ) ) ; <nl> + CheckedCastKind OpCastKind = CheckedCastKind : : ExistentialToConcrete ; <nl> + doPostProcess ( Inst , <nl> + getBuilder ( ) . createCheckedCastBranch ( OpLoc , <nl> + OpCastKind , <nl> + OpValue , <nl> + OpType , <nl> + OpSuccBB , <nl> + OpFailBB ) ) ; <nl> + return ; <nl> + } <nl> } <nl> } <nl> <nl>\n", "msg": "[ specialization ] Teach the specializer how to handle checked_cast_br correctly .\n"}
{"diff_id": 18904, "msg": "CGUIWindowMusicBase : clear the cached source listing when removing a music source\n", "msgGPT": "remove disc cache when removing a source from the music window.", "METEOR Score": "44.40105421921805", "BLEU Score": "0.48938779598674237", "ROUGE-L Score": "0.3333333283680556", "score": 1, "repo": "xbmc/xbmc\n", "sha": "9b72c7db78fde7720f88983f5e521f6f4c1b2865\n", "time": "2015-10-11T14:09:31Z\n", "diff": "mmm a / xbmc / music / windows / GUIWindowMusicBase . cpp <nl> ppp b / xbmc / music / windows / GUIWindowMusicBase . cpp <nl> void CGUIWindowMusicBase : : OnRemoveSource ( int iItem ) <nl> database . RemoveSongsFromPath ( m_vecItems - > Get ( iItem ) - > GetPath ( ) , songs , false ) ; <nl> database . CleanupOrphanedItems ( ) ; <nl> g_infoManager . ResetLibraryBools ( ) ; <nl> + m_vecItems - > RemoveDiscCache ( GetID ( ) ) ; <nl> } <nl> } <nl> <nl>\n"}
{"diff_id": 18966, "repo": "tesseract-ocr/tesseract\n", "sha": "62b857554a9c9300a9c3ee11eb75be8b324883e4\n", "time": "2019-01-08T20:52:29Z\n", "diff": "mmm a / sw . cpp <nl> ppp b / sw . cpp <nl> void build ( Solution & s ) <nl> libtesseract . Interface + = sw : : Shared , \" TESS_IMPORTS \" _d ; <nl> libtesseract . Private + = sw : : Shared , \" TESS_EXPORTS \" _d ; <nl> <nl> - libtesseract . Public + = \" org . sw . demo . danbloomberg . leptonica - 1 \" _dep ; <nl> + libtesseract . Public + = \" org . sw . demo . danbloomberg . leptonica - master \" _dep ; <nl> <nl> if ( s . Settings . TargetOS . Type = = OSType : : Windows ) <nl> libtesseract . Public + = \" ws2_32 . lib \" _l ; <nl>\n", "msg": "[ sw ] Depend on leptonica - master .\n"}
{"diff_id": 19017, "repo": "apple/swift\n", "sha": "0d610cf95264c97e3e77f42ca3adf865a31e7520\n", "time": "2013-10-14T04:24:08Z\n", "diff": "mmm a / lib / SILPasses / AllocBoxToStack . cpp <nl> ppp b / lib / SILPasses / AllocBoxToStack . cpp <nl> <nl> using namespace swift ; <nl> <nl> STATISTIC ( NumStackPromoted , \" Number of alloc_box ' s promoted to the stack \" ) ; <nl> + STATISTIC ( NumStackRemoved , \" Number of variables removed completely \" ) ; <nl> <nl> / / = = = mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm - = = = / / <nl> / / alloc_box Promotion <nl> static bool optimizeAllocBox ( AllocBoxInst * ABI , <nl> User - > eraseFromParent ( ) ; <nl> } <nl> <nl> + return true ; <nl> + } <nl> + <nl> + / / = = = mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm - = = = / / <nl> + / / AllocStack Removal <nl> + / / = = = mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm - = = = / / <nl> + <nl> + <nl> + / / / areAllocStackUsesSafeToRemove - Return true if there are no uses of the <nl> + / / / specified address ( or any pointers derived from it ) that prevent us from <nl> + / / / removing the allocation . For example , stores to the value can just be <nl> + / / / discarded , but loads from the value require the memory to exist . <nl> + static bool areAllocStackUsesSafeToRemove ( SILValue V ) { <nl> + for ( auto UI : V . getUses ( ) ) { <nl> + auto * User = cast < SILInstruction > ( UI - > getUser ( ) ) ; <nl> + <nl> + / / Stores to the pointer ( either in store or copy_addr form ) can be <nl> + / / discarded . <nl> + if ( ( isa < CopyAddrInst > ( User ) | | isa < StoreInst > ( User ) ) & & <nl> + UI - > getOperandNumber ( ) = = 1 ) <nl> + continue ; <nl> + <nl> + / / Zero initializations can be dropped . <nl> + if ( isa < InitializeVarInst > ( User ) ) <nl> + continue ; <nl> + <nl> + / / Recursively check uses of instructions that derive a pointer from the <nl> + / / original pointer . <nl> + if ( isa < StructElementAddrInst > ( User ) | | isa < TupleElementAddrInst > ( User ) | | <nl> + isa < ProjectExistentialInst > ( User ) ) { <nl> + if ( ! areAllocStackUsesSafeToRemove ( SILValue ( User , 0 ) ) ) <nl> + return false ; <nl> + continue ; <nl> + } <nl> + <nl> + / / Otherwise , this is something we don ' t know about , conservatively keep the <nl> + / / instruction <nl> + DEBUG ( llvm : : errs ( ) < < \" * * * Failed to remove autogenerated alloc_stack : \" <nl> + \" kept alive by : \" < < * User ) ; <nl> + return false ; <nl> + } <nl> <nl> return true ; <nl> } <nl> <nl> + static void eraseUsesOfInstruction ( SILInstruction * Inst ) { <nl> + for ( auto UI : Inst - > getUses ( ) ) { <nl> + auto * User = cast < SILInstruction > ( UI - > getUser ( ) ) ; <nl> + eraseUsesOfInstruction ( User ) ; <nl> + User - > eraseFromParent ( ) ; <nl> + } <nl> + } <nl> + <nl> + / / / optimizeAllocStack - Remove alloc_stack ' s the are only stored to , if they <nl> + / / / are artificial allocations . We keep around normal allocations for debug <nl> + / / / info generation to use . <nl> + static bool optimizeAllocStack ( AllocStackInst * ASI ) { <nl> + / / We only look at ( and try to remove ) autogenerated allocations . <nl> + if ( ! ASI - > getLoc ( ) . isAutoGenerated ( ) & & <nl> + / / FIXME : This is a temporary hack . The transparent inliner should set <nl> + / / the autogenerated bit on inlined allocations . <nl> + ! ASI - > getLoc ( ) . is < InlinedLocation > ( ) ) <nl> + return false ; <nl> + <nl> + / / Walk the use list to see if we have only safe - to - remove uses hanging off <nl> + / / of the allocation . Check the local_storage piece first . <nl> + for ( auto UI : SILValue ( ASI , 0 ) . getUses ( ) ) { <nl> + auto * User = cast < SILInstruction > ( UI - > getUser ( ) ) ; <nl> + <nl> + if ( isa < DeallocStackInst > ( User ) ) <nl> + continue ; <nl> + <nl> + / / Otherwise , it was an instruction we can ' t handle . <nl> + DEBUG ( llvm : : errs ( ) < < \" * * * Failed to remove autogenerated alloc_stack : \" <nl> + \" kept alive by : \" < < * User ) ; <nl> + return false ; <nl> + } <nl> + <nl> + / / Next , check uses of the address . <nl> + if ( ! areAllocStackUsesSafeToRemove ( SILValue ( ASI , 1 ) ) ) <nl> + return false ; <nl> + <nl> + DEBUG ( llvm : : errs ( ) < < \" * * * Removing autogenerated alloc_stack : \" < < * ASI ) ; <nl> + <nl> + / / If it is safe to remove , do it . Recursively remove all instructions <nl> + / / hanging off the alloc_stack , then return success . <nl> + eraseUsesOfInstruction ( ASI ) ; <nl> + return true ; <nl> + } <nl> + <nl> + <nl> + <nl> / / = = = mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm - = = = / / <nl> - / / Top Level Driver <nl> + / / Top Level Driver <nl> / / = = = mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm - = = = / / <nl> <nl> void swift : : performSILAllocBoxToStackPromotion ( SILModule * M ) { <nl> void swift : : performSILAllocBoxToStackPromotion ( SILModule * M ) { <nl> for ( auto & BB : Fn ) { <nl> auto I = BB . begin ( ) , E = BB . end ( ) ; <nl> while ( I ! = E ) { <nl> - auto * ABI = dyn_cast < AllocBoxInst > ( I ) ; <nl> - <nl> - if ( ! ABI ) { <nl> - + + I ; <nl> - continue ; <nl> - } <nl> - <nl> - if ( optimizeAllocBox ( ABI , PostDomInfo ) ) { <nl> - + + NumStackPromoted ; <nl> - / / Carefully move iterator to avoid invalidation problems . <nl> - + + I ; <nl> - ABI - > eraseFromParent ( ) ; <nl> - } else { <nl> - + + I ; <nl> - } <nl> + if ( auto * ABI = dyn_cast < AllocBoxInst > ( I ) ) <nl> + if ( optimizeAllocBox ( ABI , PostDomInfo ) ) { <nl> + + + NumStackPromoted ; <nl> + / / Carefully move iterator to avoid invalidation problems . <nl> + + + I ; <nl> + ABI - > eraseFromParent ( ) ; <nl> + continue ; <nl> + } <nl> + <nl> + if ( auto * ASI = dyn_cast < AllocStackInst > ( I ) ) <nl> + if ( optimizeAllocStack ( ASI ) ) { <nl> + + + NumStackRemoved ; <nl> + / / Carefully move iterator to avoid invalidation problems . <nl> + + + I ; <nl> + ASI - > eraseFromParent ( ) ; <nl> + continue ; <nl> + } <nl> + <nl> + + + I ; <nl> } <nl> } <nl> } <nl>\n", "msg": "teach AllocBoxToStack to remove alloc_stack ' s that are artificial ( or inlined )\n"}
{"diff_id": 19063, "repo": "bitcoin/bitcoin\n", "sha": "ae1d2b0308d7fe9df7fc18699c69e9587e6154bd\n", "time": "2018-04-12T21:00:34Z\n", "diff": "mmm a / src / wallet / rpcdump . cpp <nl> ppp b / src / wallet / rpcdump . cpp <nl> UniValue importprivkey ( const JSONRPCRequest & request ) <nl> } <nl> } <nl> if ( fRescan ) { <nl> - pwallet - > RescanFromTime ( TIMESTAMP_MIN , reserver , true / * update * / ) ; <nl> + int64_t scanned_time = pwallet - > RescanFromTime ( TIMESTAMP_MIN , reserver , true / * update * / ) ; <nl> + if ( pwallet - > IsAbortingRescan ( ) ) { <nl> + throw JSONRPCError ( RPC_MISC_ERROR , \" Rescan aborted by user . \" ) ; <nl> + } <nl> + if ( scanned_time > TIMESTAMP_MIN ) { <nl> + throw JSONRPCError ( RPC_WALLET_ERROR , \" Rescan was unable to fully rescan the blockchain . Some transactions may be missing . \" ) ; <nl> + } <nl> } <nl> <nl> return NullUniValue ; <nl> UniValue importaddress ( const JSONRPCRequest & request ) <nl> } <nl> if ( fRescan ) <nl> { <nl> - pwallet - > RescanFromTime ( TIMESTAMP_MIN , reserver , true / * update * / ) ; <nl> + int64_t scanned_time = pwallet - > RescanFromTime ( TIMESTAMP_MIN , reserver , true / * update * / ) ; <nl> + if ( pwallet - > IsAbortingRescan ( ) ) { <nl> + throw JSONRPCError ( RPC_MISC_ERROR , \" Rescan aborted by user . \" ) ; <nl> + } <nl> + if ( scanned_time > TIMESTAMP_MIN ) { <nl> + throw JSONRPCError ( RPC_WALLET_ERROR , \" Rescan was unable to fully rescan the blockchain . Some transactions may be missing . \" ) ; <nl> + } <nl> pwallet - > ReacceptWalletTransactions ( ) ; <nl> } <nl> <nl> UniValue importpubkey ( const JSONRPCRequest & request ) <nl> } <nl> if ( fRescan ) <nl> { <nl> - pwallet - > RescanFromTime ( TIMESTAMP_MIN , reserver , true / * update * / ) ; <nl> + int64_t scanned_time = pwallet - > RescanFromTime ( TIMESTAMP_MIN , reserver , true / * update * / ) ; <nl> + if ( pwallet - > IsAbortingRescan ( ) ) { <nl> + throw JSONRPCError ( RPC_MISC_ERROR , \" Rescan aborted by user . \" ) ; <nl> + } <nl> + if ( scanned_time > TIMESTAMP_MIN ) { <nl> + throw JSONRPCError ( RPC_WALLET_ERROR , \" Rescan was unable to fully rescan the blockchain . Some transactions may be missing . \" ) ; <nl> + } <nl> pwallet - > ReacceptWalletTransactions ( ) ; <nl> } <nl> <nl> UniValue importwallet ( const JSONRPCRequest & request ) <nl> uiInterface . ShowProgress ( \" \" , 100 , false ) ; / / hide progress dialog in GUI <nl> pwallet - > UpdateTimeFirstKey ( nTimeBegin ) ; <nl> } <nl> - pwallet - > RescanFromTime ( nTimeBegin , reserver , false / * update * / ) ; <nl> + uiInterface . ShowProgress ( \" \" , 100 , false ) ; / / hide progress dialog in GUI <nl> + int64_t scanned_time = pwallet - > RescanFromTime ( nTimeBegin , reserver , false / * update * / ) ; <nl> + if ( pwallet - > IsAbortingRescan ( ) ) { <nl> + throw JSONRPCError ( RPC_MISC_ERROR , \" Rescan aborted by user . \" ) ; <nl> + } <nl> + if ( scanned_time > nTimeBegin ) { <nl> + throw JSONRPCError ( RPC_WALLET_ERROR , \" Rescan was unable to fully rescan the blockchain . Some transactions may be missing . \" ) ; <nl> + } <nl> pwallet - > MarkDirty ( ) ; <nl> <nl> if ( ! fGood ) <nl> UniValue importmulti ( const JSONRPCRequest & mainRequest ) <nl> int64_t scannedTime = pwallet - > RescanFromTime ( nLowestTimestamp , reserver , true / * update * / ) ; <nl> pwallet - > ReacceptWalletTransactions ( ) ; <nl> <nl> + if ( pwallet - > IsAbortingRescan ( ) ) { <nl> + throw JSONRPCError ( RPC_MISC_ERROR , \" Rescan aborted by user . \" ) ; <nl> + } <nl> if ( scannedTime > nLowestTimestamp ) { <nl> std : : vector < UniValue > results = response . getValues ( ) ; <nl> response . clear ( ) ; <nl>\n", "msg": "Give an error when rescan is aborted by the user\n"}
{"diff_id": 19211, "repo": "sqlitebrowser/sqlitebrowser\n", "sha": "60f3f4404a0dc85b7874cce97f83d85c9c6de037\n", "time": "2020-02-16T14:04:13Z\n", "diff": "mmm a / src / ExtendedTableWidget . cpp <nl> ppp b / src / ExtendedTableWidget . cpp <nl> void ExtendedTableWidget : : vscrollbarChanged ( int value ) <nl> <nl> int ExtendedTableWidget : : numVisibleRows ( ) const <nl> { <nl> - if ( ! isVisible ( ) ) <nl> + if ( ! isVisible ( ) | | ! model ( ) | | ! verticalHeader ( ) ) <nl> return 0 ; <nl> <nl> / / Get the row numbers of the rows currently visible at the top and the bottom of the widget <nl>\n", "msg": "Try to fix possible crash in cee3523f37bf89780e42fc65fd327c2e1ea3a752\n"}
{"diff_id": 19353, "repo": "godotengine/godot\n", "sha": "94a50839feb8d3702eddfae6226b1b82baa34650\n", "time": "2019-10-23T15:53:29Z\n", "diff": "mmm a / editor / script_editor_debugger . cpp <nl> ppp b / editor / script_editor_debugger . cpp <nl> void ScriptEditorDebugger : : _parse_message ( const String & p_msg , const Array & p_da <nl> if ( var . is_zero ( ) ) { <nl> var = RES ( ) ; <nl> } else if ( var . get_type ( ) = = Variant : : STRING ) { <nl> - var = ResourceLoader : : load ( var ) ; <nl> + String path = var ; <nl> + if ( path . find ( \" : : \" ) ! = - 1 ) { <nl> + / / built - in resource <nl> + String base_path = path . get_slice ( \" : : \" , 0 ) ; <nl> + if ( ResourceLoader : : get_resource_type ( base_path ) = = \" PackedScene \" ) { <nl> + if ( ! EditorNode : : get_singleton ( ) - > is_scene_open ( base_path ) ) { <nl> + EditorNode : : get_singleton ( ) - > load_scene ( base_path ) ; <nl> + } <nl> + } else { <nl> + EditorNode : : get_singleton ( ) - > load_resource ( base_path ) ; <nl> + } <nl> + } <nl> + var = ResourceLoader : : load ( path ) ; <nl> <nl> if ( pinfo . hint_string = = \" Script \" ) <nl> debugObj - > set_script ( var ) ; <nl>\n", "msg": "Fixed variables with built - in resource in remote inspector\n"}
{"diff_id": 19411, "repo": "godotengine/godot\n", "sha": "4293f76cf104027c7ded89fc6d3d0ce11a758fb0\n", "time": "2020-01-08T13:01:08Z\n", "diff": "mmm a / scene / gui / rich_text_label . cpp <nl> ppp b / scene / gui / rich_text_label . cpp <nl> void RichTextLabel : : _notification ( int p_what ) { <nl> <nl> switch ( p_what ) { <nl> <nl> + case NOTIFICATION_MOUSE_EXIT : { <nl> + if ( meta_hovering ) { <nl> + meta_hovering = NULL ; <nl> + emit_signal ( \" meta_hover_ended \" , current_meta ) ; <nl> + current_meta = false ; <nl> + update ( ) ; <nl> + } <nl> + } break ; <nl> case NOTIFICATION_RESIZED : { <nl> <nl> main - > first_invalid_line = 0 ; / / invalidate ALL <nl>\n", "msg": "Emits meta_hover_ended when mouse exit RichTextLabel\n", "score": 1}
{"diff_id": 19806, "repo": "mongodb/mongo\n", "sha": "9b83485bb1cf8813d22690f6a2518e6d80f8ef1f\n", "time": "2012-05-22T18:52:17Z\n", "diff": "mmm a / src / mongo / db / dbcommands . cpp <nl> ppp b / src / mongo / db / dbcommands . cpp <nl> namespace mongo { <nl> uassert ( 10040 , \" chunks out of order \" , n = = myn ) ; <nl> } <nl> <nl> + / / make a copy of obj since we access data in it while yielding <nl> + BSONObj owned = obj . getOwned ( ) ; <nl> int len ; <nl> - const char * data = obj [ \" data \" ] . binDataClean ( len ) ; <nl> + const char * data = owned [ \" data \" ] . binDataClean ( len ) ; <nl> <nl> ClientCursor : : YieldLock yield ( cc . get ( ) ) ; <nl> try { <nl>\n", "msg": "Make copy of chunk object before yielding in filemd5 command\n"}
{"diff_id": 19882, "repo": "bitcoin/bitcoin\n", "sha": "4aaa01783d4e3592db456fb2db05207c3c278244\n", "time": "2014-06-11T10:16:26Z\n", "diff": "mmm a / src / init . cpp <nl> ppp b / src / init . cpp <nl> std : : string HelpMessage ( HelpMessageMode hmm ) <nl> # ifdef ENABLE_WALLET <nl> strUsage + = \" \\ n \" + _ ( \" Wallet options : \" ) + \" \\ n \" ; <nl> strUsage + = \" - disablewallet \" + _ ( \" Do not load the wallet and disable wallet RPC calls \" ) + \" \\ n \" ; <nl> - strUsage + = \" - paytxfee = < amt > \" + _ ( \" Fee per kB to add to transactions you send \" ) + \" \\ n \" ; <nl> + strUsage + = \" - paytxfee = < amt > \" + strprintf ( _ ( \" Fee ( in BTC / kB ) to add to transactions you send ( default : % s ) \" ) , FormatMoney ( payTxFee . GetFeePerK ( ) ) ) + \" \\ n \" ; <nl> strUsage + = \" - rescan \" + _ ( \" Rescan the block chain for missing wallet transactions \" ) + \" \" + _ ( \" on startup \" ) + \" \\ n \" ; <nl> strUsage + = \" - salvagewallet \" + _ ( \" Attempt to recover private keys from a corrupt wallet . dat \" ) + \" \" + _ ( \" on startup \" ) + \" \\ n \" ; <nl> strUsage + = \" - spendzeroconfchange \" + _ ( \" Spend unconfirmed change when sending transactions ( default : 1 ) \" ) + \" \\ n \" ; <nl> std : : string HelpMessage ( HelpMessageMode hmm ) <nl> strUsage + = \" - limitfreerelay = < n > \" + _ ( \" Continuously rate - limit free transactions to < n > * 1000 bytes per minute ( default : 15 ) \" ) + \" \\ n \" ; <nl> strUsage + = \" - maxsigcachesize = < n > \" + _ ( \" Limit size of signature cache to < n > entries ( default : 50000 ) \" ) + \" \\ n \" ; <nl> } <nl> - strUsage + = \" - mintxfee = < amt > \" + _ ( \" Fees smaller than this are considered zero fee ( for transaction creation ) ( default : \" ) + \" \" + FormatMoney ( CTransaction : : minTxFee . GetFeePerK ( ) ) + \" ) \" + \" \\ n \" ; <nl> - strUsage + = \" - minrelaytxfee = < amt > \" + _ ( \" Fees smaller than this are considered zero fee ( for relaying ) ( default : \" ) + \" \" + FormatMoney ( CTransaction : : minRelayTxFee . GetFeePerK ( ) ) + \" ) \" + \" \\ n \" ; <nl> + strUsage + = \" - mintxfee = < amt > \" + strprintf ( _ ( \" Fees ( in BTC / Kb ) smaller than this are considered zero fee for transaction creation ( default : % s ) \" ) , FormatMoney ( CTransaction : : minTxFee . GetFeePerK ( ) ) ) + \" \\ n \" ; <nl> + strUsage + = \" - minrelaytxfee = < amt > \" + strprintf ( _ ( \" Fees ( in BTC / Kb ) smaller than this are considered zero fee for relaying ( default : % s ) \" ) , FormatMoney ( CTransaction : : minRelayTxFee . GetFeePerK ( ) ) ) + \" \\ n \" ; <nl> strUsage + = \" - printtoconsole \" + _ ( \" Send trace / debug info to console instead of debug . log file \" ) + \" \\ n \" ; <nl> if ( GetBoolArg ( \" - help - debug \" , false ) ) <nl> { <nl>\n", "msg": "rework help messages for fee - related options\n", "score": 1}
{"diff_id": 20035, "msg": "AST : Use ResolutionKind : : TypesOnly for qualified lookup too\n", "msgGPT": "refactor lookup qualified function to use a variable for the resolution kind option instead of hardcoding it.", "METEOR Score": "38.62885727981546", "BLEU Score": "0.39310321116247066", "ROUGE-L Score": "0.2142857095153062", "score": 1, "repo": "apple/swift\n", "sha": "9e18f2a1fe4c3117f196bab54a9dfa7d3b92e782\n", "time": "2019-08-25T02:35:51Z\n", "diff": "mmm a / lib / AST / NameLookup . cpp <nl> ppp b / lib / AST / NameLookup . cpp <nl> bool DeclContext : : lookupQualified ( ModuleDecl * module , DeclName member , <nl> bool isLookupCascading ; <nl> configureLookup ( this , options , tracker , isLookupCascading ) ; <nl> <nl> + auto kind = ( options & NL_OnlyTypes <nl> + ? ResolutionKind : : TypesOnly <nl> + : ResolutionKind : : Overloadable ) ; <nl> auto topLevelScope = getModuleScopeContext ( ) ; <nl> if ( module = = topLevelScope - > getParentModule ( ) ) { <nl> if ( tracker ) { <nl> recordLookupOfTopLevelName ( topLevelScope , member , isLookupCascading ) ; <nl> } <nl> lookupInModule ( module , / * accessPath = * / { } , member , decls , <nl> - NLKind : : QualifiedLookup , ResolutionKind : : Overloadable , <nl> - topLevelScope ) ; <nl> + NLKind : : QualifiedLookup , kind , topLevelScope ) ; <nl> } else { <nl> / / Note : This is a lookup into another module . Unless we ' re compiling <nl> / / multiple modules at once , or if the other module re - exports this one , <nl> bool DeclContext : : lookupQualified ( ModuleDecl * module , DeclName member , <nl> if ( import . second ! = module ) <nl> return true ; <nl> lookupInModule ( import . second , import . first , member , decls , <nl> - NLKind : : QualifiedLookup , ResolutionKind : : Overloadable , <nl> - topLevelScope ) ; <nl> + NLKind : : QualifiedLookup , kind , topLevelScope ) ; <nl> / / If we ' re able to do an unscoped lookup , we see everything . No need <nl> / / to keep going . <nl> return ! import . first . empty ( ) ; <nl> bool DeclContext : : lookupQualified ( ModuleDecl * module , DeclName member , <nl> llvm : : SmallPtrSet < ValueDecl * , 4 > knownDecls ; <nl> decls . erase ( std : : remove_if ( decls . begin ( ) , decls . end ( ) , <nl> [ & ] ( ValueDecl * vd ) - > bool { <nl> - / / If we ' re performing a type lookup , skip non - types . <nl> - if ( ( options & NL_OnlyTypes ) & & ! isa < TypeDecl > ( vd ) ) <nl> - return true ; <nl> - <nl> return ! knownDecls . insert ( vd ) . second ; <nl> } ) , decls . end ( ) ) ; <nl> <nl>\n"}
{"diff_id": 20204, "repo": "cocos2d/cocos2d-x\n", "sha": "fcd48ce2c31daa11c411f3129a32a9c3a22f9548\n", "time": "2015-04-21T10:16:38Z\n", "diff": "mmm a / cocos / editor - support / cocostudio / WidgetReader / Node3DReader / Node3DReader . cpp <nl> ppp b / cocos / editor - support / cocostudio / WidgetReader / Node3DReader / Node3DReader . cpp <nl> namespace cocostudio <nl> return _instanceNode3DReader ; <nl> } <nl> <nl> + void Node3DReader : : purge ( ) <nl> + { <nl> + CC_SAFE_DELETE ( _instanceNode3DReader ) ; <nl> + } <nl> + <nl> void Node3DReader : : destroyInstance ( ) <nl> { <nl> CC_SAFE_DELETE ( _instanceNode3DReader ) ; <nl>\n", "msg": "Reset method purge ( ) definition .\n"}
{"diff_id": 20290, "repo": "apple/swift\n", "sha": "704bbbac085f63d25590f38603c02dd960ecf96a\n", "time": "2013-12-05T23:17:29Z\n", "diff": "mmm a / lib / SILPasses / Specializer . cpp <nl> ppp b / lib / SILPasses / Specializer . cpp <nl> <nl> # include \" swift / SIL / SILInstruction . h \" <nl> # include \" swift / SIL / SILModule . h \" <nl> # include \" swift / SILPasses / Passes . h \" <nl> - # include \" llvm / ADT / DenseSet . h \" <nl> # include \" llvm / ADT / Statistic . h \" <nl> + # include \" llvm / ADT / MapVector . h \" <nl> # include \" llvm / ADT / ImmutableSet . h \" <nl> # include \" llvm / Support / Debug . h \" <nl> using namespace swift ; <nl> struct SILSpecializer { <nl> } <nl> <nl> / / / Maps a function to all of the ApplyInst that call it . <nl> - llvm : : DenseMap < SILFunction * , AIList > ApplyInstMap ; <nl> + llvm : : MapVector < SILFunction * , AIList > ApplyInstMap ; <nl> } ; <nl> <nl> } / / end anonymous namespace . <nl>\n", "msg": "Make the order of specializing functions deterministic .\n"}
{"diff_id": 20346, "repo": "mongodb/mongo\n", "sha": "1c180c6a60126e8468e71d7b36b29ee0d7b7bdb9\n", "time": "2011-06-15T17:42:21Z\n", "diff": "mmm a / shell / dbshell . cpp <nl> ppp b / shell / dbshell . cpp <nl> int _main ( int argc , char * argv [ ] ) { <nl> <nl> shellHistoryInit ( ) ; <nl> <nl> + string prompt ; <nl> + <nl> / / v8 : : Handle < v8 : : Object > shellHelper = baseContext_ - > Global ( ) - > Get ( v8 : : String : : New ( \" shellHelper \" ) ) - > ToObject ( ) ; <nl> <nl> while ( 1 ) { <nl> int _main ( int argc , char * argv [ ] ) { <nl> / / shellMainScope - > localConnect ; <nl> / / DBClientWithCommands * c = getConnection ( JSContext * cx , JSObject * obj ) ; <nl> <nl> - string prompt ( sayReplSetMemberState ( ) + \" > \" ) ; <nl> - <nl> + if ( scope - > exec ( \" prompt \" , \" \" , false , false , false ) ) { <nl> + prompt = scope - > getString ( \" prompt \" ) ; <nl> + } else { <nl> + prompt = sayReplSetMemberState ( ) + \" > \" ; <nl> + } <nl> char * line = shellReadline ( prompt . c_str ( ) ) ; <nl> <nl> if ( line ) { <nl>\n", "msg": "SERVER - 3267 very basic custom prompt added\n"}
{"diff_id": 20349, "repo": "bitcoin/bitcoin\n", "sha": "7ef9cd8491185af26295b3501fca9d2a49379364\n", "time": "2018-04-09T23:59:29Z\n", "diff": "mmm a / src / test / test_bitcoin . cpp <nl> ppp b / src / test / test_bitcoin . cpp <nl> TestingSetup : : TestingSetup ( const std : : string & chainName ) : BasicTestingSetup ( cha <nl> <nl> RegisterAllCoreRPCCommands ( tableRPC ) ; <nl> ClearDatadirCache ( ) ; <nl> - pathTemp = fs : : temp_directory_path ( ) / strprintf ( \" test_bitcoin_ % lu_ % i \" , ( unsigned long ) GetTime ( ) , ( int ) ( InsecureRandRange ( 100000 ) ) ) ; <nl> + pathTemp = fs : : temp_directory_path ( ) / strprintf ( \" test_bitcoin_ % lu_ % i \" , ( unsigned long ) GetTime ( ) , ( int ) ( InsecureRandRange ( 1 < < 30 ) ) ) ; <nl> fs : : create_directories ( pathTemp ) ; <nl> gArgs . ForceSetArg ( \" - datadir \" , pathTemp . string ( ) ) ; <nl> <nl>\n", "msg": "Increase entropy in test temp directory name\n"}
{"diff_id": 20365, "repo": "ocornut/imgui\n", "sha": "1b330f420e5138dbd24049daa4c115f3959e68ec\n", "time": "2014-08-11T19:43:48Z\n", "diff": "mmm a / imgui . cpp <nl> ppp b / imgui . cpp <nl> void Checkbox ( const char * label , bool * v ) <nl> const ImGuiAabb text_bb ( window - > DC . CursorPos + ImVec2 ( 0 , style . FramePadding . y ) , window - > DC . CursorPos + ImVec2 ( 0 , style . FramePadding . y ) + text_size ) ; <nl> ItemSize ( ImVec2 ( text_bb . GetWidth ( ) , check_bb . GetHeight ( ) ) ) ; <nl> <nl> - if ( ClipAdvance ( check_bb ) ) <nl> + const ImGuiAabb total_bb ( ImMin ( check_bb . Min , text_bb . Min ) , ImMax ( check_bb . Max , text_bb . Max ) ) ; <nl> + <nl> + if ( ClipAdvance ( total_bb ) ) <nl> return ; <nl> <nl> - const bool hovered = ( g . HoveredWindow = = window ) & & ( g . HoveredId = = 0 ) & & IsMouseHoveringBox ( check_bb ) ; <nl> + const bool hovered = ( g . HoveredWindow = = window ) & & ( g . HoveredId = = 0 ) & & IsMouseHoveringBox ( total_bb ) ; <nl> const bool pressed = hovered & & g . IO . MouseClicked [ 0 ] ; <nl> if ( hovered ) <nl> g . HoveredId = id ; <nl> bool RadioButton ( const char * label , bool active ) <nl> const ImGuiAabb text_bb ( window - > DC . CursorPos + ImVec2 ( 0 , style . FramePadding . y ) , window - > DC . CursorPos + ImVec2 ( 0 , style . FramePadding . y ) + text_size ) ; <nl> ItemSize ( ImVec2 ( text_bb . GetWidth ( ) , check_bb . GetHeight ( ) ) ) ; <nl> <nl> - if ( ClipAdvance ( check_bb ) ) <nl> + const ImGuiAabb total_bb ( ImMin ( check_bb . Min , text_bb . Min ) , ImMax ( check_bb . Max , text_bb . Max ) ) ; <nl> + <nl> + if ( ClipAdvance ( total_bb ) ) <nl> return false ; <nl> <nl> ImVec2 center = check_bb . GetCenter ( ) ; <nl> bool RadioButton ( const char * label , bool active ) <nl> center . y = ( float ) ( int ) center . y + 0 . 5f ; <nl> const float radius = check_bb . GetHeight ( ) * 0 . 5f ; <nl> <nl> - const bool hovered = ( g . HoveredWindow = = window ) & & ( g . HoveredId = = 0 ) & & IsMouseHoveringBox ( check_bb ) ; <nl> + const bool hovered = ( g . HoveredWindow = = window ) & & ( g . HoveredId = = 0 ) & & IsMouseHoveringBox ( total_bb ) ; <nl> const bool pressed = hovered & & g . IO . MouseClicked [ 0 ] ; <nl> if ( hovered ) <nl> g . HoveredId = id ; <nl>\n", "msg": "Checkboxes and radio buttons can be clicked on their labels as well as their icon\n", "score": 1}
{"diff_id": 20574, "repo": "facebook/folly\n", "sha": "ddd5d517e8dd65304f2fb9722e1258bdd9af5b2f\n", "time": "2016-06-16T19:53:24Z\n", "diff": "mmm a / folly / Checksum . cpp <nl> ppp b / folly / Checksum . cpp <nl> <nl> # include < boost / crc . hpp > <nl> # include < folly / CpuId . h > <nl> <nl> + # if FOLLY_X64 & & ( __SSE4_2__ | | defined ( __clang__ ) | | __GNUC_PREREQ ( 4 , 9 ) ) <nl> + # include < nmmintrin . h > <nl> + # endif <nl> + <nl> namespace folly { <nl> <nl> namespace detail { <nl> <nl> - # ifndef __has_builtin <nl> - / * nolint * / <nl> - # define __has_builtin ( x ) 0 <nl> - # endif <nl> - <nl> - # if __SSE4_2__ & & \\ <nl> - ( ( __has_builtin ( __builtin_ia32_crc32qi ) & & \\ <nl> - __has_builtin ( __builtin_ia32_crc32di ) ) | | \\ <nl> - ( FOLLY_X64 & & defined ( __GNUC__ ) & & defined ( __GNUC_MINOR__ ) & & \\ <nl> - ( ( ( __GNUC__ * 100 ) + __GNUC_MINOR__ ) > = 407 ) ) ) <nl> + # if FOLLY_X64 & & ( __SSE4_2__ | | defined ( __clang__ ) | | __GNUC_PREREQ ( 4 , 9 ) ) <nl> <nl> / / Fast SIMD implementation of CRC - 32C for x86 with SSE 4 . 2 <nl> + FOLLY_TARGET_ATTRIBUTE ( \" sse4 . 2 \" ) <nl> uint32_t crc32c_hw ( const uint8_t * data , size_t nbytes , <nl> uint32_t startingChecksum ) { <nl> uint32_t sum = startingChecksum ; <nl> uint32_t crc32c_hw ( const uint8_t * data , size_t nbytes , <nl> if ( mask ! = 0 ) { <nl> size_t limit = std : : min ( nbytes , sizeof ( uint64_t ) - mask ) ; <nl> while ( offset < limit ) { <nl> - sum = ( uint32_t ) __builtin_ia32_crc32qi ( sum , data [ offset ] ) ; <nl> + sum = ( uint32_t ) _mm_crc32_u8 ( sum , data [ offset ] ) ; <nl> offset + + ; <nl> } <nl> } <nl> uint32_t crc32c_hw ( const uint8_t * data , size_t nbytes , <nl> / / Process 8 bytes at a time until we have fewer than 8 bytes left . <nl> while ( offset + sizeof ( uint64_t ) < = nbytes ) { <nl> const uint64_t * src = ( const uint64_t * ) ( data + offset ) ; <nl> - sum = __builtin_ia32_crc32di ( sum , * src ) ; <nl> + sum = _mm_crc32_u64 ( sum , * src ) ; <nl> offset + = sizeof ( uint64_t ) ; <nl> } <nl> <nl> / / Process any bytes remaining after the last aligned 8 - byte block . <nl> while ( offset < nbytes ) { <nl> - sum = ( uint32_t ) __builtin_ia32_crc32qi ( sum , data [ offset ] ) ; <nl> + sum = ( uint32_t ) _mm_crc32_u8 ( sum , data [ offset ] ) ; <nl> offset + + ; <nl> } <nl> return sum ; <nl>\n", "msg": "Use the standard intrinsics for crc32c\n"}
{"diff_id": 20689, "repo": "CRYTEK/CRYENGINE\n", "sha": "6d357b97ed7ab35b57f23dbefa8d980cb8335e80\n", "time": "2016-10-25T10:19:21Z\n", "diff": "mmm a / Code / CryEngine / CryPhysics / qhull . cpp <nl> ppp b / Code / CryEngine / CryPhysics / qhull . cpp <nl> int qhull2d ( ptitem2d * pts , int nVtx , edgeitem * edges , int nMaxContacts ) <nl> ppt_best = ( ptitem2d * ) ( ( intptr_t ) ppt & imask | ( intptr_t ) ppt_best & ~ imask ) ; <nl> } while ( ( ppt = ppt - > next ) ! = edges [ i ] . plist ) ; <nl> / / trace contour from i cw while edges are facing the point ppt_best ( pstart - 1st edge to be deleted ) <nl> - for ( pstart = edges + i ; pstart - > prev ! = edges + i & & <nl> + / * for ( pstart = edges + i ; pstart - > prev ! = edges + i & & <nl> ( ppt_best - > pt - pstart - > prev - > pvtx - > pt ^ pstart - > pvtx - > pt - pstart - > prev - > pvtx - > pt ) > 0 ; pstart = pstart - > prev ) ; <nl> / / trace contour from i ccw while edges are facing the point ppt_best ( pend - edge after the last edge to be deleted ) <nl> for ( pend = edges [ i ] . next ; pend ! = edges + i & & <nl> - ( ppt_best - > pt - pend - > pvtx - > pt ^ pend - > next - > pvtx - > pt - pend - > pvtx - > pt ) > 0 ; pend = pend - > next ) ; <nl> + ( ppt_best - > pt - pend - > pvtx - > pt ^ pend - > next - > pvtx - > pt - pend - > pvtx - > pt ) > 0 ; pend = pend - > next ) ; * / <nl> + pstart = edges + i ; pend = edges [ i ] . next ; <nl> / / delete point ppt_best from the ith edge associated list <nl> delete_item ( ppt_best , edges [ i ] . plist ) ; <nl> / / merge point lists for edges pstart - pend <nl>\n", "msg": "! B ( CE - 10796 ) ( Physics ) degeneracy issue in qhull2d ( Approved by samuelk )\n"}
{"diff_id": 20696, "repo": "godotengine/godot\n", "sha": "7a880029929aa09cf5e9b281b50043df5bb17aa2\n", "time": "2019-03-03T21:24:58Z\n", "diff": "mmm a / editor / editor_node . cpp <nl> ppp b / editor / editor_node . cpp <nl> EditorNode : : EditorNode ( ) { <nl> p - > add_shortcut ( ED_SHORTCUT ( \" editor / undo \" , TTR ( \" Undo \" ) , KEY_MASK_CMD + KEY_Z ) , EDIT_UNDO , true ) ; <nl> p - > add_shortcut ( ED_SHORTCUT ( \" editor / redo \" , TTR ( \" Redo \" ) , KEY_MASK_SHIFT + KEY_MASK_CMD + KEY_Z ) , EDIT_REDO , true ) ; <nl> p - > add_separator ( ) ; <nl> - p - > add_item ( TTR ( \" Revert Scene \" ) , EDIT_REVERT ) ; <nl> + p - > add_shortcut ( ED_SHORTCUT ( \" editor / revert_scene \" , TTR ( \" Revert Scene \" ) ) , EDIT_REVERT ) ; <nl> <nl> recent_scenes = memnew ( PopupMenu ) ; <nl> recent_scenes - > set_name ( \" RecentScenes \" ) ; <nl> EditorNode : : EditorNode ( ) { <nl> <nl> p = project_menu - > get_popup ( ) ; <nl> p - > set_hide_on_window_lose_focus ( true ) ; <nl> - p - > add_item ( TTR ( \" Project Settings \" ) , RUN_SETTINGS ) ; <nl> + p - > add_shortcut ( ED_SHORTCUT ( \" editor / project_settings \" , TTR ( \" Project Settings \" ) ) , RUN_SETTINGS ) ; <nl> p - > add_separator ( ) ; <nl> p - > connect ( \" id_pressed \" , this , \" _menu_option \" ) ; <nl> - p - > add_item ( TTR ( \" Export \" ) , FILE_EXPORT_PROJECT ) ; <nl> + p - > add_shortcut ( ED_SHORTCUT ( \" editor / export \" , TTR ( \" Export \" ) ) , FILE_EXPORT_PROJECT ) ; <nl> <nl> plugin_config_dialog = memnew ( PluginConfigDialog ) ; <nl> plugin_config_dialog - > connect ( \" plugin_ready \" , this , \" _on_plugin_ready \" ) ; <nl> EditorNode : : EditorNode ( ) { <nl> tool_menu - > connect ( \" index_pressed \" , this , \" _tool_menu_option \" ) ; <nl> p - > add_child ( tool_menu ) ; <nl> p - > add_submenu_item ( TTR ( \" Tools \" ) , \" Tools \" ) ; <nl> - tool_menu - > add_item ( TTR ( \" Orphan Resource Explorer \" ) , TOOLS_ORPHAN_RESOURCES ) ; <nl> + tool_menu - > add_shortcut ( ED_SHORTCUT ( \" editor / orphan_resource_explorer \" , TTR ( \" Orphan Resource Explorer \" ) ) , TOOLS_ORPHAN_RESOURCES ) ; <nl> p - > add_separator ( ) ; <nl> <nl> - p - > add_item ( TTR ( \" Open Project Data Folder \" ) , RUN_PROJECT_DATA_FOLDER ) ; <nl> + p - > add_shortcut ( ED_SHORTCUT ( \" editor / open_project_data_folder \" , TTR ( \" Open Project Data Folder \" ) ) , RUN_PROJECT_DATA_FOLDER ) ; <nl> p - > add_separator ( ) ; <nl> <nl> # ifdef OSX_ENABLED <nl> EditorNode : : EditorNode ( ) { <nl> p = debug_menu - > get_popup ( ) ; <nl> p - > set_hide_on_window_lose_focus ( true ) ; <nl> p - > set_hide_on_item_selection ( false ) ; <nl> - p - > add_check_item ( TTR ( \" Deploy with Remote Debug \" ) , RUN_DEPLOY_REMOTE_DEBUG ) ; <nl> + p - > add_check_shortcut ( ED_SHORTCUT ( \" editor / deploy_with_remote_debug \" , TTR ( \" Deploy with Remote Debug \" ) ) , RUN_DEPLOY_REMOTE_DEBUG ) ; <nl> p - > set_item_tooltip ( p - > get_item_count ( ) - 1 , TTR ( \" When exporting or deploying , the resulting executable will attempt to connect to the IP of this computer in order to be debugged . \" ) ) ; <nl> - p - > add_check_item ( TTR ( \" Small Deploy with Network FS \" ) , RUN_FILE_SERVER ) ; <nl> + p - > add_check_shortcut ( ED_SHORTCUT ( \" editor / small_deploy_with_network_fs \" , TTR ( \" Small Deploy with Network FS \" ) ) , RUN_FILE_SERVER ) ; <nl> p - > set_item_tooltip ( p - > get_item_count ( ) - 1 , TTR ( \" When this option is enabled , export or deploy will produce a minimal executable . \\ nThe filesystem will be provided from the project by the editor over the network . \\ nOn Android , deploy will use the USB cable for faster performance . This option speeds up testing for games with a large footprint . \" ) ) ; <nl> p - > add_separator ( ) ; <nl> - p - > add_check_item ( TTR ( \" Visible Collision Shapes \" ) , RUN_DEBUG_COLLISONS ) ; <nl> + p - > add_check_shortcut ( ED_SHORTCUT ( \" editor / visible_collision_shapes \" , TTR ( \" Visible Collision Shapes \" ) ) , RUN_DEBUG_COLLISONS ) ; <nl> p - > set_item_tooltip ( p - > get_item_count ( ) - 1 , TTR ( \" Collision shapes and raycast nodes ( for 2D and 3D ) will be visible on the running game if this option is turned on . \" ) ) ; <nl> - p - > add_check_item ( TTR ( \" Visible Navigation \" ) , RUN_DEBUG_NAVIGATION ) ; <nl> + p - > add_check_shortcut ( ED_SHORTCUT ( \" editor / visible_navigation \" , TTR ( \" Visible Navigation \" ) ) , RUN_DEBUG_NAVIGATION ) ; <nl> p - > set_item_tooltip ( p - > get_item_count ( ) - 1 , TTR ( \" Navigation meshes and polygons will be visible on the running game if this option is turned on . \" ) ) ; <nl> p - > add_separator ( ) ; <nl> / / those are now on by default , since they are harmless <nl> - p - > add_check_item ( TTR ( \" Sync Scene Changes \" ) , RUN_LIVE_DEBUG ) ; <nl> + p - > add_check_shortcut ( ED_SHORTCUT ( \" editor / sync_scene_changes \" , TTR ( \" Sync Scene Changes \" ) ) , RUN_LIVE_DEBUG ) ; <nl> p - > set_item_tooltip ( p - > get_item_count ( ) - 1 , TTR ( \" When this option is turned on , any changes made to the scene in the editor will be replicated in the running game . \\ nWhen used remotely on a device , this is more efficient with network filesystem . \" ) ) ; <nl> p - > set_item_checked ( p - > get_item_count ( ) - 1 , true ) ; <nl> - p - > add_check_item ( TTR ( \" Sync Script Changes \" ) , RUN_RELOAD_SCRIPTS ) ; <nl> + p - > add_check_shortcut ( ED_SHORTCUT ( \" editor / sync_script_changes \" , TTR ( \" Sync Script Changes \" ) ) , RUN_RELOAD_SCRIPTS ) ; <nl> p - > set_item_tooltip ( p - > get_item_count ( ) - 1 , TTR ( \" When this option is turned on , any script that is saved will be reloaded on the running game . \\ nWhen used remotely on a device , this is more efficient with network filesystem . \" ) ) ; <nl> p - > set_item_checked ( p - > get_item_count ( ) - 1 , true ) ; <nl> p - > connect ( \" id_pressed \" , this , \" _menu_option \" ) ; <nl> EditorNode : : EditorNode ( ) { <nl> <nl> p = settings_menu - > get_popup ( ) ; <nl> p - > set_hide_on_window_lose_focus ( true ) ; <nl> - p - > add_item ( TTR ( \" Editor Settings \" ) , SETTINGS_PREFERENCES ) ; <nl> + p - > add_shortcut ( ED_SHORTCUT ( \" editor / editor_settings \" , TTR ( \" Editor Settings \" ) ) , SETTINGS_PREFERENCES ) ; <nl> p - > add_separator ( ) ; <nl> <nl> editor_layouts = memnew ( PopupMenu ) ; <nl> EditorNode : : EditorNode ( ) { <nl> p - > connect ( \" id_pressed \" , this , \" _menu_option \" ) ; <nl> p - > add_icon_shortcut ( gui_base - > get_icon ( \" HelpSearch \" , \" EditorIcons \" ) , ED_SHORTCUT ( \" editor / editor_help \" , TTR ( \" Search \" ) , KEY_F4 ) , HELP_SEARCH ) ; <nl> p - > add_separator ( ) ; <nl> - p - > add_icon_item ( gui_base - > get_icon ( \" Instance \" , \" EditorIcons \" ) , TTR ( \" Online Docs \" ) , HELP_DOCS ) ; <nl> - p - > add_icon_item ( gui_base - > get_icon ( \" Instance \" , \" EditorIcons \" ) , TTR ( \" Q & A \" ) , HELP_QA ) ; <nl> - p - > add_icon_item ( gui_base - > get_icon ( \" Instance \" , \" EditorIcons \" ) , TTR ( \" Issue Tracker \" ) , HELP_ISSUES ) ; <nl> - p - > add_icon_item ( gui_base - > get_icon ( \" Instance \" , \" EditorIcons \" ) , TTR ( \" Community \" ) , HELP_COMMUNITY ) ; <nl> + p - > add_icon_shortcut ( gui_base - > get_icon ( \" Instance \" , \" EditorIcons \" ) , ED_SHORTCUT ( \" editor / online_docs \" , TTR ( \" Online Docs \" ) ) , HELP_DOCS ) ; <nl> + p - > add_icon_shortcut ( gui_base - > get_icon ( \" Instance \" , \" EditorIcons \" ) , ED_SHORTCUT ( \" editor / q & a \" , TTR ( \" Q & A \" ) ) , HELP_QA ) ; <nl> + p - > add_icon_shortcut ( gui_base - > get_icon ( \" Instance \" , \" EditorIcons \" ) , ED_SHORTCUT ( \" editor / issue_tracker \" , TTR ( \" Issue Tracker \" ) ) , HELP_ISSUES ) ; <nl> + p - > add_icon_shortcut ( gui_base - > get_icon ( \" Instance \" , \" EditorIcons \" ) , ED_SHORTCUT ( \" editor / community \" , TTR ( \" Community \" ) ) , HELP_COMMUNITY ) ; <nl> p - > add_separator ( ) ; <nl> - p - > add_icon_item ( gui_base - > get_icon ( \" Godot \" , \" EditorIcons \" ) , TTR ( \" About \" ) , HELP_ABOUT ) ; <nl> + p - > add_icon_shortcut ( gui_base - > get_icon ( \" Godot \" , \" EditorIcons \" ) , ED_SHORTCUT ( \" editor / about \" , TTR ( \" About \" ) ) , HELP_ABOUT ) ; <nl> <nl> HBoxContainer * play_hb = memnew ( HBoxContainer ) ; <nl> menu_hb - > add_child ( play_hb ) ; <nl>\n", "msg": "New shortcuts for the editor menu items\n"}
{"diff_id": 20726, "repo": "taichi-dev/taichi\n", "sha": "9b61bd04808272e40fdfed4852437f56b5b25bbc\n", "time": "2019-01-12T22:41:20Z\n", "diff": "mmm a / lang / mass_spring . cpp <nl> ppp b / lang / mass_spring . cpp <nl> TC_TEST ( \" mass_spring \" ) { <nl> fork2 . fixed ( j , 64 ) . place ( expr ) ; <nl> } ; <nl> <nl> + auto & fork3 = root . fixed ( i , max_n ) . fixed ( j , 8 ) ; <nl> + auto place_blocked = [ & ] ( Expr expr ) { <nl> + fork3 . fixed ( j , 8 ) . place ( expr ) ; <nl> + } ; <nl> + <nl> place_fixed ( l0 ) ; <nl> place_fixed ( stiffness ) ; <nl> for ( auto & e : K . entries ) { <nl> - place_fixed ( e ) ; <nl> + place_blocked ( e ) ; <nl> } <nl> <nl> auto & particle = root . fixed ( i , max_n ) ; <nl>\n", "msg": "Blocked storage of K : 20 % faster\n"}
{"diff_id": 20797, "repo": "mongodb/mongo\n", "sha": "46f97f8fe758d97033d1e0319ab029e0906e43a2\n", "time": "2012-05-28T02:19:58Z\n", "diff": "mmm a / src / mongo / s / commands_public . cpp <nl> ppp b / src / mongo / s / commands_public . cpp <nl> namespace mongo { <nl> * / <nl> if ( limit ! = 0 & & cmdObj [ \" skip \" ] . isNumber ( ) ) { <nl> long long skip = cmdObj [ \" skip \" ] . numberLong ( ) ; <nl> - verify ( skip > = 0 ) ; <nl> + uassert ( 16260 , \" skip has to be positive \" , skip > = 0 ) ; <nl> if ( limit > 0 ) <nl> limit + = skip ; <nl> else <nl>\n", "msg": "uassert instead of verify for invalid skip\n"}
{"diff_id": 20800, "repo": "apple/swift\n", "sha": "f0c4b46bf6f1c60af3791c9b008fc51987f19d93\n", "time": "2014-11-06T22:32:13Z\n", "diff": "mmm a / stdlib / runtime / Casting . cpp <nl> ppp b / stdlib / runtime / Casting . cpp <nl> static bool _conformsToProtocols ( const OpaqueValue * value , <nl> return true ; <nl> } <nl> <nl> - static const OpaqueValue * <nl> - _dynamicCastToExistential ( const OpaqueValue * value , <nl> - const Metadata * sourceType , <nl> - const ExistentialTypeMetadata * targetType ) { <nl> - for ( unsigned i = 0 , n = targetType - > Protocols . NumProtocols ; i ! = n ; + + i ) { <nl> - auto * protocol = targetType - > Protocols [ i ] ; <nl> - if ( ! _conformsToProtocol ( value , sourceType , protocol , nullptr ) ) <nl> - return nullptr ; <nl> - } <nl> - <nl> - return value ; <nl> - } <nl> - <nl> static bool shouldDeallocateSource ( bool castSucceeded , DynamicCastFlags flags ) { <nl> return ( castSucceeded & & ( flags & DynamicCastFlags : : TakeOnSuccess ) ) | | <nl> ( ! castSucceeded & & ( flags & DynamicCastFlags : : DestroyOnFailure ) ) ; <nl>\n", "msg": "Runtime : Remove unused helper .\n"}
{"diff_id": 20812, "repo": "opencv/opencv\n", "sha": "bf808fac255b75554fef4814b325ec9050cc2888\n", "time": "2010-12-02T23:42:46Z\n", "diff": "mmm a / samples / c / latentsvmdetect . cpp <nl> ppp b / samples / c / latentsvmdetect . cpp <nl> <nl> <nl> using namespace cv ; <nl> <nl> + void help ( ) <nl> + { <nl> + printf ( \" This program demonstrated the use of the latentSVM detector . \\ n \" <nl> + \" It reads in a trained object model and then uses that to detect the object in an image \\ n \" <nl> + \" Call : \\ n \" <nl> + \" . / latentsvmdetect [ < image_filename > < model_filename ] \\ n \" <nl> + \" The defaults for image_filename and model_filename are cat . jpg and cat . xml respectively \\ n \" <nl> + \" Press any key to quit . \\ n \" ) ; <nl> + } <nl> + <nl> const char * model_filename = \" cat . xml \" ; <nl> const char * image_filename = \" cat . jpg \" ; <nl> <nl> void detect_and_draw_objects ( IplImage * image , CvLatentSvmDetector * detector ) <nl> cvReleaseMemStorage ( & storage ) ; <nl> } <nl> <nl> - <nl> int main ( int argc , char * argv [ ] ) <nl> { <nl> + help ( ) ; <nl> if ( argc > 2 ) <nl> { <nl> image_filename = argv [ 1 ] ; <nl> int main ( int argc , char * argv [ ] ) <nl> cvDestroyAllWindows ( ) ; <nl> <nl> return 0 ; <nl> - } <nl> \\ No newline at end of file <nl> + } <nl>\n", "msg": "created parameter description doc and output\n"}
{"diff_id": 20829, "repo": "microsoft/CNTK\n", "sha": "08942320b7c2f6b35c45f8e6d2a19ac08730d5e9\n", "time": "2016-02-18T07:02:06Z\n", "diff": "mmm a / Source / SGDLib / SGD . cpp <nl> ppp b / Source / SGDLib / SGD . cpp <nl> size_t SGD < ElemType > : : TrainOneEpoch ( ComputationNetworkPtr net , <nl> bool wasDataRead = DataReaderHelpers : : GetMinibatchIntoNetwork ( * trainSetDataReader , net , criterionNodes [ 0 ] , <nl> useDistributedMBReading , useParallelTrain , * inputMatrices , actualMBSize ) ; <nl> <nl> - if ( ! m_multiversoBarrier & & useASGD ) <nl> - { <nl> - m_multiverso - > WaitAll ( ) ; <nl> - m_multiversoBarrier = true ; <nl> - } <nl> - <nl> if ( ! wasDataRead & & ( ! useDistributedMBReading | | noMoreSamplesToProcess ) ) / / in case of distributed reading , we do a few more loops until all ranks have completed <nl> break ; <nl> <nl> static LearningRateSearchAlgorithm ParseLearningRateSearchType ( const wstring & s ) <nl> else InvalidArgument ( \" autoAdjustLR : Invalid learning rate search type . Valid values are ( none | searchBeforeEpoch | adjustAfterEpoch ) \" ) ; <nl> } <nl> <nl> - static AdjustLearningRateatBeginning AdjustLearningRateAtBeginningType ( wstring s ) <nl> - { <nl> - if ( ! _wcsicmp ( s . c_str ( ) , L \" \" ) | | ! _wcsicmp ( s . c_str ( ) , L \" none \" ) ) <nl> - return AdjustLearningRateatBeginning : : None ; <nl> - else if ( ! _wcsicmp ( s . c_str ( ) , L \" linearly \" ) ) <nl> - return AdjustLearningRateatBeginning : : Linearly ; <nl> - else if ( ! _wcsicmp ( s . c_str ( ) , L \" staircase \" ) ) <nl> - return AdjustLearningRateatBeginning : : Staircase ; <nl> - else <nl> - InvalidArgument ( \" AdjustLearningRateatBeginningType : Invalid Type . Valid values are ( None | Linearly | Staircase ) \" ) ; <nl> - } <nl> + static AdjustLearningRateatBeginning AdjustLearningRateAtBeginningType ( wstring s ) <nl> + { <nl> + if ( EqualCI ( s . c_str ( ) , L \" \" ) | | EqualCI ( s . c_str ( ) , L \" none \" ) ) return AdjustLearningRateatBeginning : : None ; <nl> + else if ( EqualCI ( s . c_str ( ) , L \" linearly \" ) ) return AdjustLearningRateatBeginning : : Linearly ; <nl> + else if ( EqualCI ( s . c_str ( ) , L \" staircase \" ) ) return AdjustLearningRateatBeginning : : Staircase ; <nl> + else InvalidArgument ( \" AdjustLearningRateatBeginningType : Invalid Type . Valid values are ( None | Linearly | Staircase ) \" ) ; <nl> + } <nl> <nl> template < class ConfigRecordType > <nl> SGDParams : : SGDParams ( const ConfigRecordType & configSGD , size_t sizeofElemType ) <nl> SGDParams : : SGDParams ( const ConfigRecordType & configSGD , size_t sizeofElemType ) <nl> m_momentumParam = momentumPerSampleVec ; <nl> m_momentumSpecifiedForMBSize = intargvector ( L \" 1 \" ) ; <nl> } <nl> - else if ( momentumPerMB . size ( ) > 0 ) <nl> - { <nl> - m_momentumParam = momentumPerMB ; <nl> - m_momentumSpecifiedForMBSize = m_mbSize ; <nl> - } <nl> - else / / default : momentumPerMB = 0 . 9 per MB <nl> - { <nl> - m_momentumParam = floatargvector ( L \" 0 . 9 \" ) ; <nl> - m_momentumSpecifiedForMBSize = m_mbSize ; <nl> - } <nl> - m_useNesterovMomentum = useNesterovMomentum ; <nl> + else if ( momentumPerMB . size ( ) > 0 ) <nl> + { <nl> + m_momentumParam = momentumPerMB ; <nl> + m_momentumSpecifiedForMBSize = m_mbSize ; <nl> + } <nl> + else / / default : momentumPerMB = 0 . 9 per MB <nl> + { <nl> + m_momentumParam = floatargvector ( L \" 0 . 9 \" ) ; <nl> + m_momentumSpecifiedForMBSize = m_mbSize ; <nl> + } <nl> + m_useNesterovMomentum = useNesterovMomentum ; <nl> <nl> - for ( int i = 0 ; i < m_momentumParam . size ( ) ; i + + ) <nl> - { <nl> - if ( m_momentumParam [ i ] > = 1 . 0 | | m_momentumParam [ i ] < 0 . 0 ) <nl> - { <nl> - InvalidArgument ( \" Momentum parameter must be in [ 0 , 1 ) . \" ) ; <nl> - } <nl> - } <nl> + for ( int i = 0 ; i < m_momentumParam . size ( ) ; i + + ) <nl> + { <nl> + if ( m_momentumParam [ i ] > = 1 . 0 | | m_momentumParam [ i ] < 0 . 0 ) <nl> + { <nl> + InvalidArgument ( \" Momentum parameter must be in [ 0 , 1 ) . \" ) ; <nl> + } <nl> + } <nl> <nl> - if ( m_learnRateDecreaseFactor > 1 | | m_learnRateIncreaseFactor < 1 ) <nl> - { <nl> - InvalidArgument ( \" learnRateIncreaseFactor must be > = 1 and learnRateDecreaseFactor must be < = 1 . \" ) ; <nl> - } <nl> + if ( m_learnRateDecreaseFactor > 1 | | m_learnRateIncreaseFactor < 1 ) <nl> + { <nl> + InvalidArgument ( \" learnRateIncreaseFactor must be > = 1 and learnRateDecreaseFactor must be < = 1 . \" ) ; <nl> + } <nl> <nl> - for ( size_t i = 0 ; i < m_dropoutRates . size ( ) ; i + + ) <nl> - { <nl> - if ( m_dropoutRates [ i ] > = 1 | | m_dropoutRates [ i ] < 0 ) <nl> - { <nl> - InvalidArgument ( \" dropoutRate must be > = 0 and < 1 . \" ) ; <nl> - } <nl> + for ( size_t i = 0 ; i < m_dropoutRates . size ( ) ; i + + ) <nl> + { <nl> + if ( m_dropoutRates [ i ] > = 1 | | m_dropoutRates [ i ] < 0 ) <nl> + { <nl> + InvalidArgument ( \" dropoutRate must be > = 0 and < 1 . \" ) ; <nl> + } <nl> } <nl> <nl> if ( m_adaptationRegWeight > 1 | | m_adaptationRegWeight < 0 ) <nl> SGDParams : : SGDParams ( const ConfigRecordType & configSGD , size_t sizeofElemType ) <nl> <nl> static size_t GetSizeOfPrecision ( const ScriptableObjects : : IConfigRecordPtr configp ) <nl> { <nl> - wstring precision = configp - > Get ( L \" precision \" ) ; <nl> - if ( precision = = L \" float \" ) <nl> - return sizeof ( float ) ; <nl> - else if ( precision = = L \" double \" ) <nl> - return sizeof ( double ) ; <nl> - else <nl> - RuntimeError ( \" invalid value ' % ls ' for ' precision ' , must be ' float ' or ' double ' \" , precision . c_str ( ) ) ; <nl> + wstring precision = configp - > Get ( L \" precision \" ) ; <nl> + if ( precision = = L \" float \" ) <nl> + return sizeof ( float ) ; <nl> + else if ( precision = = L \" double \" ) <nl> + return sizeof ( double ) ; <nl> + else <nl> + RuntimeError ( \" invalid value ' % ls ' for ' precision ' , must be ' float ' or ' double ' \" , precision . c_str ( ) ) ; <nl> } <nl> <nl> SGDParams : : SGDParams ( const ScriptableObjects : : IConfigRecordPtr configp ) <nl>\n", "msg": "using unify function for config parsing\n", "score": 1}
{"diff_id": 20865, "repo": "MarlinFirmware/Marlin\n", "sha": "850259bb254e934bcc7add7f90e2f95812823cf8\n", "time": "2016-09-28T19:14:04Z\n", "diff": "mmm a / Marlin / ultralcd . cpp <nl> ppp b / Marlin / ultralcd . cpp <nl> void kill_screen ( const char * lcd_msg ) { <nl> / / Bed : <nl> / / <nl> # if TEMP_SENSOR_BED ! = 0 <nl> - MENU_MULTIPLIER_ITEM_EDIT ( int3 , MSG_BED , & thermalManager . target_temperature_bed , 0 , BED_MAXTEMP - 15 ) ; <nl> + MENU_MULTIPLIER_ITEM_EDIT_CALLBACK ( int3 , MSG_BED , & thermalManager . target_temperature_bed , 0 , BED_MAXTEMP - 15 , watch_temp_callback_bed ) ; <nl> # endif <nl> <nl> / / <nl>\n", "msg": "Watch bed temp also for Control menu item\n"}
{"diff_id": 20958, "repo": "bitcoin/bitcoin\n", "sha": "b1ca5eb58ac322a1a14f5f8479502a735d128443\n", "time": "2011-01-31T16:13:02Z\n", "diff": "mmm a / db . cpp <nl> ppp b / db . cpp <nl> bool LoadWallet ( bool & fFirstRunRet ) <nl> keyUser . MakeNewKey ( ) ; <nl> if ( ! AddKey ( keyUser ) ) <nl> return false ; <nl> - if ( ! SetAddressBookName ( PubKeyToAddress ( keyUser . GetPubKey ( ) ) , \" Your Address \" ) ) <nl> + if ( ! SetAddressBookName ( PubKeyToAddress ( keyUser . GetPubKey ( ) ) , \" \" ) ) <nl> return false ; <nl> CWalletDB ( ) . WriteDefaultKey ( keyUser . GetPubKey ( ) ) ; <nl> } <nl>\n", "msg": "do not create ' Your Address ' account\n"}
{"diff_id": 20994, "repo": "apple/swift\n", "sha": "4f09c4c25ba389116256eaa2885ee85305fac41b\n", "time": "2016-01-09T01:24:49Z\n", "diff": "mmm a / lib / ABI / Compression . cpp <nl> ppp b / lib / ABI / Compression . cpp <nl> std : : string swift : : Compress : : EncodeCBCString ( StringRef In ) { <nl> static std : : pair < uint64_t , uint64_t > get64bitEncodingParams ( ) { <nl> uint64_t CL = Huffman : : CharsetLength ; <nl> <nl> - <nl> / / We encode each letter using Log2 ( CL ) bits , and the number of letters we can <nl> / / encode is a 64bit number is 64 / Log2 ( CL ) . <nl> / / <nl> static void DecodeFixedWidth ( APInt & Num , std : : string & SB ) { <nl> } <nl> } <nl> <nl> - static void EncodeFixedWidth ( APInt & num , char ch ) { <nl> - APInt C = APInt ( num . getBitWidth ( ) , Huffman : : CharsetLength ) ; <nl> + static unsigned GetCharIndex ( char ch ) { <nl> / / TODO : autogenerate a table for the reverse lookup . <nl> for ( unsigned i = 0 ; i < Huffman : : CharsetLength ; i + + ) { <nl> if ( Huffman : : Charset [ i ] = = ch ) { <nl> - num * = C ; <nl> - num + = APInt ( num . getBitWidth ( ) , i ) ; <nl> - return ; <nl> + return i ; <nl> } <nl> } <nl> llvm_unreachable ( \" Can ' t find the requested character in the alphabet . \" ) ; <nl> swift : : Compress : : EncodeStringAsNumber ( StringRef In , EncodingKind Kind ) { <nl> } <nl> <nl> / / Encode fixed width strings . <nl> + <nl> + / / Try to decode a few numbers at once . First encode characters into a local <nl> + / / variable and then encode that variable . It is much faster to work with <nl> + / / local 64 - bit numbers than APInts . <nl> + uint64_t CL = Huffman : : CharsetLength ; <nl> + uint64_t CLX ; <nl> + uint64_t maxNumLetters ; <nl> + std : : tie ( maxNumLetters , CLX ) = get64bitEncodingParams ( ) ; <nl> + <nl> + uint64_t numEncodedChars = 0 ; <nl> + uint64_t encodedCharsValue = 0 ; <nl> + <nl> for ( int i = In . size ( ) - 1 ; i > = 0 ; i - - ) { <nl> - char ch = In [ i ] ; <nl> - / / Extend the number and create room for encoding another character . <nl> - unsigned MinBits = num . getActiveBits ( ) + Huffman : : LongestEncodingLength ; <nl> - num = num . zextOrTrunc ( std : : max ( 64u , MinBits ) ) ; <nl> - EncodeFixedWidth ( num , ch ) ; <nl> + / / Encode a single char into the local temporary variable . <nl> + unsigned charIdx = GetCharIndex ( In [ i ] ) ; <nl> + encodedCharsValue = encodedCharsValue * CL + charIdx ; <nl> + numEncodedChars + + ; <nl> + <nl> + / / If we ' ve reached the maximum capacity then push the value into the APInt . <nl> + if ( numEncodedChars = = maxNumLetters ) { <nl> + num = num . zextOrSelf ( num . getActiveBits ( ) + 64 ) ; <nl> + num * = APInt ( num . getBitWidth ( ) , CLX ) ; <nl> + num + = APInt ( num . getBitWidth ( ) , encodedCharsValue ) ; <nl> + numEncodedChars = 0 ; <nl> + encodedCharsValue = 0 ; <nl> + } <nl> + } <nl> + <nl> + / / Encode the last few characters . <nl> + if ( numEncodedChars ) { <nl> + / / Compute the value that we need to multiply the APInt to make room for the <nl> + / / last few characters that did not make a complete 64 - bit value . <nl> + uint64_t tailCLX = 1 ; <nl> + for ( unsigned i = 0 ; i < numEncodedChars ; i + + ) { tailCLX * = CL ; } <nl> + <nl> + num = num . zextOrSelf ( num . getActiveBits ( ) + 64 ) ; <nl> + num * = APInt ( num . getBitWidth ( ) , tailCLX ) ; <nl> + num + = APInt ( num . getBitWidth ( ) , encodedCharsValue ) ; <nl> } <nl> <nl> return num ; <nl>\n", "msg": "[ Compression ] Accelerate the decompression of mangled strings .\n"}
{"diff_id": 21182, "repo": "facebook/hhvm\n", "sha": "1c2486029303681155bb3e715dcc3156a91d710c\n", "time": "2019-01-31T10:15:52Z\n", "diff": "mmm a / hphp / compiler / option . cpp <nl> ppp b / hphp / compiler / option . cpp <nl> void Option : : Load ( const IniSetting : : Map & ini , Hdf & config ) { <nl> <nl> { <nl> / / AutoloadMap <nl> - Config : : Bind ( AutoloadClassMap , ini , config , \" AutoloadMap . class \" ) ; <nl> - Config : : Bind ( AutoloadFuncMap , ini , config , \" AutoloadMap . function \" ) ; <nl> - Config : : Bind ( AutoloadConstMap , ini , config , \" AutoloadMap . constant \" ) ; <nl> - Config : : Bind ( AutoloadRoot , ini , config , \" AutoloadMap . root \" ) ; <nl> + / / not using Bind here because those maps are enormous and cause performance <nl> + / / problems when showing up later <nl> + AutoloadClassMap = Config : : GetMapC ( ini , config , \" AutoloadMap . class \" ) ; <nl> + AutoloadFuncMap = Config : : GetMapC ( ini , config , \" AutoloadMap . function \" ) ; <nl> + AutoloadConstMap = Config : : GetMap ( ini , config , \" AutoloadMap . constant \" ) ; <nl> + AutoloadRoot = Config : : GetString ( ini , config , \" AutoloadMap . root \" ) ; <nl> } <nl> <nl> Config : : Bind ( RuntimeOption : : EvalHardTypeHints , ini , config , <nl>\n", "msg": "Avoid passing autoload map data from HHVM to HackC process , reduce peak build memory by 50 %\n"}
{"diff_id": 21282, "repo": "MarlinFirmware/Marlin\n", "sha": "68b46fb2c96ac97776482f348e81ed53a586c477\n", "time": "2016-11-08T23:54:55Z\n", "diff": "mmm a / Marlin / twibus . cpp <nl> ppp b / Marlin / twibus . cpp <nl> void TWIBus : : addstring ( char str [ ] ) { <nl> } <nl> <nl> void TWIBus : : send ( ) { <nl> - if ( ! this - > addr ) return ; <nl> - <nl> # if ENABLED ( DEBUG_TWIBUS ) <nl> debug ( PSTR ( \" send \" ) , this - > addr ) ; <nl> # endif <nl>\n", "msg": "Allow send to i2c address 0 ( broadcast )\n"}
{"diff_id": 21431, "repo": "bitcoin/bitcoin\n", "sha": "a8c108bca1a2e67bd7c335119d9b04c87552c159\n", "time": "2011-09-27T15:19:57Z\n", "diff": "mmm a / src / main . cpp <nl> ppp b / src / main . cpp <nl> bool CTransaction : : AcceptToMemoryPool ( CTxDB & txdb , bool fCheckInputs , bool * pfMi <nl> / / 34 bytes because a TxOut is : <nl> / / 20 - byte address + 8 byte bitcoin amount + 5 bytes of ops + 1 byte script length <nl> if ( GetSigOpCount ( ) > nSize / 34 | | nSize < 100 ) <nl> - return DoS ( 10 , error ( \" AcceptToMemoryPool ( ) : transaction with out - of - bounds SigOpCount \" ) ) ; <nl> + return error ( \" AcceptToMemoryPool ( ) : transaction with out - of - bounds SigOpCount \" ) ; <nl> <nl> / / Rather not work on nonstandard transactions ( unless - testnet ) <nl> if ( ! fTestNet & & ! IsStandard ( ) ) <nl> bool CTransaction : : ConnectInputs ( CTxDB & txdb , map < uint256 , CTxIndex > & mapTestPoo <nl> if ( txPrev . IsCoinBase ( ) ) <nl> for ( CBlockIndex * pindex = pindexBlock ; pindex & & pindexBlock - > nHeight - pindex - > nHeight < COINBASE_MATURITY ; pindex = pindex - > pprev ) <nl> if ( pindex - > nBlockPos = = txindex . pos . nBlockPos & & pindex - > nFile = = txindex . pos . nFile ) <nl> - return DoS ( 10 , error ( \" ConnectInputs ( ) : tried to spend coinbase at depth % d \" , pindexBlock - > nHeight - pindex - > nHeight ) ) ; <nl> + return error ( \" ConnectInputs ( ) : tried to spend coinbase at depth % d \" , pindexBlock - > nHeight - pindex - > nHeight ) ; <nl> <nl> / / Skip ECDSA signature verification when connecting blocks ( fBlock = true ) during initial download <nl> / / ( before the last blockchain checkpoint ) . This is safe because block merkle hashes are <nl>\n", "msg": "Remove DoS penalty for SigOpCount or immature transactions\n"}
{"diff_id": 21522, "repo": "apple/swift\n", "sha": "68bc265190a6737541e1f8cde9e6ab700a51834a\n", "time": "2020-05-08T11:27:49Z\n", "diff": "mmm a / lib / SIL / IR / AbstractionPattern . cpp <nl> ppp b / lib / SIL / IR / AbstractionPattern . cpp <nl> void AbstractionPattern : : print ( raw_ostream & out ) const { <nl> case Kind : : CurriedCFunctionAsMethodType : <nl> case Kind : : PartialCurriedCFunctionAsMethodType : <nl> case Kind : : CFunctionAsMethodType : <nl> - case Kind : : CXXMethodType : <nl> - case Kind : : CurriedCXXMethodType : <nl> - case Kind : : PartialCurriedCXXMethodType : <nl> out < < ( getKind ( ) = = Kind : : ClangType <nl> ? \" AP : : ClangType ( \" : <nl> getKind ( ) = = Kind : : CurriedCFunctionAsMethodType <nl> ? \" AP : : CurriedCFunctionAsMethodType ( \" : <nl> - getKind ( ) = = Kind : : CFunctionAsMethodType <nl> - ? \" AP : : CFunctionAsMethodType ( \" : <nl> - getKind ( ) = = Kind : : CXXMethodType <nl> - ? \" AP : : CXXMethodType ( \" : <nl> - getKind ( ) = = Kind : : CurriedCXXMethodType <nl> - ? \" AP : : CurriedCXXMethodType ( \" : <nl> - getKind ( ) = = Kind : : PartialCurriedCXXMethodType <nl> - ? \" AP : : PartialCurriedCXXMethodType ( \" <nl> - : \" AP : : PartialCurriedCFunctionAsMethodType ( \" ) ; <nl> + getKind ( ) = = Kind : : PartialCurriedCFunctionAsMethodType <nl> + ? \" AP : : PartialCurriedCFunctionAsMethodType ( \" <nl> + : \" AP : : CFunctionAsMethodType ( \" ) ; <nl> if ( auto sig = getGenericSignature ( ) ) { <nl> sig - > print ( out ) ; <nl> } <nl> void AbstractionPattern : : print ( raw_ostream & out ) const { <nl> } <nl> out < < \" ) \" ; <nl> return ; <nl> + case Kind : : CXXMethodType : <nl> + case Kind : : CurriedCXXMethodType : <nl> + case Kind : : PartialCurriedCXXMethodType : <nl> + out < < ( getKind ( ) = = Kind : : CXXMethodType <nl> + ? \" AP : : CXXMethodType ( \" : <nl> + getKind ( ) = = Kind : : CurriedCXXMethodType <nl> + ? \" AP : : CurriedCXXMethodType ( \" <nl> + : \" AP : : PartialCurriedCXXMethodType \" ) ; <nl> + if ( auto sig = getGenericSignature ( ) ) { <nl> + sig - > print ( out ) ; <nl> + } <nl> + getType ( ) . dump ( out ) ; <nl> + out < < \" , \" ; <nl> + getCXXMethod ( ) - > dump ( ) ; <nl> + assert ( ! hasImportAsMemberStatus ( ) ) ; <nl> + out < < \" ) \" ; <nl> + return ; <nl> case Kind : : CurriedObjCMethodType : <nl> case Kind : : PartialCurriedObjCMethodType : <nl> case Kind : : ObjCMethodType : <nl>\n", "msg": "Correctly print an AbstractionPattern with C + + method types\n"}
{"diff_id": 21556, "repo": "qbittorrent/qBittorrent\n", "sha": "f211b238c487b8ece18655812536427937a833e5\n", "time": "2017-05-10T23:10:23Z\n", "diff": "mmm a / src / gui / properties / piecesbar . cpp <nl> ppp b / src / gui / properties / piecesbar . cpp <nl> void PiecesBar : : showToolTip ( const QHelpEvent * e ) <nl> <nl> QString toolTipText ; <nl> QTextStream stream ( & toolTipText , QIODevice : : WriteOnly ) ; <nl> - bool showDetailedInformation = QApplication : : keyboardModifiers ( ) . testFlag ( Qt : : ShiftModifier ) ; <nl> - if ( showDetailedInformation ) { <nl> + const bool showDetailedInformation = QApplication : : keyboardModifiers ( ) . testFlag ( Qt : : ShiftModifier ) ; <nl> + if ( showDetailedInformation & & m_torrent - > hasMetadata ( ) ) { <nl> const int imagePos = e - > pos ( ) . x ( ) - borderWidth ; <nl> if ( ( imagePos > = 0 ) & & ( imagePos < m_image . width ( ) ) ) { <nl> stream < < \" < html > < body > \" ; <nl> void PiecesBar : : showToolTip ( const QHelpEvent * e ) <nl> } <nl> else { <nl> stream < < simpleToolTipText ( ) ; <nl> - stream < < ' \\ n ' < < tr ( \" Hold Shift key for detailed information \" ) ; <nl> + if ( showDetailedInformation ) / / metadata are not available at this point <nl> + stream < < ' \\ n ' < < tr ( \" Wait until metadata become available to see detailed information \" ) ; <nl> + else <nl> + stream < < ' \\ n ' < < tr ( \" Hold Shift key for detailed information \" ) ; <nl> } <nl> <nl> stream . flush ( ) ; <nl> void PiecesBar : : showToolTip ( const QHelpEvent * e ) <nl> <nl> void PiecesBar : : highlightFile ( int imagePos ) <nl> { <nl> - if ( ! m_torrent | | ( imagePos < 0 ) | | ( imagePos > = m_image . width ( ) ) ) <nl> + if ( ! m_torrent | | ! m_torrent - > hasMetadata ( ) | | ( imagePos < 0 ) | | ( imagePos > = m_image . width ( ) ) ) <nl> return ; <nl> <nl> PieceIndexToImagePos transform { m_torrent - > info ( ) , m_image } ; <nl>\n", "msg": "Do not attempt to show detailed tooltips without torrent metadata . Closes .\n"}
{"diff_id": 21571, "repo": "xbmc/xbmc\n", "sha": "79818548cb249b5e7e0e27389dbe48cfe50591ee\n", "time": "2015-08-12T09:01:50Z\n", "diff": "mmm a / xbmc / guilib / GUITextBox . cpp <nl> ppp b / xbmc / guilib / GUITextBox . cpp <nl> bool CGUITextBox : : OnMessage ( CGUIMessage & message ) <nl> m_scrollOffset = 0 ; <nl> ResetAutoScrolling ( ) ; <nl> CGUITextLayout : : Reset ( ) ; <nl> - if ( m_pageControl ) <nl> - { <nl> - CGUIMessage msg ( GUI_MSG_LABEL_RESET , GetID ( ) , m_pageControl , m_itemsPerPage , m_lines . size ( ) ) ; <nl> - SendWindowMessage ( msg ) ; <nl> - } <nl> + UpdatePageControl ( ) ; <nl> + SetInvalid ( ) ; <nl> } <nl> <nl> if ( message . GetMessage ( ) = = GUI_MSG_PAGE_CHANGE ) <nl>\n", "msg": "[ textbox ] remove duplicate code\n"}
{"diff_id": 21832, "repo": "xbmc/xbmc\n", "sha": "bffa7bb5e33aff1325e090eddbba16a2740637bb\n", "time": "2020-04-17T18:08:20Z\n", "diff": "mmm a / xbmc / video / VideoDatabase . cpp <nl> ppp b / xbmc / video / VideoDatabase . cpp <nl> void CVideoDatabase : : CreateAnalytics ( ) <nl> m_pDS - > exec ( \" CREATE INDEX ix_uniqueid1 ON uniqueid ( media_id , media_type ( 20 ) , type ( 20 ) ) \" ) ; <nl> m_pDS - > exec ( \" CREATE INDEX ix_uniqueid2 ON uniqueid ( media_type ( 20 ) , value ( 20 ) ) \" ) ; <nl> <nl> + m_pDS - > exec ( \" CREATE UNIQUE INDEX ix_actor_1 ON actor ( name ( 255 ) ) \" ) ; <nl> + m_pDS - > exec ( \" CREATE INDEX ix_actor_link_1 ON actor_link ( media_type ( 20 ) ) \" ) ; <nl> + m_pDS - > exec ( \" CREATE UNIQUE INDEX ix_actor_link_2 ON \" <nl> + \" actor_link ( actor_id , media_id , media_type , role ) \" ) ; <nl> + <nl> CreateLinkIndex ( \" tag \" ) ; <nl> - CreateLinkIndex ( \" actor \" ) ; <nl> CreateForeignLinkIndex ( \" director \" , \" actor \" ) ; <nl> CreateForeignLinkIndex ( \" writer \" , \" actor \" ) ; <nl> CreateLinkIndex ( \" studio \" ) ; <nl> int CVideoDatabase : : AddActor ( const std : : string & name , const std : : string & thumbUR <nl> <nl> void CVideoDatabase : : AddLinkToActor ( int mediaId , const char * mediaType , int actorId , const std : : string & role , int order ) <nl> { <nl> - std : : string sql = PrepareSQL ( \" SELECT 1 FROM actor_link WHERE actor_id = % i AND media_id = % i AND media_type = ' % s ' \" , actorId , mediaId , mediaType ) ; <nl> + std : : string sql = PrepareSQL ( \" SELECT 1 FROM actor_link WHERE actor_id = % i AND \" <nl> + \" media_id = % i AND media_type = ' % s ' AND role = ' % s ' \" , <nl> + actorId , mediaId , mediaType , role . c_str ( ) ) ; <nl> <nl> if ( GetSingleValue ( sql ) . empty ( ) ) <nl> { / / doesnt exists , add it <nl> void CVideoDatabase : : GetCast ( int media_id , const std : : string & media_type , std : : v <nl> { <nl> SActorInfo info ; <nl> info . strName = m_pDS2 - > fv ( 0 ) . get_asString ( ) ; <nl> - bool found = false ; <nl> - for ( const auto & i : cast ) <nl> - { <nl> - if ( i . strName = = info . strName ) <nl> - { <nl> - found = true ; <nl> - break ; <nl> - } <nl> - } <nl> - if ( ! found ) <nl> - { <nl> - info . strRole = m_pDS2 - > fv ( 1 ) . get_asString ( ) ; <nl> - info . order = m_pDS2 - > fv ( 2 ) . get_asInt ( ) ; <nl> - info . thumbUrl . ParseString ( m_pDS2 - > fv ( 3 ) . get_asString ( ) ) ; <nl> - info . thumb = m_pDS2 - > fv ( 4 ) . get_asString ( ) ; <nl> - cast . emplace_back ( std : : move ( info ) ) ; <nl> - } <nl> + info . strRole = m_pDS2 - > fv ( 1 ) . get_asString ( ) ; <nl> + info . order = m_pDS2 - > fv ( 2 ) . get_asInt ( ) ; <nl> + info . thumbUrl . ParseString ( m_pDS2 - > fv ( 3 ) . get_asString ( ) ) ; <nl> + info . thumb = m_pDS2 - > fv ( 4 ) . get_asString ( ) ; <nl> + cast . emplace_back ( std : : move ( info ) ) ; <nl> + <nl> m_pDS2 - > next ( ) ; <nl> } <nl> m_pDS2 - > close ( ) ; <nl> void CVideoDatabase : : UpdateTables ( int iVersion ) <nl> <nl> int CVideoDatabase : : GetSchemaVersion ( ) const <nl> { <nl> - return 116 ; <nl> + return 117 ; <nl> } <nl> <nl> bool CVideoDatabase : : LookupByFolders ( const std : : string & path , bool shows ) <nl>\n", "msg": "[ videodb ] allow the same actor to appear multiple times in the same media with different roles\n"}
{"diff_id": 21893, "repo": "ocornut/imgui\n", "sha": "c4fc87950897ca5f0a1861c4f3d2a60d1f2f331a\n", "time": "2018-02-01T21:33:48Z\n", "diff": "mmm a / imgui . cpp <nl> ppp b / imgui . cpp <nl> bool ImGui : : CloseButton ( ImGuiID id , const ImVec2 & pos , float radius ) <nl> <nl> / / Render <nl> const ImU32 col = GetColorU32 ( ( held & & hovered ) ? ImGuiCol_CloseButtonActive : hovered ? ImGuiCol_CloseButtonHovered : ImGuiCol_CloseButton ) ; <nl> - const ImVec2 center = bb . GetCenter ( ) ; <nl> + ImVec2 center = bb . GetCenter ( ) ; <nl> window - > DrawList - > AddCircleFilled ( center , ImMax ( 2 . 0f , radius ) , col , 12 ) ; <nl> <nl> const float cross_extent = ( radius * 0 . 7071f ) - 1 . 0f ; <nl> if ( hovered ) <nl> { <nl> + center - = ImVec2 ( 0 . 5f , 0 . 5f ) ; <nl> window - > DrawList - > AddLine ( center + ImVec2 ( + cross_extent , + cross_extent ) , center + ImVec2 ( - cross_extent , - cross_extent ) , GetColorU32 ( ImGuiCol_Text ) ) ; <nl> window - > DrawList - > AddLine ( center + ImVec2 ( + cross_extent , - cross_extent ) , center + ImVec2 ( - cross_extent , + cross_extent ) , GetColorU32 ( ImGuiCol_Text ) ) ; <nl> } <nl>\n", "msg": "CloseButton : Fixed cross positioning .\n"}
{"diff_id": 21996, "repo": "bitcoin/bitcoin\n", "sha": "d9a4738c9d3d3c8c8a0ca4e7ee6ced721da15d53\n", "time": "2020-12-15T20:38:33Z\n", "diff": "mmm a / src / chainparams . cpp <nl> ppp b / src / chainparams . cpp <nl> class SigNetParams : public CChainParams { <nl> bin = ParseHex ( \" 512103ad5e0edad18cb1f0fc0d28a3d4f1f3e445640337489abb10404f2d1e086be430210359ef5021964fe22d6f8e05b2463c9540ce96883fe3b278760f048f5189f2e6c452ae \" ) ; <nl> vSeeds . emplace_back ( \" 178 . 128 . 221 . 177 \" ) ; <nl> vSeeds . emplace_back ( \" 2a01 : 7c8 : d005 : 390 : : 5 \" ) ; <nl> - vSeeds . emplace_back ( \" ntv3mtqw5wt63red . onion : 38333 \" ) ; <nl> + vSeeds . emplace_back ( \" v7ajjeirttkbnt32wpy3c6w3emwnfr3fkla7hpxcfokr3ysd3kqtzmqd . onion : 38333 \" ) ; <nl> <nl> consensus . nMinimumChainWork = uint256S ( \" 0x00000000000000000000000000000000000000000000000000000019fd16269a \" ) ; <nl> consensus . defaultAssumeValid = uint256S ( \" 0x0000002a1de0f46379358c1fd09906f7ac59adf3712323ed90eb59e4c183c020 \" ) ; / / 9434 <nl>\n", "msg": "Merge : Move signet onion seed from v2 to v3\n"}
{"diff_id": 22139, "repo": "notepad-plus-plus/notepad-plus-plus\n", "sha": "daafd77c515abefd8253f141a977eb3e79f4afe4\n", "time": "2016-07-18T23:21:36Z\n", "diff": "mmm a / PowerEditor / src / ScitillaComponent / AutoCompletion . cpp <nl> ppp b / PowerEditor / src / ScitillaComponent / AutoCompletion . cpp <nl> void AutoCompletion : : getCloseTag ( char * closeTag , size_t closeTagSize , size_t car <nl> if ( tagHead [ 1 ] = = ' / ' ) / / \" < / toto > \" will be ignored <nl> return ; <nl> <nl> + if ( tagHead [ 1 ] = = ' ? ' ) / / \" < ? \" ( Processing Instructions ) will be ignored <nl> + return ; <nl> + <nl> if ( strncmp ( tagHead , \" < ! - - \" , 4 ) = = 0 ) / / Comments will be ignored <nl> return ; <nl> <nl>\n", "msg": "Skip auto - complete of XML processing instructions\n"}
{"diff_id": 22303, "repo": "EOSIO/eos\n", "sha": "9723af53fe159df8d2ae1c6814cca1e6b85fe3a8\n", "time": "2019-07-27T03:34:23Z\n", "diff": "mmm a / plugins / producer_plugin / producer_plugin . cpp <nl> ppp b / plugins / producer_plugin / producer_plugin . cpp <nl> class producer_plugin_impl : public std : : enable_shared_from_this < producer_plugin <nl> return trx - > packed_trx ( ) - > get_unprunable_size ( ) + trx - > packed_trx ( ) - > get_prunable_size ( ) + sizeof ( * trx ) ; <nl> } <nl> <nl> + void add_size ( const transaction_metadata_ptr & trx ) { <nl> + auto size = calc_size ( trx ) ; <nl> + EOS_ASSERT ( size_in_bytes + size < max_incoming_transaction_queue_size , tx_resource_exhaustion , \" Transaction exceeded producer resource limit \" ) ; <nl> + size_in_bytes + = size ; <nl> + } <nl> + <nl> public : <nl> void set_max_incoming_transaction_queue_size ( uint64_t v ) { max_incoming_transaction_queue_size = v ; } <nl> <nl> void add ( const transaction_metadata_ptr & trx , bool persist_until_expired , next_function < transaction_trace_ptr > next ) { <nl> - auto size = calc_size ( trx ) ; <nl> - EOS_ASSERT ( size_in_bytes + size < max_incoming_transaction_queue_size , tx_resource_exhaustion , \" Transaction exceeded producer resource limit \" ) ; <nl> - size_in_bytes + = size ; <nl> + add_size ( trx ) ; <nl> + _incoming_transactions . emplace_back ( trx , persist_until_expired , std : : move ( next ) ) ; <nl> + } <nl> + <nl> + void add_front ( const transaction_metadata_ptr & trx , bool persist_until_expired , next_function < transaction_trace_ptr > next ) { <nl> + add_size ( trx ) ; <nl> _incoming_transactions . emplace_back ( trx , persist_until_expired , std : : move ( next ) ) ; <nl> } <nl> <nl> class producer_plugin_impl : public std : : enable_shared_from_this < producer_plugin <nl> auto trace = chain . push_transaction ( trx , deadline ) ; <nl> if ( trace - > except ) { <nl> if ( failure_is_subjective ( * trace - > except , deadline_is_subjective ) ) { <nl> - _pending_incoming_transactions . add ( trx , persist_until_expired , next ) ; <nl> + _pending_incoming_transactions . add_front ( trx , persist_until_expired , next ) ; <nl> if ( _pending_block_mode = = pending_block_mode : : producing ) { <nl> fc_dlog ( _trx_trace_log , \" [ TRX_TRACE ] Block $ { block_num } for producer $ { prod } COULD NOT FIT , tx : $ { txid } RETRYING \" , <nl> ( \" block_num \" , chain . head_block_num ( ) + 1 ) <nl>\n", "msg": "add to front of incoming_transaction_queue when block time / net exhausted so it will be the first one next time around\n"}
{"diff_id": 22339, "repo": "apple/swift\n", "sha": "498a71ceedd3932003db969353e046396033dd15\n", "time": "2015-04-28T14:27:25Z\n", "diff": "mmm a / stdlib / public / runtime / Metadata . cpp <nl> ppp b / stdlib / public / runtime / Metadata . cpp <nl> using namespace metadataimpl ; <nl> void * MetadataAllocator : : alloc ( size_t size ) { <nl> static const uintptr_t pagesizeMask = sysconf ( _SC_PAGESIZE ) - 1 ; <nl> <nl> + / / If the requested size is a page or larger , map page ( s ) for it <nl> + / / specifically . <nl> + if ( LLVM_UNLIKELY ( size > pagesizeMask ) ) { <nl> + auto mem = mmap ( nullptr , ( size + pagesizeMask ) & ~ pagesizeMask , <nl> + PROT_READ | PROT_WRITE , MAP_ANON | MAP_PRIVATE , <nl> + - 1 , 0 ) ; <nl> + if ( next = = MAP_FAILED ) <nl> + crash ( \" unable to allocate memory for metadata cache \" ) ; <nl> + return mem ; <nl> + } <nl> + <nl> char * end = next + size ; <nl> <nl> / / Allocate a new page if we need one . <nl>\n", "msg": "Runtime : Handle large metadata allocations .\n"}
{"diff_id": 22407, "repo": "mongodb/mongo\n", "sha": "29596f5f9681595b515469c8bc5a2d8bc8d8c0f5\n", "time": "2010-08-30T15:22:34Z\n", "diff": "mmm a / util / mmap . cpp <nl> ppp b / util / mmap . cpp <nl> namespace mongo { <nl> <nl> static set < MongoFile * > mmfiles ; <nl> static RWLock mmmutex ( \" rw : mmmutex \" ) ; <nl> - static mutex flush_mutex ( \" rw : flush_mutex \" ) ; <nl> <nl> void MongoFile : : destroyed ( ) { <nl> rwlock lk ( mmmutex , true ) ; <nl> namespace mongo { <nl> / * static * / int MongoFile : : flushAll ( bool sync ) { <nl> if ( ! sync ) { <nl> int num = 0 ; <nl> - scoped_lock flushlk ( flush_mutex ) ; <nl> rwlock lk ( mmmutex , false ) ; <nl> for ( set < MongoFile * > : : iterator i = mmfiles . begin ( ) ; i ! = mmfiles . end ( ) ; i + + ) { <nl> num + + ; <nl> namespace mongo { <nl> if ( ! f . get ( ) ) <nl> break ; <nl> <nl> - { <nl> - scoped_lock flushlk ( flush_mutex ) ; <nl> - f - > flush ( ) ; <nl> - } <nl> + f - > flush ( ) ; <nl> } <nl> return seen . size ( ) ; <nl> } <nl>\n", "msg": "Revert \" make sure only one flush happens at a time SERVER - 1163 \"\n", "score": 1}
{"diff_id": 22498, "repo": "godotengine/godot\n", "sha": "02c0edac60edda48a83cb007ad1e7bd2e58556ad\n", "time": "2020-09-29T11:01:01Z\n", "diff": "mmm a / scene / resources / resource_format_text . cpp <nl> ppp b / scene / resources / resource_format_text . cpp <nl> Error ResourceFormatSaverTextInstance : : save ( const String & p_path , const RES & p_r <nl> } <nl> <nl> for ( int i = 0 ; i < state - > get_connection_count ( ) ; i + + ) { <nl> + if ( i = = 0 ) { <nl> + f - > store_line ( \" \" ) ; <nl> + } <nl> + <nl> String connstr = \" [ connection \" ; <nl> connstr + = \" signal = \\ \" \" + String ( state - > get_connection_signal ( i ) ) + \" \\ \" \" ; <nl> connstr + = \" from = \\ \" \" + String ( state - > get_connection_source ( i ) . simplified ( ) ) + \" \\ \" \" ; <nl> Error ResourceFormatSaverTextInstance : : save ( const String & p_path , const RES & p_r <nl> <nl> Vector < NodePath > editable_instances = state - > get_editable_instances ( ) ; <nl> for ( int i = 0 ; i < editable_instances . size ( ) ; i + + ) { <nl> - f - > store_line ( \" \\ n [ editable path = \\ \" \" + editable_instances [ i ] . operator String ( ) + \" \\ \" ] \" ) ; <nl> + if ( i = = 0 ) { <nl> + f - > store_line ( \" \" ) ; <nl> + } <nl> + f - > store_line ( \" [ editable path = \\ \" \" + editable_instances [ i ] . operator String ( ) + \" \\ \" ] \" ) ; <nl> } <nl> } <nl> <nl>\n", "msg": "Improve appearance of [ connection ] and [ editable ] sections in . tscn files\n", "score": 1}
{"diff_id": 22549, "repo": "apple/swift\n", "sha": "68bba56cecf679f5dcf7e76012f1e80e3215cf6f\n", "time": "2013-08-01T18:39:20Z\n", "diff": "mmm a / unittests / Parse / LexerTests . cpp <nl> ppp b / unittests / Parse / LexerTests . cpp <nl> class LexerTest : public : : testing : : Test { <nl> <nl> public : <nl> <nl> - std : : vector < Token > tokenizeAndKeepEOF ( llvm : : SourceMgr & SM , <nl> - unsigned BufferID ) { <nl> - const llvm : : MemoryBuffer * Buffer = SM . getMemoryBuffer ( BufferID ) ; <nl> - Lexer L ( Buffer - > getBuffer ( ) , SM , / * Diags = * / nullptr , / * InSILMode = * / false ) ; <nl> + std : : vector < Token > tokenizeAndKeepEOF ( unsigned BufferID ) { <nl> + const llvm : : MemoryBuffer * Buffer = SourceMgr . getMemoryBuffer ( BufferID ) ; <nl> + Lexer L ( Buffer - > getBuffer ( ) , SourceMgr , / * Diags = * / nullptr , <nl> + / * InSILMode = * / false ) ; <nl> std : : vector < Token > Tokens ; <nl> do { <nl> Tokens . emplace_back ( ) ; <nl> class LexerTest : public : : testing : : Test { <nl> <nl> std : : vector < Token > Toks ; <nl> if ( KeepEOF ) <nl> - Toks = tokenizeAndKeepEOF ( SourceMgr , BufID ) ; <nl> + Toks = tokenizeAndKeepEOF ( BufID ) ; <nl> else <nl> Toks = tokenize ( SourceMgr , BufID , 0 , 0 , KeepComments ) ; <nl> EXPECT_EQ ( ExpectedTokens . size ( ) , Toks . size ( ) ) ; <nl>\n", "msg": "Lexer tests : simplify helper function : no need to pass down a SourceMgr\n"}
{"diff_id": 22618, "repo": "xbmc/xbmc\n", "sha": "6a0304af523137ccd51eb2072f7e04cfd203ffe5\n", "time": "2014-03-07T22:39:48Z\n", "diff": "mmm a / xbmc / music / infoscanner / MusicInfoScanner . cpp <nl> ppp b / xbmc / music / infoscanner / MusicInfoScanner . cpp <nl> INFO_RET CMusicInfoScanner : : DownloadAlbumInfo ( const CAlbum & album , const ADDON : : <nl> } <nl> <nl> / / handle nfo files <nl> - CStdString strNfo = URIUtils : : AddFileToFolder ( album . strPath , \" album . nfo \" ) ; <nl> + CStdString path = album . strPath ; <nl> + if ( path . empty ( ) ) <nl> + m_musicDatabase . GetAlbumPath ( album . idAlbum , path ) ; <nl> + <nl> + CStdString strNfo = URIUtils : : AddFileToFolder ( path , \" album . nfo \" ) ; <nl> CNfoFile : : NFOResult result = CNfoFile : : NO_NFO ; <nl> CNfoFile nfoReader ; <nl> if ( XFILE : : CFile : : Exists ( strNfo ) ) <nl> INFO_RET CMusicInfoScanner : : DownloadArtistInfo ( const CArtist & artist , const ADDO <nl> } <nl> <nl> / / handle nfo files <nl> - CStdString strNfo = URIUtils : : AddFileToFolder ( artist . strPath , \" artist . nfo \" ) ; <nl> + CStdString path = artist . strPath ; <nl> + if ( path . empty ( ) ) <nl> + m_musicDatabase . GetArtistPath ( artist . idArtist , path ) ; <nl> + <nl> + CStdString strNfo = URIUtils : : AddFileToFolder ( path , \" artist . nfo \" ) ; <nl> CNfoFile : : NFOResult result = CNfoFile : : NO_NFO ; <nl> CNfoFile nfoReader ; <nl> if ( XFILE : : CFile : : Exists ( strNfo ) ) <nl>\n", "msg": "[ music ] ensure we grab the path of albums and artists before looking for . nfo files - fixes\n"}
{"diff_id": 22666, "repo": "godotengine/godot\n", "sha": "75897710b301b7c5254ecd67099f31cb6ee840d5\n", "time": "2018-04-27T19:06:05Z\n", "diff": "mmm a / editor / plugins / animation_player_editor_plugin . cpp <nl> ppp b / editor / plugins / animation_player_editor_plugin . cpp <nl> void AnimationPlayerEditor : : _update_player ( ) { <nl> save_anim - > set_disabled ( animlist . size ( ) = = 0 ) ; <nl> tool_anim - > set_disabled ( player = = NULL ) ; <nl> onion_skinning - > set_disabled ( player = = NULL ) ; <nl> + pin - > set_disabled ( player = = NULL ) ; <nl> <nl> int active_idx = - 1 ; <nl> for ( List < StringName > : : Element * E = animlist . front ( ) ; E ; E = E - > next ( ) ) { <nl>\n", "msg": "Made the Pin button disable when no AnimationPlayer is selected .\n"}
{"diff_id": 22699, "repo": "yuzu-emu/yuzu\n", "sha": "9cd7485cd738cd2936dc31a34fda76860ff9d190\n", "time": "2018-04-24T16:00:56Z\n", "diff": "mmm a / src / core / hle / service / hid / hid . cpp <nl> ppp b / src / core / hle / service / hid / hid . cpp <nl> class IAppletResource final : public ServiceFramework < IAppletResource > { <nl> IPC : : ResponseBuilder rb { ctx , 2 , 1 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> rb . PushCopyObjects ( shared_mem ) ; <nl> - LOG_DEBUG ( Service_HID , \" called \" ) ; <nl> + NGLOG_DEBUG ( Service_HID , \" called \" ) ; <nl> } <nl> <nl> void LoadInputDevices ( ) { <nl> class IActiveVibrationDeviceList final : public ServiceFramework < IActiveVibratio <nl> void ActivateVibrationDevice ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> } ; <nl> <nl> class Hid final : public ServiceFramework < Hid > { <nl> IPC : : ResponseBuilder rb { ctx , 2 , 0 , 1 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> rb . PushIpcInterface < IAppletResource > ( applet_resource ) ; <nl> - LOG_DEBUG ( Service_HID , \" called \" ) ; <nl> + NGLOG_DEBUG ( Service_HID , \" called \" ) ; <nl> } <nl> <nl> void ActivateDebugPad ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void ActivateTouchScreen ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void ActivateMouse ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void ActivateKeyboard ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void StartSixAxisSensor ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void SetGyroscopeZeroDriftMode ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void SetSupportedNpadStyleSet ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void GetSupportedNpadStyleSet ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 3 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> rb . Push < u32 > ( 0 ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void SetSupportedNpadIdType ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void ActivateNpad ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void AcquireNpadStyleSetUpdateEventHandle ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 , 1 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> rb . PushCopyObjects ( event ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void GetPlayerLedPattern ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void SetNpadJoyHoldType ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void GetNpadJoyHoldType ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 3 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> rb . Push ( joy_hold_type ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void SetNpadJoyAssignmentModeSingleByDefault ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void SendVibrationValue ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void GetActualVibrationValue ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void SetNpadJoyAssignmentModeDual ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void SetNpadHandheldActivationMode ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void GetVibrationDeviceInfo ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 4 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> rb . Push < u64 > ( 0 ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> <nl> void CreateActiveVibrationDeviceList ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 , 0 , 1 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> rb . PushIpcInterface < IActiveVibrationDeviceList > ( ) ; <nl> - LOG_DEBUG ( Service_HID , \" called \" ) ; <nl> + NGLOG_DEBUG ( Service_HID , \" called \" ) ; <nl> } <nl> <nl> void SendVibrationValues ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> - LOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> + NGLOG_WARNING ( Service_HID , \" ( STUBBED ) called \" ) ; <nl> } <nl> } ; <nl> <nl>\n", "msg": "hid : Move logging macros over to new fmt - compatible ones\n"}
{"diff_id": 22745, "repo": "bitcoin/bitcoin\n", "sha": "d547a4433217061ef4791cfb4cdbab8cd8606074\n", "time": "2011-07-03T15:20:39Z\n", "diff": "mmm a / src / main . cpp <nl> ppp b / src / main . cpp <nl> map < COutPoint , CInPoint > mapNextTx ; <nl> map < uint256 , CBlockIndex * > mapBlockIndex ; <nl> uint256 hashGenesisBlock ( \" 0x000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f \" ) ; <nl> CBigNum bnProofOfWorkLimit ( ~ uint256 ( 0 ) > > 32 ) ; <nl> - const int nTotalBlocksEstimate = 131000 ; / / Conservative estimate of total nr of blocks on main chain <nl> - const int nInitialBlockThreshold = 10000 ; / / Regard blocks up until N - threshold as \" initial download \" <nl> + const int nTotalBlocksEstimate = 134444 ; / / Conservative estimate of total nr of blocks on main chain <nl> + const int nInitialBlockThreshold = 120 ; / / Regard blocks up until N - threshold as \" initial download \" <nl> CBlockIndex * pindexGenesisBlock = NULL ; <nl> int nBestHeight = - 1 ; <nl> CBigNum bnBestChainWork = 0 ; <nl> bool CBlock : : AcceptBlock ( ) <nl> ( nHeight = = 70567 & & hash ! = uint256 ( \" 0x00000000006a49b14bcf27462068f1264c961f11fa2e0eddd2be0791e1d4124a \" ) ) | | <nl> ( nHeight = = 74000 & & hash ! = uint256 ( \" 0x0000000000573993a3c9e41ce34471c079dcf5f52a0e824a81e7f953b8661a20 \" ) ) | | <nl> ( nHeight = = 105000 & & hash ! = uint256 ( \" 0x00000000000291ce28027faea320c8d2b054b2e0fe44a773f3eefb151d6bdc97 \" ) ) | | <nl> - ( nHeight = = 118000 & & hash ! = uint256 ( \" 0x000000000000774a7f8a7a12dc906ddb9e17e75d684f15e00f8767f9e8f36553 \" ) ) ) <nl> + ( nHeight = = 118000 & & hash ! = uint256 ( \" 0x000000000000774a7f8a7a12dc906ddb9e17e75d684f15e00f8767f9e8f36553 \" ) ) | | <nl> + ( nHeight = = 134444 & & hash ! = uint256 ( \" 0x00000000000005b12ffd4cd315cd34ffd4a594f430ac814c91184a0d42d2b0fe \" ) ) ) <nl> return error ( \" AcceptBlock ( ) : rejected by checkpoint lockin at % d \" , nHeight ) ; <nl> <nl> / / Write block to history file <nl> bool CBlock : : AcceptBlock ( ) <nl> if ( hashBestChain = = hash ) <nl> CRITICAL_BLOCK ( cs_vNodes ) <nl> BOOST_FOREACH ( CNode * pnode , vNodes ) <nl> - if ( nBestHeight > ( pnode - > nStartingHeight ! = - 1 ? pnode - > nStartingHeight - 2000 : 118000 ) ) <nl> + if ( nBestHeight > ( pnode - > nStartingHeight ! = - 1 ? pnode - > nStartingHeight - 2000 : 134444 ) ) <nl> pnode - > PushInventory ( CInv ( MSG_BLOCK , hash ) ) ; <nl> <nl> return true ; <nl>\n", "msg": "Block - chain lock - in at 134444\n"}
{"diff_id": 22746, "repo": "aseprite/aseprite\n", "sha": "e392934afcea257b8b6cc7e5f6bb666b0043cf4e\n", "time": "2017-08-22T12:03:17Z\n", "diff": "mmm a / src / app / file / ase_format . cpp <nl> ppp b / src / app / file / ase_format . cpp <nl> static bool ase_file_read_header ( FILE * f , ASE_Header * header ) <nl> <nl> header - > size = fgetl ( f ) ; <nl> header - > magic = fgetw ( f ) ; <nl> + <nl> + / / Developers can open any . ase file <nl> + # if ! defined ( ENABLE_DEVMODE ) <nl> if ( header - > magic ! = ASE_FILE_MAGIC ) <nl> return false ; <nl> + # endif <nl> <nl> header - > frames = fgetw ( f ) ; <nl> header - > width = fgetw ( f ) ; <nl> static bool ase_file_read_header ( FILE * f , ASE_Header * header ) <nl> header - > pixel_height = 1 ; <nl> } <nl> <nl> + # if defined ( ENABLE_DEVMODE ) <nl> + / / This is useful to read broken . ase files <nl> + if ( header - > magic ! = ASE_FILE_MAGIC ) { <nl> + header - > frames = 256 ; / / Frames number might be not enought for some files <nl> + header - > width = 1024 ; / / Size doesn ' t matter , the sprite can be crop <nl> + header - > height = 1024 ; <nl> + } <nl> + # endif <nl> + <nl> fseek ( f , header - > pos + 128 , SEEK_SET ) ; <nl> return true ; <nl> } <nl>\n", "msg": "Add possibility to open broken . ase files on devmode\n", "score": 1}
{"diff_id": 22838, "repo": "apple/swift\n", "sha": "ca6637909da4ca18dafdc5e307dc677c431cc548\n", "time": "2017-04-20T20:05:20Z\n", "diff": "mmm a / lib / Sema / TypeCheckAttr . cpp <nl> ppp b / lib / Sema / TypeCheckAttr . cpp <nl> class AttributeEarlyChecker : public AttributeVisitor < AttributeEarlyChecker > { <nl> / / ' final ' only makes sense in the context of a class declaration . <nl> / / Reject it on global functions , protocols , structs , enums , etc . <nl> if ( ! D - > getDeclContext ( ) - > getAsClassOrClassExtensionContext ( ) ) { <nl> - if ( D - > getDeclContext ( ) - > getAsProtocolExtensionContext ( ) ) <nl> + if ( TC . Context . isSwiftVersion3 ( ) & & <nl> + D - > getDeclContext ( ) - > getAsProtocolExtensionContext ( ) ) <nl> TC . diagnose ( attr - > getLocation ( ) , <nl> diag : : protocol_extension_cannot_be_final ) <nl> . fixItRemove ( attr - > getRange ( ) ) ; <nl>\n", "msg": "Only emit compatibility warning in Swift 3 mode\n"}
{"diff_id": 22999, "repo": "bitcoin/bitcoin\n", "sha": "b5c1467a7d7d261de5f87d6f26a00cf5ab230dfb\n", "time": "2012-08-31T15:41:58Z\n", "diff": "mmm a / src / qt / rpcconsole . cpp <nl> ppp b / src / qt / rpcconsole . cpp <nl> void RPCExecutor : : request ( const QString & command ) <nl> } <nl> if ( args . empty ( ) ) <nl> return ; / / Nothing to do <nl> - try { <nl> + try <nl> + { <nl> std : : string strPrint ; <nl> / / Convert argument list to JSON objects in method - dependent way , <nl> / / and pass it along with the method name to the dispatcher . <nl> void RPCExecutor : : request ( const QString & command ) <nl> } <nl> catch ( json_spirit : : Object & objError ) <nl> { <nl> - emit reply ( RPCConsole : : CMD_ERROR , QString : : fromStdString ( write_string ( json_spirit : : Value ( objError ) , false ) ) ) ; <nl> + try / / Nice formatting for standard - format error <nl> + { <nl> + int code = find_value ( objError , \" code \" ) . get_int ( ) ; <nl> + std : : string message = find_value ( objError , \" message \" ) . get_str ( ) ; <nl> + emit reply ( RPCConsole : : CMD_ERROR , QString : : fromStdString ( message ) + \" ( code \" + QString : : number ( code ) + \" ) \" ) ; <nl> + } <nl> + catch ( std : : runtime_error & ) / / raised when converting to invalid type , i . e . missing code or message <nl> + { <nl> + / / Show raw JSON object <nl> + emit reply ( RPCConsole : : CMD_ERROR , QString : : fromStdString ( write_string ( json_spirit : : Value ( objError ) , false ) ) ) ; <nl> + } <nl> } <nl> catch ( std : : exception & e ) <nl> { <nl>\n", "msg": "In RPC console , attempt to format errors\n"}
{"diff_id": 23047, "repo": "mongodb/mongo\n", "sha": "459d1f8b0d9b92581a5be293f78de88f7ca9220e\n", "time": "2012-04-11T03:21:55Z\n", "diff": "mmm a / src / mongo / shell / shell_utils_extended . cpp <nl> ppp b / src / mongo / shell / shell_utils_extended . cpp <nl> namespace mongo { <nl> * / <nl> BSONObj fuzzFile ( const BSONObj & args , void * data ) { <nl> uassert ( 13619 , \" fuzzFile takes 2 arguments \" , args . nFields ( ) = = 2 ) ; <nl> - shared_ptr < File > f ( new File ( ) ) ; <nl> + scoped_ptr < File > f ( new File ( ) ) ; <nl> f - > open ( args . getStringField ( \" 0 \" ) ) ; <nl> uassert ( 13620 , \" couldn ' t open file to fuzz \" , ! f - > bad ( ) & & f - > is_open ( ) ) ; <nl> <nl>\n", "msg": "Use scoped_ptr not shared_ptr in fuzzFile ( ) .\n"}
{"diff_id": 23048, "repo": "apple/foundationdb\n", "sha": "b3ea9d5896df7f1fab4095f69965c0ed776670aa\n", "time": "2020-03-05T02:45:26Z\n", "diff": "mmm a / fdbserver / ClusterController . actor . cpp <nl> ppp b / fdbserver / ClusterController . actor . cpp <nl> ACTOR Future < Void > failureDetectionServer ( UID uniqueID , ClusterControllerData * <nl> / / TraceEvent ( \" FailureDetectionPoll \" , uniqueID ) . detail ( \" PivotDelay \" , pivotDelay ) . detail ( \" Clients \" , currentStatus . size ( ) ) ; <nl> / / TraceEvent ( \" FailureDetectionAcceptableDelay \" ) . detail ( \" Delay \" , acceptableDelay1000 ) ; <nl> <nl> - bool tooManyLogGenerations = std : : max ( self - > db . unfinishedRecoveries , self - > db . logGenerations ) > CLIENT_KNOBS - > FAILURE_MAX_GENERATIONS ; <nl> + bool tooManyLogGenerations = ( std : : max ( self - > db . unfinishedRecoveries , self - > db . logGenerations ) > CLIENT_KNOBS - > FAILURE_MAX_GENERATIONS ) | | <nl> + ( now ( ) - self - > startTime < CLIENT_KNOBS - > FAILURE_EMERGENCY_DELAY ) ; <nl> <nl> for ( auto it = currentStatus . begin ( ) ; it ! = currentStatus . end ( ) ; ) { <nl> double delay = t - it - > second . lastRequestTime ; <nl>\n", "msg": "Do not allow the cluster controller to mark any process as failed within 30 seconds of startup\n", "score": 1}
{"diff_id": 23074, "repo": "apple/swift\n", "sha": "922b71f900f776c9885b76097995845ceb737ca8\n", "time": "2019-10-04T20:43:16Z\n", "diff": "mmm a / stdlib / public / runtime / HeapObject . cpp <nl> ppp b / stdlib / public / runtime / HeapObject . cpp <nl> static inline bool isValidPointerForNativeRetain ( const void * p ) { <nl> # endif <nl> } <nl> <nl> + / / Call the appropriate implementation of the ` name ` function , passing ` args ` <nl> + / / to the call . This checks for an override in the function pointer . If an <nl> + / / override is present , it calls that override . Otherwise it directly calls <nl> + / / the default implementation . This allows the compiler to inline the default <nl> + / / implementation and avoid the performance penalty of indirecting through <nl> + / / the function pointer in the common case . <nl> + # define CALL_IMPL ( name , args ) do { \\ <nl> + if ( SWIFT_UNLIKELY ( _ # # name ! = _ # # name # # _ ) ) \\ <nl> + return _ # # name args ; \\ <nl> + return _ # # name # # _ args ; \\ <nl> + } while ( 0 ) <nl> + <nl> + <nl> static HeapObject * _swift_allocObject_ ( HeapMetadata const * metadata , <nl> size_t requiredSize , <nl> size_t requiredAlignmentMask ) { <nl> static HeapObject * _swift_allocObject_ ( HeapMetadata const * metadata , <nl> HeapObject * swift : : swift_allocObject ( HeapMetadata const * metadata , <nl> size_t requiredSize , <nl> size_t requiredAlignmentMask ) { <nl> - if ( SWIFT_UNLIKELY ( _swift_allocObject ! = _swift_allocObject_ ) ) <nl> - return _swift_allocObject ( metadata , requiredSize , requiredAlignmentMask ) ; <nl> - return _swift_allocObject_ ( metadata , requiredSize , requiredAlignmentMask ) ; <nl> + CALL_IMPL ( swift_allocObject , ( metadata , requiredSize , requiredAlignmentMask ) ) ; <nl> } <nl> <nl> HeapObject * ( * swift : : _swift_allocObject ) ( HeapMetadata const * metadata , <nl> static HeapObject * _swift_retain_ ( HeapObject * object ) { <nl> } <nl> <nl> HeapObject * swift : : swift_retain ( HeapObject * object ) { <nl> - if ( SWIFT_UNLIKELY ( _swift_retain ! = _swift_retain_ ) ) <nl> - return _swift_retain ( object ) ; <nl> - return _swift_retain_ ( object ) ; <nl> + CALL_IMPL ( swift_retain , ( object ) ) ; <nl> } <nl> <nl> HeapObject * ( * swift : : _swift_retain ) ( HeapObject * object ) = _swift_retain_ ; <nl> static HeapObject * _swift_retain_n_ ( HeapObject * object , uint32_t n ) { <nl> } <nl> <nl> HeapObject * swift : : swift_retain_n ( HeapObject * object , uint32_t n ) { <nl> - if ( SWIFT_UNLIKELY ( _swift_retain_n ! = _swift_retain_n_ ) ) <nl> - return _swift_retain_n ( object , n ) ; <nl> - return _swift_retain_n_ ( object , n ) ; <nl> + CALL_IMPL ( swift_retain_n , ( object , n ) ) ; <nl> } <nl> <nl> HeapObject * ( * swift : : _swift_retain_n ) ( HeapObject * object , uint32_t n ) = <nl> static void _swift_release_ ( HeapObject * object ) { <nl> } <nl> <nl> void swift : : swift_release ( HeapObject * object ) { <nl> - if ( SWIFT_UNLIKELY ( _swift_release ! = _swift_release_ ) ) <nl> - _swift_release ( object ) ; <nl> - _swift_release_ ( object ) ; <nl> + CALL_IMPL ( swift_release , ( object ) ) ; <nl> } <nl> <nl> void ( * swift : : _swift_release ) ( HeapObject * object ) = _swift_release_ ; <nl> static void _swift_release_n_ ( HeapObject * object , uint32_t n ) { <nl> } <nl> <nl> void swift : : swift_release_n ( HeapObject * object , uint32_t n ) { <nl> - if ( SWIFT_UNLIKELY ( _swift_release_n ! = _swift_release_n_ ) ) <nl> - return _swift_release_n ( object , n ) ; <nl> - return _swift_release_n_ ( object , n ) ; <nl> + CALL_IMPL ( swift_release_n , ( object , n ) ) ; <nl> } <nl> <nl> void ( * swift : : _swift_release_n ) ( HeapObject * object , uint32_t n ) = <nl> static HeapObject * _swift_tryRetain_ ( HeapObject * object ) { <nl> } <nl> <nl> HeapObject * swift : : swift_tryRetain ( HeapObject * object ) { <nl> - if ( SWIFT_UNLIKELY ( _swift_tryRetain ! = _swift_tryRetain_ ) ) <nl> - return _swift_tryRetain ( object ) ; <nl> - return _swift_tryRetain_ ( object ) ; <nl> + CALL_IMPL ( swift_tryRetain , ( object ) ) ; <nl> } <nl> <nl> HeapObject * ( * swift : : _swift_tryRetain ) ( HeapObject * object ) = _swift_tryRetain_ ; <nl>\n", "msg": "[ Runtime ] Refactor HeapObject override checks to use a macro .\n", "score": 1}
{"diff_id": 23156, "repo": "ocornut/imgui\n", "sha": "a5600b6e5904c19cbfe752806778bb9122388cb1\n", "time": "2016-11-13T04:23:33Z\n", "diff": "mmm a / examples / vulkan_example / main . cpp <nl> ppp b / examples / vulkan_example / main . cpp <nl> static VkRenderPass g_RenderPass = VK_NULL_HANDLE ; <nl> static uint32_t g_QueueFamily = 0 ; <nl> static VkQueue g_Queue = VK_NULL_HANDLE ; <nl> <nl> - static VkFormat g_Format = VK_FORMAT_B8G8R8A8_UNORM ; <nl> + static VkFormat g_ImageFormat = VK_FORMAT_B8G8R8A8_UNORM ; <nl> static VkFormat g_ViewFormat = VK_FORMAT_B8G8R8A8_UNORM ; <nl> static VkColorSpaceKHR g_ColorSpace = VK_COLORSPACE_SRGB_NONLINEAR_KHR ; <nl> static VkImageSubresourceRange g_ImageRange = { VK_IMAGE_ASPECT_COLOR_BIT , 0 , 1 , 0 , 1 } ; <nl> static void resize_vulkan ( GLFWwindow * / * window * / , int w , int h ) <nl> VkSwapchainCreateInfoKHR info = { } ; <nl> info . sType = VK_STRUCTURE_TYPE_SWAPCHAIN_CREATE_INFO_KHR ; <nl> info . surface = g_Surface ; <nl> - info . imageFormat = g_Format ; <nl> + info . imageFormat = g_ImageFormat ; <nl> info . imageColorSpace = g_ColorSpace ; <nl> info . imageArrayLayers = 1 ; <nl> info . imageUsage | = VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT ; <nl> static void setup_vulkan ( GLFWwindow * window ) <nl> / / Get queue <nl> { <nl> uint32_t count ; <nl> - vkGetPhysicalDeviceQueueFamilyProperties ( g_Gpu , & count , nullptr ) ; <nl> + vkGetPhysicalDeviceQueueFamilyProperties ( g_Gpu , & count , NULL ) ; <nl> VkQueueFamilyProperties * queues = ( VkQueueFamilyProperties * ) malloc ( sizeof ( VkQueueFamilyProperties ) * count ) ; <nl> vkGetPhysicalDeviceQueueFamilyProperties ( g_Gpu , & count , queues ) ; <nl> for ( uint32_t i = 0 ; i < count ; i + + ) { <nl> static void setup_vulkan ( GLFWwindow * window ) <nl> } <nl> } <nl> <nl> - / / Get Surface Format ( WARNING here we assume the first format is the one we want ) <nl> + / / Get Surface Format <nl> { <nl> - uint32_t count = 1 ; <nl> - VkSurfaceFormatKHR format ; <nl> - vkGetPhysicalDeviceSurfaceFormatsKHR ( g_Gpu , g_Surface , & count , & format ) ; <nl> - g_Format = format . format ; <nl> - g_ColorSpace = format . colorSpace ; <nl> + VkFormat image_view_format [ ] [ 2 ] = { { VK_FORMAT_B8G8R8A8_UNORM , VK_FORMAT_B8G8R8A8_UNORM } , <nl> + { VK_FORMAT_B8G8R8A8_SRGB , VK_FORMAT_B8G8R8A8_UNORM } } ; <nl> + uint32_t count ; <nl> + vkGetPhysicalDeviceSurfaceFormatsKHR ( g_Gpu , g_Surface , & count , NULL ) ; <nl> + VkSurfaceFormatKHR * formats = ( VkSurfaceFormatKHR * ) malloc ( sizeof ( VkSurfaceFormatKHR ) * count ) ; <nl> + vkGetPhysicalDeviceSurfaceFormatsKHR ( g_Gpu , g_Surface , & count , formats ) ; <nl> + for ( size_t i = 0 ; i < sizeof ( image_view_format ) / sizeof ( image_view_format [ 0 ] ) ; i + + ) { <nl> + for ( uint32_t j = 0 ; j < count ; j + + ) { <nl> + if ( formats [ j ] . format = = image_view_format [ i ] [ 0 ] ) { <nl> + g_ImageFormat = image_view_format [ i ] [ 0 ] ; <nl> + g_ViewFormat = image_view_format [ i ] [ 1 ] ; <nl> + g_ColorSpace = formats [ j ] . colorSpace ; <nl> + } <nl> + } <nl> + } <nl> + free ( formats ) ; <nl> } <nl> <nl> / / Create Logical Device <nl>\n", "msg": "Vulkan example : Proper surface format search .\n"}
{"diff_id": 23194, "repo": "mongodb/mongo\n", "sha": "994f0a6a01fce88ce96a792f966e81c675d884c9\n", "time": "2011-07-18T15:54:50Z\n", "diff": "mmm a / db / repl / consensus . cpp <nl> ppp b / db / repl / consensus . cpp <nl> namespace mongo { <nl> public : <nl> CmdReplSetFresh ( ) : ReplSetCommand ( \" replSetFresh \" ) { } <nl> private : <nl> + bool shouldVeto ( const BSONObj & cmdObj , string & errmsg ) { <nl> + unsigned id = cmdObj [ \" id \" ] . Int ( ) ; <nl> + const Member * primary = theReplSet - > box . getPrimary ( ) ; <nl> + const Member * hopeful = theReplSet - > findById ( id ) ; <nl> + const Member * highestPriority = theReplSet - > getMostElectable ( ) ; <nl> + <nl> + if ( ! hopeful ) { <nl> + errmsg = str : : stream ( ) < < \" replSet couldn ' t find member with id \" < < id ; <nl> + return true ; <nl> + } <nl> + else if ( theReplSet - > isPrimary ( ) & & theReplSet - > lastOpTimeWritten > = hopeful - > hbinfo ( ) . opTime ) { <nl> + / / hbinfo is not updated , so we have to check the primary ' s last optime separately <nl> + errmsg = str : : stream ( ) < < \" I am already primary , \" < < hopeful - > fullName ( ) < < <nl> + \" can try again once I ' ve stepped down \" ; <nl> + return true ; <nl> + } <nl> + else if ( primary & & primary - > hbinfo ( ) . opTime > = hopeful - > hbinfo ( ) . opTime ) { <nl> + / / other members might be aware of more up - to - date nodes <nl> + errmsg = str : : stream ( ) < < hopeful - > fullName ( ) < < \" is trying to elect itself but \" < < <nl> + primary - > fullName ( ) < < \" is already primary and more up - to - date \" ; <nl> + return true ; <nl> + } <nl> + else if ( highestPriority & & highestPriority - > config ( ) . priority > hopeful - > config ( ) . priority ) { <nl> + errmsg = str : : stream ( ) < < hopeful - > fullName ( ) < < \" has lower priority than \" < < highestPriority - > fullName ( ) ; <nl> + return true ; <nl> + } <nl> + <nl> + / / don ' t veto older versions <nl> + if ( cmdObj [ \" id \" ] . eoo ( ) ) { <nl> + / / they won ' t be looking for the veto field <nl> + return false ; <nl> + } <nl> + <nl> + if ( ! hopeful | | ! theReplSet - > isElectable ( id ) | | <nl> + ( highestPriority & & highestPriority - > config ( ) . priority > hopeful - > config ( ) . priority ) ) { <nl> + return true ; <nl> + } <nl> + <nl> + return false ; <nl> + } <nl> + <nl> virtual bool run ( const string & , BSONObj & cmdObj , string & errmsg , BSONObjBuilder & result , bool fromRepl ) { <nl> if ( ! check ( errmsg , result ) ) <nl> return false ; <nl> namespace mongo { <nl> } <nl> result . appendDate ( \" opTime \" , theReplSet - > lastOpTimeWritten . asDate ( ) ) ; <nl> result . append ( \" fresher \" , weAreFresher ) ; <nl> - <nl> - / / don ' t veto older versions <nl> - if ( cmdObj [ \" id \" ] . eoo ( ) ) { <nl> - / / they won ' t be looking for the priorityVeto field <nl> - return true ; <nl> - } <nl> - <nl> - unsigned id = cmdObj [ \" id \" ] . Int ( ) ; <nl> - const Member * hopeful = theReplSet - > findById ( id ) ; <nl> - const Member * highestPriority = theReplSet - > getMostElectable ( ) ; <nl> - bool veto = false ; <nl> - if ( ! hopeful | | ! theReplSet - > isElectable ( id ) | | <nl> - ( highestPriority & & highestPriority - > config ( ) . priority > hopeful - > config ( ) . priority ) ) { <nl> - veto = true ; <nl> - } <nl> + result . append ( \" veto \" , shouldVeto ( cmdObj , errmsg ) ) ; <nl> <nl> - result . append ( \" priorityVeto \" , veto ) ; <nl> return true ; <nl> } <nl> } cmdReplSetFresh ; <nl> namespace mongo { <nl> nTies + + ; <nl> assert ( remoteOrd < = ord ) ; <nl> <nl> - if ( i - > result [ \" priorityVeto \" ] . trueValue ( ) ) { <nl> - log ( ) < < \" not electing self , \" < < i - > toHost < < \" thinks another member is more electable \" < < rsLog ; <nl> + if ( i - > result [ \" veto \" ] . trueValue ( ) ) { <nl> + BSONElement msg = i - > result [ \" errmsg \" ] ; <nl> + if ( ! msg . eoo ( ) ) { <nl> + log ( ) < < \" not electing self , \" < < i - > toHost < < \" would veto with ' \" < < <nl> + msg . String ( ) < < \" ' \" < < rsLog ; <nl> + } <nl> + else { <nl> + log ( ) < < \" not electing self , \" < < i - > toHost < < \" would veto \" < < rsLog ; <nl> + } <nl> return false ; <nl> } <nl> } <nl>\n", "msg": "cancel election if a member will veto SERVER - 3389\n"}
{"diff_id": 23647, "repo": "MarlinFirmware/Marlin\n", "sha": "72281c4ff968ac6d7edcb1546619baff29247aa5\n", "time": "2018-03-19T07:37:55Z\n", "diff": "mmm a / Marlin / src / Marlin . cpp <nl> ppp b / Marlin / src / Marlin . cpp <nl> void kill ( const char * lcd_msg ) { <nl> # endif <nl> <nl> # if HAS_POWER_SWITCH <nl> - SET_INPUT ( PS_ON_PIN ) ; <nl> + PSU_OFF ( ) ; <nl> # endif <nl> <nl> # if HAS_SUICIDE <nl>\n", "msg": "Turn power off in ` kill ` instead of setting PS_ON to input\n"}
{"diff_id": 23691, "repo": "osquery/osquery\n", "sha": "e6c838131be89023c7a76f8fe662e360a21e9b13\n", "time": "2015-05-05T23:14:24Z\n", "diff": "mmm a / osquery / database / db_handle . cpp <nl> ppp b / osquery / database / db_handle . cpp <nl> FLAG_ALIAS ( bool , use_in_memory_database , database_in_memory ) ; <nl> DBHandle : : DBHandle ( const std : : string & path , bool in_memory ) { <nl> options_ . create_if_missing = true ; <nl> options_ . create_missing_column_families = true ; <nl> + options_ . info_log_level = rocksdb : : WARN_LEVEL ; <nl> + options_ . log_file_time_to_roll = 0 ; <nl> + options_ . keep_log_file_num = 10 ; <nl> + options_ . max_log_file_size = 1024 * 1024 * 1 ; <nl> <nl> if ( in_memory ) { <nl> / / Remove when MemEnv is included in librocksdb <nl>\n", "msg": "Limit the number of RocksDB log files\n"}
{"diff_id": 24074, "repo": "facebook/hhvm\n", "sha": "e16600d61fff26b5b841deeb554a1902be379222\n", "time": "2019-06-21T03:42:51Z\n", "diff": "mmm a / hphp / runtime / vm / jit / irgen - builtin . cpp <nl> ppp b / hphp / runtime / vm / jit / irgen - builtin . cpp <nl> const StaticString <nl> s_container_last_key ( \" HH \\ \\ Lib \\ \\ _Private \\ \\ Native \\ \\ last_key \" ) , <nl> s_class_meth_get_class ( \" HH \\ \\ class_meth_get_class \" ) , <nl> s_class_meth_get_method ( \" HH \\ \\ class_meth_get_method \" ) , <nl> + s_shapes_idx ( \" HH \\ \\ Shapes : : idx \" ) , <nl> s_vm_switch_mode ( \" __VMSwitchMode \" ) , <nl> s_is_meth_caller ( \" HH \\ \\ is_meth_caller \" ) , <nl> s_meth_caller_get_class ( \" HH \\ \\ meth_caller_get_class \" ) , <nl> SSATmp * opt_class_meth_get_method ( IRGS & env , const ParamPrep & params ) { <nl> return nullptr ; <nl> } <nl> <nl> + SSATmp * opt_shapes_idx ( IRGS & env , const ParamPrep & params ) { <nl> + / / We first check the number and types of each argument . If any check fails , <nl> + / / we ' ll fall back to the native code which will raise an appropriate error . <nl> + auto const nparams = params . size ( ) ; <nl> + if ( nparams ! = 2 & & nparams ! = 3 ) return nullptr ; <nl> + <nl> + / / params [ 0 ] is a darray , which may be a Dict or an Arr based on options . <nl> + / / If the Hack typehint check flag is on , then we fall back to the native <nl> + / / implementation of this method , which checks the DVArray bit in ArrayData . <nl> + bool is_dict ; <nl> + auto const arrType = params [ 0 ] . value - > type ( ) ; <nl> + if ( RuntimeOption : : EvalHackArrDVArrs & & arrType < = TDict ) { <nl> + is_dict = true ; <nl> + } else if ( ! RuntimeOption : : EvalHackArrDVArrs & & arrType < = TArr ) { <nl> + if ( RuntimeOption : : EvalHackArrCompatTypeHintNotices ) return nullptr ; <nl> + is_dict = false ; <nl> + } else { <nl> + return nullptr ; <nl> + } <nl> + <nl> + / / params [ 1 ] is an arraykey . We only optimize if it ' s narrowed to int or str . <nl> + auto const keyType = params [ 1 ] . value - > type ( ) ; <nl> + if ( ! ( keyType < = TInt | | keyType < = TStr ) ) return nullptr ; <nl> + <nl> + / / params [ 2 ] is an optional argument . If it ' s uninit , we convert it to null . <nl> + / / We only optimize if we can distinguish between uninit and other types . <nl> + auto const defType = nparams = = 3 ? params [ 2 ] . value - > type ( ) : TUninit ; <nl> + if ( ! ( defType < = TUninit ) & & defType . maybe ( TUninit ) ) return nullptr ; <nl> + auto const def = defType < = TUninit ? cns ( env , TInitNull ) : params [ 2 ] . value ; <nl> + <nl> + / / Do the array access , using array offset profiling to optimize it . <nl> + auto const arr = params [ 0 ] . value ; <nl> + auto const key = params [ 1 ] . value ; <nl> + auto const elm = profiledArrayAccess ( env , arr , key , <nl> + [ & ] ( SSATmp * arr , SSATmp * key , uint32_t pos ) { <nl> + auto const op = is_dict ? DictGetK : MixedArrayGetK ; <nl> + return gen ( env , op , IndexData { pos } , arr , key ) ; <nl> + } , <nl> + [ & ] ( SSATmp * key ) { <nl> + auto const op = is_dict ? DictIdx : ArrayIdx ; <nl> + return gen ( env , op , arr , key , def ) ; <nl> + } <nl> + ) ; <nl> + auto const cell = is_dict ? elm : unbox ( env , elm , nullptr ) ; <nl> + gen ( env , IncRef , cell ) ; <nl> + return cell ; <nl> + } <nl> + <nl> SSATmp * opt_is_meth_caller ( IRGS & env , const ParamPrep & params ) { <nl> if ( params . size ( ) ! = 1 ) return nullptr ; <nl> auto const value = params [ 0 ] . value ; <nl> SSATmp * optimizedFCallBuiltin ( IRGS & env , <nl> X ( container_last_key ) <nl> X ( class_meth_get_class ) <nl> X ( class_meth_get_method ) <nl> + X ( shapes_idx ) <nl> X ( is_meth_caller ) <nl> X ( meth_caller_get_class ) <nl> X ( meth_caller_get_method ) <nl>\n", "msg": "Use array profiling to optimize Shapes : : idx\n"}
{"diff_id": 24136, "repo": "EOSIO/eos\n", "sha": "6fe60002f4f0b59eb82430f4304480b1a1d33299\n", "time": "2017-09-07T22:17:02Z\n", "diff": "mmm a / plugins / net_plugin / net_plugin . cpp <nl> ppp b / plugins / net_plugin / net_plugin . cpp <nl> namespace eos { <nl> fc : : datastream < char * > ds ( buffer . data ( ) , buffer . size ( ) ) ; <nl> ds . write ( ( char * ) & size , sizeof ( size ) ) ; <nl> fc : : raw : : pack ( ds , m ) ; <nl> + dlog ( \" send_next_message called , buffer size = $ { s } \" , ( \" s \" , buffer . size ( ) ) ) ; <nl> + <nl> <nl> boost : : asio : : async_write ( * socket , boost : : asio : : buffer ( buffer . data ( ) , buffer . size ( ) ) , <nl> [ this , buf = std : : move ( buffer ) ] ( boost : : system : : error_code ec , std : : size_t bytes_transferred ) { <nl> namespace eos { <nl> } else { <nl> out_queue . pop_front ( ) ; <nl> } <nl> + dlog ( \" after write , bytes_transferred = $ { bt } buf . size = $ { bs } \" , <nl> + ( \" bt \" , bytes_transferred ) ( \" bs \" , buf . size ( ) ) ) ; <nl> + <nl> send_next_message ( ) ; <nl> } <nl> } ) ; <nl> namespace eos { <nl> sync_state req = { low , high , sync_req_head , time_point : : now ( ) , vector < signed_block > ( ) } ; <nl> c - > in_sync_state . push_back ( req ) ; <nl> sync_request_message srm = { req . start_block , req . end_block } ; <nl> + dlog ( \" sending srm , from $ { s } to $ { e } \" , ( \" s \" , req . start_block ) ( \" e \" , req . end_block ) ) ; <nl> c - > send ( srm ) ; <nl> sync_req_head = high ; <nl> return ( sync_req_head = = sync_head ) ; <nl> } <nl> <nl> void set_sync_head ( uint32_t target ) { <nl> - uint32_t cchead = chain_plug - > chain ( ) . head_block_num ( ) ; <nl> if ( sync_head = = sync_req_head ) { <nl> sync_req_head = chain_plug - > chain ( ) . head_block_num ( ) ; <nl> } <nl> namespace eos { <nl> } <nl> } <nl> if ( chain_plug - > chain ( ) . head_block_num ( ) = = sync_head ) { <nl> - c - > send_handshake ( ) ; <nl> + handshake_message hello ; <nl> + handshake_initializer : : populate ( hello ) ; <nl> + send_all ( hello , [ c ] ( connection_ptr conn ) - > bool { <nl> + return true ; <nl> + } ) ; <nl> } <nl> <nl> return ; <nl>\n", "msg": "incremental fixes and debugging output .\n"}
{"diff_id": 24154, "repo": "EOSIO/eos\n", "sha": "5347ee8725319b36e5141fce1f8547c75b40bb80\n", "time": "2017-10-31T19:42:45Z\n", "diff": "mmm a / tests / tests / chain_tests . cpp <nl> ppp b / tests / tests / chain_tests . cpp <nl> <nl> <nl> using namespace eos ; <nl> using namespace chain ; <nl> - <nl> + using rate_limiting_type = eos : : chain : : testing_blockchain : : rate_limit_type ; <nl> <nl> BOOST_AUTO_TEST_SUITE ( chain_tests ) <nl> <nl> BOOST_FIXTURE_TEST_CASE ( get_required_keys , testing_fixture ) <nl> } FC_LOG_AND_RETHROW ( ) } <nl> <nl> / / Test chain_controller : : _transaction_message_rate message rate calculation <nl> - BOOST_FIXTURE_TEST_CASE ( transaction_msg_rate_calculation , testing_fixture ) <nl> + template < typename tx_msgs_exceeded > <nl> + void transaction_msg_rate_calculation ( rate_limiting_type account_type ) <nl> { try { <nl> uint32_t now = 0 ; <nl> uint32_t last_update_sec = 0 ; <nl> BOOST_FIXTURE_TEST_CASE ( transaction_msg_rate_calculation , testing_fixture ) <nl> uint32_t rate_limit = 10 ; <nl> uint32_t previous_rate = 9 ; <nl> auto rate = eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , previous_rate , \" account \" , N ( my . name ) ) ; <nl> + rate_limit , previous_rate , account_type , N ( my . name ) ) ; <nl> BOOST_CHECK_EQUAL ( 10 , rate ) ; <nl> <nl> previous_rate = 10 ; <nl> BOOST_CHECK_EXCEPTION ( eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , previous_rate , \" account \" , N ( my . name ) ) , \\ <nl> + rate_limit , previous_rate , account_type , N ( my . name ) ) , \\ <nl> tx_msgs_exceeded , <nl> [ ] ( tx_msgs_exceeded const & e ) - > bool { return true ; } ) ; <nl> <nl> last_update_sec = 10 ; <nl> now = 11 ; <nl> rate = eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , previous_rate , \" account \" , N ( my . name ) ) ; <nl> + rate_limit , previous_rate , account_type , N ( my . name ) ) ; <nl> BOOST_CHECK_EQUAL ( 10 , rate ) ; <nl> <nl> now = 12 ; <nl> rate = eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , previous_rate , \" account \" , N ( my . name ) ) ; <nl> + rate_limit , previous_rate , account_type , N ( my . name ) ) ; <nl> BOOST_CHECK_EQUAL ( 9 , rate ) ; <nl> <nl> now = 13 ; <nl> rate = eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , previous_rate , \" account \" , N ( my . name ) ) ; <nl> + rate_limit , previous_rate , account_type , N ( my . name ) ) ; <nl> BOOST_CHECK_EQUAL ( 8 , rate ) ; <nl> <nl> now = 19 ; <nl> rate = eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , previous_rate , \" account \" , N ( my . name ) ) ; <nl> + rate_limit , previous_rate , account_type , N ( my . name ) ) ; <nl> BOOST_CHECK_EQUAL ( 2 , rate ) ; <nl> <nl> now = 19 ; <nl> / / our scenario will never have a previous_rate higher than max ( since it was limited ) but just checking algorithm <nl> previous_rate = 90 ; <nl> rate = eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , previous_rate , \" account \" , N ( my . name ) ) ; <nl> + rate_limit , previous_rate , account_type , N ( my . name ) ) ; <nl> BOOST_CHECK_EQUAL ( 10 , rate ) ; <nl> <nl> now = 20 ; <nl> / / our scenario will never have a previous_rate higher than max ( since it was limited ) but just checking algorithm <nl> previous_rate = 10000 ; <nl> rate = eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , previous_rate , \" account \" , N ( my . name ) ) ; <nl> + rate_limit , previous_rate , account_type , N ( my . name ) ) ; <nl> BOOST_CHECK_EQUAL ( 1 , rate ) ; <nl> <nl> now = 2000 ; <nl> rate = eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , previous_rate , \" account \" , N ( my . name ) ) ; <nl> + rate_limit , previous_rate , account_type , N ( my . name ) ) ; <nl> BOOST_CHECK_EQUAL ( 1 , rate ) ; <nl> <nl> rate_limit_time_frame_sec = 10000 ; <nl> now = 2010 ; <nl> previous_rate = 10 ; <nl> rate = eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , previous_rate , \" account \" , N ( my . name ) ) ; <nl> + rate_limit , previous_rate , account_type , N ( my . name ) ) ; <nl> BOOST_CHECK_EQUAL ( 9 , rate ) ; <nl> <nl> rate_limit = 10000 ; <nl> BOOST_FIXTURE_TEST_CASE ( transaction_msg_rate_calculation , testing_fixture ) <nl> last_update_sec = 9999 ; <nl> previous_rate = 10000 ; <nl> rate = eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , previous_rate , \" account \" , N ( my . name ) ) ; <nl> + rate_limit , previous_rate , account_type , N ( my . name ) ) ; <nl> BOOST_CHECK_EQUAL ( 10000 , rate ) ; <nl> <nl> last_update_sec = 10000 ; <nl> BOOST_CHECK_EXCEPTION ( eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , previous_rate , \" account \" , N ( my . name ) ) , \\ <nl> + rate_limit , previous_rate , account_type , N ( my . name ) ) , \\ <nl> tx_msgs_exceeded , <nl> [ ] ( tx_msgs_exceeded const & e ) - > bool { return true ; } ) ; <nl> <nl> } FC_LOG_AND_RETHROW ( ) } <nl> <nl> / / Test chain_controller : : _transaction_message_rate message rate calculation <nl> - BOOST_FIXTURE_TEST_CASE ( transaction_msg_rate_running_calculation , testing_fixture ) <nl> + template < typename tx_msgs_exceeded > <nl> + void transaction_msg_rate_running_calculation ( rate_limiting_type account_type ) <nl> { try { <nl> uint32_t now = 1000 ; <nl> uint32_t last_update_sec = 1000 ; <nl> BOOST_FIXTURE_TEST_CASE ( transaction_msg_rate_running_calculation , testing_fixtur <nl> for ( uint32_t i = 0 ; i < 1000 ; + + i ) <nl> { <nl> rate = eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , rate , \" account \" , N ( my . name ) ) ; <nl> + rate_limit , rate , account_type , N ( my . name ) ) ; <nl> } <nl> BOOST_REQUIRE_EQUAL ( 1000 , rate ) ; <nl> <nl> BOOST_REQUIRE_EXCEPTION ( eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , rate , \" account \" , N ( my . name ) ) , \\ <nl> + rate_limit , rate , account_type , N ( my . name ) ) , \\ <nl> tx_msgs_exceeded , <nl> [ ] ( tx_msgs_exceeded const & e ) - > bool { return true ; } ) ; <nl> <nl> + + now ; <nl> rate = eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , rate , \" account \" , N ( my . name ) ) ; <nl> + rate_limit , rate , account_type , N ( my . name ) ) ; <nl> BOOST_REQUIRE_EQUAL ( 1000 , rate ) ; <nl> <nl> last_update_sec = now ; <nl> BOOST_REQUIRE_EXCEPTION ( eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , rate , \" account \" , N ( my . name ) ) , \\ <nl> + rate_limit , rate , account_type , N ( my . name ) ) , \\ <nl> tx_msgs_exceeded , <nl> [ ] ( tx_msgs_exceeded const & e ) - > bool { return true ; } ) ; <nl> <nl> now + = 10 ; <nl> rate = eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , rate , \" account \" , N ( my . name ) ) ; <nl> + rate_limit , rate , account_type , N ( my . name ) ) ; <nl> last_update_sec = now ; <nl> for ( uint32_t i = 0 ; i < 9 ; + + i ) <nl> { <nl> rate = eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , rate , \" account \" , N ( my . name ) ) ; <nl> + rate_limit , rate , account_type , N ( my . name ) ) ; <nl> } <nl> BOOST_REQUIRE_EQUAL ( 1000 , rate ) ; <nl> <nl> BOOST_REQUIRE_EXCEPTION ( eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , rate , \" account \" , N ( my . name ) ) , \\ <nl> + rate_limit , rate , account_type , N ( my . name ) ) , \\ <nl> tx_msgs_exceeded , <nl> [ ] ( tx_msgs_exceeded const & e ) - > bool { return true ; } ) ; <nl> <nl> BOOST_FIXTURE_TEST_CASE ( transaction_msg_rate_running_calculation , testing_fixtur <nl> <nl> now + = 10 ; <nl> rate = eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , rate , \" account \" , N ( my . name ) ) ; <nl> + rate_limit , rate , account_type , N ( my . name ) ) ; <nl> last_update_sec = now ; <nl> for ( uint32_t i = 0 ; i < 9 ; + + i ) <nl> { <nl> rate = eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , rate , \" account \" , N ( my . name ) ) ; <nl> + rate_limit , rate , account_type , N ( my . name ) ) ; <nl> } <nl> BOOST_REQUIRE_EQUAL ( 1000 , rate ) ; <nl> <nl> BOOST_REQUIRE_EXCEPTION ( eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , rate , \" account \" , N ( my . name ) ) , \\ <nl> + rate_limit , rate , account_type , N ( my . name ) ) , \\ <nl> tx_msgs_exceeded , <nl> [ ] ( tx_msgs_exceeded const & e ) - > bool { return true ; } ) ; <nl> } <nl> <nl> now + = 100 ; <nl> rate = eos : : chain : : chain_controller : : _transaction_message_rate ( now , last_update_sec , rate_limit_time_frame_sec , <nl> - rate_limit , rate , \" account \" , N ( my . name ) ) ; <nl> + rate_limit , rate , account_type , N ( my . name ) ) ; <nl> BOOST_REQUIRE_EQUAL ( 901 , rate ) ; <nl> } FC_LOG_AND_RETHROW ( ) } <nl> <nl> + BOOST_FIXTURE_TEST_CASE ( authorization_transaction_msg_rate_calculation , testing_fixture ) <nl> + { <nl> + transaction_msg_rate_calculation < tx_msgs_auth_exceeded > ( rate_limiting_type : : authorization_account ) ; <nl> + } <nl> + <nl> + BOOST_FIXTURE_TEST_CASE ( authorization_transaction_msg_rate_running_calculation , testing_fixture ) <nl> + { <nl> + transaction_msg_rate_running_calculation < tx_msgs_auth_exceeded > ( rate_limiting_type : : authorization_account ) ; <nl> + } <nl> + <nl> + BOOST_FIXTURE_TEST_CASE ( code_transaction_msg_rate_calculation , testing_fixture ) <nl> + { <nl> + transaction_msg_rate_calculation < tx_msgs_code_exceeded > ( rate_limiting_type : : code_account ) ; <nl> + } <nl> + <nl> + BOOST_FIXTURE_TEST_CASE ( code_transaction_msg_rate_running_calculation , testing_fixture ) <nl> + { <nl> + transaction_msg_rate_running_calculation < tx_msgs_code_exceeded > ( rate_limiting_type : : code_account ) ; <nl> + } <nl> + <nl> <nl> BOOST_AUTO_TEST_SUITE_END ( ) <nl>\n", "msg": "Made tests to verify reporting each type of rate limiting exception .\n"}
{"diff_id": 24219, "repo": "CRYTEK/CRYENGINE\n", "sha": "500e658dab34f08feffd96658fad01d723939548\n", "time": "2019-03-27T13:30:22Z\n", "diff": "mmm a / Code / Sandbox / Plugins / EditorAudioControlsEditor / SystemControlsWidget . cpp <nl> ppp b / Code / Sandbox / Plugins / EditorAudioControlsEditor / SystemControlsWidget . cpp <nl> void CSystemControlsWidget : : OnContextMenu ( QPoint const & pos ) <nl> } <nl> else if ( controlType = = EAssetType : : Preload ) <nl> { <nl> - if ( ! pControl - > IsAutoLoad ( ) ) <nl> + if ( ! pControl - > IsAutoLoad ( ) & & <nl> + ( ( pControl - > GetContextId ( ) = = CryAudio : : GlobalContextId ) | | <nl> + ( std : : find ( g_activeUserDefinedContexts . begin ( ) , g_activeUserDefinedContexts . end ( ) , pControl - > GetContextId ( ) ) ! = g_activeUserDefinedContexts . end ( ) ) ) ) <nl> { <nl> QAction * const pLoadAction = new QAction ( tr ( \" Load Preload Request \" ) , pContextMenu ) ; <nl> QAction * const pUnloadAction = new QAction ( tr ( \" Unload Preload Request \" ) , pContextMenu ) ; <nl> void CSystemControlsWidget : : OnContextMenu ( QPoint const & pos ) <nl> } <nl> else if ( controls . size ( ) > 1 ) <nl> { <nl> - bool hasOnlyGlobalPreloads = false ; <nl> + bool hasOnlyPreloadsInActiveContext = false ; <nl> <nl> for ( auto const pControl : controls ) <nl> { <nl> - if ( ( pControl - > GetType ( ) = = EAssetType : : Preload ) & & ( pControl - > GetContextId ( ) = = CryAudio : : GlobalContextId ) & & ! pControl - > IsAutoLoad ( ) ) <nl> + if ( ( pControl - > GetType ( ) = = EAssetType : : Preload ) & & <nl> + ! pControl - > IsAutoLoad ( ) & & <nl> + ( ( pControl - > GetContextId ( ) = = CryAudio : : GlobalContextId ) | | <nl> + ( std : : find ( g_activeUserDefinedContexts . begin ( ) , g_activeUserDefinedContexts . end ( ) , pControl - > GetContextId ( ) ) ! = g_activeUserDefinedContexts . end ( ) ) ) ) <nl> { <nl> - hasOnlyGlobalPreloads = true ; <nl> + hasOnlyPreloadsInActiveContext = true ; <nl> } <nl> else <nl> { <nl> - hasOnlyGlobalPreloads = false ; <nl> + hasOnlyPreloadsInActiveContext = false ; <nl> break ; <nl> } <nl> } <nl> <nl> - if ( hasOnlyGlobalPreloads ) <nl> + if ( hasOnlyPreloadsInActiveContext ) <nl> { <nl> - <nl> - QAction * const pLoadAction = new QAction ( tr ( \" Load Global Preload Requests \" ) , pContextMenu ) ; <nl> - QAction * const pUnloadAction = new QAction ( tr ( \" Unload Global Preload Requests \" ) , pContextMenu ) ; <nl> - QObject : : connect ( pLoadAction , & QAction : : triggered , [ & ] ( ) <nl> + QAction * const pLoadAction = new QAction ( tr ( \" Load reload Requests \" ) , pContextMenu ) ; <nl> + QAction * const pUnloadAction = new QAction ( tr ( \" Unload Preload Requests \" ) , pContextMenu ) ; <nl> + QObject : : connect ( pLoadAction , & QAction : : triggered , [ = ] ( ) <nl> { <nl> for ( auto const pControl : controls ) <nl> { <nl> void CSystemControlsWidget : : OnContextMenu ( QPoint const & pos ) <nl> } <nl> } ) ; <nl> <nl> - QObject : : connect ( pUnloadAction , & QAction : : triggered , [ & ] ( ) <nl> + QObject : : connect ( pUnloadAction , & QAction : : triggered , [ = ] ( ) <nl> { <nl> for ( auto const pControl : controls ) <nl> { <nl>\n", "msg": "! XT ( Audio ) ACE : Show option to load preload requests only when its context is active .\n"}
{"diff_id": 24250, "repo": "godotengine/godot\n", "sha": "ab12a5cf8e9fb6b12cfeb4a0a0e13671fca9ede0\n", "time": "2017-12-30T09:39:09Z\n", "diff": "mmm a / editor / editor_node . cpp <nl> ppp b / editor / editor_node . cpp <nl> void EditorNode : : _fs_changed ( ) { <nl> E - > get ( ) - > invalidate ( ) ; <nl> } <nl> <nl> - if ( export_defer . preset ! = \" \" ) { <nl> - Ref < EditorExportPreset > preset ; <nl> - for ( int i = 0 ; i < EditorExport : : get_singleton ( ) - > get_export_preset_count ( ) ; + + i ) { <nl> - preset = EditorExport : : get_singleton ( ) - > get_export_preset ( i ) ; <nl> - if ( preset - > get_name ( ) = = export_defer . preset ) { <nl> - break ; <nl> - } <nl> - preset . unref ( ) ; <nl> - } <nl> - if ( preset . is_null ( ) ) { <nl> - String err = \" Unknown export preset : \" + export_defer . preset ; <nl> - ERR_PRINT ( err . utf8 ( ) . get_data ( ) ) ; <nl> - } else { <nl> - Ref < EditorExportPlatform > platform = preset - > get_platform ( ) ; <nl> - if ( platform . is_null ( ) ) { <nl> - String err = \" Preset \\ \" \" + export_defer . preset + \" \\ \" doesn ' t have a platform . \" ; <nl> - ERR_PRINT ( err . utf8 ( ) . get_data ( ) ) ; <nl> - } else { <nl> - / / ensures export_project does not loop infinitely , because notifications may <nl> - / / come during the export <nl> - export_defer . preset = \" \" ; <nl> - if ( ! preset - > is_runnable ( ) & & ( export_defer . path . ends_with ( \" . pck \" ) | | export_defer . path . ends_with ( \" . zip \" ) ) ) { <nl> - if ( export_defer . path . ends_with ( \" . zip \" ) ) { <nl> - platform - > save_zip ( preset , export_defer . path ) ; <nl> - } else if ( export_defer . path . ends_with ( \" . pck \" ) ) { <nl> - platform - > save_pack ( preset , export_defer . path ) ; <nl> - } <nl> - } else { <nl> - platform - > export_project ( preset , export_defer . debug , export_defer . path , / * p_flags * / 0 ) ; <nl> - } <nl> - } <nl> - } <nl> - <nl> - get_tree ( ) - > quit ( ) ; <nl> - } <nl> - <nl> { <nl> / / reload changed resources <nl> List < Ref < Resource > > changed ; <nl> void EditorNode : : _fs_changed ( ) { <nl> } <nl> <nl> _mark_unsaved_scenes ( ) ; <nl> + <nl> + if ( export_defer . preset ! = \" \" & & ! EditorFileSystem : : get_singleton ( ) - > is_scanning ( ) ) { <nl> + Ref < EditorExportPreset > preset ; <nl> + for ( int i = 0 ; i < EditorExport : : get_singleton ( ) - > get_export_preset_count ( ) ; + + i ) { <nl> + preset = EditorExport : : get_singleton ( ) - > get_export_preset ( i ) ; <nl> + if ( preset - > get_name ( ) = = export_defer . preset ) { <nl> + break ; <nl> + } <nl> + preset . unref ( ) ; <nl> + } <nl> + if ( preset . is_null ( ) ) { <nl> + String err = \" Unknown export preset : \" + export_defer . preset ; <nl> + ERR_PRINT ( err . utf8 ( ) . get_data ( ) ) ; <nl> + } else { <nl> + Ref < EditorExportPlatform > platform = preset - > get_platform ( ) ; <nl> + if ( platform . is_null ( ) ) { <nl> + String err = \" Preset \\ \" \" + export_defer . preset + \" \\ \" doesn ' t have a platform . \" ; <nl> + ERR_PRINT ( err . utf8 ( ) . get_data ( ) ) ; <nl> + } else { <nl> + / / ensures export_project does not loop infinitely , because notifications may <nl> + / / come during the export <nl> + export_defer . preset = \" \" ; <nl> + if ( ! preset - > is_runnable ( ) & & ( export_defer . path . ends_with ( \" . pck \" ) | | export_defer . path . ends_with ( \" . zip \" ) ) ) { <nl> + if ( export_defer . path . ends_with ( \" . zip \" ) ) { <nl> + platform - > save_zip ( preset , export_defer . path ) ; <nl> + } else if ( export_defer . path . ends_with ( \" . pck \" ) ) { <nl> + platform - > save_pack ( preset , export_defer . path ) ; <nl> + } <nl> + } else { <nl> + platform - > export_project ( preset , export_defer . debug , export_defer . path , / * p_flags * / 0 ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + get_tree ( ) - > quit ( ) ; <nl> + } <nl> } <nl> <nl> void EditorNode : : _resources_reimported ( const Vector < String > & p_resources ) { <nl>\n", "msg": "Perform export after import is fully complete\n"}
{"diff_id": 24331, "repo": "apple/swift\n", "sha": "df1b64eaa7f88fbdae7839dc176d1f24ba4f5f57\n", "time": "2017-04-18T19:24:07Z\n", "diff": "mmm a / lib / IRGen / IRGenDebugInfo . cpp <nl> ppp b / lib / IRGen / IRGenDebugInfo . cpp <nl> llvm : : DIType * IRGenDebugInfo : : createType ( DebugTypeInfo DbgTy , <nl> auto IdTy = DBuilder . createForwardDecl ( <nl> llvm : : dwarf : : DW_TAG_structure_type , MangledName , Scope , File , 0 , <nl> llvm : : dwarf : : DW_LANG_ObjC , 0 , 0 ) ; <nl> - return DBuilder . createPointerType ( IdTy , PtrSize , 0 , MangledName ) ; <nl> + return DBuilder . createPointerType ( IdTy , PtrSize , 0 , <nl> + / * DWARFAddressSpace * / None , <nl> + MangledName ) ; <nl> } <nl> <nl> case TypeKind : : BuiltinNativeObject : { <nl> unsigned PtrSize = CI . getTargetInfo ( ) . getPointerWidth ( 0 ) ; <nl> - auto PTy = DBuilder . createPointerType ( nullptr , PtrSize , 0 , MangledName ) ; <nl> + auto PTy = DBuilder . createPointerType ( nullptr , PtrSize , 0 , <nl> + / * DWARFAddressSpace * / None , <nl> + MangledName ) ; <nl> return DBuilder . createObjectPointerType ( PTy ) ; <nl> } <nl> <nl> case TypeKind : : BuiltinBridgeObject : { <nl> unsigned PtrSize = CI . getTargetInfo ( ) . getPointerWidth ( 0 ) ; <nl> - auto PTy = DBuilder . createPointerType ( nullptr , PtrSize , 0 , MangledName ) ; <nl> + auto PTy = DBuilder . createPointerType ( nullptr , PtrSize , 0 , <nl> + / * DWARFAddressSpace * / None , <nl> + MangledName ) ; <nl> return DBuilder . createObjectPointerType ( PTy ) ; <nl> } <nl> <nl> case TypeKind : : BuiltinRawPointer : { <nl> unsigned PtrSize = CI . getTargetInfo ( ) . getPointerWidth ( 0 ) ; <nl> - return DBuilder . createPointerType ( nullptr , PtrSize , 0 , MangledName ) ; <nl> + return DBuilder . createPointerType ( nullptr , PtrSize , 0 , <nl> + / * DWARFAddressSpace * / None , <nl> + MangledName ) ; <nl> } <nl> <nl> case TypeKind : : DynamicSelf : { <nl>\n", "msg": "Update uses of DIBuilder . createPointerType to match LLVM r297320 .\n", "score": 1}
{"diff_id": 24397, "repo": "apple/swift\n", "sha": "a31c2ab4f758e0bdcb382871ed04308debf7db85\n", "time": "2014-07-15T23:36:49Z\n", "diff": "mmm a / lib / Frontend / CompilerInvocation . cpp <nl> ppp b / lib / Frontend / CompilerInvocation . cpp <nl> static bool ParseLangArgs ( LangOptions & Opts , ArgList & Args , <nl> = A - > getOption ( ) . matches ( OPT_enable_access_control ) ; <nl> } <nl> <nl> - Opts . ImportUnions = Args . hasArg ( OPT_enable_union_import ) ; <nl> + Opts . ImportUnions | = Args . hasArg ( OPT_enable_union_import ) ; <nl> <nl> - Opts . EnableDynamic = Args . hasArg ( OPT_enable_dynamic ) ; <nl> + Opts . EnableDynamic | = Args . hasArg ( OPT_enable_dynamic ) ; <nl> <nl> Opts . DebugConstraintSolver | = Args . hasArg ( OPT_debug_constraints ) ; <nl> <nl>\n", "msg": "Make it easier to tweak the EnableDynamic and ImportUnion flags in testing .\n", "score": 1}
{"diff_id": 24483, "repo": "xbmc/xbmc\n", "sha": "7faf41132e3ff9ad38013f7395c42c62386477b0\n", "time": "2012-08-13T15:36:32Z\n", "diff": "mmm a / xbmc / guilib / GraphicContext . cpp <nl> ppp b / xbmc / guilib / GraphicContext . cpp <nl> void CGraphicContext : : ResetOverscan ( RESOLUTION res , OVERSCAN & overscan ) <nl> overscan . right = 960 ; <nl> overscan . bottom = 1080 ; <nl> break ; <nl> + case RES_HDTV_1080pTB : <nl> + overscan . right = 1920 ; <nl> + overscan . bottom = 540 ; <nl> + break ; <nl> case RES_HDTV_720p : <nl> overscan . right = 1280 ; <nl> overscan . bottom = 720 ; <nl>\n", "msg": "[ rbp ] added missing mode from b0f57b850b5b51710f84e94e94a5125d82017580\n"}
{"diff_id": 24484, "repo": "xbmc/xbmc\n", "sha": "0a093f88915e63491b56af2991239fab8c2b64b7\n", "time": "2014-07-02T06:32:36Z\n", "diff": "mmm a / xbmc / filesystem / posix / PosixDirectory . cpp <nl> ppp b / xbmc / filesystem / posix / PosixDirectory . cpp <nl> bool CPosixDirectory : : Remove ( const CURL & url ) <nl> <nl> bool CPosixDirectory : : Exists ( const CURL & url ) <nl> { <nl> + std : : string path = url . Get ( ) ; <nl> + <nl> + if ( IsAliasShortcut ( path ) ) <nl> + TranslateAliasShortcut ( path ) ; <nl> + <nl> struct stat buffer ; <nl> - if ( stat ( url . Get ( ) . c_str ( ) , & buffer ) ! = 0 ) <nl> + if ( stat ( path . c_str ( ) , & buffer ) ! = 0 ) <nl> return false ; <nl> return S_ISDIR ( buffer . st_mode ) ? true : false ; <nl> } <nl>\n", "msg": "[ posixdirectory ] changed IsAliasShortcut handling\n"}
{"diff_id": 24618, "repo": "apple/swift\n", "sha": "f32af9b047c6108e2333988c81fb6c08859e2e14\n", "time": "2019-12-18T22:15:51Z\n", "diff": "mmm a / stdlib / public / runtime / Metadata . cpp <nl> ppp b / stdlib / public / runtime / Metadata . cpp <nl> static void initGenericClassObjCName ( ClassMetadata * theClass ) { <nl> getROData ( theMetaclass ) - > Name = name ; <nl> } <nl> <nl> - static bool installLazyClassNameHandler ( ) { <nl> - auto _objc_setLazyClassNamer = <nl> - ( void ( * ) ( char * ( * ) ( Class ) ) ) <nl> - dlsym ( RTLD_NEXT , \" _objc_setLazyClassNamer \" ) ; <nl> - if ( _objc_setLazyClassNamer = = nullptr ) <nl> - return false ; <nl> + static bool installLazyClassNameHook ( ) { <nl> + # if ! OBJC_SETHOOK_LAZYCLASSNAMER_DEFINED <nl> + using objc_hook_lazyClassNamer = <nl> + const char * _Nullable ( * ) ( _Nonnull Class cls ) ; <nl> + auto objc_setHook_lazyClassNamer = <nl> + ( void ( * ) ( objc_hook_lazyClassNamer , objc_hook_lazyClassNamer * ) ) <nl> + dlsym ( RTLD_NEXT , \" objc_setHook_lazyClassNamer \" ) ; <nl> + # endif <nl> <nl> - _objc_setLazyClassNamer ( [ ] ( Class theClass ) { <nl> + static objc_hook_lazyClassNamer oldHook ; <nl> + auto myHook = [ ] ( Class theClass ) - > const char * { <nl> ClassMetadata * metadata = ( ClassMetadata * ) theClass ; <nl> - return copyGenericClassObjCName ( metadata ) ; <nl> - } ) ; <nl> + if ( metadata - > isTypeMetadata ( ) ) <nl> + return copyGenericClassObjCName ( metadata ) ; <nl> + return oldHook ( theClass ) ; <nl> + } ; <nl> + <nl> + # pragma clang diagnostic push <nl> + # pragma clang diagnostic ignored \" - Wunguarded - availability \" <nl> + if ( objc_setHook_lazyClassNamer = = nullptr ) <nl> + return false ; <nl> + objc_setHook_lazyClassNamer ( myHook , & oldHook ) ; <nl> + # pragma clang diagnostic pop <nl> + <nl> return true ; <nl> } <nl> <nl> static void setUpGenericClassObjCName ( ClassMetadata * theClass ) { <nl> - bool supportsLazyNames = SWIFT_LAZY_CONSTANT ( installLazyClassNameHandler ( ) ) ; <nl> + bool supportsLazyNames = SWIFT_LAZY_CONSTANT ( installLazyClassNameHook ( ) ) ; <nl> if ( supportsLazyNames ) { <nl> getROData ( theClass ) - > Name = nullptr ; <nl> auto theMetaclass = ( ClassMetadata * ) object_getClass ( ( id ) theClass ) ; <nl>\n", "msg": "[ Runtime ] Adjust lazy name API to a hook - based call that can have multiple hooks . Use the API from the headers if present .\n"}
{"diff_id": 24652, "repo": "apple/swift\n", "sha": "81f851131dfb02a82832b3535cb0a8eef8ee781f\n", "time": "2016-01-16T04:12:35Z\n", "diff": "mmm a / lib / ClangImporter / ImportDecl . cpp <nl> ppp b / lib / ClangImporter / ImportDecl . cpp <nl> StringRef ClangImporter : : Implementation : : getCFTypeName ( <nl> <nl> if ( auto pointee = CFPointeeInfo : : classifyTypedef ( decl ) ) { <nl> auto name = decl - > getName ( ) ; <nl> - if ( pointee . isRecord ( ) ) { <nl> + if ( pointee . isRecord ( ) | | pointee . isTypedef ( ) ) { <nl> auto resultName = getImportedCFTypeName ( name ) ; <nl> if ( secondaryName & & name ! = resultName ) <nl> * secondaryName = name ; <nl> StringRef ClangImporter : : Implementation : : getCFTypeName ( <nl> return resultName ; <nl> } <nl> <nl> - if ( pointee . isTypedef ( ) & & secondaryName ) { <nl> - StringRef otherName = getImportedCFTypeName ( name ) ; <nl> - if ( otherName ! = name ) <nl> - * secondaryName = otherName ; <nl> - } <nl> - <nl> return name ; <nl> } <nl> <nl> namespace { <nl> return nullptr ; <nl> <nl> / / If there is an alias ( i . e . , that doesn ' t have \" Ref \" ) , <nl> - / / create that separate typedef . <nl> + / / use that as the name of the typedef later ; create a separate <nl> + / / typedef for the one with \" Ref \" . <nl> if ( importedName . Alias ) { <nl> auto aliasWithoutRef = <nl> Impl . createDeclWithClangNode < TypeAliasDecl > ( <nl> Decl , <nl> Impl . importSourceLoc ( Decl - > getLocStart ( ) ) , <nl> - importedName . Alias . getBaseName ( ) , <nl> + Name , <nl> Impl . importSourceLoc ( Decl - > getLocation ( ) ) , <nl> TypeLoc : : withoutLoc ( SwiftType ) , <nl> DC ) ; <nl> namespace { <nl> aliasWithoutRef - > computeType ( ) ; <nl> SwiftType = aliasWithoutRef - > getDeclaredType ( ) ; <nl> NameMapping = MappedTypeNameKind : : DefineOnly ; <nl> + Name = importedName . Alias . getBaseName ( ) ; <nl> <nl> / / Store this alternative declaration . <nl> alternateDecl = aliasWithoutRef ; <nl>\n", "msg": "[ ClangImporter ] Be consistent for CF types about whether \" Ref \" is the alias .\n"}
{"diff_id": 24670, "repo": "facebook/hhvm\n", "sha": "23a6c4cdcd4f02608f24db68994df707804d7653\n", "time": "2012-11-28T18:54:41Z\n", "diff": "mmm a / src / runtime / base / server / http_protocol . cpp <nl> ppp b / src / runtime / base / server / http_protocol . cpp <nl> void HttpProtocol : : PrepareSystemVariables ( Transport * transport , <nl> if ( server . asArrRef ( ) . exists ( key ) ) { <nl> if ( ! ( + + bad_request_count % RuntimeOption : : LogHeaderMangle ) ) { <nl> Logger : : Warning ( <nl> + \" HeaderMangle warning : \" <nl> \" The header % s overwrote another header which mapped to the same \" <nl> \" key . This happens because PHP normalises - to _ , ie AN_EXAMPLE \" <nl> \" and AN - EXAMPLE are equivalent . You should treat this as \" <nl>\n", "msg": "Made the log line for HeaderMangle more greppable\n"}
{"diff_id": 24756, "repo": "yuzu-emu/yuzu\n", "sha": "d01d1f7e016253dd6e7f7d13a0054eeed35eaba2\n", "time": "2016-01-25T04:29:44Z\n", "diff": "mmm a / src / video_core / pica . cpp <nl> ppp b / src / video_core / pica . cpp <nl> namespace Pica { <nl> <nl> State g_state ; <nl> <nl> + static const std : : pair < u16 , const char * > register_names [ ] = { <nl> + { 0x010 , \" GPUREG_FINALIZE \" } , <nl> + <nl> + { 0x040 , \" GPUREG_FACECULLING_CONFIG \" } , <nl> + { 0x041 , \" GPUREG_VIEWPORT_WIDTH \" } , <nl> + { 0x042 , \" GPUREG_VIEWPORT_INVW \" } , <nl> + { 0x043 , \" GPUREG_VIEWPORT_HEIGHT \" } , <nl> + { 0x044 , \" GPUREG_VIEWPORT_INVH \" } , <nl> + <nl> + { 0x047 , \" GPUREG_FRAGOP_CLIP \" } , <nl> + { 0x048 , \" GPUREG_FRAGOP_CLIP_DATA0 \" } , <nl> + { 0x049 , \" GPUREG_FRAGOP_CLIP_DATA1 \" } , <nl> + { 0x04A , \" GPUREG_FRAGOP_CLIP_DATA2 \" } , <nl> + { 0x04B , \" GPUREG_FRAGOP_CLIP_DATA3 \" } , <nl> + <nl> + { 0x04D , \" GPUREG_DEPTHMAP_SCALE \" } , <nl> + { 0x04E , \" GPUREG_DEPTHMAP_OFFSET \" } , <nl> + { 0x04F , \" GPUREG_SH_OUTMAP_TOTAL \" } , <nl> + { 0x050 , \" GPUREG_SH_OUTMAP_O0 \" } , <nl> + { 0x051 , \" GPUREG_SH_OUTMAP_O1 \" } , <nl> + { 0x052 , \" GPUREG_SH_OUTMAP_O2 \" } , <nl> + { 0x053 , \" GPUREG_SH_OUTMAP_O3 \" } , <nl> + { 0x054 , \" GPUREG_SH_OUTMAP_O4 \" } , <nl> + { 0x055 , \" GPUREG_SH_OUTMAP_O5 \" } , <nl> + { 0x056 , \" GPUREG_SH_OUTMAP_O6 \" } , <nl> + <nl> + { 0x061 , \" GPUREG_EARLYDEPTH_FUNC \" } , <nl> + { 0x062 , \" GPUREG_EARLYDEPTH_TEST1 \" } , <nl> + { 0x063 , \" GPUREG_EARLYDEPTH_CLEAR \" } , <nl> + { 0x064 , \" GPUREG_SH_OUTATTR_MODE \" } , <nl> + { 0x065 , \" GPUREG_SCISSORTEST_MODE \" } , <nl> + { 0x066 , \" GPUREG_SCISSORTEST_POS \" } , <nl> + { 0x067 , \" GPUREG_SCISSORTEST_DIM \" } , <nl> + { 0x068 , \" GPUREG_VIEWPORT_XY \" } , <nl> + <nl> + { 0x06A , \" GPUREG_EARLYDEPTH_DATA \" } , <nl> + <nl> + { 0x06D , \" GPUREG_DEPTHMAP_ENABLE \" } , <nl> + { 0x06E , \" GPUREG_RENDERBUF_DIM \" } , <nl> + { 0x06F , \" GPUREG_SH_OUTATTR_CLOCK \" } , <nl> + <nl> + { 0x080 , \" GPUREG_TEXUNIT_CONFIG \" } , <nl> + { 0x081 , \" GPUREG_TEXUNIT0_BORDER_COLOR \" } , <nl> + { 0x082 , \" GPUREG_TEXUNIT0_DIM \" } , <nl> + { 0x083 , \" GPUREG_TEXUNIT0_PARAM \" } , <nl> + { 0x084 , \" GPUREG_TEXUNIT0_LOD \" } , <nl> + { 0x085 , \" GPUREG_TEXUNIT0_ADDR1 \" } , <nl> + { 0x086 , \" GPUREG_TEXUNIT0_ADDR2 \" } , <nl> + { 0x087 , \" GPUREG_TEXUNIT0_ADDR3 \" } , <nl> + { 0x088 , \" GPUREG_TEXUNIT0_ADDR4 \" } , <nl> + { 0x089 , \" GPUREG_TEXUNIT0_ADDR5 \" } , <nl> + { 0x08A , \" GPUREG_TEXUNIT0_ADDR6 \" } , <nl> + { 0x08B , \" GPUREG_TEXUNIT0_SHADOW \" } , <nl> + <nl> + { 0x08E , \" GPUREG_TEXUNIT0_TYPE \" } , <nl> + { 0x08F , \" GPUREG_LIGHTING_ENABLE0 \" } , <nl> + <nl> + { 0x091 , \" GPUREG_TEXUNIT1_BORDER_COLOR \" } , <nl> + { 0x092 , \" GPUREG_TEXUNIT1_DIM \" } , <nl> + { 0x093 , \" GPUREG_TEXUNIT1_PARAM \" } , <nl> + { 0x094 , \" GPUREG_TEXUNIT1_LOD \" } , <nl> + { 0x095 , \" GPUREG_TEXUNIT1_ADDR \" } , <nl> + { 0x096 , \" GPUREG_TEXUNIT1_TYPE \" } , <nl> + <nl> + { 0x099 , \" GPUREG_TEXUNIT2_BORDER_COLOR \" } , <nl> + { 0x09A , \" GPUREG_TEXUNIT2_DIM \" } , <nl> + { 0x09B , \" GPUREG_TEXUNIT2_PARAM \" } , <nl> + { 0x09C , \" GPUREG_TEXUNIT2_LOD \" } , <nl> + { 0x09D , \" GPUREG_TEXUNIT2_ADDR \" } , <nl> + { 0x09E , \" GPUREG_TEXUNIT2_TYPE \" } , <nl> + <nl> + { 0x0A8 , \" GPUREG_TEXUNIT3_PROCTEX0 \" } , <nl> + { 0x0A9 , \" GPUREG_TEXUNIT3_PROCTEX1 \" } , <nl> + { 0x0AA , \" GPUREG_TEXUNIT3_PROCTEX2 \" } , <nl> + { 0x0AB , \" GPUREG_TEXUNIT3_PROCTEX3 \" } , <nl> + { 0x0AC , \" GPUREG_TEXUNIT3_PROCTEX4 \" } , <nl> + { 0x0AD , \" GPUREG_TEXUNIT3_PROCTEX5 \" } , <nl> + <nl> + { 0x0AF , \" GPUREG_PROCTEX_LUT \" } , <nl> + { 0x0B0 , \" GPUREG_PROCTEX_LUT_DATA0 \" } , <nl> + { 0x0B1 , \" GPUREG_PROCTEX_LUT_DATA1 \" } , <nl> + { 0x0B2 , \" GPUREG_PROCTEX_LUT_DATA2 \" } , <nl> + { 0x0B3 , \" GPUREG_PROCTEX_LUT_DATA3 \" } , <nl> + { 0x0B4 , \" GPUREG_PROCTEX_LUT_DATA4 \" } , <nl> + { 0x0B5 , \" GPUREG_PROCTEX_LUT_DATA5 \" } , <nl> + { 0x0B6 , \" GPUREG_PROCTEX_LUT_DATA6 \" } , <nl> + { 0x0B7 , \" GPUREG_PROCTEX_LUT_DATA7 \" } , <nl> + <nl> + { 0x0C0 , \" GPUREG_TEXENV0_SOURCE \" } , <nl> + { 0x0C1 , \" GPUREG_TEXENV0_OPERAND \" } , <nl> + { 0x0C2 , \" GPUREG_TEXENV0_COMBINER \" } , <nl> + { 0x0C3 , \" GPUREG_TEXENV0_COLOR \" } , <nl> + { 0x0C4 , \" GPUREG_TEXENV0_SCALE \" } , <nl> + <nl> + { 0x0C8 , \" GPUREG_TEXENV1_SOURCE \" } , <nl> + { 0x0C9 , \" GPUREG_TEXENV1_OPERAND \" } , <nl> + { 0x0CA , \" GPUREG_TEXENV1_COMBINER \" } , <nl> + { 0x0CB , \" GPUREG_TEXENV1_COLOR \" } , <nl> + { 0x0CC , \" GPUREG_TEXENV1_SCALE \" } , <nl> + <nl> + { 0x0D0 , \" GPUREG_TEXENV2_SOURCE \" } , <nl> + { 0x0D1 , \" GPUREG_TEXENV2_OPERAND \" } , <nl> + { 0x0D2 , \" GPUREG_TEXENV2_COMBINER \" } , <nl> + { 0x0D3 , \" GPUREG_TEXENV2_COLOR \" } , <nl> + { 0x0D4 , \" GPUREG_TEXENV2_SCALE \" } , <nl> + <nl> + { 0x0D8 , \" GPUREG_TEXENV3_SOURCE \" } , <nl> + { 0x0D9 , \" GPUREG_TEXENV3_OPERAND \" } , <nl> + { 0x0DA , \" GPUREG_TEXENV3_COMBINER \" } , <nl> + { 0x0DB , \" GPUREG_TEXENV3_COLOR \" } , <nl> + { 0x0DC , \" GPUREG_TEXENV3_SCALE \" } , <nl> + <nl> + { 0x0E0 , \" GPUREG_TEXENV_UPDATE_BUFFER \" } , <nl> + { 0x0E1 , \" GPUREG_FOG_COLOR \" } , <nl> + <nl> + { 0x0E4 , \" GPUREG_GAS_ATTENUATION \" } , <nl> + { 0x0E5 , \" GPUREG_GAS_ACCMAX \" } , <nl> + { 0x0E6 , \" GPUREG_FOG_LUT_INDEX \" } , <nl> + <nl> + { 0x0E8 , \" GPUREG_FOG_LUT_DATA0 \" } , <nl> + { 0x0E9 , \" GPUREG_FOG_LUT_DATA1 \" } , <nl> + { 0x0EA , \" GPUREG_FOG_LUT_DATA2 \" } , <nl> + { 0x0EB , \" GPUREG_FOG_LUT_DATA3 \" } , <nl> + { 0x0EC , \" GPUREG_FOG_LUT_DATA4 \" } , <nl> + { 0x0ED , \" GPUREG_FOG_LUT_DATA5 \" } , <nl> + { 0x0EE , \" GPUREG_FOG_LUT_DATA6 \" } , <nl> + { 0x0EF , \" GPUREG_FOG_LUT_DATA7 \" } , <nl> + { 0x0F0 , \" GPUREG_TEXENV4_SOURCE \" } , <nl> + { 0x0F1 , \" GPUREG_TEXENV4_OPERAND \" } , <nl> + { 0x0F2 , \" GPUREG_TEXENV4_COMBINER \" } , <nl> + { 0x0F3 , \" GPUREG_TEXENV4_COLOR \" } , <nl> + { 0x0F4 , \" GPUREG_TEXENV4_SCALE \" } , <nl> + <nl> + { 0x0F8 , \" GPUREG_TEXENV5_SOURCE \" } , <nl> + { 0x0F9 , \" GPUREG_TEXENV5_OPERAND \" } , <nl> + { 0x0FA , \" GPUREG_TEXENV5_COMBINER \" } , <nl> + { 0x0FB , \" GPUREG_TEXENV5_COLOR \" } , <nl> + { 0x0FC , \" GPUREG_TEXENV5_SCALE \" } , <nl> + { 0x0FD , \" GPUREG_TEXENV_BUFFER_COLOR \" } , <nl> + <nl> + { 0x100 , \" GPUREG_COLOR_OPERATION \" } , <nl> + { 0x101 , \" GPUREG_BLEND_FUNC \" } , <nl> + { 0x102 , \" GPUREG_LOGIC_OP \" } , <nl> + { 0x103 , \" GPUREG_BLEND_COLOR \" } , <nl> + { 0x104 , \" GPUREG_FRAGOP_ALPHA_TEST \" } , <nl> + { 0x105 , \" GPUREG_STENCIL_TEST \" } , <nl> + { 0x106 , \" GPUREG_STENCIL_OP \" } , <nl> + { 0x107 , \" GPUREG_DEPTH_COLOR_MASK \" } , <nl> + <nl> + { 0x110 , \" GPUREG_FRAMEBUFFER_INVALIDATE \" } , <nl> + { 0x111 , \" GPUREG_FRAMEBUFFER_FLUSH \" } , <nl> + { 0x112 , \" GPUREG_COLORBUFFER_READ \" } , <nl> + { 0x113 , \" GPUREG_COLORBUFFER_WRITE \" } , <nl> + { 0x114 , \" GPUREG_DEPTHBUFFER_READ \" } , <nl> + { 0x115 , \" GPUREG_DEPTHBUFFER_WRITE \" } , <nl> + { 0x116 , \" GPUREG_DEPTHBUFFER_FORMAT \" } , <nl> + { 0x117 , \" GPUREG_COLORBUFFER_FORMAT \" } , <nl> + { 0x118 , \" GPUREG_EARLYDEPTH_TEST2 \" } , <nl> + <nl> + { 0x11B , \" GPUREG_FRAMEBUFFER_BLOCK32 \" } , <nl> + { 0x11C , \" GPUREG_DEPTHBUFFER_LOC \" } , <nl> + { 0x11D , \" GPUREG_COLORBUFFER_LOC \" } , <nl> + { 0x11E , \" GPUREG_FRAMEBUFFER_DIM \" } , <nl> + <nl> + { 0x120 , \" GPUREG_GAS_LIGHT_XY \" } , <nl> + { 0x121 , \" GPUREG_GAS_LIGHT_Z \" } , <nl> + { 0x122 , \" GPUREG_GAS_LIGHT_Z_COLOR \" } , <nl> + { 0x123 , \" GPUREG_GAS_LUT_INDEX \" } , <nl> + { 0x124 , \" GPUREG_GAS_LUT_DATA \" } , <nl> + <nl> + { 0x126 , \" GPUREG_GAS_DELTAZ_DEPTH \" } , <nl> + <nl> + { 0x130 , \" GPUREG_FRAGOP_SHADOW \" } , <nl> + <nl> + { 0x140 , \" GPUREG_LIGHT0_SPECULAR0 \" } , <nl> + { 0x141 , \" GPUREG_LIGHT0_SPECULAR1 \" } , <nl> + { 0x142 , \" GPUREG_LIGHT0_DIFFUSE \" } , <nl> + { 0x143 , \" GPUREG_LIGHT0_AMBIENT \" } , <nl> + { 0x144 , \" GPUREG_LIGHT0_XY \" } , <nl> + { 0x145 , \" GPUREG_LIGHT0_Z \" } , <nl> + { 0x146 , \" GPUREG_LIGHT0_SPOTDIR_XY \" } , <nl> + { 0x147 , \" GPUREG_LIGHT0_SPOTDIR_Z \" } , <nl> + <nl> + { 0x149 , \" GPUREG_LIGHT0_CONFIG \" } , <nl> + { 0x14A , \" GPUREG_LIGHT0_ATTENUATION_BIAS \" } , <nl> + { 0x14B , \" GPUREG_LIGHT0_ATTENUATION_SCALE \" } , <nl> + <nl> + { 0x150 , \" GPUREG_LIGHT1_SPECULAR0 \" } , <nl> + { 0x151 , \" GPUREG_LIGHT1_SPECULAR1 \" } , <nl> + { 0x152 , \" GPUREG_LIGHT1_DIFFUSE \" } , <nl> + { 0x153 , \" GPUREG_LIGHT1_AMBIENT \" } , <nl> + { 0x154 , \" GPUREG_LIGHT1_XY \" } , <nl> + { 0x155 , \" GPUREG_LIGHT1_Z \" } , <nl> + { 0x156 , \" GPUREG_LIGHT1_SPOTDIR_XY \" } , <nl> + { 0x157 , \" GPUREG_LIGHT1_SPOTDIR_Z \" } , <nl> + <nl> + { 0x159 , \" GPUREG_LIGHT1_CONFIG \" } , <nl> + { 0x15A , \" GPUREG_LIGHT1_ATTENUATION_BIAS \" } , <nl> + { 0x15B , \" GPUREG_LIGHT1_ATTENUATION_SCALE \" } , <nl> + <nl> + { 0x160 , \" GPUREG_LIGHT2_SPECULAR0 \" } , <nl> + { 0x161 , \" GPUREG_LIGHT2_SPECULAR1 \" } , <nl> + { 0x162 , \" GPUREG_LIGHT2_DIFFUSE \" } , <nl> + { 0x163 , \" GPUREG_LIGHT2_AMBIENT \" } , <nl> + { 0x164 , \" GPUREG_LIGHT2_XY \" } , <nl> + { 0x165 , \" GPUREG_LIGHT2_Z \" } , <nl> + { 0x166 , \" GPUREG_LIGHT2_SPOTDIR_XY \" } , <nl> + { 0x167 , \" GPUREG_LIGHT2_SPOTDIR_Z \" } , <nl> + <nl> + { 0x169 , \" GPUREG_LIGHT2_CONFIG \" } , <nl> + { 0x16A , \" GPUREG_LIGHT2_ATTENUATION_BIAS \" } , <nl> + { 0x16B , \" GPUREG_LIGHT2_ATTENUATION_SCALE \" } , <nl> + <nl> + { 0x170 , \" GPUREG_LIGHT3_SPECULAR0 \" } , <nl> + { 0x171 , \" GPUREG_LIGHT3_SPECULAR1 \" } , <nl> + { 0x172 , \" GPUREG_LIGHT3_DIFFUSE \" } , <nl> + { 0x173 , \" GPUREG_LIGHT3_AMBIENT \" } , <nl> + { 0x174 , \" GPUREG_LIGHT3_XY \" } , <nl> + { 0x175 , \" GPUREG_LIGHT3_Z \" } , <nl> + { 0x176 , \" GPUREG_LIGHT3_SPOTDIR_XY \" } , <nl> + { 0x177 , \" GPUREG_LIGHT3_SPOTDIR_Z \" } , <nl> + <nl> + { 0x179 , \" GPUREG_LIGHT3_CONFIG \" } , <nl> + { 0x17A , \" GPUREG_LIGHT3_ATTENUATION_BIAS \" } , <nl> + { 0x17B , \" GPUREG_LIGHT3_ATTENUATION_SCALE \" } , <nl> + <nl> + { 0x180 , \" GPUREG_LIGHT4_SPECULAR0 \" } , <nl> + { 0x181 , \" GPUREG_LIGHT4_SPECULAR1 \" } , <nl> + { 0x182 , \" GPUREG_LIGHT4_DIFFUSE \" } , <nl> + { 0x183 , \" GPUREG_LIGHT4_AMBIENT \" } , <nl> + { 0x184 , \" GPUREG_LIGHT4_XY \" } , <nl> + { 0x185 , \" GPUREG_LIGHT4_Z \" } , <nl> + { 0x186 , \" GPUREG_LIGHT4_SPOTDIR_XY \" } , <nl> + { 0x187 , \" GPUREG_LIGHT4_SPOTDIR_Z \" } , <nl> + <nl> + { 0x189 , \" GPUREG_LIGHT4_CONFIG \" } , <nl> + { 0x18A , \" GPUREG_LIGHT4_ATTENUATION_BIAS \" } , <nl> + { 0x18B , \" GPUREG_LIGHT4_ATTENUATION_SCALE \" } , <nl> + <nl> + { 0x190 , \" GPUREG_LIGHT5_SPECULAR0 \" } , <nl> + { 0x191 , \" GPUREG_LIGHT5_SPECULAR1 \" } , <nl> + { 0x192 , \" GPUREG_LIGHT5_DIFFUSE \" } , <nl> + { 0x193 , \" GPUREG_LIGHT5_AMBIENT \" } , <nl> + { 0x194 , \" GPUREG_LIGHT5_XY \" } , <nl> + { 0x195 , \" GPUREG_LIGHT5_Z \" } , <nl> + { 0x196 , \" GPUREG_LIGHT5_SPOTDIR_XY \" } , <nl> + { 0x197 , \" GPUREG_LIGHT5_SPOTDIR_Z \" } , <nl> + <nl> + { 0x199 , \" GPUREG_LIGHT5_CONFIG \" } , <nl> + { 0x19A , \" GPUREG_LIGHT5_ATTENUATION_BIAS \" } , <nl> + { 0x19B , \" GPUREG_LIGHT5_ATTENUATION_SCALE \" } , <nl> + <nl> + { 0x1A0 , \" GPUREG_LIGHT6_SPECULAR0 \" } , <nl> + { 0x1A1 , \" GPUREG_LIGHT6_SPECULAR1 \" } , <nl> + { 0x1A2 , \" GPUREG_LIGHT6_DIFFUSE \" } , <nl> + { 0x1A3 , \" GPUREG_LIGHT6_AMBIENT \" } , <nl> + { 0x1A4 , \" GPUREG_LIGHT6_XY \" } , <nl> + { 0x1A5 , \" GPUREG_LIGHT6_Z \" } , <nl> + { 0x1A6 , \" GPUREG_LIGHT6_SPOTDIR_XY \" } , <nl> + { 0x1A7 , \" GPUREG_LIGHT6_SPOTDIR_Z \" } , <nl> + <nl> + { 0x1A9 , \" GPUREG_LIGHT6_CONFIG \" } , <nl> + { 0x1AA , \" GPUREG_LIGHT6_ATTENUATION_BIAS \" } , <nl> + { 0x1AB , \" GPUREG_LIGHT6_ATTENUATION_SCALE \" } , <nl> + <nl> + { 0x1B0 , \" GPUREG_LIGHT7_SPECULAR0 \" } , <nl> + { 0x1B1 , \" GPUREG_LIGHT7_SPECULAR1 \" } , <nl> + { 0x1B2 , \" GPUREG_LIGHT7_DIFFUSE \" } , <nl> + { 0x1B3 , \" GPUREG_LIGHT7_AMBIENT \" } , <nl> + { 0x1B4 , \" GPUREG_LIGHT7_XY \" } , <nl> + { 0x1B5 , \" GPUREG_LIGHT7_Z \" } , <nl> + { 0x1B6 , \" GPUREG_LIGHT7_SPOTDIR_XY \" } , <nl> + { 0x1B7 , \" GPUREG_LIGHT7_SPOTDIR_Z \" } , <nl> + <nl> + { 0x1B9 , \" GPUREG_LIGHT7_CONFIG \" } , <nl> + { 0x1BA , \" GPUREG_LIGHT7_ATTENUATION_BIAS \" } , <nl> + { 0x1BB , \" GPUREG_LIGHT7_ATTENUATION_SCALE \" } , <nl> + <nl> + { 0x1C0 , \" GPUREG_LIGHTING_AMBIENT \" } , <nl> + <nl> + { 0x1C2 , \" GPUREG_LIGHTING_NUM_LIGHTS \" } , <nl> + { 0x1C3 , \" GPUREG_LIGHTING_CONFIG0 \" } , <nl> + { 0x1C4 , \" GPUREG_LIGHTING_CONFIG1 \" } , <nl> + { 0x1C5 , \" GPUREG_LIGHTING_LUT_INDEX \" } , <nl> + { 0x1C6 , \" GPUREG_LIGHTING_ENABLE1 \" } , <nl> + <nl> + { 0x1C8 , \" GPUREG_LIGHTING_LUT_DATA0 \" } , <nl> + { 0x1C9 , \" GPUREG_LIGHTING_LUT_DATA1 \" } , <nl> + { 0x1CA , \" GPUREG_LIGHTING_LUT_DATA2 \" } , <nl> + { 0x1CB , \" GPUREG_LIGHTING_LUT_DATA3 \" } , <nl> + { 0x1CC , \" GPUREG_LIGHTING_LUT_DATA4 \" } , <nl> + { 0x1CD , \" GPUREG_LIGHTING_LUT_DATA5 \" } , <nl> + { 0x1CE , \" GPUREG_LIGHTING_LUT_DATA6 \" } , <nl> + { 0x1CF , \" GPUREG_LIGHTING_LUT_DATA7 \" } , <nl> + { 0x1D0 , \" GPUREG_LIGHTING_LUTINPUT_ABS \" } , <nl> + { 0x1D1 , \" GPUREG_LIGHTING_LUTINPUT_SELECT \" } , <nl> + { 0x1D2 , \" GPUREG_LIGHTING_LUTINPUT_SCALE \" } , <nl> + <nl> + { 0x1D9 , \" GPUREG_LIGHTING_LIGHT_PERMUTATION \" } , <nl> + <nl> + { 0x200 , \" GPUREG_ATTRIBBUFFERS_LOC \" } , <nl> + { 0x201 , \" GPUREG_ATTRIBBUFFERS_FORMAT_LOW \" } , <nl> + { 0x202 , \" GPUREG_ATTRIBBUFFERS_FORMAT_HIGH \" } , <nl> + { 0x203 , \" GPUREG_ATTRIBBUFFER0_OFFSET \" } , <nl> + { 0x204 , \" GPUREG_ATTRIBBUFFER0_CONFIG1 \" } , <nl> + { 0x205 , \" GPUREG_ATTRIBBUFFER0_CONFIG2 \" } , <nl> + { 0x206 , \" GPUREG_ATTRIBBUFFER1_OFFSET \" } , <nl> + { 0x207 , \" GPUREG_ATTRIBBUFFER1_CONFIG1 \" } , <nl> + { 0x208 , \" GPUREG_ATTRIBBUFFER1_CONFIG2 \" } , <nl> + { 0x209 , \" GPUREG_ATTRIBBUFFER2_OFFSET \" } , <nl> + { 0x20A , \" GPUREG_ATTRIBBUFFER2_CONFIG1 \" } , <nl> + { 0x20B , \" GPUREG_ATTRIBBUFFER2_CONFIG2 \" } , <nl> + { 0x20C , \" GPUREG_ATTRIBBUFFER3_OFFSET \" } , <nl> + { 0x20D , \" GPUREG_ATTRIBBUFFER3_CONFIG1 \" } , <nl> + { 0x20E , \" GPUREG_ATTRIBBUFFER3_CONFIG2 \" } , <nl> + { 0x20F , \" GPUREG_ATTRIBBUFFER4_OFFSET \" } , <nl> + { 0x210 , \" GPUREG_ATTRIBBUFFER4_CONFIG1 \" } , <nl> + { 0x211 , \" GPUREG_ATTRIBBUFFER4_CONFIG2 \" } , <nl> + { 0x212 , \" GPUREG_ATTRIBBUFFER5_OFFSET \" } , <nl> + { 0x213 , \" GPUREG_ATTRIBBUFFER5_CONFIG1 \" } , <nl> + { 0x214 , \" GPUREG_ATTRIBBUFFER5_CONFIG2 \" } , <nl> + { 0x215 , \" GPUREG_ATTRIBBUFFER6_OFFSET \" } , <nl> + { 0x216 , \" GPUREG_ATTRIBBUFFER6_CONFIG1 \" } , <nl> + { 0x217 , \" GPUREG_ATTRIBBUFFER6_CONFIG2 \" } , <nl> + { 0x218 , \" GPUREG_ATTRIBBUFFER7_OFFSET \" } , <nl> + { 0x219 , \" GPUREG_ATTRIBBUFFER7_CONFIG1 \" } , <nl> + { 0x21A , \" GPUREG_ATTRIBBUFFER7_CONFIG2 \" } , <nl> + { 0x21B , \" GPUREG_ATTRIBBUFFER8_OFFSET \" } , <nl> + { 0x21C , \" GPUREG_ATTRIBBUFFER8_CONFIG1 \" } , <nl> + { 0x21D , \" GPUREG_ATTRIBBUFFER8_CONFIG2 \" } , <nl> + { 0x21E , \" GPUREG_ATTRIBBUFFER9_OFFSET \" } , <nl> + { 0x21F , \" GPUREG_ATTRIBBUFFER9_CONFIG1 \" } , <nl> + { 0x220 , \" GPUREG_ATTRIBBUFFER9_CONFIG2 \" } , <nl> + { 0x221 , \" GPUREG_ATTRIBBUFFER10_OFFSET \" } , <nl> + { 0x222 , \" GPUREG_ATTRIBBUFFER10_CONFIG1 \" } , <nl> + { 0x223 , \" GPUREG_ATTRIBBUFFER10_CONFIG2 \" } , <nl> + { 0x224 , \" GPUREG_ATTRIBBUFFER11_OFFSET \" } , <nl> + { 0x225 , \" GPUREG_ATTRIBBUFFER11_CONFIG1 \" } , <nl> + { 0x226 , \" GPUREG_ATTRIBBUFFER11_CONFIG2 \" } , <nl> + { 0x227 , \" GPUREG_INDEXBUFFER_CONFIG \" } , <nl> + { 0x228 , \" GPUREG_NUMVERTICES \" } , <nl> + { 0x229 , \" GPUREG_GEOSTAGE_CONFIG \" } , <nl> + { 0x22A , \" GPUREG_VERTEX_OFFSET \" } , <nl> + <nl> + { 0x22D , \" GPUREG_POST_VERTEX_CACHE_NUM \" } , <nl> + { 0x22E , \" GPUREG_DRAWARRAYS \" } , <nl> + { 0x22F , \" GPUREG_DRAWELEMENTS \" } , <nl> + <nl> + { 0x231 , \" GPUREG_VTX_FUNC \" } , <nl> + { 0x232 , \" GPUREG_FIXEDATTRIB_INDEX \" } , <nl> + { 0x233 , \" GPUREG_FIXEDATTRIB_DATA0 \" } , <nl> + { 0x234 , \" GPUREG_FIXEDATTRIB_DATA1 \" } , <nl> + { 0x235 , \" GPUREG_FIXEDATTRIB_DATA2 \" } , <nl> + <nl> + { 0x238 , \" GPUREG_CMDBUF_SIZE0 \" } , <nl> + { 0x239 , \" GPUREG_CMDBUF_SIZE1 \" } , <nl> + { 0x23A , \" GPUREG_CMDBUF_ADDR0 \" } , <nl> + { 0x23B , \" GPUREG_CMDBUF_ADDR1 \" } , <nl> + { 0x23C , \" GPUREG_CMDBUF_JUMP0 \" } , <nl> + { 0x23D , \" GPUREG_CMDBUF_JUMP1 \" } , <nl> + <nl> + { 0x242 , \" GPUREG_VSH_NUM_ATTR \" } , <nl> + <nl> + { 0x244 , \" GPUREG_VSH_COM_MODE \" } , <nl> + { 0x245 , \" GPUREG_START_DRAW_FUNC0 \" } , <nl> + <nl> + { 0x24A , \" GPUREG_VSH_OUTMAP_TOTAL1 \" } , <nl> + <nl> + { 0x251 , \" GPUREG_VSH_OUTMAP_TOTAL2 \" } , <nl> + { 0x252 , \" GPUREG_GSH_MISC0 \" } , <nl> + { 0x253 , \" GPUREG_GEOSTAGE_CONFIG2 \" } , <nl> + { 0x254 , \" GPUREG_GSH_MISC1 \" } , <nl> + <nl> + { 0x25E , \" GPUREG_PRIMITIVE_CONFIG \" } , <nl> + { 0x25F , \" GPUREG_RESTART_PRIMITIVE \" } , <nl> + <nl> + { 0x280 , \" GPUREG_GSH_BOOLUNIFORM \" } , <nl> + { 0x281 , \" GPUREG_GSH_INTUNIFORM_I0 \" } , <nl> + { 0x282 , \" GPUREG_GSH_INTUNIFORM_I1 \" } , <nl> + { 0x283 , \" GPUREG_GSH_INTUNIFORM_I2 \" } , <nl> + { 0x284 , \" GPUREG_GSH_INTUNIFORM_I3 \" } , <nl> + <nl> + { 0x289 , \" GPUREG_GSH_INPUTBUFFER_CONFIG \" } , <nl> + { 0x28A , \" GPUREG_GSH_ENTRYPOINT \" } , <nl> + { 0x28B , \" GPUREG_GSH_ATTRIBUTES_PERMUTATION_LOW \" } , <nl> + { 0x28C , \" GPUREG_GSH_ATTRIBUTES_PERMUTATION_HIGH \" } , <nl> + { 0x28D , \" GPUREG_GSH_OUTMAP_MASK \" } , <nl> + <nl> + { 0x28F , \" GPUREG_GSH_CODETRANSFER_END \" } , <nl> + { 0x290 , \" GPUREG_GSH_FLOATUNIFORM_INDEX \" } , <nl> + { 0x291 , \" GPUREG_GSH_FLOATUNIFORM_DATA0 \" } , <nl> + { 0x292 , \" GPUREG_GSH_FLOATUNIFORM_DATA1 \" } , <nl> + { 0x293 , \" GPUREG_GSH_FLOATUNIFORM_DATA2 \" } , <nl> + { 0x294 , \" GPUREG_GSH_FLOATUNIFORM_DATA3 \" } , <nl> + { 0x295 , \" GPUREG_GSH_FLOATUNIFORM_DATA4 \" } , <nl> + { 0x296 , \" GPUREG_GSH_FLOATUNIFORM_DATA5 \" } , <nl> + { 0x297 , \" GPUREG_GSH_FLOATUNIFORM_DATA6 \" } , <nl> + { 0x298 , \" GPUREG_GSH_FLOATUNIFORM_DATA7 \" } , <nl> + <nl> + { 0x29B , \" GPUREG_GSH_CODETRANSFER_INDEX \" } , <nl> + { 0x29C , \" GPUREG_GSH_CODETRANSFER_DATA0 \" } , <nl> + { 0x29D , \" GPUREG_GSH_CODETRANSFER_DATA1 \" } , <nl> + { 0x29E , \" GPUREG_GSH_CODETRANSFER_DATA2 \" } , <nl> + { 0x29F , \" GPUREG_GSH_CODETRANSFER_DATA3 \" } , <nl> + { 0x2A0 , \" GPUREG_GSH_CODETRANSFER_DATA4 \" } , <nl> + { 0x2A1 , \" GPUREG_GSH_CODETRANSFER_DATA5 \" } , <nl> + { 0x2A2 , \" GPUREG_GSH_CODETRANSFER_DATA6 \" } , <nl> + { 0x2A3 , \" GPUREG_GSH_CODETRANSFER_DATA7 \" } , <nl> + <nl> + { 0x2A5 , \" GPUREG_GSH_OPDESCS_INDEX \" } , <nl> + { 0x2A6 , \" GPUREG_GSH_OPDESCS_DATA0 \" } , <nl> + { 0x2A7 , \" GPUREG_GSH_OPDESCS_DATA1 \" } , <nl> + { 0x2A8 , \" GPUREG_GSH_OPDESCS_DATA2 \" } , <nl> + { 0x2A9 , \" GPUREG_GSH_OPDESCS_DATA3 \" } , <nl> + { 0x2AA , \" GPUREG_GSH_OPDESCS_DATA4 \" } , <nl> + { 0x2AB , \" GPUREG_GSH_OPDESCS_DATA5 \" } , <nl> + { 0x2AC , \" GPUREG_GSH_OPDESCS_DATA6 \" } , <nl> + { 0x2AD , \" GPUREG_GSH_OPDESCS_DATA7 \" } , <nl> + <nl> + { 0x2B0 , \" GPUREG_VSH_BOOLUNIFORM \" } , <nl> + { 0x2B1 , \" GPUREG_VSH_INTUNIFORM_I0 \" } , <nl> + { 0x2B2 , \" GPUREG_VSH_INTUNIFORM_I1 \" } , <nl> + { 0x2B3 , \" GPUREG_VSH_INTUNIFORM_I2 \" } , <nl> + { 0x2B4 , \" GPUREG_VSH_INTUNIFORM_I3 \" } , <nl> + <nl> + { 0x2B9 , \" GPUREG_VSH_INPUTBUFFER_CONFIG \" } , <nl> + { 0x2BA , \" GPUREG_VSH_ENTRYPOINT \" } , <nl> + { 0x2BB , \" GPUREG_VSH_ATTRIBUTES_PERMUTATION_LOW \" } , <nl> + { 0x2BC , \" GPUREG_VSH_ATTRIBUTES_PERMUTATION_HIGH \" } , <nl> + { 0x2BD , \" GPUREG_VSH_OUTMAP_MASK \" } , <nl> + <nl> + { 0x2BF , \" GPUREG_VSH_CODETRANSFER_END \" } , <nl> + { 0x2C0 , \" GPUREG_VSH_FLOATUNIFORM_INDEX \" } , <nl> + { 0x2C1 , \" GPUREG_VSH_FLOATUNIFORM_DATA0 \" } , <nl> + { 0x2C2 , \" GPUREG_VSH_FLOATUNIFORM_DATA1 \" } , <nl> + { 0x2C3 , \" GPUREG_VSH_FLOATUNIFORM_DATA2 \" } , <nl> + { 0x2C4 , \" GPUREG_VSH_FLOATUNIFORM_DATA3 \" } , <nl> + { 0x2C5 , \" GPUREG_VSH_FLOATUNIFORM_DATA4 \" } , <nl> + { 0x2C6 , \" GPUREG_VSH_FLOATUNIFORM_DATA5 \" } , <nl> + { 0x2C7 , \" GPUREG_VSH_FLOATUNIFORM_DATA6 \" } , <nl> + { 0x2C8 , \" GPUREG_VSH_FLOATUNIFORM_DATA7 \" } , <nl> + <nl> + { 0x2CB , \" GPUREG_VSH_CODETRANSFER_INDEX \" } , <nl> + { 0x2CC , \" GPUREG_VSH_CODETRANSFER_DATA0 \" } , <nl> + { 0x2CD , \" GPUREG_VSH_CODETRANSFER_DATA1 \" } , <nl> + { 0x2CE , \" GPUREG_VSH_CODETRANSFER_DATA2 \" } , <nl> + { 0x2CF , \" GPUREG_VSH_CODETRANSFER_DATA3 \" } , <nl> + { 0x2D0 , \" GPUREG_VSH_CODETRANSFER_DATA4 \" } , <nl> + { 0x2D1 , \" GPUREG_VSH_CODETRANSFER_DATA5 \" } , <nl> + { 0x2D2 , \" GPUREG_VSH_CODETRANSFER_DATA6 \" } , <nl> + { 0x2D3 , \" GPUREG_VSH_CODETRANSFER_DATA7 \" } , <nl> + <nl> + { 0x2D5 , \" GPUREG_VSH_OPDESCS_INDEX \" } , <nl> + { 0x2D6 , \" GPUREG_VSH_OPDESCS_DATA0 \" } , <nl> + { 0x2D7 , \" GPUREG_VSH_OPDESCS_DATA1 \" } , <nl> + { 0x2D8 , \" GPUREG_VSH_OPDESCS_DATA2 \" } , <nl> + { 0x2D9 , \" GPUREG_VSH_OPDESCS_DATA3 \" } , <nl> + { 0x2DA , \" GPUREG_VSH_OPDESCS_DATA4 \" } , <nl> + { 0x2DB , \" GPUREG_VSH_OPDESCS_DATA5 \" } , <nl> + { 0x2DC , \" GPUREG_VSH_OPDESCS_DATA6 \" } , <nl> + { 0x2DD , \" GPUREG_VSH_OPDESCS_DATA7 \" } , <nl> + } ; <nl> + <nl> std : : string Regs : : GetCommandName ( int index ) { <nl> - static std : : unordered_map < u32 , std : : string > map ; <nl> + static std : : unordered_map < u32 , const char * > map ; <nl> <nl> if ( map . empty ( ) ) { <nl> - # define ADD_FIELD ( name ) \\ <nl> - map . insert ( { static_cast < u32 > ( PICA_REG_INDEX ( name ) ) , # name } ) ; \\ <nl> - / * TODO : change to Regs : : name when VS2015 and other compilers support it * / \\ <nl> - for ( u32 i = PICA_REG_INDEX ( name ) + 1 ; i < PICA_REG_INDEX ( name ) + sizeof ( Regs ( ) . name ) / 4 ; + + i ) \\ <nl> - map . insert ( { i , # name + std : : string ( \" + \" ) + std : : to_string ( i - PICA_REG_INDEX ( name ) ) } ) ; \\ <nl> - <nl> - ADD_FIELD ( trigger_irq ) ; <nl> - ADD_FIELD ( cull_mode ) ; <nl> - ADD_FIELD ( viewport_size_x ) ; <nl> - ADD_FIELD ( viewport_size_y ) ; <nl> - ADD_FIELD ( viewport_depth_range ) ; <nl> - ADD_FIELD ( viewport_depth_far_plane ) ; <nl> - ADD_FIELD ( viewport_corner ) ; <nl> - ADD_FIELD ( texture0_enable ) ; <nl> - ADD_FIELD ( texture0 ) ; <nl> - ADD_FIELD ( texture0_format ) ; <nl> - ADD_FIELD ( texture1 ) ; <nl> - ADD_FIELD ( texture1_format ) ; <nl> - ADD_FIELD ( texture2 ) ; <nl> - ADD_FIELD ( texture2_format ) ; <nl> - ADD_FIELD ( tev_stage0 ) ; <nl> - ADD_FIELD ( tev_stage1 ) ; <nl> - ADD_FIELD ( tev_stage2 ) ; <nl> - ADD_FIELD ( tev_stage3 ) ; <nl> - ADD_FIELD ( tev_combiner_buffer_input ) ; <nl> - ADD_FIELD ( tev_stage4 ) ; <nl> - ADD_FIELD ( tev_stage5 ) ; <nl> - ADD_FIELD ( tev_combiner_buffer_color ) ; <nl> - ADD_FIELD ( output_merger ) ; <nl> - ADD_FIELD ( framebuffer ) ; <nl> - ADD_FIELD ( vertex_attributes ) ; <nl> - ADD_FIELD ( index_array ) ; <nl> - ADD_FIELD ( num_vertices ) ; <nl> - ADD_FIELD ( vertex_offset ) ; <nl> - ADD_FIELD ( trigger_draw ) ; <nl> - ADD_FIELD ( trigger_draw_indexed ) ; <nl> - ADD_FIELD ( vs_default_attributes_setup ) ; <nl> - ADD_FIELD ( command_buffer ) ; <nl> - ADD_FIELD ( triangle_topology ) ; <nl> - ADD_FIELD ( restart_primitive ) ; <nl> - ADD_FIELD ( gs . bool_uniforms ) ; <nl> - ADD_FIELD ( gs . int_uniforms ) ; <nl> - ADD_FIELD ( gs . main_offset ) ; <nl> - ADD_FIELD ( gs . input_register_map ) ; <nl> - ADD_FIELD ( gs . uniform_setup ) ; <nl> - ADD_FIELD ( gs . program ) ; <nl> - ADD_FIELD ( gs . swizzle_patterns ) ; <nl> - ADD_FIELD ( vs . bool_uniforms ) ; <nl> - ADD_FIELD ( vs . int_uniforms ) ; <nl> - ADD_FIELD ( vs . main_offset ) ; <nl> - ADD_FIELD ( vs . input_register_map ) ; <nl> - ADD_FIELD ( vs . uniform_setup ) ; <nl> - ADD_FIELD ( vs . program ) ; <nl> - ADD_FIELD ( vs . swizzle_patterns ) ; <nl> - <nl> - # undef ADD_FIELD <nl> + map . insert ( begin ( register_names ) , end ( register_names ) ) ; <nl> } <nl> <nl> / / Return empty string if no match is found <nl>\n", "msg": "Debugger : Use 3dbrew names for GPU registers\n"}
{"diff_id": 24823, "repo": "apple/swift\n", "sha": "6e987033917b9c3dd352843ab1575e811d6f46e4\n", "time": "2018-03-24T18:21:29Z\n", "diff": "mmm a / lib / SILOptimizer / IPO / GlobalOpt . cpp <nl> ppp b / lib / SILOptimizer / IPO / GlobalOpt . cpp <nl> class SILGlobalOpt { <nl> / / / The set of functions that have had their loops analyzed . <nl> llvm : : DenseSet < SILFunction * > LoopCheckedFunctions ; <nl> <nl> - / / / Keep track of cold blocks . <nl> - ColdBlockInfo ColdBlocks ; <nl> - <nl> - / / / Whether we see a \" once \" call to callees that we currently don ' t handle . <nl> + / / / Whether we have seen any \" once \" calls to callees that we currently don ' t <nl> + / / / handle . <nl> bool UnhandledOnceCallee = false ; <nl> <nl> / / / A map from a globalinit_func to the number of times \" once \" has called the <nl> class SILGlobalOpt { <nl> llvm : : DenseMap < SILFunction * , unsigned > InitializerCount ; <nl> public : <nl> SILGlobalOpt ( SILModule * M , DominanceAnalysis * DA ) <nl> - : Module ( M ) , DA ( DA ) , ColdBlocks ( DA ) { } <nl> + : Module ( M ) , DA ( DA ) { } <nl> <nl> bool run ( ) ; <nl> <nl>\n", "msg": "[ globalopt ] Eliminate unused field .\n"}
{"diff_id": 24932, "repo": "apple/swift\n", "sha": "1bd15b7b178f7bcf42a6097e683405c60aac85bd\n", "time": "2014-01-17T04:23:11Z\n", "diff": "mmm a / lib / ClangImporter / ImportDecl . cpp <nl> ppp b / lib / ClangImporter / ImportDecl . cpp <nl> namespace { <nl> } <nl> } <nl> <nl> - if ( getter & & getterIndices ) <nl> - getterThunk = buildGetterThunk ( getter , dc , getterIndices ) ; <nl> - if ( setter & & setterIndices ) <nl> + getterThunk = buildGetterThunk ( getter , dc , getterIndices ) ; <nl> + if ( setter ) <nl> setterThunk = buildSetterThunk ( setter , dc , setterIndices ) ; <nl> <nl> / / Build the subscript declaration . <nl> namespace { <nl> subscript - > setOverriddenDecl ( parentSub ) ; <nl> if ( auto parentGetter = parentSub - > getGetter ( ) ) { <nl> if ( getterThunk ) <nl> - getterThunk - > setOverriddenDecl ( parentGetter ) ; <nl> + getterThunk - > setOverriddenDecl ( parentGetter ) ; <nl> } <nl> if ( auto parentSetter = parentSub - > getSetter ( ) ) { <nl> if ( setterThunk ) <nl>\n", "msg": "Clean up handling of getter / setter thunks . < rdar : / / problem / 14109713 >\n"}
{"diff_id": 24989, "repo": "xbmc/xbmc\n", "sha": "3daf23d66bba7b87cbff031656fe1bad2e7f9c4c\n", "time": "2012-12-02T13:45:05Z\n", "diff": "mmm a / xbmc / guilib / GUIWindow . cpp <nl> ppp b / xbmc / guilib / GUIWindow . cpp <nl> bool CGUIWindow : : Load ( TiXmlElement * pRootElement ) <nl> return false ; <nl> } <nl> <nl> + / / we must create copy of root element as we will manipulate it when resolving includes <nl> + / / and we don ' t want original root element to change <nl> + pRootElement = ( TiXmlElement * ) pRootElement - > Clone ( ) ; <nl> + <nl> / / set the scaling resolution so that any control creation or initialisation can <nl> / / be done with respect to the correct aspect ratio <nl> g_graphicsContext . SetScalingResolution ( m_coordsRes , m_needsScaling ) ; <nl> bool CGUIWindow : : Load ( TiXmlElement * pRootElement ) <nl> <nl> m_windowLoaded = true ; <nl> OnWindowLoaded ( ) ; <nl> + delete pRootElement ; <nl> return true ; <nl> } <nl> <nl>\n", "msg": "CGUIWindow : resolve includes on copy of xml element to avoid manipulation of stored xml element\n"}
{"diff_id": 25016, "repo": "godotengine/godot\n", "sha": "3c1f8efd9e5066ded2d36e99ce40511fdea79488\n", "time": "2018-02-16T13:07:19Z\n", "diff": "mmm a / modules / mono / editor / bindings_generator . cpp <nl> ppp b / modules / mono / editor / bindings_generator . cpp <nl> void BindingsGenerator : : _populate_builtin_type_interfaces ( ) { <nl> \" this . \" BINDINGS_PTR_FIELD \" = NativeCalls . godot_icall_NodePath_Ctor ( path ) ; \\ n \" CLOSE_BLOCK_L2 <nl> MEMBER_BEGIN \" public static implicit operator NodePath ( string from ) \\ n \" OPEN_BLOCK_L2 \" return new NodePath ( from ) ; \\ n \" CLOSE_BLOCK_L2 <nl> MEMBER_BEGIN \" public static implicit operator string ( NodePath from ) \\ n \" OPEN_BLOCK_L2 <nl> - \" return NativeCalls . \" ICALL_PREFIX \" NodePath_operator_String ( NodePath . \" CS_SMETHOD_GETINSTANCE \" ( from ) ) ; \\ n \" CLOSE_BLOCK_L2 ) ; <nl> + \" return NativeCalls . \" ICALL_PREFIX \" NodePath_operator_String ( NodePath . \" CS_SMETHOD_GETINSTANCE \" ( from ) ) ; \\ n \" CLOSE_BLOCK_L2 <nl> + MEMBER_BEGIN \" public override string ToString ( ) \\ n \" OPEN_BLOCK_L2 \" return ( string ) this ; \\ n \" CLOSE_BLOCK_L2 ) ; <nl> builtin_types . insert ( itype . cname , itype ) ; <nl> <nl> / / RID <nl>\n", "msg": "Give C # NodePath a ToString ( ) .\n"}
{"diff_id": 25035, "repo": "mongodb/mongo\n", "sha": "069d9e9c3cfd20ed7e6c370e36526b4fe6408cae\n", "time": "2010-01-19T15:01:15Z\n", "diff": "mmm a / util / miniwebserver . cpp <nl> ppp b / util / miniwebserver . cpp <nl> namespace mongo { <nl> string responseMsg ; <nl> int responseCode = 599 ; <nl> vector < string > headers ; <nl> - doRequest ( buf , parseURL ( buf ) , responseMsg , responseCode , headers , from ) ; <nl> + <nl> + try { <nl> + doRequest ( buf , parseURL ( buf ) , responseMsg , responseCode , headers , from ) ; <nl> + } <nl> + catch ( std : : exception & e ) { <nl> + responseCode = 500 ; <nl> + responseMsg = \" error loading page : \" ; <nl> + responseMsg + = e . what ( ) ; <nl> + } <nl> + catch ( std : : exception & e ) { <nl> + responseCode = 500 ; <nl> + responseMsg = \" error loading page : \" ; <nl> + responseMsg + = e . what ( ) ; <nl> + } <nl> <nl> stringstream ss ; <nl> ss < < \" HTTP / 1 . 0 \" < < responseCode ; <nl>\n", "msg": "catch exceptions in webserver SERVER - 551\n"}
{"diff_id": 25123, "repo": "mongodb/mongo\n", "sha": "d2b8a2070709d8b9a2646a0a33467a9480c728dd\n", "time": "2013-11-18T20:56:39Z\n", "diff": "mmm a / src / mongo / db / query / query_planner_test . cpp <nl> ppp b / src / mongo / db / query / query_planner_test . cpp <nl> namespace { <nl> void runQuery ( BSONObj query ) { <nl> solns . clear ( ) ; <nl> queryObj = query . getOwned ( ) ; <nl> - ASSERT_OK ( CanonicalQuery : : canonicalize ( ns , queryObj , & cq ) ) ; <nl> + Status s = CanonicalQuery : : canonicalize ( ns , queryObj , & cq ) ; <nl> + if ( ! s . isOK ( ) ) { cq = NULL ; } <nl> + ASSERT_OK ( s ) ; <nl> params . options = QueryPlannerParams : : INCLUDE_COLLSCAN ; <nl> QueryPlanner : : plan ( * cq , params , & solns ) ; <nl> } <nl> <nl> void runDetailedQuery ( const BSONObj & query , const BSONObj & sort , const BSONObj & proj ) { <nl> solns . clear ( ) ; <nl> - ASSERT_OK ( CanonicalQuery : : canonicalize ( ns , query , sort , proj , & cq ) ) ; <nl> + Status s = CanonicalQuery : : canonicalize ( ns , query , sort , proj , & cq ) ; <nl> + if ( ! s . isOK ( ) ) { cq = NULL ; } <nl> + ASSERT_OK ( s ) ; <nl> params . options = QueryPlannerParams : : INCLUDE_COLLSCAN ; <nl> QueryPlanner : : plan ( * cq , params , & solns ) ; <nl> - ASSERT_GREATER_THAN ( solns . size ( ) , 0U ) ; ; <nl> + ASSERT_GREATER_THAN ( solns . size ( ) , 0U ) ; <nl> + } <nl> + <nl> + void runQuerySkipLimit ( const BSONObj & query , long long skip , long long limit ) { <nl> + solns . clear ( ) ; <nl> + Status s = CanonicalQuery : : canonicalize ( ns , query , skip , limit , & cq ) ; <nl> + if ( ! s . isOK ( ) ) { cq = NULL ; } <nl> + ASSERT_OK ( s ) ; <nl> + params . options = QueryPlannerParams : : INCLUDE_COLLSCAN ; <nl> + QueryPlanner : : plan ( * cq , params , & solns ) ; <nl> + ASSERT_GREATER_THAN ( solns . size ( ) , 0U ) ; <nl> } <nl> <nl> / / <nl> namespace { <nl> } <nl> } <nl> <nl> - / / TODO : <nl> - / / bool hasIndexedPlan ( BSONObj indexKeyPattern ) ; <nl> - <nl> - void getPlanByType ( StageType stageType , QuerySolution * * soln ) const { <nl> - size_t found = 0 ; <nl> - for ( vector < QuerySolution * > : : const_iterator it = solns . begin ( ) ; <nl> - it ! = solns . end ( ) ; <nl> - + + it ) { <nl> - if ( ( * it ) - > root - > getType ( ) = = stageType ) { <nl> - * soln = * it ; <nl> - found + + ; <nl> - } <nl> - } <nl> - if ( 1 ! = found ) { <nl> - cout < < \" Can ' t find requested stage type \" < < stageType <nl> - < < \" , dump of all solutions : \\ n \" ; <nl> - for ( vector < QuerySolution * > : : const_iterator it = solns . begin ( ) ; <nl> - it ! = solns . end ( ) ; <nl> - + + it ) { <nl> - cout < < ( * it ) - > toString ( ) < < endl ; <nl> + / * * <nl> + * Looks in the children stored in the ' nodes ' field of ' testSoln ' <nl> + * to see if they match the ' children ' field of ' trueSoln ' . <nl> + * <nl> + * This does an unordered comparison , i . e . childrenMatch returns true <nl> + * as long as the set of subtrees in testSoln ' s ' nodes ' matches the set of <nl> + * subtrees in trueSoln ' s ' children ' vector . <nl> + * / <nl> + bool childrenMatch ( const BSONObj & testSoln , const QuerySolutionNode * trueSoln ) const { <nl> + BSONElement children = testSoln [ \" nodes \" ] ; <nl> + if ( children . eoo ( ) | | ! children . isABSONObj ( ) ) { return false ; } <nl> + <nl> + / / The order of the children array in testSoln might not match <nl> + / / the order in trueSoln , so we have to check all combos with <nl> + / / these nested loops . <nl> + BSONObjIterator i ( children . Obj ( ) ) ; <nl> + while ( i . more ( ) ) { <nl> + BSONElement child = i . next ( ) ; <nl> + if ( child . eoo ( ) | | ! child . isABSONObj ( ) ) { return false ; } <nl> + <nl> + / / try to match against one of the QuerySolutionNode ' s children <nl> + bool found = false ; <nl> + for ( size_t j = 0 ; j < trueSoln - > children . size ( ) ; + + j ) { <nl> + if ( solutionMatches ( child . Obj ( ) , trueSoln - > children [ j ] ) ) { <nl> + found = true ; <nl> + break ; <nl> + } <nl> } <nl> + <nl> + / / we couldn ' t match child <nl> + if ( ! found ) { return false ; } <nl> } <nl> - ASSERT_EQUALS ( found , 1U ) ; <nl> + <nl> + return true ; <nl> } <nl> <nl> - void getAllPlans ( StageType stageType , vector < QuerySolution * > * out ) const { <nl> - for ( vector < QuerySolution * > : : const_iterator it = solns . begin ( ) ; <nl> - it ! = solns . end ( ) ; <nl> - + + it ) { <nl> - if ( ( * it ) - > root - > getType ( ) = = stageType ) { <nl> - out - > push_back ( * it ) ; <nl> - } <nl> + bool solutionMatches ( const BSONObj & testSoln , const QuerySolutionNode * trueSoln ) const { <nl> + <nl> + / / <nl> + / / leaf nodes <nl> + / / <nl> + if ( STAGE_COLLSCAN = = trueSoln - > getType ( ) ) { <nl> + return testSoln . hasField ( \" cscan \" ) & & ( testSoln . nFields ( ) = = 1 ) ; <nl> + } <nl> + else if ( STAGE_IXSCAN = = trueSoln - > getType ( ) ) { <nl> + const IndexScanNode * ixn = static_cast < const IndexScanNode * > ( trueSoln ) ; <nl> + BSONElement el = testSoln [ \" ixscan \" ] ; <nl> + if ( el . eoo ( ) | | ! el . isABSONObj ( ) ) { return false ; } <nl> + BSONObj argObj = el . Obj ( ) ; <nl> + return argObj = = ixn - > indexKeyPattern ; <nl> + } <nl> + else if ( STAGE_GEO_2D = = trueSoln - > getType ( ) ) { <nl> + const Geo2DNode * node = static_cast < const Geo2DNode * > ( trueSoln ) ; <nl> + BSONElement el = testSoln [ \" geo2d \" ] ; <nl> + if ( el . eoo ( ) | | ! el . isABSONObj ( ) ) { return false ; } <nl> + BSONObj geoObj = el . Obj ( ) ; <nl> + return geoObj = = node - > indexKeyPattern ; <nl> + } <nl> + else if ( STAGE_GEO_NEAR_2D = = trueSoln - > getType ( ) ) { <nl> + const GeoNear2DNode * node = static_cast < const GeoNear2DNode * > ( trueSoln ) ; <nl> + BSONElement el = testSoln [ \" geoNear2d \" ] ; <nl> + if ( el . eoo ( ) | | ! el . isABSONObj ( ) ) { return false ; } <nl> + BSONObj geoObj = el . Obj ( ) ; <nl> + return geoObj = = node - > indexKeyPattern ; <nl> + } <nl> + else if ( STAGE_GEO_NEAR_2DSPHERE = = trueSoln - > getType ( ) ) { <nl> + const GeoNear2DSphereNode * node = static_cast < const GeoNear2DSphereNode * > ( trueSoln ) ; <nl> + BSONElement el = testSoln [ \" geoNear2dsphere \" ] ; <nl> + if ( el . eoo ( ) | | ! el . isABSONObj ( ) ) { return false ; } <nl> + BSONObj geoObj = el . Obj ( ) ; <nl> + return geoObj = = node - > indexKeyPattern ; <nl> } <nl> - } <nl> <nl> - / / { ' field ' : [ [ min , max , startInclusive , endInclusive ] , . . . ] , ' field ' : . . . } <nl> - void boundsEqual ( BSONObj boundsObj , IndexBounds bounds ) const { <nl> - ASSERT_EQUALS ( static_cast < int > ( bounds . size ( ) ) , boundsObj . nFields ( ) ) ; <nl> + / / <nl> + / / internal nodes <nl> + / / <nl> <nl> - size_t i = 0 ; <nl> - BSONObjIterator iti ( boundsObj ) ; <nl> - while ( iti . more ( ) ) { <nl> + else if ( STAGE_FETCH = = trueSoln - > getType ( ) ) { <nl> + const FetchNode * fn = static_cast < const FetchNode * > ( trueSoln ) ; <nl> + BSONElement el = testSoln [ \" fetch \" ] ; <nl> + if ( el . eoo ( ) | | ! el . isABSONObj ( ) ) { return false ; } <nl> + return solutionMatches ( el . Obj ( ) , fn - > children [ 0 ] ) ; <nl> + } <nl> + else if ( STAGE_OR = = trueSoln - > getType ( ) ) { <nl> + const OrNode * orn = static_cast < const OrNode * > ( trueSoln ) ; <nl> + BSONElement el = testSoln [ \" or \" ] ; <nl> + if ( el . eoo ( ) | | ! el . isABSONObj ( ) ) { return false ; } <nl> + BSONObj orObj = el . Obj ( ) ; <nl> + return childrenMatch ( orObj , orn ) ; <nl> + } <nl> + else if ( STAGE_PROJECTION = = trueSoln - > getType ( ) ) { <nl> + const ProjectionNode * pn = static_cast < const ProjectionNode * > ( trueSoln ) ; <nl> <nl> - BSONElement field = iti . next ( ) ; <nl> - ASSERT_EQUALS ( field . type ( ) , Array ) ; <nl> - ASSERT_EQUALS ( static_cast < int > ( bounds . getNumIntervals ( i ) ) , <nl> - field . embeddedObject ( ) . nFields ( ) ) ; <nl> + BSONElement el = testSoln [ \" proj \" ] ; <nl> + if ( el . eoo ( ) | | ! el . isABSONObj ( ) ) { return false ; } <nl> + BSONObj projObj = el . Obj ( ) ; <nl> <nl> - size_t j = 0 ; <nl> - BSONObjIterator itj ( field . embeddedObject ( ) ) ; <nl> - while ( itj . more ( ) ) { <nl> + BSONElement spec = projObj [ \" spec \" ] ; <nl> + if ( spec . eoo ( ) | | ! spec . isABSONObj ( ) ) { return false ; } <nl> + BSONElement child = projObj [ \" node \" ] ; <nl> + if ( child . eoo ( ) | | ! child . isABSONObj ( ) ) { return false ; } <nl> <nl> - BSONElement intervalElem = itj . next ( ) ; <nl> - ASSERT_EQUALS ( intervalElem . type ( ) , Array ) ; <nl> - BSONObj intervalObj = intervalElem . embeddedObject ( ) ; <nl> - ASSERT_EQUALS ( intervalObj . nFields ( ) , 4 ) ; <nl> + return ( spec . Obj ( ) = = pn - > liteProjection - > getProjectionSpec ( ) ) <nl> + & & solutionMatches ( child . Obj ( ) , pn - > children [ 0 ] ) ; <nl> + } <nl> + else if ( STAGE_SORT = = trueSoln - > getType ( ) ) { <nl> + const SortNode * sn = static_cast < const SortNode * > ( trueSoln ) ; <nl> + BSONElement el = testSoln [ \" sort \" ] ; <nl> + if ( el . eoo ( ) | | ! el . isABSONObj ( ) ) { return false ; } <nl> + BSONObj sortObj = el . Obj ( ) ; <nl> + <nl> + BSONElement patternEl = sortObj [ \" pattern \" ] ; <nl> + if ( patternEl . eoo ( ) | | ! patternEl . isABSONObj ( ) ) { return false ; } <nl> + BSONElement child = sortObj [ \" node \" ] ; <nl> + if ( child . eoo ( ) | | ! child . isABSONObj ( ) ) { return false ; } <nl> + <nl> + return ( patternEl . Obj ( ) = = sn - > pattern ) <nl> + & & solutionMatches ( child . Obj ( ) , sn - > children [ 0 ] ) ; <nl> + } <nl> + else if ( STAGE_SORT_MERGE = = trueSoln - > getType ( ) ) { <nl> + const MergeSortNode * msn = static_cast < const MergeSortNode * > ( trueSoln ) ; <nl> + BSONElement el = testSoln [ \" mergeSort \" ] ; <nl> + if ( el . eoo ( ) | | ! el . isABSONObj ( ) ) { return false ; } <nl> + BSONObj mergeSortObj = el . Obj ( ) ; <nl> + return childrenMatch ( mergeSortObj , msn ) ; <nl> + } <nl> + else if ( STAGE_SKIP = = trueSoln - > getType ( ) ) { <nl> + const SkipNode * sn = static_cast < const SkipNode * > ( trueSoln ) ; <nl> + BSONElement el = testSoln [ \" skip \" ] ; <nl> + if ( el . eoo ( ) | | ! el . isABSONObj ( ) ) { return false ; } <nl> + BSONObj sortObj = el . Obj ( ) ; <nl> + <nl> + BSONElement skipEl = sortObj [ \" n \" ] ; <nl> + if ( ! skipEl . isNumber ( ) ) { return false ; } <nl> + BSONElement child = sortObj [ \" node \" ] ; <nl> + if ( child . eoo ( ) | | ! child . isABSONObj ( ) ) { return false ; } <nl> + <nl> + return ( skipEl . numberInt ( ) = = sn - > skip ) <nl> + & & solutionMatches ( child . Obj ( ) , sn - > children [ 0 ] ) ; <nl> + } <nl> + else if ( STAGE_LIMIT = = trueSoln - > getType ( ) ) { <nl> + const LimitNode * ln = static_cast < const LimitNode * > ( trueSoln ) ; <nl> + BSONElement el = testSoln [ \" limit \" ] ; <nl> + if ( el . eoo ( ) | | ! el . isABSONObj ( ) ) { return false ; } <nl> + BSONObj sortObj = el . Obj ( ) ; <nl> + <nl> + BSONElement limitEl = sortObj [ \" n \" ] ; <nl> + if ( ! limitEl . isNumber ( ) ) { return false ; } <nl> + BSONElement child = sortObj [ \" node \" ] ; <nl> + if ( child . eoo ( ) | | ! child . isABSONObj ( ) ) { return false ; } <nl> + <nl> + return ( limitEl . numberInt ( ) = = ln - > limit ) <nl> + & & solutionMatches ( child . Obj ( ) , ln - > children [ 0 ] ) ; <nl> + } <nl> <nl> - Interval interval ( intervalObj , intervalObj [ 2 ] . Bool ( ) , intervalObj [ 3 ] . Bool ( ) ) ; <nl> - ASSERT_EQUALS ( interval . compare ( bounds . getInterval ( i , j ) ) , <nl> - Interval : : INTERVAL_EQUALS ) ; <nl> + return false ; <nl> + } <nl> <nl> - j + + ; <nl> + / * * <nl> + * Verifies that the solution tree represented in json by ' solnJson ' is <nl> + * one of the solutions generated by QueryPlanner . <nl> + * <nl> + * By default , ' expectMatches ' is 1 . In rare cases expectMatches may be <nl> + * have to be specified as some other positive integer . For example , in <nl> + * the BasicAllElemMatch test case , there are two possible query plans <nl> + * using each of the available indices which differ only by their filter . <nl> + * Since assertSolutionExists , at least for now , does not look at the filter , <nl> + * we cannot distinguish between the two plans and expect two matches . <nl> + * / <nl> + void assertSolutionExists ( const string & solnJson , size_t expectMatches = 1 ) const { <nl> + BSONObj testSoln = fromjson ( solnJson ) ; <nl> + size_t matches = 0 ; <nl> + for ( vector < QuerySolution * > : : const_iterator it = solns . begin ( ) ; <nl> + it ! = solns . end ( ) ; <nl> + + + it ) { <nl> + QuerySolutionNode * root = ( * it ) - > root . get ( ) ; <nl> + if ( solutionMatches ( testSoln , root ) ) { <nl> + + + matches ; <nl> } <nl> + } <nl> + ASSERT_EQUALS ( matches , expectMatches ) ; <nl> + } <nl> <nl> - i + + ; <nl> + / / TODO : <nl> + / / bool hasIndexedPlan ( BSONObj indexKeyPattern ) ; <nl> + <nl> + void getAllPlans ( StageType stageType , vector < QuerySolution * > * out ) const { <nl> + for ( vector < QuerySolution * > : : const_iterator it = solns . begin ( ) ; <nl> + it ! = solns . end ( ) ; <nl> + + + it ) { <nl> + if ( ( * it ) - > root - > getType ( ) = = stageType ) { <nl> + out - > push_back ( * it ) ; <nl> + } <nl> } <nl> } <nl> <nl> namespace { <nl> runQuery ( BSON ( \" x \" < < 5 ) ) ; <nl> <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> - <nl> - QuerySolution * collScanSolution ; <nl> - getPlanByType ( STAGE_COLLSCAN , & collScanSolution ) ; <nl> - <nl> - QuerySolution * indexedSolution ; <nl> - getPlanByType ( STAGE_FETCH , & indexedSolution ) ; <nl> - FetchNode * fn = static_cast < FetchNode * > ( indexedSolution - > root . get ( ) ) ; <nl> - IndexScanNode * ixNode = static_cast < IndexScanNode * > ( fn - > children [ 0 ] ) ; <nl> - boundsEqual ( fromjson ( \" { x : [ [ 5 , 5 , true , true ] ] } \" ) , ixNode - > bounds ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { x : 1 } } } \" ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , EqualityIndexScanWithTrailingFields ) { <nl> namespace { <nl> runQuery ( BSON ( \" x \" < < 5 ) ) ; <nl> <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> - <nl> - QuerySolution * collScanSolution ; <nl> - getPlanByType ( STAGE_COLLSCAN , & collScanSolution ) ; <nl> - <nl> - QuerySolution * indexedSolution ; <nl> - getPlanByType ( STAGE_FETCH , & indexedSolution ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { x : 1 , y : 1 } } } \" ) ; <nl> } <nl> <nl> / / <nl> namespace { <nl> runQuery ( BSON ( \" x \" < < BSON ( \" $ lt \" < < 5 ) ) ) ; <nl> <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> - <nl> - QuerySolution * collScanSolution ; <nl> - getPlanByType ( STAGE_COLLSCAN , & collScanSolution ) ; <nl> - <nl> - QuerySolution * indexedSolution ; <nl> - getPlanByType ( STAGE_FETCH , & indexedSolution ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { x : 1 } } } \" ) ; <nl> } <nl> <nl> / / <nl> namespace { <nl> runQuery ( BSON ( \" x \" < < BSON ( \" $ lte \" < < 5 ) ) ) ; <nl> <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> - <nl> - QuerySolution * collScanSolution ; <nl> - getPlanByType ( STAGE_COLLSCAN , & collScanSolution ) ; <nl> - <nl> - QuerySolution * indexedSolution ; <nl> - getPlanByType ( STAGE_FETCH , & indexedSolution ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { x : 1 } } } \" ) ; <nl> } <nl> <nl> / / <nl> namespace { <nl> runQuery ( BSON ( \" x \" < < BSON ( \" $ gt \" < < 5 ) ) ) ; <nl> <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> - <nl> - QuerySolution * collScanSolution ; <nl> - getPlanByType ( STAGE_COLLSCAN , & collScanSolution ) ; <nl> - <nl> - QuerySolution * indexedSolution ; <nl> - getPlanByType ( STAGE_FETCH , & indexedSolution ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { x : 1 } } } \" ) ; <nl> } <nl> <nl> / / <nl> namespace { <nl> runQuery ( BSON ( \" x \" < < BSON ( \" $ gte \" < < 5 ) ) ) ; <nl> <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { x : 1 } } } \" ) ; <nl> + } <nl> <nl> - QuerySolution * collScanSolution ; <nl> - getPlanByType ( STAGE_COLLSCAN , & collScanSolution ) ; <nl> + / / <nl> + / / skip and limit <nl> + / / <nl> + <nl> + TEST_F ( IndexAssignmentTest , BasicSkipNoIndex ) { <nl> + addIndex ( BSON ( \" a \" < < 1 ) ) ; <nl> <nl> - QuerySolution * indexedSolution ; <nl> - getPlanByType ( STAGE_FETCH , & indexedSolution ) ; <nl> + runQuerySkipLimit ( BSON ( \" x \" < < 5 ) , 3 , 0 ) ; <nl> + <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 1U ) ; <nl> + assertSolutionExists ( \" { skip : { n : 3 , node : { cscan : 1 } } } \" ) ; <nl> + } <nl> + <nl> + TEST_F ( IndexAssignmentTest , BasicSkipWithIndex ) { <nl> + addIndex ( BSON ( \" a \" < < 1 < < \" b \" < < 1 ) ) ; <nl> + <nl> + runQuerySkipLimit ( BSON ( \" a \" < < 5 ) , 8 , 0 ) ; <nl> + <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { skip : { n : 8 , node : { cscan : 1 } } } \" ) ; <nl> + assertSolutionExists ( \" { skip : { n : 8 , node : { fetch : { ixscan : { a : 1 , b : 1 } } } } } \" ) ; <nl> + } <nl> + <nl> + TEST_F ( IndexAssignmentTest , BasicLimitNoIndex ) { <nl> + addIndex ( BSON ( \" a \" < < 1 ) ) ; <nl> + <nl> + runQuerySkipLimit ( BSON ( \" x \" < < 5 ) , 0 , - 3 ) ; <nl> + <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 1U ) ; <nl> + assertSolutionExists ( \" { limit : { n : 3 , node : { cscan : 1 } } } \" ) ; <nl> + } <nl> + <nl> + TEST_F ( IndexAssignmentTest , BasicLimitWithIndex ) { <nl> + addIndex ( BSON ( \" a \" < < 1 < < \" b \" < < 1 ) ) ; <nl> + <nl> + runQuerySkipLimit ( BSON ( \" a \" < < 5 ) , 0 , - 5 ) ; <nl> + <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { limit : { n : 5 , node : { cscan : 1 } } } \" ) ; <nl> + assertSolutionExists ( \" { limit : { n : 5 , node : { fetch : { ixscan : { a : 1 , b : 1 } } } } } \" ) ; <nl> + } <nl> + <nl> + TEST_F ( IndexAssignmentTest , SkipAndLimit ) { <nl> + addIndex ( BSON ( \" x \" < < 1 ) ) ; <nl> + <nl> + runQuerySkipLimit ( BSON ( \" x \" < < BSON ( \" $ lte \" < < 4 ) ) , 7 , - 2 ) ; <nl> + <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { limit : { n : 2 , node : { skip : { n : 7 , node : { cscan : 1 } } } } } \" ) ; <nl> + assertSolutionExists ( \" { limit : { n : 2 , node : { skip : { n : 7 , node : { fetch : { ixscan : { x : 1 } } } } } } } \" ) ; <nl> } <nl> <nl> / / <nl> namespace { <nl> runQuery ( fromjson ( \" { $ and : [ { x : { $ gt : 1 } } , { x : { $ lt : 3 } } ] } \" ) ) ; <nl> <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> - <nl> - QuerySolution * collScanSolution ; <nl> - getPlanByType ( STAGE_COLLSCAN , & collScanSolution ) ; <nl> - <nl> - QuerySolution * indexedSolution ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> / / This is a fetch not an ixscan because our index tagging isn ' t good so far and we don ' t <nl> / / know that the index is used for the second predicate . <nl> - getPlanByType ( STAGE_FETCH , & indexedSolution ) ; <nl> - <nl> - / / FetchNode * fn = static_cast < FetchNode * > ( indexedSolution - > root . get ( ) ) ; <nl> - / / IndexScanNode * ixNode = static_cast < IndexScanNode * > ( fn - > child . get ( ) ) ; <nl> - / / TODO : use this when we tag both indices . <nl> - / / boundsEqual ( fromjson ( \" { x : [ [ 1 , 3 , false , false ] ] } \" ) , ixNode - > bounds ) ; <nl> - / / TODO check filter <nl> + assertSolutionExists ( \" { fetch : { ixscan : { x : 1 } } } \" ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , SimpleOr ) { <nl> addIndex ( BSON ( \" a \" < < 1 ) ) ; <nl> runQuery ( fromjson ( \" { $ or : [ { a : 20 } , { a : 21 } ] } \" ) ) ; <nl> + <nl> + dumpSolutions ( ) ; <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> - QuerySolution * indexedSolution = NULL ; <nl> - getPlanByType ( STAGE_FETCH , & indexedSolution ) ; <nl> - cout < < indexedSolution - > toString ( ) < < endl ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { a : 1 } } } \" ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , OrWithoutEnoughIndices ) { <nl> addIndex ( BSON ( \" a \" < < 1 ) ) ; <nl> runQuery ( fromjson ( \" { $ or : [ { a : 20 } , { b : 21 } ] } \" ) ) ; <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 1U ) ; <nl> - QuerySolution * collScanSolution ; <nl> - getPlanByType ( STAGE_COLLSCAN , & collScanSolution ) ; <nl> - cout < < collScanSolution - > toString ( ) < < endl ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , OrWithAndChild ) { <nl> addIndex ( BSON ( \" a \" < < 1 ) ) ; <nl> runQuery ( fromjson ( \" { $ or : [ { a : 20 } , { $ and : [ { a : 1 } , { b : 7 } ] } ] } \" ) ) ; <nl> + <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> - QuerySolution * indexedSolution = NULL ; <nl> - getPlanByType ( STAGE_FETCH , & indexedSolution ) ; <nl> - cout < < indexedSolution - > toString ( ) < < endl ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { or : { nodes : [ { fetch : { ixscan : { a : 1 } } } , { ixscan : { a : 1 } } ] } } } \" ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , AndWithUnindexedOrChild ) { <nl> addIndex ( BSON ( \" a \" < < 1 ) ) ; <nl> runQuery ( fromjson ( \" { a : 20 , $ or : [ { b : 1 } , { c : 7 } ] } \" ) ) ; <nl> + <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> - QuerySolution * indexedSolution = NULL ; <nl> - getPlanByType ( STAGE_FETCH , & indexedSolution ) ; <nl> - cout < < indexedSolution - > toString ( ) < < endl ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { a : 1 } } } \" ) ; <nl> } <nl> <nl> <nl> namespace { <nl> addIndex ( BSON ( \" b \" < < 1 ) ) ; <nl> addIndex ( BSON ( \" a \" < < 1 ) ) ; <nl> runQuery ( fromjson ( \" { $ or : [ { b : 1 } , { c : 7 } ] , a : 20 } \" ) ) ; <nl> + <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> - QuerySolution * indexedSolution = NULL ; <nl> - getPlanByType ( STAGE_FETCH , & indexedSolution ) ; <nl> - cout < < indexedSolution - > toString ( ) < < endl ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { a : 1 } } } \" ) ; <nl> } <nl> <nl> / / <nl> namespace { <nl> TEST_F ( IndexAssignmentTest , AndOfAnd ) { <nl> addIndex ( BSON ( \" x \" < < 1 ) ) ; <nl> runQuery ( fromjson ( \" { $ and : [ { $ and : [ { x : 2 . 5 } ] } , { x : { $ gt : 1 } } , { x : { $ lt : 3 } } ] } \" ) ) ; <nl> - ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> - <nl> - QuerySolution * collScanSolution ; <nl> - getPlanByType ( STAGE_COLLSCAN , & collScanSolution ) ; <nl> - / / TODO check filter <nl> <nl> - QuerySolution * indexedSolution ; <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> / / This is a fetch not an ixscan because our index tagging isn ' t good so far and we don ' t <nl> / / know that the index is used for the second predicate . <nl> - getPlanByType ( STAGE_FETCH , & indexedSolution ) ; <nl> - cout < < indexedSolution - > toString ( ) < < endl ; <nl> - <nl> - / / FetchNode * fn = static_cast < FetchNode * > ( indexedSolution - > root . get ( ) ) ; <nl> - / / IndexScanNode * ixNode = static_cast < IndexScanNode * > ( fn - > child . get ( ) ) ; <nl> - / / boundsEqual ( BSON ( \" x \" < < BSON_ARRAY ( BSON_ARRAY ( 1 < < MAXKEY < < false < < true ) ) ) , ixNode - > bounds ) ; <nl> - / / TODO : use this when we tag both indices . <nl> - / / boundsEqual ( fromjson ( \" { x : [ [ 1 , 3 , false , false ] ] } \" ) , ixNode - > bounds ) ; <nl> - / / TODO check filter <nl> + assertSolutionExists ( \" { fetch : { ixscan : { x : 1 } } } \" ) ; <nl> } <nl> <nl> / / <nl> namespace { <nl> runDetailedQuery ( fromjson ( \" { x : { $ gt : 1 } } \" ) , BSONObj ( ) , fromjson ( \" { _id : 0 , x : 1 } \" ) ) ; <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> <nl> - vector < QuerySolution * > solns ; <nl> - getAllPlans ( STAGE_PROJECTION , & solns ) ; <nl> ASSERT_EQUALS ( solns . size ( ) , 2U ) ; <nl> - <nl> - for ( size_t i = 0 ; i < solns . size ( ) ; + + i ) { <nl> - cout < < solns [ i ] - > toString ( ) ; <nl> - ProjectionNode * pn = static_cast < ProjectionNode * > ( solns [ i ] - > root . get ( ) ) ; <nl> - ASSERT ( STAGE_COLLSCAN = = pn - > children [ 0 ] - > getType ( ) | | STAGE_IXSCAN = = pn - > children [ 0 ] - > getType ( ) ) ; <nl> - } <nl> + assertSolutionExists ( \" { proj : { spec : { _id : 0 , x : 1 } , node : { ixscan : { x : 1 } } } } \" ) ; <nl> + assertSolutionExists ( \" { proj : { spec : { _id : 0 , x : 1 } , node : { cscan : 1 } } } \" ) ; <nl> } <nl> <nl> / / <nl> namespace { <nl> addIndex ( BSON ( \" x \" < < 1 ) ) ; <nl> / / query , sort , proj <nl> runDetailedQuery ( fromjson ( \" { x : { $ gt : 1 } } \" ) , fromjson ( \" { x : 1 } \" ) , BSONObj ( ) ) ; <nl> - ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> <nl> - QuerySolution * collScanSolution ; <nl> - getPlanByType ( STAGE_SORT , & collScanSolution ) ; <nl> - <nl> - QuerySolution * indexedSolution ; <nl> - getPlanByType ( STAGE_FETCH , & indexedSolution ) ; <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { sort : { pattern : { x : 1 } , node : { cscan : 1 } } } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { x : 1 } } } \" ) ; <nl> } <nl> <nl> / / <nl> namespace { <nl> TEST_F ( IndexAssignmentTest , BasicCompound ) { <nl> addIndex ( BSON ( \" x \" < < 1 < < \" y \" < < 1 ) ) ; <nl> runQuery ( fromjson ( \" { x : 5 , y : 10 } \" ) ) ; <nl> - ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> <nl> - QuerySolution * collScanSolution ; <nl> - getPlanByType ( STAGE_COLLSCAN , & collScanSolution ) ; <nl> - <nl> - QuerySolution * indexedSolution ; <nl> - getPlanByType ( STAGE_FETCH , & indexedSolution ) ; <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { x : 1 , y : 1 } } } \" ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , CompoundMissingField ) { <nl> addIndex ( BSON ( \" x \" < < 1 < < \" y \" < < 1 < < \" z \" < < 1 ) ) ; <nl> runQuery ( fromjson ( \" { x : 5 , z : 10 } \" ) ) ; <nl> - ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> - <nl> - QuerySolution * collScanSolution ; <nl> - getPlanByType ( STAGE_COLLSCAN , & collScanSolution ) ; <nl> <nl> - QuerySolution * indexedSolution ; <nl> - getPlanByType ( STAGE_FETCH , & indexedSolution ) ; <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { x : 1 , y : 1 , z : 1 } } } \" ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , CompoundFieldsOrder ) { <nl> addIndex ( BSON ( \" x \" < < 1 < < \" y \" < < 1 < < \" z \" < < 1 ) ) ; <nl> runQuery ( fromjson ( \" { x : 5 , z : 10 , y : 1 } \" ) ) ; <nl> - ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> - <nl> - QuerySolution * collScanSolution ; <nl> - getPlanByType ( STAGE_COLLSCAN , & collScanSolution ) ; <nl> <nl> - QuerySolution * indexedSolution ; <nl> - getPlanByType ( STAGE_FETCH , & indexedSolution ) ; <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { x : 1 , y : 1 , z : 1 } } } \" ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , CantUseCompound ) { <nl> addIndex ( BSON ( \" x \" < < 1 < < \" y \" < < 1 ) ) ; <nl> runQuery ( fromjson ( \" { y : 10 } \" ) ) ; <nl> - ASSERT_EQUALS ( getNumSolutions ( ) , 1U ) ; <nl> <nl> - QuerySolution * collScanSolution ; <nl> - getPlanByType ( STAGE_COLLSCAN , & collScanSolution ) ; <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 1U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> } <nl> <nl> / / <nl> namespace { <nl> TEST_F ( IndexAssignmentTest , ElemMatchOneField ) { <nl> addIndex ( BSON ( \" a . b \" < < 1 ) ) ; <nl> runQuery ( fromjson ( \" { a : { $ elemMatch : { b : 1 } } } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> + <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { ' a . b ' : 1 } } } \" ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , ElemMatchTwoFields ) { <nl> addIndex ( BSON ( \" a . b \" < < 1 ) ) ; <nl> addIndex ( BSON ( \" a . c \" < < 1 ) ) ; <nl> runQuery ( fromjson ( \" { a : { $ elemMatch : { b : 1 , c : 1 } } } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> + <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 3U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { ' a . b ' : 1 } } } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { ' a . c ' : 1 } } } \" ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , BasicAllElemMatch ) { <nl> addIndex ( BSON ( \" foo . a \" < < 1 ) ) ; <nl> addIndex ( BSON ( \" foo . b \" < < 1 ) ) ; <nl> runQuery ( fromjson ( \" { foo : { $ all : [ { $ elemMatch : { a : 1 , b : 1 } } , { $ elemMatch : { a : 2 , b : 2 } } ] } } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> + <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 5U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { ' foo . a ' : 1 } } } \" , 2 ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { ' foo . b ' : 1 } } } \" , 2 ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , ElemMatchValueMatch ) { <nl> addIndex ( BSON ( \" foo \" < < 1 ) ) ; <nl> addIndex ( BSON ( \" foo \" < < 1 < < \" bar \" < < 1 ) ) ; <nl> runQuery ( fromjson ( \" { foo : { $ elemMatch : { $ gt : 5 , $ lt : 10 } } } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> + <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 3U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { foo : 1 } } } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { foo : 1 , bar : 1 } } } \" ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , ElemMatchNested ) { <nl> addIndex ( BSON ( \" a . b . c \" < < 1 ) ) ; <nl> runQuery ( fromjson ( \" { a : { $ elemMatch : { b : { $ elemMatch : { c : { $ gte : 1 , $ lte : 1 } } } } } } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> + <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { ' a . b . c ' : 1 } } } \" ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , TwoElemMatchNested ) { <nl> namespace { <nl> runQuery ( fromjson ( \" { a : { $ elemMatch : { d : { $ elemMatch : { e : { $ lte : 1 } } } , \" <nl> \" b : { $ elemMatch : { c : { $ gte : 1 } } } } } } \" ) ) ; <nl> dumpSolutions ( ) ; <nl> + <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 3U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { ' a . d . e ' : 1 } } } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { ' a . b . c ' : 1 } } } \" ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , ElemMatchCompoundTwoFields ) { <nl> addIndex ( BSON ( \" a . b \" < < 1 < < \" a . c \" < < 1 ) ) ; <nl> runQuery ( fromjson ( \" { a : { $ elemMatch : { b : 1 , c : 1 } } } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> + <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { ' a . b ' : 1 , ' a . c ' : 1 } } } \" ) ; <nl> } <nl> <nl> / / <nl> namespace { <nl> <nl> / / Polygon <nl> runQuery ( fromjson ( \" { a : { $ within : { $ polygon : [ [ 0 , 0 ] , [ 2 , 0 ] , [ 4 , 0 ] ] } } } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { geo2d : { a : ' 2d ' } } } \" ) ; <nl> <nl> / / Center <nl> runQuery ( fromjson ( \" { a : { $ within : { $ center : [ [ 5 , 5 ] , 7 ] } } } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { geo2d : { a : ' 2d ' } } } \" ) ; <nl> <nl> / / Centersphere <nl> runQuery ( fromjson ( \" { a : { $ within : { $ centerSphere : [ [ 10 , 20 ] , 0 . 01 ] } } } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { geo2d : { a : ' 2d ' } } } \" ) ; <nl> <nl> / / Within box . <nl> runQuery ( fromjson ( \" { a : { $ within : { $ box : [ [ 0 , 0 ] , [ 9 , 9 ] ] } } } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { geo2d : { a : ' 2d ' } } } \" ) ; <nl> <nl> / / TODO : test that we * don ' t * annotate for things we shouldn ' t . <nl> } <nl> namespace { <nl> <nl> runQuery ( fromjson ( \" { a : { $ geoIntersects : { $ geometry : { type : ' Point ' , \" <nl> \" coordinates : [ 10 . 0 , 10 . 0 ] } } } } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { a : ' 2dsphere ' } } } \" ) ; <nl> <nl> runQuery ( fromjson ( \" { a : { $ geoWithin : { $ centerSphere : [ [ 10 , 20 ] , 0 . 01 ] } } } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { a : ' 2dsphere ' } } } \" ) ; <nl> <nl> / / TODO : test that we * don ' t * annotate for things we shouldn ' t . <nl> } <nl> namespace { <nl> / / Can only do near + old point . <nl> addIndex ( BSON ( \" a \" < < \" 2d \" ) ) ; <nl> runQuery ( fromjson ( \" { a : { $ near : [ 0 , 0 ] , $ maxDistance : 0 . 3 } } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 1U ) ; <nl> + assertSolutionExists ( \" { geoNear2d : { a : ' 2d ' } } \" ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , Basic2DSphereGeoNear ) { <nl> namespace { <nl> addIndex ( BSON ( \" a \" < < \" 2dsphere \" ) ) ; <nl> <nl> runQuery ( fromjson ( \" { a : { $ nearSphere : [ 0 , 0 ] , $ maxDistance : 0 . 31 } } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 1U ) ; <nl> + assertSolutionExists ( \" { geoNear2dsphere : { a : ' 2dsphere ' } } \" ) ; <nl> <nl> runQuery ( fromjson ( \" { a : { $ geoNear : { $ geometry : { type : ' Point ' , coordinates : [ 0 , 0 ] } , \" <nl> \" $ maxDistance : 100 } } } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 1U ) ; <nl> + assertSolutionExists ( \" { geoNear2dsphere : { a : ' 2dsphere ' } } \" ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , Basic2DSphereGeoNearReverseCompound ) { <nl> addIndex ( BSON ( \" x \" < < 1 ) ) ; <nl> addIndex ( BSON ( \" x \" < < 1 < < \" a \" < < \" 2dsphere \" ) ) ; <nl> runQuery ( fromjson ( \" { x : 1 , a : { $ nearSphere : [ 0 , 0 ] , $ maxDistance : 0 . 31 } } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> + <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 1U ) ; <nl> + assertSolutionExists ( \" { geoNear2dsphere : { x : 1 , a : ' 2dsphere ' } } \" ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , NearNoIndex ) { <nl> addIndex ( BSON ( \" x \" < < 1 ) ) ; <nl> runQuery ( fromjson ( \" { x : 1 , a : { $ nearSphere : [ 0 , 0 ] , $ maxDistance : 0 . 31 } } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 0U ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , TwoDSphereNoGeoPred ) { <nl> addIndex ( BSON ( \" x \" < < 1 < < \" a \" < < \" 2dsphere \" ) ) ; <nl> runQuery ( fromjson ( \" { x : 1 } \" ) ) ; <nl> - dumpSolutions ( ) ; <nl> + <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { x : 1 , a : ' 2dsphere ' } } } \" ) ; <nl> + } <nl> + <nl> + / / SERVER - 3984 , $ or 2d index <nl> + TEST_F ( IndexAssignmentTest , Or2DNonNear ) { <nl> + addIndex ( BSON ( \" a \" < < \" 2d \" ) ) ; <nl> + addIndex ( BSON ( \" b \" < < \" 2d \" ) ) ; <nl> + runQuery ( fromjson ( \" { $ or : [ { a : { $ within : { $ polygon : [ [ 0 , 0 ] , [ 2 , 0 ] , [ 4 , 0 ] ] } } } , \" <nl> + \" { b : { $ within : { $ center : [ [ 5 , 5 ] , 7 ] } } } ] } \" ) ) ; <nl> + <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { or : { nodes : [ { geo2d : { a : ' 2d ' } } , { geo2d : { b : ' 2d ' } } ] } } } \" ) ; <nl> } <nl> <nl> + / / SERVER - 3984 , $ or 2dsphere index <nl> + TEST_F ( IndexAssignmentTest , Or2DSphereNonNear ) { <nl> + addIndex ( BSON ( \" a \" < < \" 2dsphere \" ) ) ; <nl> + addIndex ( BSON ( \" b \" < < \" 2dsphere \" ) ) ; <nl> + runQuery ( fromjson ( \" { $ or : [ { a : { $ geoIntersects : { $ geometry : { type : ' Point ' , coordinates : [ 10 . 0 , 10 . 0 ] } } } } , \" <nl> + \" { b : { $ geoWithin : { $ centerSphere : [ [ 10 , 20 ] , 0 . 01 ] } } } ] } \" ) ) ; <nl> + <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + / / TODO investigate why no indexed solution exists <nl> + } <nl> + <nl> + <nl> / / <nl> / / Multiple solutions <nl> / / <nl> namespace { <nl> <nl> runQuery ( fromjson ( \" { a : 1 , b : { $ gt : 2 , $ lt : 2 } } \" ) ) ; <nl> <nl> - dumpSolutions ( ) ; <nl> - <nl> / / 2 indexed solns and one non - indexed <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 3U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { a : 1 } } } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { a : 1 , b : 1 } } } \" ) ; <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , TwoPlansElemMatch ) { <nl> namespace { <nl> runQuery ( fromjson ( \" { arr : { $ elemMatch : { x : 5 , y : 5 } } , \" <nl> \" a : 55 , b : { $ in : [ 1 , 5 , 8 ] } } \" ) ) ; <nl> <nl> - dumpSolutions ( ) ; <nl> - <nl> / / 2 indexed solns and one non - indexed <nl> ASSERT_EQUALS ( getNumSolutions ( ) , 3U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { a : 1 , b : 1 } } } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { fetch : { ixscan : { ' arr . x ' : 1 , a : 1 } } } } \" ) ; <nl> } <nl> <nl> / / <nl> namespace { <nl> addIndex ( BSON ( \" a \" < < 1 < < \" c \" < < 1 ) ) ; <nl> addIndex ( BSON ( \" b \" < < 1 < < \" c \" < < 1 ) ) ; <nl> runDetailedQuery ( fromjson ( \" { $ or : [ { a : 1 } , { b : 1 } ] } \" ) , fromjson ( \" { c : 1 } \" ) , BSONObj ( ) ) ; <nl> - dumpSolutions ( ) ; <nl> + <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { fetch : { mergeSort : { nodes : [ { ixscan : { a : 1 , c : 1 } } , { ixscan : { b : 1 , c : 1 } } ] } } } \" ) ; <nl> + assertSolutionExists ( \" { sort : { pattern : { c : 1 } , node : { cscan : 1 } } } \" ) ; <nl> } <nl> <nl> / / SERVER - 1205 as well . <nl> namespace { <nl> addIndex ( BSON ( \" a \" < < 1 < < \" c \" < < 1 ) ) ; <nl> addIndex ( BSON ( \" b \" < < 1 < < \" c \" < < 1 ) ) ; <nl> runDetailedQuery ( fromjson ( \" { $ or : [ { a : 1 } , { b : 1 } ] } \" ) , BSONObj ( ) , BSONObj ( ) ) ; <nl> - dumpSolutions ( ) ; <nl> + <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { cscan : 1 } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { or : { nodes : [ { ixscan : { a : 1 , c : 1 } } , { ixscan : { b : 1 , c : 1 } } ] } } } \" ) ; <nl> } <nl> <nl> / / SERVER - 10801 <nl> namespace { <nl> BSONObj query = fromjson ( \" { position : { $ geoWithin : { $ geometry : { type : \\ \" Polygon \\ \" , coordinates : [ [ [ 1 , 1 ] , [ 1 , 90 ] , [ 180 , 90 ] , [ 180 , 1 ] , [ 1 , 1 ] ] ] } } } } \" ) ; <nl> BSONObj sort = fromjson ( \" { timestamp : - 1 } \" ) ; <nl> runDetailedQuery ( query , sort , BSONObj ( ) ) ; <nl> - dumpSolutions ( ) ; <nl> + <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { sort : { pattern : { timestamp : - 1 } , node : { cscan : 1 } } } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { timestamp : - 1 , position : ' 2dsphere ' } } } \" ) ; <nl> } <nl> <nl> / / SERVER - 9257 <nl> namespace { <nl> addIndex ( BSON ( \" creationDate \" < < 1 < < \" foo . bar \" < < \" 2dsphere \" ) ) ; <nl> runDetailedQuery ( fromjson ( \" { creationDate : { $ gt : 7 } } \" ) , <nl> fromjson ( \" { creationDate : 1 } \" ) , BSONObj ( ) ) ; <nl> - dumpSolutions ( ) ; <nl> + <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { sort : { pattern : { creationDate : 1 } , node : { cscan : 1 } } } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { creationDate : 1 , ' foo . bar ' : ' 2dsphere ' } } } \" ) ; <nl> } <nl> <nl> / / Basic \" keep sort in mind with an OR \" <nl> TEST_F ( IndexAssignmentTest , MergeSortEvenIfSameIndex ) { <nl> addIndex ( BSON ( \" a \" < < 1 < < \" b \" < < 1 ) ) ; <nl> runDetailedQuery ( fromjson ( \" { $ or : [ { a : 1 } , { a : 7 } ] } \" ) , fromjson ( \" { b : 1 } \" ) , BSONObj ( ) ) ; <nl> - dumpSolutions ( ) ; <nl> + <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { sort : { pattern : { b : 1 } , node : { cscan : 1 } } } \" ) ; <nl> + / / TODO the second solution should be mergeSort rather than just sort <nl> } <nl> <nl> TEST_F ( IndexAssignmentTest , ReverseScanForSort ) { <nl> addIndex ( BSON ( \" _id \" < < 1 ) ) ; <nl> runDetailedQuery ( BSONObj ( ) , fromjson ( \" { _id : - 1 } \" ) , BSONObj ( ) ) ; <nl> - dumpSolutions ( ) ; <nl> + <nl> + ASSERT_EQUALS ( getNumSolutions ( ) , 2U ) ; <nl> + assertSolutionExists ( \" { sort : { pattern : { _id : - 1 } , node : { cscan : 1 } } } \" ) ; <nl> + assertSolutionExists ( \" { fetch : { ixscan : { _id : 1 } } } \" ) ; <nl> } <nl> <nl> / / STOPPED HERE - need to hook up machinery for multiple indexed predicates <nl>\n", "msg": "SERVER - 11679 improve query planner unit test\n"}
{"diff_id": 25202, "repo": "xbmc/xbmc\n", "sha": "00c37913b66ca53539fc38f7b40fb1239096916e\n", "time": "2010-06-18T02:39:21Z\n", "diff": "mmm a / guilib / D3DResource . cpp <nl> ppp b / guilib / D3DResource . cpp <nl> bool CD3DTexture : : Create ( UINT width , UINT height , UINT mipLevels , DWORD usage , D <nl> m_pool = pool ; <nl> / / create the texture <nl> Release ( ) ; <nl> - if ( D3D_OK = = D3DXCreateTexture ( g_Windowing . Get3DDevice ( ) , m_width , m_height , m_mipLevels , m_usage , m_format , m_pool , & m_texture ) ) <nl> + HRESULT hr = D3DXCreateTexture ( g_Windowing . Get3DDevice ( ) , m_width , m_height , m_mipLevels , m_usage , m_format , m_pool , & m_texture ) ; <nl> + if ( FAILED ( hr ) ) <nl> + { <nl> + CLog : : Log ( LOGERROR , __FUNCTION__ \" - failed 0x % 08X \" , hr ) ; <nl> + } <nl> + else <nl> { <nl> D3DSURFACE_DESC desc ; <nl> if ( D3D_OK = = m_texture - > GetLevelDesc ( 0 , & desc ) ) <nl> void CD3DTexture : : RestoreTexture ( ) <nl> / / yay , we ' re back - make a new copy of the texture <nl> if ( ! m_texture ) <nl> { <nl> - D3DXCreateTexture ( g_Windowing . Get3DDevice ( ) , m_width , m_height , m_mipLevels , m_usage , m_format , m_pool , & m_texture ) ; <nl> - / / copy the data to the texture <nl> - D3DLOCKED_RECT lr ; <nl> - if ( m_texture & & m_data & & LockRect ( 0 , & lr , NULL , 0 ) ) <nl> + HRESULT hr = D3DXCreateTexture ( g_Windowing . Get3DDevice ( ) , m_width , m_height , m_mipLevels , m_usage , m_format , m_pool , & m_texture ) ; <nl> + if ( FAILED ( hr ) ) <nl> + { <nl> + CLog : : Log ( LOGERROR , __FUNCTION__ \" : D3DXCreateTexture failed 0x % 08X \" , hr ) ; <nl> + } <nl> + else <nl> { <nl> - if ( lr . Pitch = = m_pitch ) <nl> - memcpy ( lr . pBits , m_data , GetMemoryUsage ( lr . Pitch ) ) ; <nl> - else <nl> + / / copy the data to the texture <nl> + D3DLOCKED_RECT lr ; <nl> + if ( m_texture & & m_data & & LockRect ( 0 , & lr , NULL , 0 ) ) <nl> { <nl> - UINT minpitch = ( ( UINT ) lr . Pitch < m_pitch ) ? lr . Pitch : m_pitch ; <nl> - <nl> - for ( UINT i = 0 ; i < m_height ; + + i ) <nl> + if ( lr . Pitch = = m_pitch ) <nl> + memcpy ( lr . pBits , m_data , GetMemoryUsage ( lr . Pitch ) ) ; <nl> + else <nl> { <nl> - / / Get pointers to the \" rows \" of pixels in texture <nl> - BYTE * pBits = ( BYTE * ) lr . pBits + i * lr . Pitch ; <nl> - BYTE * pData = m_data + i * m_pitch ; <nl> - memcpy ( pBits , pData , minpitch ) ; <nl> + UINT minpitch = ( ( UINT ) lr . Pitch < m_pitch ) ? lr . Pitch : m_pitch ; <nl> + <nl> + for ( UINT i = 0 ; i < m_height ; + + i ) <nl> + { <nl> + / / Get pointers to the \" rows \" of pixels in texture <nl> + BYTE * pBits = ( BYTE * ) lr . pBits + i * lr . Pitch ; <nl> + BYTE * pData = m_data + i * m_pitch ; <nl> + memcpy ( pBits , pData , minpitch ) ; <nl> + } <nl> } <nl> + UnlockRect ( 0 ) ; <nl> } <nl> - UnlockRect ( 0 ) ; <nl> } <nl> + <nl> delete [ ] m_data ; <nl> m_data = NULL ; <nl> m_pitch = 0 ; <nl>\n", "msg": "[ WIN32 ] added : logging in case of texture creation failure\n"}
{"diff_id": 25263, "repo": "mongodb/mongo\n", "sha": "a241bf7b69d34004a2238ad3108b19cd09f62a6a\n", "time": "2011-01-31T18:37:42Z\n", "diff": "mmm a / s / chunk . cpp <nl> ppp b / s / chunk . cpp <nl> namespace mongo { <nl> <nl> int nc = numChunks ( ) ; <nl> <nl> - if ( nc < 16 ) { <nl> + if ( nc < 10 ) { <nl> splitThreshold = max ( splitThreshold / 4 , minChunkSize ) ; <nl> } <nl> - else if ( nc < 32 ) { <nl> + else if ( nc < 20 ) { <nl> splitThreshold = max ( splitThreshold / 2 , minChunkSize ) ; <nl> } <nl> <nl>\n", "msg": "Revert \" increase threshold for making chunks smaller \"\n"}
{"diff_id": 25290, "repo": "facebook/watchman\n", "sha": "60727f98758a43405eef2845229203e3d71463c2\n", "time": "2017-01-23T17:03:43Z\n", "diff": "mmm a / main . cpp <nl> ppp b / main . cpp <nl> static void spawn_via_launchd ( void ) <nl> <nl> compute_file_name ( & pid_file , compute_user_name ( ) , \" pid \" , \" pidfile \" ) ; <nl> <nl> - fprintf ( fp , <nl> - \" < ? xml version = \\ \" 1 . 0 \\ \" encoding = \\ \" UTF - 8 \\ \" ? > \\ n \" <nl> - \" < ! DOCTYPE plist PUBLIC \\ \" - / / Apple / / DTD PLIST 1 . 0 / / EN \\ \" \" <nl> - \" \\ \" http : / / www . apple . com / DTDs / PropertyList - 1 . 0 . dtd \\ \" > \\ n \" <nl> - \" < plist version = \\ \" 1 . 0 \\ \" > \\ n \" <nl> - \" < dict > \\ n \" <nl> - \" < key > Label < / key > \\ n \" <nl> - \" < string > com . github . facebook . watchman < / string > \\ n \" <nl> - \" < key > Disabled < / key > \\ n \" <nl> - \" < false / > \\ n \" <nl> - \" < key > ProgramArguments < / key > \\ n \" <nl> - \" < array > \\ n \" <nl> - \" < string > % s < / string > \\ n \" <nl> - \" < string > - - foreground < / string > \\ n \" <nl> - \" < string > - - logfile = % s < / string > \\ n \" <nl> - \" < string > - - log - level = % d < / string > \\ n \" <nl> - \" < string > - - sockname = % s < / string > \\ n \" <nl> - \" < string > - - statefile = % s < / string > \\ n \" <nl> - \" < string > - - pidfile = % s < / string > \\ n \" <nl> - \" < / array > \\ n \" <nl> - \" < key > Sockets < / key > \\ n \" <nl> - \" < dict > \\ n \" <nl> - \" < key > sock < / key > \\ n \" / / coupled with get_listener_socket_from_launchd <nl> - \" < dict > \\ n \" <nl> - \" < key > SockPathName < / key > \\ n \" <nl> - \" < string > % s < / string > \\ n \" <nl> - \" < key > SockPathMode < / key > \\ n \" <nl> - \" < integer > % d < / integer > \\ n \" <nl> - \" < / dict > \\ n \" <nl> - \" < / dict > \\ n \" <nl> - \" < key > KeepAlive < / key > \\ n \" <nl> - \" < dict > \\ n \" <nl> - \" < key > Crashed < / key > \\ n \" <nl> - \" < true / > \\ n \" <nl> - \" < / dict > \\ n \" <nl> - \" < key > RunAtLoad < / key > \\ n \" <nl> - \" < true / > \\ n \" <nl> - \" < key > EnvironmentVariables < / key > \\ n \" <nl> - \" < dict > \\ n \" <nl> - \" < key > PATH < / key > \\ n \" <nl> - \" < string > < ! [ CDATA [ % s ] ] > < / string > \\ n \" <nl> - \" < / dict > \\ n \" <nl> - \" < key > ProcessType < / key > \\ n \" <nl> - \" < string > Interactive < / string > \\ n \" <nl> - \" < key > Nice < / key > \\ n \" <nl> - \" < integer > - 5 < / integer > \\ n \" <nl> - \" < / dict > \\ n \" <nl> - \" < / plist > \\ n \" , <nl> - watchman_path , log_name , log_level , sock_name , <nl> - watchman_state_file , pid_file , sock_name , 0600 , <nl> - getenv ( \" PATH \" ) ) ; <nl> + auto plist_content = watchman : : to < std : : string > ( <nl> + \" < ? xml version = \\ \" 1 . 0 \\ \" encoding = \\ \" UTF - 8 \\ \" ? > \\ n \" <nl> + \" < ! DOCTYPE plist PUBLIC \\ \" - / / Apple / / DTD PLIST 1 . 0 / / EN \\ \" \" <nl> + \" \\ \" http : / / www . apple . com / DTDs / PropertyList - 1 . 0 . dtd \\ \" > \\ n \" <nl> + \" < plist version = \\ \" 1 . 0 \\ \" > \\ n \" <nl> + \" < dict > \\ n \" <nl> + \" < key > Label < / key > \\ n \" <nl> + \" < string > com . github . facebook . watchman < / string > \\ n \" <nl> + \" < key > Disabled < / key > \\ n \" <nl> + \" < false / > \\ n \" <nl> + \" < key > ProgramArguments < / key > \\ n \" <nl> + \" < array > \\ n \" <nl> + \" < string > \" , <nl> + watchman_path , <nl> + \" < / string > \\ n \" <nl> + \" < string > - - foreground < / string > \\ n \" <nl> + \" < string > - - logfile = \" , <nl> + log_name , <nl> + \" < / string > \\ n \" <nl> + \" < string > - - log - level = \" , <nl> + log_level , <nl> + \" < / string > \\ n \" <nl> + \" < string > - - sockname = \" , <nl> + sock_name , <nl> + \" < / string > \\ n \" <nl> + \" < string > - - statefile = \" , <nl> + watchman_state_file , <nl> + \" < / string > \\ n \" <nl> + \" < string > - - pidfile = \" , <nl> + pid_file , <nl> + \" < / string > \\ n \" <nl> + \" < / array > \\ n \" <nl> + \" < key > Sockets < / key > \\ n \" <nl> + \" < dict > \\ n \" <nl> + \" < key > sock < / key > \\ n \" / / coupled with <nl> + / / get_listener_socket_from_launchd <nl> + \" < dict > \\ n \" <nl> + \" < key > SockPathName < / key > \\ n \" <nl> + \" < string > \" , <nl> + sock_name , <nl> + \" < / string > \\ n \" <nl> + \" < key > SockPathMode < / key > \\ n \" <nl> + \" < integer > \" , <nl> + 0600 , <nl> + \" < / integer > \\ n \" <nl> + \" < / dict > \\ n \" <nl> + \" < / dict > \\ n \" <nl> + \" < key > KeepAlive < / key > \\ n \" <nl> + \" < dict > \\ n \" <nl> + \" < key > Crashed < / key > \\ n \" <nl> + \" < true / > \\ n \" <nl> + \" < / dict > \\ n \" <nl> + \" < key > RunAtLoad < / key > \\ n \" <nl> + \" < true / > \\ n \" <nl> + \" < key > EnvironmentVariables < / key > \\ n \" <nl> + \" < dict > \\ n \" <nl> + \" < key > PATH < / key > \\ n \" <nl> + \" < string > < ! [ CDATA [ \" , <nl> + getenv ( \" PATH \" ) , <nl> + \" ] ] > < / string > \\ n \" <nl> + \" < / dict > \\ n \" <nl> + \" < key > ProcessType < / key > \\ n \" <nl> + \" < string > Interactive < / string > \\ n \" <nl> + \" < key > Nice < / key > \\ n \" <nl> + \" < integer > - 5 < / integer > \\ n \" <nl> + \" < / dict > \\ n \" <nl> + \" < / plist > \\ n \" ) ; <nl> + fwrite ( plist_content . data ( ) , 1 , plist_content . size ( ) , fp ) ; <nl> fclose ( fp ) ; <nl> / / Don ' t rely on umask , ensure we have the correct perms <nl> chmod ( plist_path , 0644 ) ; <nl>\n", "msg": "refactor the launchd . plist construction\n"}
{"diff_id": 25366, "repo": "godotengine/godot\n", "sha": "fd52555bbe53d08ec6d1652b6f26b76e4bb8da23\n", "time": "2017-11-19T05:24:55Z\n", "diff": "mmm a / editor / editor_node . cpp <nl> ppp b / editor / editor_node . cpp <nl> EditorNode : : EditorNode ( ) { <nl> dock_tab_move_left - > set_focus_mode ( Control : : FOCUS_NONE ) ; <nl> dock_tab_move_left - > connect ( \" pressed \" , this , \" _dock_move_left \" ) ; <nl> dock_hb - > add_child ( dock_tab_move_left ) ; <nl> - dock_hb - > add_spacer ( ) ; <nl> + <nl> + Label * dock_label = memnew ( Label ) ; <nl> + dock_label - > set_text ( TTR ( \" Dock Position \" ) ) ; <nl> + dock_label - > set_h_size_flags ( Control : : SIZE_EXPAND_FILL ) ; <nl> + dock_hb - > add_child ( dock_label ) ; <nl> + <nl> dock_tab_move_right = memnew ( ToolButton ) ; <nl> dock_tab_move_right - > set_icon ( theme - > get_icon ( \" Forward \" , \" EditorIcons \" ) ) ; <nl> dock_tab_move_right - > set_focus_mode ( Control : : FOCUS_NONE ) ; <nl>\n", "msg": "Added a label to the Dock Positioner .\n"}
{"diff_id": 25456, "repo": "apple/swift\n", "sha": "a0343ee136fb3d099840968cca5d723ba1edca15\n", "time": "2017-09-19T21:53:28Z\n", "diff": "mmm a / lib / AST / ASTPrinter . cpp <nl> ppp b / lib / AST / ASTPrinter . cpp <nl> void PrintAST : : visitSubscriptDecl ( SubscriptDecl * decl ) { <nl> recordDeclLoc ( decl , [ & ] { <nl> Printer < < \" subscript \" ; <nl> } , [ & ] { / / Parameters <nl> - printParameterList ( decl - > getIndices ( ) , decl - > getIndicesInterfaceType ( ) , <nl> + printParameterList ( decl - > getIndices ( ) , <nl> + decl - > hasInterfaceType ( ) <nl> + ? decl - > getIndicesInterfaceType ( ) <nl> + : nullptr , <nl> / * isCurried = * / false , <nl> / * isAPINameByDefault * / [ ] ( ) - > bool { return false ; } ) ; <nl> } ) ; <nl>\n", "msg": "[ AST Printer ] Print non - type - checked subscript declarations .\n"}
{"diff_id": 25479, "repo": "apple/swift\n", "sha": "5a1f06a1ef2350a7cd0b656f72b6bae4432fa630\n", "time": "2019-09-05T20:05:32Z\n", "diff": "mmm a / lib / Sema / CSDiagnostics . cpp <nl> ppp b / lib / Sema / CSDiagnostics . cpp <nl> bool ContextualFailure : : tryProtocolConformanceFixIt ( <nl> / / If the protocol requires a class & we don ' t have one ( maybe the context <nl> / / is a struct ) , then bail out instead of offering a broken fix - it later on . <nl> auto requiresClass = false ; <nl> + ExistentialLayout layout ; <nl> if ( unwrappedToType - > isExistentialType ( ) ) { <nl> - requiresClass = unwrappedToType - > getExistentialLayout ( ) . requiresClass ( ) ; <nl> + layout = unwrappedToType - > getExistentialLayout ( ) ; <nl> + requiresClass = layout . requiresClass ( ) ; <nl> } <nl> if ( requiresClass & & ! FromType - > is < ClassType > ( ) ) { <nl> return false ; <nl> bool ContextualFailure : : tryProtocolConformanceFixIt ( <nl> diagnostic . flush ( ) ; <nl> <nl> / / Let ' s build a list of protocols that the contextual type does not <nl> - / / conform to . We will start by first checking if we have a protocol <nl> - / / composition type and add all the individual types that the context <nl> - / / does not conform to . <nl> + / / conform to . <nl> SmallVector < std : : string , 8 > missingProtoTypeStrings ; <nl> - if ( auto compositionTy = unwrappedToType - > getAs < ProtocolCompositionType > ( ) ) { <nl> - for ( auto memberTy : compositionTy - > getMembers ( ) ) { <nl> - auto protocol = memberTy - > getAnyNominal ( ) - > getSelfProtocolDecl ( ) ; <nl> - if ( ! getTypeChecker ( ) . conformsToProtocol ( <nl> - FromType , protocol , getDC ( ) , <nl> - ConformanceCheckFlags : : InExpression ) ) { <nl> - missingProtoTypeStrings . push_back ( memberTy - > getString ( ) ) ; <nl> - } <nl> + for ( auto protocol : layout . getProtocols ( ) ) { <nl> + if ( ! getTypeChecker ( ) . conformsToProtocol ( <nl> + FromType , protocol - > getDecl ( ) , getDC ( ) , <nl> + ConformanceCheckFlags : : InExpression ) ) { <nl> + missingProtoTypeStrings . push_back ( protocol - > getString ( ) ) ; <nl> } <nl> - / / If we don ' t conform to all of the protocols in the composition , then <nl> - / / store the composition type only . This is because we need to append <nl> - / / ' Foo & Bar ' instead of ' Foo , Bar ' in order to match the written type . <nl> - if ( missingProtoTypeStrings . size ( ) = = compositionTy - > getMembers ( ) . size ( ) ) { <nl> + } <nl> + <nl> + / / If we have a protocol composition type and we don ' t conform to all <nl> + / / the protocols of the composition , then store the composition directly . <nl> + if ( auto compositionTy = unwrappedToType - > getAs < ProtocolCompositionType > ( ) ) { <nl> + if ( compositionTy - > getMembers ( ) . size ( ) = = missingProtoTypeStrings . size ( ) ) { <nl> missingProtoTypeStrings = { compositionTy - > getString ( ) } ; <nl> } <nl> } <nl>\n", "msg": "[ CSDiagnostics ] Use the existential layout to get the protocols\n"}
{"diff_id": 25507, "repo": "EOSIO/eos\n", "sha": "8db6cabb402cd05b79d19aa5569fb1358c1addd5\n", "time": "2018-03-21T18:53:49Z\n", "diff": "mmm a / libraries / chain / contracts / eosio_contract . cpp <nl> ppp b / libraries / chain / contracts / eosio_contract . cpp <nl> void apply_eosio_postrecovery ( apply_context & context ) { <nl> auto data = get_abi_serializer ( ) . variant_to_binary ( \" pending_recovery \" , record_data ) ; <nl> const uint64_t id = account ; <nl> const uint64_t table = N ( recovery ) ; <nl> - const auto payer = config : : system_account_name ; <nl> + const auto payer = account ; <nl> const auto iter = context . db_find_i64 ( config : : system_account_name , account , table , id ) ; <nl> if ( iter = = - 1 ) { <nl> context . db_store_i64 ( account , table , payer , id , ( const char * ) data . data ( ) , data . size ( ) ) ; <nl>\n", "msg": "Changed recovery payer to be requesting account .\n", "score": 1}
{"diff_id": 25527, "msg": "increased the trees number for ERTrees\n", "msgGPT": "increase the number of trees in the ertrees.train function.", "METEOR Score": "22.593247779002194", "BLEU Score": "0.47309766024819494", "ROUGE-L Score": "0.39999999520000007", "score": 1, "repo": "opencv/opencv\n", "sha": "8a8b34667dea45f8752b9f85d2ae939fb0c96231\n", "time": "2012-04-12T14:05:55Z\n", "diff": "mmm a / samples / c / tree_engine . cpp <nl> ppp b / samples / c / tree_engine . cpp <nl> int main ( int argc , char * * argv ) <nl> print_result ( rtrees . calc_error ( & data , CV_TRAIN_ERROR ) , rtrees . calc_error ( & data , CV_TEST_ERROR ) , rtrees . get_var_importance ( ) ) ; <nl> <nl> printf ( \" = = = = = = ERTREES = = = = = \\ n \" ) ; <nl> - ertrees . train ( & data , CvRTParams ( 10 , 2 , 0 , false , 16 , 0 , true , 0 , 100 , 0 , CV_TERMCRIT_ITER ) ) ; <nl> + ertrees . train ( & data , CvRTParams ( 18 , 2 , 0 , false , 16 , 0 , true , 0 , 100 , 0 , CV_TERMCRIT_ITER ) ) ; <nl> print_result ( ertrees . calc_error ( & data , CV_TRAIN_ERROR ) , ertrees . calc_error ( & data , CV_TEST_ERROR ) , ertrees . get_var_importance ( ) ) ; <nl> <nl> printf ( \" = = = = = = GBTREES = = = = = \\ n \" ) ; <nl>\n"}
{"diff_id": 25529, "repo": "apple/swift\n", "sha": "ff75f1d3f92b310270b60d4a438c7809d1476240\n", "time": "2018-06-25T23:49:33Z\n", "diff": "mmm a / lib / AST / ProtocolConformance . cpp <nl> ppp b / lib / AST / ProtocolConformance . cpp <nl> void SpecializedProtocolConformance : : computeConditionalRequirements ( ) const { <nl> auto & ctxt = getProtocol ( ) - > getASTContext ( ) ; <nl> ConditionalRequirements = ctxt . AllocateCopy ( newReqs ) ; <nl> } else { <nl> - ConditionalRequirements = { } ; <nl> + ConditionalRequirements = Optional < ArrayRef < Requirement > > ( ) ; <nl> } <nl> } <nl> <nl>\n", "msg": "[ master - next ] Adjust syntax for setting an Optional member\n"}
{"diff_id": 25774, "repo": "aseprite/aseprite\n", "sha": "4c0bbd50f805a35bd5eb9df2d5b793383a8ec396\n", "time": "2015-05-19T17:51:01Z\n", "diff": "mmm a / src / she / win / vk . cpp <nl> ppp b / src / she / win / vk . cpp <nl> <nl> namespace she { <nl> <nl> KeyScancode win32vk_to_scancode ( int vk ) { <nl> - static KeyScancode keymap [ 0xFF ] = { <nl> + static KeyScancode keymap [ 256 ] = { <nl> / / 0x00 <nl> - kKeyNil , <nl> + kKeyNil , / / 0x00 <nl> kKeyNil , / / 0x01 - VK_LBUTTON <nl> kKeyNil , / / 0x02 - VK_RBUTTON <nl> kKeyNil , / / 0x03 - VK_CANCEL <nl> KeyScancode win32vk_to_scancode ( int vk ) { <nl> kKeyNil , / / 0x0E - Undefined <nl> kKeyNil , / / 0x0F - Undefined <nl> / / 0x10 <nl> - kKeyLShift , / / 0x10 - VK_SHIFT <nl> - kKeyLControl , / / 0x11 - VK_CONTROL <nl> - kKeyMenu , / / 0x12 - VK_MENU <nl> + kKeyNil , / / 0x10 - VK_SHIFT <nl> + kKeyNil , / / 0x11 - VK_CONTROL <nl> + kKeyNil , / / 0x12 - VK_MENU <nl> kKeyPause , / / 0x13 - VK_PAUSE <nl> kKeyCapsLock , / / 0x14 - VK_CAPITAL <nl> - kKeyNil , / / 0x15 - VK_KANA <nl> + kKeyKana , / / 0x15 - VK_KANA <nl> + kKeyNil , / / 0x16 - Undefined <nl> kKeyNil , / / 0x17 - VK_JUNJA <nl> kKeyNil , / / 0x18 - VK_FINAL <nl> kKeyKanji , / / 0x19 - VK_KANJI <nl> KeyScancode win32vk_to_scancode ( int vk ) { <nl> kKeyRight , / / 0x27 - VK_RIGHT <nl> kKeyDown , / / 0x28 - VK_DOWN <nl> kKeyNil , / / 0x29 - VK_SELECT <nl> - kKeyPrtscr , / / 0x2A - VK_PRINT <nl> + kKeyNil , / / 0x2A - VK_PRINT <nl> kKeyNil , / / 0x2B - VK_EXECUTE <nl> - kKeyNil , / / 0x2C - VK_SNAPSHOT <nl> + kKeyPrtscr , / / 0x2C - VK_SNAPSHOT <nl> kKeyInsert , / / 0x2D - VK_INSERT <nl> kKeyDel , / / 0x2E - VK_DELETE <nl> kKeyNil , / / 0x2F - VK_HELP <nl> KeyScancode win32vk_to_scancode ( int vk ) { <nl> kKey7 , / / 0x37 - VK_7 <nl> kKey8 , / / 0x38 - VK_8 <nl> kKey9 , / / 0x39 - VK_9 <nl> + kKeyNil , / / 0x3A - Unassigned <nl> + kKeyNil , / / 0x3B - Unassigned <nl> + kKeyNil , / / 0x3C - Unassigned <nl> + kKeyNil , / / 0x3D - Unassigned <nl> + kKeyNil , / / 0x3E - Unassigned <nl> + kKeyNil , / / 0x3F - Unassigned <nl> / / 0x40 <nl> kKeyNil , / / 0x40 - Unassigned <nl> kKeyA , / / 0x41 - VK_A <nl> KeyScancode win32vk_to_scancode ( int vk ) { <nl> kKeyNil , / / 0x6C - VK_SEPARATOR <nl> kKeyMinusPad , / / 0x6D - VK_SUBTRACT <nl> kKeyNil , / / 0x6E - VK_DECIMAL <nl> - kKeyNil , / / 0x6F - VK_DIVIDE <nl> + kKeySlashPad , / / 0x6F - VK_DIVIDE <nl> / / 0x70 <nl> - kKeyNil , / / 0x70 - VK_F1 <nl> - kKeyNil , / / 0x71 - VK_F2 <nl> - kKeyNil , / / 0x72 - VK_F3 <nl> - kKeyNil , / / 0x73 - VK_F4 <nl> - kKeyNil , / / 0x74 - VK_F5 <nl> - kKeyNil , / / 0x75 - VK_F6 <nl> - kKeyNil , / / 0x76 - VK_F7 <nl> - kKeyNil , / / 0x77 - VK_F8 <nl> - kKeyNil , / / 0x78 - VK_F9 <nl> - kKeyNil , / / 0x79 - VK_F10 <nl> - kKeyNil , / / 0x7A - VK_F11 <nl> - kKeyNil , / / 0x7B - VK_F12 <nl> + kKeyF1 , / / 0x70 - VK_F1 <nl> + kKeyF2 , / / 0x71 - VK_F2 <nl> + kKeyF3 , / / 0x72 - VK_F3 <nl> + kKeyF4 , / / 0x73 - VK_F4 <nl> + kKeyF5 , / / 0x74 - VK_F5 <nl> + kKeyF6 , / / 0x75 - VK_F6 <nl> + kKeyF7 , / / 0x76 - VK_F7 <nl> + kKeyF8 , / / 0x77 - VK_F8 <nl> + kKeyF9 , / / 0x78 - VK_F9 <nl> + kKeyF10 , / / 0x79 - VK_F10 <nl> + kKeyF11 , / / 0x7A - VK_F11 <nl> + kKeyF12 , / / 0x7B - VK_F12 <nl> kKeyNil , / / 0x7C - VK_F13 <nl> kKeyNil , / / 0x7D - VK_F14 <nl> kKeyNil , / / 0x7E - VK_F15 <nl> KeyScancode win32vk_to_scancode ( int vk ) { <nl> kKeyNil , / / 0x8E - Unassigned <nl> kKeyNil , / / 0x8F - Unassigned <nl> / / 0x90 <nl> - kKeyNil , / / 0x90 - VK_NUMLOCK <nl> - kKeyNil , / / 0x91 - VK_SCROLL <nl> - kKeyEqualsPad , / / 0x92 - VK_OEM_NEC_EQUAL / VK_OEM_FJ_JISHO <nl> + kKeyNumLock , / / 0x90 - VK_NUMLOCK <nl> + kKeyScrLock , / / 0x91 - VK_SCROLL <nl> + kKeyNil , / / 0x92 - VK_OEM_NEC_EQUAL / VK_OEM_FJ_JISHO <nl> kKeyNil , / / 0x93 - VK_OEM_FJ_MASSHOU <nl> kKeyNil , / / 0x94 - VK_OEM_FJ_TOUROKU <nl> kKeyNil , / / 0x95 - VK_OEM_FJ_LOYA <nl> KeyScancode win32vk_to_scancode ( int vk ) { <nl> kKeyNil , / / 0x9E - Unassigned <nl> kKeyNil , / / 0x9F - Unassigned <nl> / / 0xA0 <nl> - kKeyNil , / / 0xA0 - VK_LSHIFT <nl> - kKeyNil , / / 0xA1 - VK_RSHIFT <nl> - kKeyNil , / / 0xA2 - VK_LCONTROL <nl> - kKeyNil , / / 0xA3 - VK_RCONTROL <nl> - kKeyNil , / / 0xA4 - VK_LMENU <nl> - kKeyNil , / / 0xA5 - VK_RMENU <nl> + kKeyLShift , / / 0xA0 - VK_LSHIFT <nl> + kKeyRShift , / / 0xA1 - VK_RSHIFT <nl> + kKeyLControl , / / 0xA2 - VK_LCONTROL <nl> + kKeyRControl , / / 0xA3 - VK_RCONTROL <nl> + kKeyAlt , / / 0xA4 - VK_LMENU <nl> + kKeyAltGr , / / 0xA5 - VK_RMENU <nl> kKeyNil , / / 0xA6 - VK_BROWSER_BACK <nl> kKeyNil , / / 0xA7 - VK_BROWSER_FORWARD <nl> kKeyNil , / / 0xA8 - VK_BROWSER_REFRESH <nl> KeyScancode win32vk_to_scancode ( int vk ) { <nl> kKeyNil , / / 0xB7 - VK_LAUNCH_APP2 <nl> kKeyNil , / / 0xB8 - Reserved <nl> kKeyNil , / / 0xB9 - Reserved <nl> - kKeyNil , / / 0xBA - VK_OEM_1 <nl> - kKeyNil , / / 0xBB - VK_OEM_PLUS <nl> - kKeyNil , / / 0xBC - VK_OEM_COMMA <nl> - kKeyNil , / / 0xBD - VK_OEM_MINUS <nl> - kKeyNil , / / 0xBE - VK_OEM_PERIOD <nl> - kKeyNil , / / 0xBF - VK_OEM_2 <nl> + kKeySemicolon , / / 0xBA - VK_OEM_1 <nl> + kKeyEquals , / / 0xBB - VK_OEM_PLUS <nl> + kKeyComma , / / 0xBC - VK_OEM_COMMA <nl> + kKeyMinus , / / 0xBD - VK_OEM_MINUS <nl> + kKeyStop , / / 0xBE - VK_OEM_PERIOD <nl> + kKeySlash , / / 0xBF - VK_OEM_2 <nl> / / 0xC0 <nl> - kKeyNil , / / 0xC0 - VK_OEM_3 <nl> + kKeyTilde , / / 0xC0 - VK_OEM_3 <nl> kKeyNil , / / 0xC1 - Reserved <nl> kKeyNil , / / 0xC2 - Reserved <nl> kKeyNil , / / 0xC3 - Reserved <nl> KeyScancode win32vk_to_scancode ( int vk ) { <nl> kKeyNil , / / 0xD8 - Unassigned <nl> kKeyNil , / / 0xD9 - Unassigned <nl> kKeyNil , / / 0xDA - Unassigned <nl> - kKeyNil , / / 0xDB - VK_OEM_4 <nl> - kKeyNil , / / 0xDC - VK_OEM_5 <nl> - kKeyNil , / / 0xDD - VK_OEM_6 <nl> - kKeyNil , / / 0xDE - VK_OEM_7 <nl> + kKeyOpenbrace , / / 0xDB - VK_OEM_4 <nl> + kKeyBackslash , / / 0xDC - VK_OEM_5 <nl> + kKeyClosebrace , / / 0xDD - VK_OEM_6 <nl> + kKeyQuote , / / 0xDE - VK_OEM_7 <nl> kKeyNil , / / 0xDF - VK_OEM_8 <nl> / / 0xE0 <nl> kKeyNil , / / 0xE0 - Reserved <nl> kKeyNil , / / 0xE1 - VK_OEM_AX <nl> - kKeyNil , / / 0xE2 - VK_OEM_102 <nl> + kKeyBackslash2 , / / 0xE2 - VK_OEM_102 <nl> kKeyNil , / / 0xE3 - VK_ICO_HELP <nl> kKeyNil , / / 0xE4 - VK_ICO_00 <nl> kKeyNil , / / 0xE5 - VK_PROCESSKEY <nl> KeyScancode win32vk_to_scancode ( int vk ) { <nl> kKeyNil , / / 0xFF - Reserved <nl> } ; <nl> if ( vk < 0 | | vk > 255 ) <nl> - vk = kKeyNil ; <nl> + vk = 0 ; <nl> return keymap [ vk ] ; <nl> } <nl> <nl>\n", "msg": "Complete she : : win32vk_to_scancode ( ) conversions\n"}
{"diff_id": 25879, "msg": "CharsetConverter : use standard conversion for utf8ToSystem\n", "msgGPT": "refactor c charset converter to support utf8 to system conversion.", "METEOR Score": "44.98172371919511", "BLEU Score": "0.6640471006217092", "ROUGE-L Score": "0.5263157844875347", "score": 1, "repo": "xbmc/xbmc\n", "sha": "4adebc696aeb77c7c162b869a52a9542a7f65e37\n", "time": "2013-10-16T14:18:56Z\n", "diff": "mmm a / xbmc / utils / CharsetConverter . cpp <nl> ppp b / xbmc / utils / CharsetConverter . cpp <nl> enum StdConversionType / * Keep it in sync with CCharsetConverter : : CInnerConverte <nl> Utf16BEtoUtf8 , <nl> Utf16LEtoUtf8 , <nl> Utf8toW , <nl> + Utf8ToSystem , <nl> Ucs2CharsetToUtf8 , <nl> NumberOfStdConversionTypes / * Dummy sentinel entry * / <nl> } ; <nl> CConverterType CCharsetConverter : : CInnerConverter : : m_stdConversion [ NumberOfStdCo <nl> / * Utf16BEtoUtf8 * / CConverterType ( \" UTF - 16BE \" , \" UTF - 8 \" , CCharsetConverter : : m_Utf8CharMaxSize ) , <nl> / * Utf16LEtoUtf8 * / CConverterType ( \" UTF - 16LE \" , \" UTF - 8 \" , CCharsetConverter : : m_Utf8CharMaxSize ) , <nl> / * Utf8toW * / CConverterType ( UTF8_SOURCE , WCHAR_CHARSET ) , <nl> + / * Utf8ToSystem * / CConverterType ( UTF8_SOURCE , SystemCharset ) , <nl> / * Ucs2CharsetToUtf8 * / CConverterType ( \" UCS - 2LE \" , \" UTF - 8 \" , CCharsetConverter : : m_Utf8CharMaxSize ) <nl> } ; <nl> <nl> bool CCharsetConverter : : utf32ToStringCharset ( const std : : u32string & utf32StringSr <nl> bool CCharsetConverter : : utf8ToSystem ( std : : string & stringSrcDst , bool failOnBadChar / * = false * / ) <nl> { <nl> std : : string strSrc ( stringSrcDst ) ; <nl> - return utf8To ( \" \" , strSrc , stringSrcDst ) ; <nl> + return CInnerConverter : : stdConvert ( Utf8ToSystem , strSrc , stringSrcDst , failOnBadChar ) ; <nl> } <nl> <nl> / / Taken from RFC2640 <nl>\n"}
{"diff_id": 25965, "repo": "mongodb/mongo\n", "sha": "63943c6541e94a28d9dbe31058c027872b06b37d\n", "time": "2011-04-12T22:23:47Z\n", "diff": "mmm a / util / file_allocator . cpp <nl> ppp b / util / file_allocator . cpp <nl> namespace mongo { <nl> < < \" took \" < < ( ( double ) t . millis ( ) ) / 1000 . 0 < < \" secs \" <nl> < < endl ; <nl> <nl> - <nl> + / / no longer in a failed state . allow new writers . <nl> + fa - > _failed = false ; <nl> } <nl> catch ( . . . ) { <nl> log ( ) < < \" error failed to allocate new file : \" < < name <nl> < < \" size : \" < < size < < ' ' < < errnoWithDescription ( ) < < endl ; <nl> + log ( ) < < \" will try again in 10 seconds \" < < endl ; <nl> try { <nl> if ( tmp . size ( ) ) <nl> BOOST_CHECK_EXCEPTION ( boost : : filesystem : : remove ( tmp ) ) ; <nl> namespace mongo { <nl> fa - > _pendingUpdated . notify_all ( ) ; <nl> <nl> <nl> - / / TODO : we should sleep and continue rather than stop <nl> - / / space might become available <nl> - return ; / / no more allocation <nl> + sleepsecs ( 10 ) ; <nl> + continue ; <nl> } <nl> <nl> { <nl>\n", "msg": "Keep trying to allocate new file SERVER - 2609\n"}
{"diff_id": 26005, "repo": "telegramdesktop/tdesktop\n", "sha": "6660206e612b35534dfa7d0085397a57400a6c5b\n", "time": "2020-11-02T08:26:39Z\n", "diff": "mmm a / Telegram / SourceFiles / history / view / history_view_list_widget . cpp <nl> ppp b / Telegram / SourceFiles / history / view / history_view_list_widget . cpp <nl> void ListWidget : : elementStartStickerLoop ( not_null < const Element * > view ) { <nl> } <nl> <nl> void ListWidget : : elementShowPollResults ( <nl> - not_null < PollData * > poll , <nl> - FullMsgId context ) { <nl> + not_null < PollData * > poll , <nl> + FullMsgId context ) { <nl> + _controller - > showPollResults ( poll , context ) ; <nl> } <nl> <nl> void ListWidget : : elementShowTooltip ( <nl>\n", "msg": "Fix poll results opening from pinned section .\n"}
{"diff_id": 26033, "repo": "telegramdesktop/tdesktop\n", "sha": "87e4bb10595ec6b65284fac2091009b1b0f8726f\n", "time": "2020-11-09T09:57:49Z\n", "diff": "mmm a / Telegram / SourceFiles / history / history_widget . cpp <nl> ppp b / Telegram / SourceFiles / history / history_widget . cpp <nl> void HistoryWidget : : showAnimated ( <nl> _a_show . stop ( ) ; <nl> <nl> _cacheUnder = params . oldContentCache ; <nl> + <nl> + / / If we show pinned bar here , we don ' t want it to change the <nl> + / / calculated and prepared scrollTop of the messages history . <nl> + _preserveScrollTop = true ; <nl> show ( ) ; <nl> _topBar - > finishAnimating ( ) ; <nl> historyDownAnimationFinish ( ) ; <nl> unreadMentionsAnimationFinish ( ) ; <nl> + if ( _pinnedBar ) { <nl> + _pinnedBar - > finishAnimating ( ) ; <nl> + } <nl> _topShadow - > setVisible ( params . withTopBarShadow ? false : true ) ; <nl> + _preserveScrollTop = false ; <nl> + <nl> _cacheOver = controller ( ) - > content ( ) - > grabForShowAnimation ( params ) ; <nl> <nl> if ( _tabbedPanel ) { <nl> void HistoryWidget : : animationCallback ( ) { <nl> if ( ! _a_show . animating ( ) ) { <nl> historyDownAnimationFinish ( ) ; <nl> unreadMentionsAnimationFinish ( ) ; <nl> + if ( _pinnedBar ) { <nl> + _pinnedBar - > finishAnimating ( ) ; <nl> + } <nl> _cacheUnder = _cacheOver = QPixmap ( ) ; <nl> doneShow ( ) ; <nl> + synteticScrollToY ( _scroll - > scrollTop ( ) ) ; <nl> } <nl> } <nl> <nl> void HistoryWidget : : updateHistoryGeometry ( <nl> } <nl> } <nl> const auto toY = std : : clamp ( newScrollTop , 0 , _scroll - > scrollTopMax ( ) ) ; <nl> - if ( _scroll - > scrollTop ( ) = = toY ) { <nl> - visibleAreaUpdated ( ) ; <nl> - } else { <nl> - synteticScrollToY ( toY ) ; <nl> - } <nl> + synteticScrollToY ( toY ) ; <nl> } <nl> <nl> void HistoryWidget : : updateListSize ( ) { <nl>\n", "msg": "Fix scroll position restore with pinned bar .\n", "score": 1}
{"diff_id": 26054, "repo": "yuzu-emu/yuzu\n", "sha": "48bf0f99968cfba34c6edb3d52a171612bcd4f0c\n", "time": "2015-01-02T02:59:37Z\n", "diff": "mmm a / src / core / arm / dyncom / arm_dyncom_interpreter . cpp <nl> ppp b / src / core / arm / dyncom / arm_dyncom_interpreter . cpp <nl> ARM_INST_PTR INTERPRETER_TRANSLATE ( sxtab ) ( unsigned int inst , int index ) { <nl> <nl> return inst_base ; <nl> } <nl> - ARM_INST_PTR INTERPRETER_TRANSLATE ( sxtab16 ) ( unsigned int inst , int index ) { UNIMPLEMENTED_INSTRUCTION ( \" SXTAB16 \" ) ; } <nl> + <nl> + ARM_INST_PTR INTERPRETER_TRANSLATE ( sxtab16 ) ( unsigned int inst , int index ) <nl> + { <nl> + arm_inst * const inst_base = ( arm_inst * ) AllocBuffer ( sizeof ( arm_inst ) + sizeof ( sxtab_inst ) ) ; <nl> + sxtab_inst * const inst_cream = ( sxtab_inst * ) inst_base - > component ; <nl> + <nl> + inst_base - > cond = BITS ( inst , 28 , 31 ) ; <nl> + inst_base - > idx = index ; <nl> + inst_base - > br = NON_BRANCH ; <nl> + inst_base - > load_r15 = 0 ; <nl> + <nl> + inst_cream - > Rm = BITS ( inst , 0 , 3 ) ; <nl> + inst_cream - > Rn = BITS ( inst , 16 , 19 ) ; <nl> + inst_cream - > Rd = BITS ( inst , 12 , 15 ) ; <nl> + inst_cream - > rotate = BITS ( inst , 10 , 11 ) ; <nl> + <nl> + return inst_base ; <nl> + } <nl> + ARM_INST_PTR INTERPRETER_TRANSLATE ( sxtb16 ) ( unsigned int inst , int index ) <nl> + { <nl> + return INTERPRETER_TRANSLATE ( sxtab16 ) ( inst , index ) ; <nl> + } <nl> + <nl> ARM_INST_PTR INTERPRETER_TRANSLATE ( sxtah ) ( unsigned int inst , int index ) { <nl> LOG_WARNING ( Core_ARM11 , \" SXTAH untested \" ) ; <nl> arm_inst * inst_base = ( arm_inst * ) AllocBuffer ( sizeof ( arm_inst ) + sizeof ( sxtah_inst ) ) ; <nl> ARM_INST_PTR INTERPRETER_TRANSLATE ( sxtah ) ( unsigned int inst , int index ) { <nl> <nl> return inst_base ; <nl> } <nl> - ARM_INST_PTR INTERPRETER_TRANSLATE ( sxtb16 ) ( unsigned int inst , int index ) { UNIMPLEMENTED_INSTRUCTION ( \" SXTB16 \" ) ; } <nl> + <nl> ARM_INST_PTR INTERPRETER_TRANSLATE ( teq ) ( unsigned int inst , int index ) <nl> { <nl> arm_inst * inst_base = ( arm_inst * ) AllocBuffer ( sizeof ( arm_inst ) + sizeof ( teq_inst ) ) ; <nl> unsigned InterpreterMainLoop ( ARMul_State * state ) { <nl> FETCH_INST ; <nl> GOTO_NEXT_INST ; <nl> } <nl> + <nl> SXTAB16_INST : <nl> + SXTB16_INST : <nl> + { <nl> + if ( inst_base - > cond = = 0xE | | CondPassed ( cpu , inst_base - > cond ) ) { <nl> + sxtab_inst * const inst_cream = ( sxtab_inst * ) inst_base - > component ; <nl> + <nl> + const u8 rotation = inst_cream - > rotate * 8 ; <nl> + u32 rm_val = RM ; <nl> + u32 rn_val = RN ; <nl> + <nl> + if ( rotation ) <nl> + rm_val = ( ( rm_val < < ( 32 - rotation ) ) | ( rm_val > > rotation ) ) ; <nl> + <nl> + / / SXTB16 <nl> + if ( inst_cream - > Rn = = 15 ) { <nl> + u32 lo = ( u32 ) ( s8 ) rm_val ; <nl> + u32 hi = ( u32 ) ( s8 ) ( rm_val > > 16 ) ; <nl> + RD = ( lo | ( hi < < 16 ) ) ; <nl> + } <nl> + / / SXTAB16 <nl> + else { <nl> + u32 lo = ( rn_val & 0xFFFF ) + ( u32 ) ( s8 ) ( rm_val & 0xFF ) ; <nl> + u32 hi = ( ( rn_val > > 16 ) & 0xFFFF ) + ( u32 ) ( s8 ) ( ( rm_val > > 16 ) & 0xFF ) ; <nl> + RD = ( lo | ( hi < < 16 ) ) ; <nl> + } <nl> + } <nl> + <nl> + cpu - > Reg [ 15 ] + = GET_INST_SIZE ( cpu ) ; <nl> + INC_PC ( sizeof ( sxtab_inst ) ) ; <nl> + FETCH_INST ; <nl> + GOTO_NEXT_INST ; <nl> + } <nl> + <nl> SXTAH_INST : <nl> { <nl> sxtah_inst * inst_cream = ( sxtah_inst * ) inst_base - > component ; <nl> unsigned InterpreterMainLoop ( ARMul_State * state ) { <nl> FETCH_INST ; <nl> GOTO_NEXT_INST ; <nl> } <nl> - SXTB16_INST : <nl> + <nl> TEQ_INST : <nl> { <nl> if ( ( inst_base - > cond = = 0xe ) | | CondPassed ( cpu , inst_base - > cond ) ) { <nl>\n", "msg": "dyncom : Implement SXTAB16 and SXTB16\n"}
{"diff_id": 26207, "msg": "UnknownSyntax now accounts for non - token children .\n", "msgGPT": "add missing increment statements for non token children and actual index variables in unknown syntax::get num children() and unknown syntax::get child() methods.", "METEOR Score": "44.13358724789048", "BLEU Score": "0.2621698779904947", "ROUGE-L Score": "0.28571428135204086", "score": 1, "repo": "apple/swift\n", "sha": "2af1a77fadb6b3e8dda290b0b8e9bbfea3b40f42\n", "time": "2017-06-23T19:55:50Z\n", "diff": "mmm a / lib / Syntax / UnknownSyntax . cpp <nl> ppp b / lib / Syntax / UnknownSyntax . cpp <nl> void UnknownSyntax : : validate ( ) const { <nl> # pragma mark - unknown - syntax API <nl> <nl> size_t UnknownSyntax : : getNumChildren ( ) const { <nl> - return Data - > getNumChildren ( ) ; <nl> + size_t NonTokenChildren = 0 ; <nl> + for ( auto Child : getRaw ( ) - > Layout ) { <nl> + if ( ! Child - > isToken ( ) ) { <nl> + + + NonTokenChildren ; <nl> + } <nl> + } <nl> + return NonTokenChildren ; <nl> } <nl> <nl> Syntax UnknownSyntax : : getChild ( const size_t N ) const { <nl> - return Syntax { Root , Data - > getChild ( N ) . get ( ) } ; <nl> + / / The actual index of the Nth non - token child . <nl> + size_t ActualIndex = 0 ; <nl> + / / The number of non - token children we ' ve seen . <nl> + size_t NumNonTokenSeen = 0 ; <nl> + for ( auto Child : getRaw ( ) - > Layout ) { <nl> + / / If we see a child that ' s not a token , count it . <nl> + if ( ! Child - > isToken ( ) ) { <nl> + + + NumNonTokenSeen ; <nl> + } <nl> + / / If the number of children we ' ve seen indexes the same ( count - 1 ) as <nl> + / / the number we ' re looking for , then we ' re done . <nl> + if ( NumNonTokenSeen = = N + 1 ) { break ; } <nl> + <nl> + / / Otherwise increment the actual index and keep searching . <nl> + + + ActualIndex ; <nl> + } <nl> + return Syntax { Root , Data - > getChild ( ActualIndex ) . get ( ) } ; <nl> } <nl> <nl>\n"}
{"diff_id": 26407, "repo": "apple/swift\n", "sha": "094bbaae7dea23ee3f37f50019fc913c5a510084\n", "time": "2011-03-21T23:15:56Z\n", "diff": "mmm a / lib / Sema / TypeChecking . cpp <nl> ppp b / lib / Sema / TypeChecking . cpp <nl> void TypeChecker : : checkBody ( Expr * & E , Type * DestTy , ConversionReason Res , <nl> / / something silly like this , then they should have used parens , as in : <nl> / / var x = ( 4 foo ( ) ) <nl> if ( SequenceExpr * SE = dyn_cast < SequenceExpr > ( E ) ) <nl> - if ( SE - > Elements [ 0 ] - > Ty - > getAs < DependentType > ( ) = = 0 ) { <nl> + # if 0 <nl> + / / FIXME : This is busted for something like this : <nl> + / / var e : ZeroOneTwoThree = : Three ( 1 , 2 , 3 ) foo ( ) ; <nl> + / / We ' ll end up trying to convert foo ( ) to be a ZeroOneTwoThree , which will <nl> + / / fail , and then we get a UnresolvedTypes error . This may be acceptable , <nl> + / / but it is unfortunate that the ; placement has a semantic effect here . <nl> + / / Disabling this so it continues to show a test failure . <nl> + # endif <nl> + if ( ! isa < DependentType > ( SE - > Elements [ 0 ] - > Ty ) | | 1 ) { <nl> E = SE - > Elements [ 0 ] ; <nl> if ( ExcessElements ) <nl> ExcessElements - > append ( SE - > Elements + 1 , SE - > Elements + SE - > NumElements ) ; <nl>\n", "msg": "On second blush , this fix isn ' t a great one . Add a fixme and disable it for now so a test continues to fail .\n", "score": 1}
{"diff_id": 26479, "repo": "sqlitebrowser/sqlitebrowser\n", "sha": "175ff7371a7c6996f002784fde2e96c9e3bd17aa\n", "time": "2020-08-29T15:35:26Z\n", "diff": "mmm a / src / main . cpp <nl> ppp b / src / main . cpp <nl> <nl> + <nl> # include \" Application . h \" <nl> # include \" sqlite . h \" <nl> <nl> # include < QMessageBox > <nl> <nl> - static QMessageBox * messageBox = nullptr ; <nl> + static QString message = QString ( ) ; <nl> <nl> void db4sMessageOutput ( QtMsgType type , const QMessageLogContext & context , const QString & msg ) <nl> { <nl> void db4sMessageOutput ( QtMsgType type , const QMessageLogContext & context , const <nl> <nl> void boxMessageOutput ( QtMsgType , const QMessageLogContext & , const QString & msg ) <nl> { <nl> - if ( ! messageBox ) <nl> - messageBox = new QMessageBox ( ) ; <nl> - <nl> - messageBox - > setText ( messageBox - > text ( ) + msg + \" \\ n \" ) ; <nl> - <nl> - if ( ! messageBox - > isVisible ( ) ) <nl> - messageBox - > show ( ) ; <nl> + message + = msg + \" \\ n \" ; <nl> } <nl> <nl> int main ( int argc , char * * argv ) <nl> int main ( int argc , char * * argv ) <nl> Application a ( argc , argv ) ; <nl> <nl> / / If there has been output in the message box , let user see it . <nl> - if ( messageBox & & messageBox - > isVisible ( ) ) <nl> - messageBox - > exec ( ) ; <nl> + if ( ! message . isEmpty ( ) ) { <nl> + QMessageBox messageBox ; <nl> + messageBox . setTextFormat ( Qt : : RichText ) ; <nl> + messageBox . setText ( \" < pre > \" + message + \" < / pre > \" ) ; <nl> + messageBox . exec ( ) ; <nl> + } <nl> <nl> / / Quit application now if user doesn ' t want to see the UI <nl> if ( a . dontShowMainWindow ( ) ) <nl>\n", "msg": "Show preformatted text for output from command line arguments in Windows\n"}
{"diff_id": 26518, "repo": "apple/swift\n", "sha": "cf3fdff042280dd3f7a86893b8c793d6920d99dd\n", "time": "2016-06-25T20:44:39Z\n", "diff": "mmm a / lib / IRGen / IRGenDebugInfo . cpp <nl> ppp b / lib / IRGen / IRGenDebugInfo . cpp <nl> static SILLocation : : DebugLoc getDebugLocation ( Optional < SILLocation > OptLoc , <nl> <nl> <nl> / / / Determine whether this debug scope belongs to an explicit closure . <nl> - static bool isExplicitClosure ( const SILDebugScope * DS ) { <nl> - if ( DS ) { <nl> - auto * SILFn = DS - > getInlinedFunction ( ) ; <nl> - if ( SILFn & & SILFn - > hasLocation ( ) ) <nl> - if ( Expr * E = SILFn - > getLocation ( ) . getAsASTNode < Expr > ( ) ) <nl> - if ( isa < ClosureExpr > ( E ) ) <nl> - return true ; <nl> - } <nl> + static bool isExplicitClosure ( const SILFunction * SILFn ) { <nl> + if ( SILFn & & SILFn - > hasLocation ( ) ) <nl> + if ( Expr * E = SILFn - > getLocation ( ) . getAsASTNode < Expr > ( ) ) <nl> + if ( isa < ClosureExpr > ( E ) ) <nl> + return true ; <nl> return false ; <nl> } <nl> <nl> llvm : : DISubprogram * IRGenDebugInfo : : emitFunction ( <nl> / / Mark everything that is not visible from the source code ( i . e . , <nl> / / does not have a Swift name ) as artificial , so the debugger can <nl> / / ignore it . Explicit closures are exempt from this rule . We also <nl> - / / make an exception for main , which , albeit it does not <nl> + / / make an exception for toplevel code , which , although it does not <nl> / / have a Swift name , does appear prominently in the source code . <nl> if ( ( Name . empty ( ) & & LinkageName ! = SWIFT_ENTRY_POINT_FUNCTION & & <nl> - ! isExplicitClosure ( DS ) ) | | <nl> + ! isExplicitClosure ( SILFn ) ) | | <nl> / / ObjC thunks should also not show up in the linetable , because we <nl> / / never want to set a breakpoint there . <nl> ( Rep = = SILFunctionTypeRepresentation : : ObjCMethod ) | | <nl>\n", "msg": "Simplify the definition of isExplicitClosure ( ) .\n"}
{"diff_id": 26721, "repo": "apple/swift\n", "sha": "19f1bbdebbc374e6c6a6906263066ddea4c7f344\n", "time": "2013-11-12T23:27:47Z\n", "diff": "mmm a / lib / SILGen / SILGenDecl . cpp <nl> ppp b / lib / SILGen / SILGenDecl . cpp <nl> class SILGenType : public Lowering : : ASTVisitor < SILGenType > { <nl> SGM . emitEnumConstructor ( ued ) ; <nl> } <nl> <nl> - / / no - op . We don ' t deal with the layout of types here . <nl> - void visitPatternBindingDecl ( PatternBindingDecl * ) { } <nl> + void visitPatternBindingDecl ( PatternBindingDecl * pd ) { <nl> + / / Emit initializers for static variables . <nl> + / / FIXME : This has to happen lazily for generic properties . <nl> + / / ( We want it to happen lazily for all globals , really . ) <nl> + <nl> + / / FIXME : Global initialization order ? ! <nl> + if ( pd - > isStatic ( ) ) { <nl> + assert ( ! theType - > getGenericParams ( ) <nl> + & & \" generic static properties not implemented \" ) ; <nl> + assert ( ( isa < StructDecl > ( theType ) | | isa < EnumDecl > ( theType ) ) <nl> + & & \" only value type static properties are implemented \" ) ; <nl> + <nl> + if ( SGM . TopLevelSGF ) { <nl> + if ( ! SGM . TopLevelSGF - > B . hasValidInsertionPoint ( ) ) <nl> + return ; <nl> + <nl> + SGM . TopLevelSGF - > visit ( pd ) ; <nl> + } <nl> + } <nl> + } <nl> <nl> void visitVarDecl ( VarDecl * vd ) { <nl> + / / Collect global variables for static properties . <nl> + / / FIXME : We can ' t statically emit a global variable for generic properties . <nl> + if ( vd - > isStatic ( ) & & ! vd - > isComputed ( ) ) { <nl> + assert ( ! theType - > getGenericParams ( ) <nl> + & & \" generic static properties not implemented \" ) ; <nl> + assert ( ( isa < StructDecl > ( theType ) | | isa < EnumDecl > ( theType ) ) <nl> + & & \" only value type static properties are implemented \" ) ; <nl> + <nl> + SGM . addGlobalVariable ( vd ) ; <nl> + <nl> + return ; <nl> + } <nl> + <nl> / / FIXME : Default implementations in protocols . <nl> if ( SGM . requiresObjCPropertyEntryPoints ( vd ) & & <nl> ! isa < ProtocolDecl > ( vd - > getDeclContext ( ) ) ) <nl>\n", "msg": "SILGen : Emit global initialization for static properties .\n", "score": 1}
{"diff_id": 26836, "repo": "CRYTEK/CRYENGINE\n", "sha": "7a964626b41daf6e585ff55aade98551541380b0\n", "time": "2018-01-22T12:05:20Z\n", "diff": "mmm a / Code / CryEngine / RenderDll / XRenderD3D9 / GraphicsPipeline / Water . cpp <nl> ppp b / Code / CryEngine / RenderDll / XRenderD3D9 / GraphicsPipeline / Water . cpp <nl> void CWaterStage : : Init ( ) <nl> m_passWaterCausticsSrcGen . SetPassResources ( m_pResourceLayout , m_pPerPassResourceSets [ ePass_CausticsGen ] ) ; <nl> m_passWaterCausticsSrcGen . SetRenderTargets ( nullptr , pDummyRenderTarget ) ; <nl> <nl> - <nl> m_passWaterFogVolumeBeforeWater . SetLabel ( \" WATER_FOG_VOLUME_BEFORE_WATER \" ) ; <nl> m_passWaterFogVolumeBeforeWater . SetupPassContext ( m_stageID , ePass_FogVolume , TTYPE_GENERAL , FB_BELOW_WATER , EFSLIST_WATER_VOLUMES , 0 , false ) ; <nl> m_passWaterFogVolumeBeforeWater . SetPassResources ( m_pResourceLayout , m_pPerPassResourceSets [ ePass_FogVolume ] ) ; <nl> bool CWaterStage : : CreatePipelineState ( <nl> if ( ! ( ePass_ReflectionGen < = passID & & passID < = ePass_Count ) ) <nl> return true ; / / psssID doesn ' t exit in water stage . <nl> <nl> + if ( ! m_bOceanMaskGen & & ( passID = = ePass_OceanMaskGen ) ) <nl> + return true ; / / OceanMaskGen is not needed ( low / medium spec ) <nl> + <nl> auto shaderType = desc . shaderItem . m_pShader - > GetShaderType ( ) ; <nl> if ( shaderType ! = eST_Water ) <nl> return true ; / / non water type shader can ' t be rendered in water stage . <nl>\n", "msg": "! R ( Renderer , Water ) Skip WaterMask stage PSO creation when not active ( sys - spec dependent )\n"}
{"diff_id": 26872, "repo": "opencv/opencv\n", "sha": "60046875634437d42caa05df15e8275fa2f42c4d\n", "time": "2011-01-19T00:05:30Z\n", "diff": "mmm a / modules / python / cv . cpp <nl> ppp b / modules / python / cv . cpp <nl> static PyObject * opencv_error ; <nl> <nl> struct memtrack_t { <nl> PyObject_HEAD <nl> + int owner ; <nl> void * ptr ; <nl> + int freeptr ; <nl> Py_ssize_t size ; <nl> + PyObject * backing ; <nl> + CvArr * backingmat ; <nl> } ; <nl> <nl> struct iplimage_t { <nl> static void cvmatnd_dealloc ( PyObject * self ) <nl> { <nl> cvmatnd_t * pc = ( cvmatnd_t * ) self ; <nl> Py_DECREF ( pc - > data ) ; <nl> + cvFree ( & pc - > a ) ; <nl> PyObject_Del ( self ) ; <nl> } <nl> <nl> static void cvlineiterator_specials ( void ) <nl> <nl> / * memtrack * / <nl> <nl> + / * Motivation for memtrack is when the storage for a Mat is an array or buffer <nl> + object . By setting ' data ' to be a memtrack , can deallocate the storage at <nl> + object destruction . <nl> + <nl> + For array objects , ' backing ' is the actual storage object . memtrack holds the reference , <nl> + then DECREF ' s it at dealloc . <nl> + <nl> + For MatND ' s , we need to cvDecRefData ( ) on release , and this is what field ' backingmat ' is for . <nl> + <nl> + If freeptr is true , then a straight cvFree ( ) of ptr happens . <nl> + <nl> + * / <nl> + <nl> + <nl> static void memtrack_dealloc ( PyObject * self ) <nl> { <nl> memtrack_t * pi = ( memtrack_t * ) self ; <nl> - / / printf ( \" = = = > memtrack_dealloc % p ! \\ n \" , pi - > ptr ) ; <nl> - cvFree ( & pi - > ptr ) ; <nl> + if ( pi - > backing ) <nl> + Py_DECREF ( pi - > backing ) ; <nl> + if ( pi - > backingmat ) <nl> + cvDecRefData ( pi - > backingmat ) ; <nl> + if ( pi - > freeptr ) <nl> + cvFree ( & pi - > ptr ) ; <nl> PyObject_Del ( self ) ; <nl> } <nl> <nl> static PyObject * pythonize_CvMat ( cvmat_t * m ) <nl> memtrack_t * o = PyObject_NEW ( memtrack_t , & memtrack_Type ) ; <nl> size_t gap = mat - > data . ptr - ( uchar * ) mat - > refcount ; <nl> o - > ptr = mat - > refcount ; <nl> + o - > owner = __LINE__ ; <nl> + o - > freeptr = true ; <nl> o - > size = gap + mat - > rows * mat - > step ; <nl> + o - > backing = NULL ; <nl> + o - > backingmat = NULL ; <nl> PyObject * data = PyBuffer_FromReadWriteObject ( ( PyObject * ) o , ( size_t ) gap , mat - > rows * mat - > step ) ; <nl> if ( data = = NULL ) <nl> return NULL ; <nl> static PyObject * pythonize_foreign_CvMat ( cvmat_t * m ) <nl> # else <nl> memtrack_t * o = PyObject_NEW ( memtrack_t , & memtrack_Type ) ; <nl> o - > ptr = mat - > data . ptr ; <nl> + o - > owner = __LINE__ ; <nl> + o - > freeptr = false ; <nl> o - > size = mat - > rows * mat - > step ; <nl> + o - > backing = NULL ; <nl> + o - > backingmat = mat ; <nl> PyObject * data = PyBuffer_FromReadWriteObject ( ( PyObject * ) o , ( size_t ) 0 , mat - > rows * mat - > step ) ; <nl> if ( data = = NULL ) <nl> return NULL ; <nl> - Py_INCREF ( o ) ; / / XXX - hack to prevent free of this foreign memory <nl> # endif <nl> m - > data = data ; <nl> m - > offset = 0 ; <nl> static PyObject * pythonize_IplImage ( iplimage_t * cva ) <nl> memtrack_t * o = PyObject_NEW ( memtrack_t , & memtrack_Type ) ; <nl> assert ( ipl - > imageDataOrigin = = ipl - > imageData ) ; <nl> o - > ptr = ipl - > imageDataOrigin ; <nl> + o - > owner = __LINE__ ; <nl> + o - > freeptr = true ; <nl> o - > size = ipl - > height * ipl - > widthStep ; <nl> + o - > backing = NULL ; <nl> + o - > backingmat = NULL ; <nl> PyObject * data = PyBuffer_FromReadWriteObject ( ( PyObject * ) o , ( size_t ) 0 , o - > size ) ; <nl> if ( data = = NULL ) <nl> return NULL ; <nl> static PyObject * pythonize_IplImage ( iplimage_t * cva ) <nl> return ( PyObject * ) cva ; <nl> } <nl> <nl> - static PyObject * pythonize_CvMatND ( cvmatnd_t * m ) <nl> + static PyObject * pythonize_CvMatND ( cvmatnd_t * m , PyObject * backing = NULL ) <nl> { <nl> / / <nl> / / Need to make this CvMatND look like any other , with a Python <nl> - / / string as its data . <nl> - / / So copy the image data into a Python string object , then release <nl> - / / it . <nl> + / / buffer object as its data . <nl> / / <nl> <nl> CvMatND * mat = m - > a ; <nl> static PyObject * pythonize_CvMatND ( cvmatnd_t * m ) <nl> PyObject * data = PyString_FromStringAndSize ( ( char * ) ( mat - > data . ptr ) , mat - > dim [ 0 ] . size * mat - > dim [ 0 ] . step ) ; <nl> # else <nl> memtrack_t * o = PyObject_NEW ( memtrack_t , & memtrack_Type ) ; <nl> - o - > ptr = cvPtr1D ( mat , 0 ) ; <nl> + o - > ptr = mat - > data . ptr ; <nl> + o - > owner = __LINE__ ; <nl> + o - > freeptr = false ; <nl> o - > size = cvmatnd_size ( mat ) ; <nl> + Py_XINCREF ( backing ) ; <nl> + o - > backing = backing ; <nl> + o - > backingmat = mat ; <nl> PyObject * data = PyBuffer_FromReadWriteObject ( ( PyObject * ) o , ( size_t ) 0 , o - > size ) ; <nl> + Py_DECREF ( o ) ; / / Now ' data ' holds the only reference to ' o ' <nl> if ( data = = NULL ) <nl> return NULL ; <nl> # endif <nl> m - > data = data ; <nl> m - > offset = 0 ; <nl> - / / cvDecRefData ( mat ) ; / / Ref count should be zero here , so this is a release <nl> <nl> return ( PyObject * ) m ; <nl> } <nl> static PyObject * pycvfromarray ( PyObject * self , PyObject * args , PyObject * kw ) <nl> static PyObject * fromarray ( PyObject * o , int allowND ) <nl> { <nl> PyObject * ao = PyObject_GetAttrString ( o , \" __array_struct__ \" ) ; <nl> + PyObject * retval ; <nl> + <nl> if ( ( ao = = NULL ) | | ! PyCObject_Check ( ao ) ) { <nl> PyErr_SetString ( PyExc_TypeError , \" object does not have array interface \" ) ; <nl> return NULL ; <nl> static PyObject * fromarray ( PyObject * o , int allowND ) <nl> return ( PyObject * ) failmsg ( \" cv . fromarray array can be 2D or 3D only , see allowND argument \" ) ; <nl> } <nl> m - > a - > data . ptr = ( uchar * ) pai - > data ; <nl> - return pythonize_foreign_CvMat ( m ) ; <nl> + retval = pythonize_foreign_CvMat ( m ) ; <nl> } else { <nl> int dims [ CV_MAX_DIM ] ; <nl> int i ; <nl> static PyObject * fromarray ( PyObject * o , int allowND ) <nl> cvmatnd_t * m = PyObject_NEW ( cvmatnd_t , & cvmatnd_Type ) ; <nl> ERRWRAP ( m - > a = cvCreateMatND ( pai - > nd , dims , type ) ) ; <nl> m - > a - > data . ptr = ( uchar * ) pai - > data ; <nl> - return pythonize_CvMatND ( m ) ; <nl> + <nl> + retval = pythonize_CvMatND ( m , ao ) ; <nl> } <nl> + Py_DECREF ( ao ) ; <nl> + return retval ; <nl> } <nl> # endif <nl> <nl>\n", "msg": ". memtrack comments , sealed the numpy MatND leak\n"}
{"diff_id": 26977, "repo": "xbmc/xbmc\n", "sha": "c3e5b2bfc99c69a9f23d70374dab739e73ca2527\n", "time": "2011-06-21T20:14:17Z\n", "diff": "mmm a / xbmc / cores / dvdplayer / DVDPlayer . cpp <nl> ppp b / xbmc / cores / dvdplayer / DVDPlayer . cpp <nl> bool CDVDPlayer : : OpenVideoStream ( int iStream , int source ) <nl> if ( aspect ! = 0 . 0 ) <nl> hint . aspect = aspect ; <nl> hint . software = true ; <nl> - hint . stills = true ; <nl> + hint . stills = static_cast < CDVDInputStreamNavigator * > ( m_pInputStream ) - > IsInMenu ( ) ; <nl> } <nl> <nl> if ( m_CurrentVideo . id < 0 <nl>\n", "msg": "changed : allow use of libavcodec for dvd decoding of non menu items\n"}
{"diff_id": 27174, "repo": "facebook/hhvm\n", "sha": "59e9b71583bc1bf5525dd5e5a8c38f97605e5b54\n", "time": "2014-09-25T15:30:19Z\n", "diff": "mmm a / hphp / util / light - process . cpp <nl> ppp b / hphp / util / light - process . cpp <nl> pid_t LightProcess : : proc_open ( const char * cmd , const std : : vector < int > & created , <nl> } <nl> return - 1 ; <nl> } <nl> - always_assert ( buf = = \" success \" ) ; <nl> + always_assert_flog ( buf = = \" success \" , <nl> + \" Unexpected message from light process : ` { } ' \" , buf ) ; <nl> int64_t pid = - 1 ; <nl> lwp_read_int64 ( fin , pid ) ; <nl> always_assert ( pid ) ; <nl>\n", "msg": "Expand assert in LightProcess : : proc_open\n"}
{"diff_id": 27213, "repo": "opencv/opencv\n", "sha": "bc434e8f67d488dfc334efde894c31dbba003d76\n", "time": "2020-11-20T20:32:59Z\n", "diff": "mmm a / modules / calib3d / src / sqpnp . cpp <nl> ppp b / modules / calib3d / src / sqpnp . cpp <nl> void PoseSolver : : computeRowAndNullspace ( const cv : : Matx < double , 9 , 1 > & r , <nl> void PoseSolver : : nearestRotationMatrix ( const cv : : Matx < double , 9 , 1 > & e , <nl> cv : : Matx < double , 9 , 1 > & r ) <nl> { <nl> - register int i ; <nl> + int i ; <nl> double l , lprev , det_e , e_sq , adj_e_sq , adj_e [ 9 ] ; <nl> <nl> / / e ' s adjoint <nl>\n", "msg": "calib3d : eliminate ' register ' build warning\n"}
{"diff_id": 27223, "repo": "yuzu-emu/yuzu\n", "sha": "022fc59dcd5e4baf2ccfd949425b28d835fe20c6\n", "time": "2018-04-24T16:00:56Z\n", "diff": "mmm a / src / core / hle / service / ns / pl_u . cpp <nl> ppp b / src / core / hle / service / ns / pl_u . cpp <nl> PL_U : : PL_U ( ) : ServiceFramework ( \" pl : u \" ) { <nl> ASSERT ( file . GetSize ( ) = = SHARED_FONT_MEM_SIZE ) ; <nl> file . ReadBytes ( shared_font - > data ( ) , shared_font - > size ( ) ) ; <nl> } else { <nl> - LOG_WARNING ( Service_NS , \" Unable to load shared font : % s \" , filepath . c_str ( ) ) ; <nl> + NGLOG_WARNING ( Service_NS , \" Unable to load shared font : { } \" , filepath ) ; <nl> } <nl> } <nl> <nl> void PL_U : : RequestLoad ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : RequestParser rp { ctx } ; <nl> const u32 shared_font_type { rp . Pop < u32 > ( ) } ; <nl> <nl> - LOG_DEBUG ( Service_NS , \" called , shared_font_type = % d \" , shared_font_type ) ; <nl> + NGLOG_DEBUG ( Service_NS , \" called , shared_font_type = { } \" , shared_font_type ) ; <nl> IPC : : ResponseBuilder rb { ctx , 2 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> } <nl> void PL_U : : GetLoadState ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : RequestParser rp { ctx } ; <nl> const u32 font_id { rp . Pop < u32 > ( ) } ; <nl> <nl> - LOG_DEBUG ( Service_NS , \" called , font_id = % d \" , font_id ) ; <nl> + NGLOG_DEBUG ( Service_NS , \" called , font_id = { } \" , font_id ) ; <nl> IPC : : ResponseBuilder rb { ctx , 3 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> rb . Push < u32 > ( static_cast < u32 > ( LoadState : : Done ) ) ; <nl> void PL_U : : GetSize ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : RequestParser rp { ctx } ; <nl> const u32 font_id { rp . Pop < u32 > ( ) } ; <nl> <nl> - LOG_DEBUG ( Service_NS , \" called , font_id = % d \" , font_id ) ; <nl> + NGLOG_DEBUG ( Service_NS , \" called , font_id = { } \" , font_id ) ; <nl> IPC : : ResponseBuilder rb { ctx , 3 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> rb . Push < u32 > ( SHARED_FONT_REGIONS [ font_id ] . size ) ; <nl> void PL_U : : GetSharedMemoryAddressOffset ( Kernel : : HLERequestContext & ctx ) { <nl> IPC : : RequestParser rp { ctx } ; <nl> const u32 font_id { rp . Pop < u32 > ( ) } ; <nl> <nl> - LOG_DEBUG ( Service_NS , \" called , font_id = % d \" , font_id ) ; <nl> + NGLOG_DEBUG ( Service_NS , \" called , font_id = { } \" , font_id ) ; <nl> IPC : : ResponseBuilder rb { ctx , 3 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> rb . Push < u32 > ( SHARED_FONT_REGIONS [ font_id ] . offset ) ; <nl> void PL_U : : GetSharedMemoryNativeHandle ( Kernel : : HLERequestContext & ctx ) { <nl> Kernel : : MemoryPermission : : Read , SHARED_FONT_MEM_VADDR , Kernel : : MemoryRegion : : BASE , <nl> \" PL_U : shared_font_mem \" ) ; <nl> <nl> - LOG_DEBUG ( Service_NS , \" called \" ) ; <nl> + NGLOG_DEBUG ( Service_NS , \" called \" ) ; <nl> IPC : : ResponseBuilder rb { ctx , 2 , 1 } ; <nl> rb . Push ( RESULT_SUCCESS ) ; <nl> rb . PushCopyObjects ( shared_font_mem ) ; <nl>\n", "msg": "ns : Move logging macros over to new fmt - compatible ones\n"}
{"diff_id": 27348, "repo": "apple/swift\n", "sha": "ebe0c837953fd642dcea6423d74b4a94e78b624e\n", "time": "2017-04-03T02:55:19Z\n", "diff": "mmm a / lib / SILOptimizer / IPO / CapturePromotion . cpp <nl> ppp b / lib / SILOptimizer / IPO / CapturePromotion . cpp <nl> computeNewArgInterfaceTypes ( SILFunction * F , <nl> <nl> DEBUG ( llvm : : dbgs ( ) < < \" Preparing New Args ! \\ n \" ) ; <nl> <nl> + auto fnTy = F - > getLoweredFunctionType ( ) ; <nl> + <nl> + auto & Types = F - > getModule ( ) . Types ; <nl> + Lowering : : GenericContextScope scope ( Types , fnTy - > getGenericSignature ( ) ) ; <nl> + <nl> / / For each parameter in the old function . . . <nl> for ( unsigned Index : indices ( Parameters ) ) { <nl> auto & param = Parameters [ Index ] ; <nl> computeNewArgInterfaceTypes ( SILFunction * F , <nl> assert ( paramBoxTy - > getLayout ( ) - > getFields ( ) . size ( ) = = 1 <nl> & & \" promoting compound box not implemented yet \" ) ; <nl> auto paramBoxedTy = paramBoxTy - > getFieldType ( F - > getModule ( ) , 0 ) ; <nl> - auto & paramTL = F - > getTypeLowering ( paramBoxedTy ) ; <nl> + auto & paramTL = Types . getTypeLowering ( paramBoxedTy ) ; <nl> ParameterConvention convention ; <nl> if ( paramTL . isFormallyPassedIndirectly ( ) ) { <nl> convention = ParameterConvention : : Indirect_In ; <nl>\n", "msg": "Capture Promotion : Fix use - after - free\n"}
{"diff_id": 27525, "repo": "opencv/opencv\n", "sha": "30d46313ecab212fa76f9fab9e32a2a00042a900\n", "time": "2015-01-29T12:03:28Z\n", "diff": "new file mode 100644 <nl> index 00000000000 . . fac1aeb5073 <nl> mmm / dev / null <nl> ppp b / apps / annotation / opencv_annotation . cpp <nl> <nl> + / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * <nl> + USAGE : <nl> + . / opencv_annotation - images < folder location > - annotations < ouput file > <nl> + <nl> + Created by : Puttemans Steven <nl> + * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / <nl> + <nl> + # include < opencv2 / core / core . hpp > <nl> + # include < opencv2 / highgui / highgui . hpp > <nl> + # include < opencv2 / imgproc / imgproc . hpp > <nl> + <nl> + # include < fstream > <nl> + # include < iostream > <nl> + <nl> + using namespace std ; <nl> + using namespace cv ; <nl> + <nl> + / / Public parameters <nl> + Mat image ; <nl> + int roi_x0 = 0 , roi_y0 = 0 , roi_x1 = 0 , roi_y1 = 0 , num_of_rec = 0 ; <nl> + bool start_draw = false ; <nl> + <nl> + / / Window name for visualisation purposes <nl> + const string window_name = \" OpenCV Based Annotation Tool \" ; <nl> + <nl> + / / FUNCTION : Mouse response for selecting objects in images <nl> + / / If left button is clicked , start drawing a rectangle as long as mouse moves <nl> + / / Stop drawing once a new left click is detected by the on_mouse function <nl> + void on_mouse ( int event , int x , int y , int flag , void * param ) <nl> + { <nl> + / / Action when left button is clicked <nl> + if ( event = = CV_EVENT_LBUTTONDOWN ) <nl> + { <nl> + if ( ! start_draw ) <nl> + { <nl> + roi_x0 = x ; <nl> + roi_y0 = y ; <nl> + start_draw = true ; <nl> + } else { <nl> + roi_x1 = x ; <nl> + roi_y1 = y ; <nl> + start_draw = false ; <nl> + } <nl> + } <nl> + / / Action when mouse is moving <nl> + if ( ( event = = CV_EVENT_MOUSEMOVE ) & & start_draw ) <nl> + { <nl> + / / Redraw bounding box for annotation <nl> + Mat current_view ; <nl> + image . copyTo ( current_view ) ; <nl> + rectangle ( current_view , Point ( roi_x0 , roi_y0 ) , Point ( x , y ) , Scalar ( 0 , 0 , 255 ) ) ; <nl> + imshow ( window_name , current_view ) ; <nl> + } <nl> + } <nl> + <nl> + / / FUNCTION : snippet to convert an integer value to a string using a clean function <nl> + / / instead of creating a stringstream each time inside the main code <nl> + string int2string ( int num ) <nl> + { <nl> + stringstream temp_stream ; <nl> + temp_stream < < num ; <nl> + return temp_stream . str ( ) ; <nl> + } <nl> + <nl> + / / FUNCTION : given an image containing positive object instances , add all the object <nl> + / / annotations to a known stringstream <nl> + void get_annotations ( Mat input_image , stringstream * output_stream ) <nl> + { <nl> + / / Make it possible to exit the annotation <nl> + bool stop = false ; <nl> + <nl> + / / Reset the num_of_rec element at each iteration <nl> + / / Make sure the global image is set to the current image <nl> + num_of_rec = 0 ; <nl> + image = input_image ; <nl> + <nl> + / / Init window interface and couple mouse actions <nl> + namedWindow ( window_name , WINDOW_AUTOSIZE ) ; <nl> + setMouseCallback ( window_name , on_mouse ) ; <nl> + <nl> + imshow ( window_name , image ) ; <nl> + stringstream temp_stream ; <nl> + int key_pressed = 0 ; <nl> + <nl> + do <nl> + { <nl> + / / Keys for processing <nl> + / / You need to select one for confirming a selection and one to continue to the next image <nl> + / / Based on the universal ASCII code of the keystroke : http : / / www . asciitable . com / <nl> + / / c = 99 add rectangle to current image <nl> + / / n = 110 save added rectangles and show next image <nl> + / / < ESC > = 27 exit program <nl> + key_pressed = waitKey ( 0 ) ; <nl> + switch ( key_pressed ) <nl> + { <nl> + case 27 : <nl> + destroyWindow ( window_name ) ; <nl> + stop = true ; <nl> + case 99 : <nl> + / / Add a rectangle to the list <nl> + num_of_rec + + ; <nl> + / / Draw initiated from top left corner <nl> + if ( roi_x0 < roi_x1 & & roi_y0 < roi_y1 ) <nl> + { <nl> + temp_stream < < \" \" < < int2string ( roi_x0 ) < < \" \" < < int2string ( roi_y0 ) < < \" \" < < int2string ( roi_x1 - roi_x0 ) < < \" \" < < int2string ( roi_y1 - roi_y0 ) ; <nl> + } <nl> + / / Draw initiated from bottom right corner <nl> + if ( roi_x0 > roi_x1 & & roi_y0 > roi_y1 ) <nl> + { <nl> + temp_stream < < \" \" < < int2string ( roi_x1 ) < < \" \" < < int2string ( roi_y1 ) < < \" \" < < int2string ( roi_x0 - roi_x1 ) < < \" \" < < int2string ( roi_y0 - roi_y1 ) ; <nl> + } <nl> + / / Draw initiated from top right corner <nl> + if ( roi_x0 > roi_x1 & & roi_y0 < roi_y1 ) <nl> + { <nl> + temp_stream < < \" \" < < int2string ( roi_x1 ) < < \" \" < < int2string ( roi_y0 ) < < \" \" < < int2string ( roi_x0 - roi_x1 ) < < \" \" < < int2string ( roi_y1 - roi_y0 ) ; <nl> + } <nl> + / / Draw initiated from bottom left corner <nl> + if ( roi_x0 < roi_x1 & & roi_y0 > roi_y1 ) <nl> + { <nl> + temp_stream < < \" \" < < int2string ( roi_x0 ) < < \" \" < < int2string ( roi_y1 ) < < \" \" < < int2string ( roi_x1 - roi_x0 ) < < \" \" < < int2string ( roi_y0 - roi_y1 ) ; <nl> + } <nl> + <nl> + rectangle ( input_image , Point ( roi_x0 , roi_y0 ) , Point ( roi_x1 , roi_y1 ) , Scalar ( 0 , 255 , 0 ) , 1 ) ; <nl> + <nl> + break ; <nl> + } <nl> + <nl> + / / Check if escape has been pressed <nl> + if ( stop ) <nl> + { <nl> + break ; <nl> + } <nl> + } <nl> + / / Continue as long as the next image key has not been pressed <nl> + while ( key_pressed ! = 110 ) ; <nl> + <nl> + / / If there are annotations AND the next image key is pressed <nl> + / / Write the image annotations to the file <nl> + if ( num_of_rec > 0 & & key_pressed = = 110 ) <nl> + { <nl> + * output_stream < < \" \" < < num_of_rec < < temp_stream . str ( ) < < endl ; <nl> + } <nl> + <nl> + / / Close down the window <nl> + destroyWindow ( window_name ) ; <nl> + } <nl> + <nl> + int main ( int argc , const char * * argv ) <nl> + { <nl> + / / Read in the input arguments <nl> + string image_folder ; <nl> + string annotations ; <nl> + for ( int i = 1 ; i < argc ; + + i ) <nl> + { <nl> + if ( ! strcmp ( argv [ i ] , \" - images \" ) ) <nl> + { <nl> + image_folder = argv [ + + i ] ; <nl> + } <nl> + else if ( ! strcmp ( argv [ i ] , \" - annotations \" ) ) <nl> + { <nl> + annotations = argv [ + + i ] ; <nl> + } <nl> + } <nl> + <nl> + / / Create the outputfilestream <nl> + ofstream output ( annotations . c_str ( ) ) ; <nl> + <nl> + / / Return the image filenames inside the image folder <nl> + vector < String > filenames ; <nl> + String folder ( image_folder ) ; <nl> + glob ( folder , filenames ) ; <nl> + <nl> + / / Loop through each image stored in the images folder <nl> + / / Create and temporarily store the annotations <nl> + / / At the end write everything to the annotations file <nl> + for ( int i = 0 ; i < filenames . size ( ) ; i + + ) { <nl> + / / Read in an image <nl> + Mat current_image = imread ( filenames [ i ] ) ; <nl> + <nl> + / / Perform annotations & generate corresponding output <nl> + stringstream output_stream ; <nl> + get_annotations ( current_image , & output_stream ) ; <nl> + <nl> + / / Store the annotations , write to the output file <nl> + if ( output_stream . str ( ) ! = \" \" ) { <nl> + output < < filenames [ i ] < < output_stream . str ( ) ; <nl> + } <nl> + } <nl> + <nl> + return 0 ; <nl> + } <nl>\n", "msg": "adding a universal OpenCV based annotation tool for cascade classifier training\n", "score": 1}
{"diff_id": 27564, "repo": "facebook/hhvm\n", "sha": "10f767013485560974328e8c21aae1f96064067e\n", "time": "2015-10-09T02:00:38Z\n", "diff": "mmm a / hphp / runtime / vm / jit / irgen - builtin . cpp <nl> ppp b / hphp / runtime / vm / jit / irgen - builtin . cpp <nl> void emitNativeImpl ( IRGS & env ) { <nl> return ; <nl> } <nl> <nl> + / / CallBuiltin doesn ' t understand IDL instance methods that have variable <nl> + / / arguments . <nl> + if ( auto const info = callee - > methInfo ( ) ) { <nl> + if ( info - > attribute & ( ClassInfo : : VariableArguments | <nl> + ClassInfo : : RefVariableArguments ) ) { <nl> + genericNativeImpl ( ) ; <nl> + return ; <nl> + } <nl> + } <nl> + <nl> auto thiz = callee - > isMethod ( ) & & ( ! callee - > isStatic ( ) | | callee - > isNative ( ) ) <nl> ? gen ( env , LdCtx , fp ( env ) ) : nullptr ; <nl> auto const numParams = gen ( env , LdARNumParams , fp ( env ) ) ; <nl>\n", "msg": "Use generic native implmentation for vararg IDL instance methods\n"}
{"diff_id": 27671, "msg": "Adding - mlir - print - internal - attributes to print attributes with ' : ' prefixes .\n", "msgGPT": "added an option to print internal attributes and modified the module printer to exclude internal attributes if the option is not enabled.", "METEOR Score": "50.27855528791271", "BLEU Score": "0.367623095578229", "ROUGE-L Score": "0.28571428094387763", "score": 1, "repo": "tensorflow/tensorflow\n", "sha": "bc01666ec4e2ebc84d891748c2ab5c9bb2c355f4\n", "time": "2019-03-29T23:34:56Z\n", "diff": "mmm a / lib / IR / AsmPrinter . cpp <nl> ppp b / lib / IR / AsmPrinter . cpp <nl> static llvm : : cl : : opt < bool > <nl> llvm : : cl : : desc ( \" Print the generic op form \" ) , <nl> llvm : : cl : : init ( false ) , llvm : : cl : : Hidden ) ; <nl> <nl> + static llvm : : cl : : opt < bool > printInternalAttributes ( <nl> + \" mlir - print - internal - attributes \" , <nl> + llvm : : cl : : desc ( <nl> + \" Print internal function and instruction attributes ( ' : ' prefix ) . \" ) , <nl> + llvm : : cl : : init ( false ) ) ; <nl> + <nl> namespace { <nl> class ModuleState { <nl> public : <nl> void ModulePrinter : : printOptionalAttrDict ( ArrayRef < NamedAttribute > attrs , <nl> auto attrName = attr . first . strref ( ) ; <nl> / / Never print attributes that start with a colon . These are internal <nl> / / attributes that represent location or other internal metadata . <nl> - if ( attrName . startswith ( \" : \" ) ) <nl> + if ( ! printInternalAttributes & & attrName . startswith ( \" : \" ) ) <nl> return ; <nl> <nl> / / If the caller has requested that this attribute be ignored , then drop it . <nl>\n"}
{"diff_id": 27872, "repo": "TheAlgorithms/C-Plus-Plus\n", "sha": "12a886fae7d8966df7fdeab952a2f2ee02de8cc1\n", "time": "2019-07-19T08:55:42Z\n", "diff": "new file mode 100644 <nl> index 0000000000 . . f6f1169d30 <nl> mmm / dev / null <nl> ppp b / String / knuth_morris_pratt . cpp <nl> <nl> + / * <nl> + The Knuth - Morris - Pratt Algorithm for finding a pattern within a piece of text <nl> + with complexity O ( n + m ) <nl> + 1 ) Preprocess pattern to identify any suffixes that are identical to prefixes <nl> + This tells us where to continue from if we get a mismatch between a character in our pattern <nl> + and the text . <nl> + 2 ) Step through the text one character at a time and compare it to a character in the pattern <nl> + updating our location within the pattern if necessary <nl> + * / <nl> + <nl> + # include < iostream > <nl> + # include < vector > <nl> + # include < string > <nl> + using namespace std ; <nl> + vector < int > getFailureArray ( string pattern ) { <nl> + int pattern_length = pattern . size ( ) ; <nl> + vector < int > failure ( pattern_length + 1 ) ; <nl> + failure [ 0 ] = - 1 ; <nl> + int j = - 1 ; <nl> + for ( int i = 0 ; i < pattern_length ; i + + ) { <nl> + while ( j ! = - 1 & & pattern [ j ] ! = pattern [ i ] ) { <nl> + j = failure [ j ] ; <nl> + } <nl> + j + + ; <nl> + failure [ i + 1 ] = j ; <nl> + } <nl> + return failure ; <nl> + } <nl> + bool kmp ( string pattern , string text ) { <nl> + int text_length = text . size ( ) , pattern_length = pattern . size ( ) ; <nl> + vector < int > failure = getFailureArray ( pattern ) ; <nl> + int k = 0 ; <nl> + for ( int j = 0 ; j < text_length ; j + + ) { <nl> + while ( k ! = - 1 & & pattern [ k ] ! = text [ j ] ) { <nl> + k = failure [ k ] ; <nl> + } <nl> + k + + ; <nl> + if ( k = = pattern_length ) return true ; <nl> + } <nl> + return false ; <nl> + } <nl> + <nl> + int main ( ) <nl> + { <nl> + <nl> + string text = \" alskfjaldsabc1abc1abc12k23adsfabcabc \" ; <nl> + string pattern = \" abc1abc12l \" ; <nl> + if ( kmp ( pattern , text ) = = true ) { <nl> + cout < < \" Found \" < < endl ; <nl> + } <nl> + else { <nl> + cout < < \" Not Found \" < < endl ; <nl> + } <nl> + text = \" abcabc \" ; <nl> + pattern = \" bca \" ; <nl> + if ( kmp ( pattern , text ) = = true ) { <nl> + cout < < \" Found \" < < endl ; <nl> + } <nl> + else { <nl> + cout < < \" Not Found \" < < endl ; <nl> + } <nl> + return 0 ; <nl> + } <nl> + <nl>\n", "msg": "Added knuth pratt morris algorithm for sfinding string match .\n", "score": 1}
{"diff_id": 27903, "repo": "godotengine/godot\n", "sha": "0ae4ca706663242cab5aaa3854bcd52f94db9d1d\n", "time": "2018-01-05T08:28:36Z\n", "diff": "mmm a / editor / plugins / tile_set_editor_plugin . cpp <nl> ppp b / editor / plugins / tile_set_editor_plugin . cpp <nl> AutotileEditor : : AutotileEditor ( EditorNode * p_editor ) { <nl> property_editor = memnew ( PropertyEditor ) ; <nl> property_editor - > set_v_size_flags ( SIZE_EXPAND_FILL ) ; <nl> property_editor - > set_h_size_flags ( SIZE_EXPAND_FILL ) ; <nl> + property_editor - > set_custom_minimum_size ( Size2 ( 10 , 70 ) ) ; <nl> split - > add_child ( property_editor ) ; <nl> <nl> helper = memnew ( AutotileEditorHelper ( this ) ) ; <nl>\n", "msg": "prevent autotile properties out of bounds\n"}
{"diff_id": 28054, "repo": "mongodb/mongo\n", "sha": "0a4056f49bda4294df9c06a47fcdd13d5454ab34\n", "time": "2019-08-23T13:46:34Z\n", "diff": "mmm a / src / mongo / shell / shell_utils_extended . cpp <nl> ppp b / src / mongo / shell / shell_utils_extended . cpp <nl> BSONObj listFiles ( const BSONObj & _args , void * data ) { <nl> stringstream ss ; <nl> ss < < \" listFiles : no such directory : \" < < rootname ; <nl> string msg = ss . str ( ) ; <nl> - uassert ( 12581 , msg . c_str ( ) , boost : : filesystem : : exists ( root ) ) ; <nl> - <nl> - boost : : filesystem : : directory_iterator end ; <nl> - boost : : filesystem : : directory_iterator i ( root ) ; <nl> - <nl> - while ( i ! = end ) { <nl> - boost : : filesystem : : path p = * i ; <nl> - BSONObjBuilder b ; <nl> - b < < \" name \" < < p . generic_string ( ) ; <nl> - b < < \" baseName \" < < p . filename ( ) . generic_string ( ) ; <nl> - b . appendBool ( \" isDirectory \" , is_directory ( p ) ) ; <nl> - if ( ! boost : : filesystem : : is_directory ( p ) ) { <nl> - try { <nl> + uassert ( 12581 , <nl> + msg . c_str ( ) , <nl> + boost : : filesystem : : exists ( root ) & & boost : : filesystem : : is_directory ( root ) ) ; <nl> + <nl> + <nl> + for ( boost : : filesystem : : directory_iterator i ( root ) , end ; i ! = end ; + + i ) <nl> + try { <nl> + const boost : : filesystem : : path & p = * i ; <nl> + BSONObjBuilder b ; <nl> + b < < \" name \" < < p . generic_string ( ) ; <nl> + b < < \" baseName \" < < p . filename ( ) . generic_string ( ) ; <nl> + const bool isDirectory = is_directory ( p ) ; <nl> + b . appendBool ( \" isDirectory \" , isDirectory ) ; <nl> + if ( ! isDirectory ) { <nl> b . append ( \" size \" , ( double ) boost : : filesystem : : file_size ( p ) ) ; <nl> - } catch ( . . . ) { <nl> - i + + ; <nl> - continue ; <nl> } <nl> - } <nl> <nl> - lst . append ( b . obj ( ) ) ; <nl> - i + + ; <nl> - } <nl> + lst . append ( b . obj ( ) ) ; <nl> + } catch ( const boost : : filesystem : : filesystem_error & ) { <nl> + continue ; / / Filesystem errors cause us to just skip that entry , entirely . <nl> + } <nl> <nl> BSONObjBuilder ret ; <nl> ret . appendArray ( \" \" , lst . done ( ) ) ; <nl>\n", "msg": "SERVER - 42817 Fix ` boost : : filesystem ` error handling in shell .\n"}
{"diff_id": 28160, "repo": "facebook/hhvm\n", "sha": "1bb5588bfe01c73de578f523c482bf1b5e85bb12\n", "time": "2017-03-13T09:32:56Z\n", "diff": "mmm a / hphp / runtime / base / execution - context . cpp <nl> ppp b / hphp / runtime / base / execution - context . cpp <nl> <nl> # include \" hphp / runtime / ext / string / ext_string . h \" <nl> # include \" hphp / runtime / ext / reflection / ext_reflection . h \" <nl> # include \" hphp / runtime / ext / apc / ext_apc . h \" <nl> + # include \" hphp / runtime / server / cli - server . h \" <nl> # include \" hphp / runtime / server / server - stats . h \" <nl> # include \" hphp / runtime / vm / debug / debug . h \" <nl> # include \" hphp / runtime / vm / jit / enter - tc . h \" <nl> String ExecutionContext : : getenv ( const String & name ) const { <nl> if ( m_envs . exists ( name ) ) { <nl> return m_envs [ name ] . toString ( ) ; <nl> } <nl> - char * value = : : getenv ( name . data ( ) ) ; <nl> - if ( value ) { <nl> + if ( is_cli_mode ( ) ) { <nl> + auto envs = cli_env ( ) ; <nl> + if ( envs . exists ( name ) ) return envs [ name ] . toString ( ) ; <nl> + return String ( ) ; <nl> + } <nl> + if ( auto value = : : getenv ( name . data ( ) ) ) { <nl> return String ( value , CopyString ) ; <nl> } <nl> if ( RuntimeOption : : EnvVariables . find ( name . c_str ( ) ) ! = RuntimeOption : : EnvVariables . end ( ) ) { <nl>\n", "msg": "Use cli_env ( ) in ExecutionContext : : getenv ( )\n"}
{"diff_id": 28246, "repo": "bitcoin/bitcoin\n", "sha": "fadf7d13905d76ef4d2d8b9b96a6b9269f78fbba\n", "time": "2019-04-19T13:50:23Z\n", "diff": "mmm a / src / wallet / wallet . cpp <nl> ppp b / src / wallet / wallet . cpp <nl> <nl> / / Copyright ( c ) 2009 - 2010 Satoshi Nakamoto <nl> - / / Copyright ( c ) 2009 - 2018 The Bitcoin Core developers <nl> + / / Copyright ( c ) 2009 - 2019 The Bitcoin Core developers <nl> / / Distributed under the MIT software license , see the accompanying <nl> / / file COPYING or http : / / www . opensource . org / licenses / mit - license . php . <nl> <nl> # include < wallet / wallet . h > <nl> <nl> # include < chain . h > <nl> - # include < checkpoints . h > <nl> # include < consensus / consensus . h > <nl> # include < consensus / validation . h > <nl> # include < fs . h > <nl>\n", "msg": "wallet : Remove unused import checkpoints . h\n"}
{"diff_id": 28273, "msg": "TypeReconstruction : Support for subclass existentials\n", "msgGPT": "add support for subclass existentials in visit node protocol list with class function.", "METEOR Score": "30.386782249667736", "BLEU Score": "0.4665683936541763", "ROUGE-L Score": "0.3999999954500001", "score": 1, "repo": "apple/swift\n", "sha": "9b49751ac15003618db67069176ea2e185238f48\n", "time": "2017-04-22T03:19:46Z\n", "diff": "mmm a / lib / IDE / TypeReconstruction . cpp <nl> ppp b / lib / IDE / TypeReconstruction . cpp <nl> static void VisitNodeProtocolList ( <nl> if ( cur_node - > begin ( ) ! = cur_node - > end ( ) ) { <nl> VisitNodeResult protocol_types_result ; <nl> VisitNode ( ast , cur_node - > getFirstChild ( ) , protocol_types_result ) ; <nl> - if ( protocol_types_result . _error <nl> - . empty ( ) / * cannot check for empty type list as Any is allowed * / ) { <nl> - if ( ast ) { <nl> - result . _types . push_back ( <nl> - ProtocolCompositionType : : get ( * ast , protocol_types_result . _types , <nl> - / * HasExplicitAnyObject = * / false ) ) ; <nl> - } else { <nl> - result . _error = \" invalid ASTContext \" ; <nl> - } <nl> + if ( protocol_types_result . _error . empty ( ) ) { <nl> + result . _types . push_back ( <nl> + ProtocolCompositionType : : get ( * ast , protocol_types_result . _types , <nl> + / * HasExplicitAnyObject = * / false ) ) ; <nl> } <nl> } <nl> } <nl> static void VisitNodeProtocolList ( <nl> static void VisitNodeProtocolListWithClass ( <nl> ASTContext * ast , <nl> Demangle : : NodePointer cur_node , VisitNodeResult & result ) { <nl> - llvm_unreachable ( \" Subclass existentials not supported here yet \" ) ; <nl> + if ( cur_node - > begin ( ) ! = cur_node - > end ( ) ) { <nl> + VisitNodeResult class_type_result ; <nl> + VisitNodeResult protocol_types_result ; <nl> + Demangle : : Node : : iterator child_end = cur_node - > end ( ) ; <nl> + for ( Demangle : : Node : : iterator child_pos = cur_node - > begin ( ) ; <nl> + child_pos ! = child_end ; + + child_pos ) { <nl> + auto child = * child_pos ; <nl> + switch ( child - > getKind ( ) ) { <nl> + case Demangle : : Node : : Kind : : ProtocolList : <nl> + VisitNode ( ast , child , protocol_types_result ) ; <nl> + break ; <nl> + case Demangle : : Node : : Kind : : Type : <nl> + VisitNode ( ast , child , class_type_result ) ; <nl> + break ; <nl> + default : <nl> + result . _error = \" invalid subclass existential \" ; <nl> + break ; <nl> + } <nl> + } <nl> + <nl> + if ( protocol_types_result . _error . empty ( ) & & <nl> + protocol_types_result . _types . size ( ) > 0 & & <nl> + class_type_result . _types . size ( ) = = 1 ) { <nl> + SmallVector < Type , 2 > members ; <nl> + members . push_back ( class_type_result . _types . front ( ) ) ; <nl> + for ( auto member : protocol_types_result . _types ) <nl> + members . push_back ( member ) ; <nl> + result . _types . push_back ( <nl> + ProtocolCompositionType : : get ( * ast , members , <nl> + / * HasExplicitAnyObject = * / false ) ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + static void VisitNodeProtocolListWithAnyObject ( <nl> + ASTContext * ast , <nl> + Demangle : : NodePointer cur_node , VisitNodeResult & result ) { <nl> + if ( cur_node - > begin ( ) ! = cur_node - > end ( ) ) { <nl> + VisitNodeResult protocol_types_result ; <nl> + VisitNode ( ast , cur_node - > getFirstChild ( ) , protocol_types_result ) ; <nl> + if ( protocol_types_result . _error . empty ( ) ) { <nl> + result . _types . push_back ( <nl> + ProtocolCompositionType : : get ( * ast , protocol_types_result . _types , <nl> + / * HasExplicitAnyObject = * / true ) ) ; <nl> + } <nl> + } <nl> } <nl> <nl> static void VisitNodeQualifiedArchetype ( <nl> static void VisitNode ( <nl> VisitNodeProtocolListWithClass ( ast , node , result ) ; <nl> break ; <nl> <nl> + case Demangle : : Node : : Kind : : ProtocolListWithAnyObject : <nl> + VisitNodeProtocolListWithAnyObject ( ast , node , result ) ; <nl> + break ; <nl> + <nl> case Demangle : : Node : : Kind : : QualifiedArchetype : <nl> VisitNodeQualifiedArchetype ( ast , node , result ) ; <nl> break ; <nl>\n"}
{"diff_id": 28286, "repo": "telegramdesktop/tdesktop\n", "sha": "367b487a6ce383483fa9c581e20ddbde869bb359\n", "time": "2020-11-17T09:56:50Z\n", "diff": "mmm a / Telegram / SourceFiles / history / view / controls / history_view_voice_record_bar . cpp <nl> ppp b / Telegram / SourceFiles / history / view / controls / history_view_voice_record_bar . cpp <nl> class RecordLock final : public Ui : : RpWidget { <nl> void init ( ) ; <nl> <nl> void drawProgress ( Painter & p ) ; <nl> + void setProgress ( float64 progress ) ; <nl> + void startLockingAnimation ( float64 to ) ; <nl> <nl> Ui : : Animations : : Simple _lockAnimation ; <nl> + Ui : : Animations : : Simple _lockEnderAnimation ; <nl> <nl> rpl : : variable < float64 > _progress = 0 . ; <nl> } ; <nl> void RecordLock : : drawProgress ( Painter & p ) { <nl> } <nl> } <nl> <nl> + void RecordLock : : startLockingAnimation ( float64 to ) { <nl> + auto callback = [ = ] ( auto value ) { setProgress ( value ) ; } ; <nl> + const auto duration = st : : historyRecordVoiceShowDuration ; <nl> + _lockEnderAnimation . start ( std : : move ( callback ) , 0 . , to , duration ) ; <nl> + } <nl> + <nl> void RecordLock : : requestPaintProgress ( float64 progress ) { <nl> - if ( isHidden ( ) | | isLocked ( ) ) { <nl> + if ( isHidden ( ) | | isLocked ( ) | | _lockEnderAnimation . animating ( ) ) { <nl> return ; <nl> } <nl> + if ( ! _progress . current ( ) & & ( progress > . 3 ) ) { <nl> + startLockingAnimation ( progress ) ; <nl> + return ; <nl> + } <nl> + setProgress ( progress ) ; <nl> + } <nl> + <nl> + void RecordLock : : setProgress ( float64 progress ) { <nl> _progress = progress ; <nl> update ( ) ; <nl> } <nl>\n", "msg": "Prettified fast locking of voice record .\n"}
{"diff_id": 28336, "repo": "apple/swift\n", "sha": "a57bfed2d10363ba85b4ec617d583c75d28ffb91\n", "time": "2015-04-05T04:53:47Z\n", "diff": "mmm a / lib / SILPasses / COWArrayOpt . cpp <nl> ppp b / lib / SILPasses / COWArrayOpt . cpp <nl> class SwiftArrayOptPass : public SILFunctionTransform { <nl> DominanceAnalysis * DA = PM - > getAnalysis < DominanceAnalysis > ( ) ; <nl> SILLoopAnalysis * LA = PM - > getAnalysis < SILLoopAnalysis > ( ) ; <nl> SILLoopInfo * LI = LA - > getLoopInfo ( getFunction ( ) ) ; <nl> - CallGraph * CG = PM - > getAnalysis < CallGraphAnalysis > ( ) - > getCallGraphOrNull ( ) ; <nl> + CallGraphAnalysis * CGA = PM - > getAnalysis < CallGraphAnalysis > ( ) ; <nl> + CallGraph * CG = CGA - > getCallGraphOrNull ( ) ; <nl> <nl> bool HasChanged = false ; <nl> <nl> class SwiftArrayOptPass : public SILFunctionTransform { <nl> if ( HasChanged ) { <nl> / / We preserve the dominator tree . Let ' s invalidate everything else . <nl> DA - > lockInvalidation ( ) ; <nl> + CGA - > lockInvalidation ( ) ; <nl> invalidateAnalysis ( SILAnalysis : : PreserveKind : : Nothing ) ; <nl> + CGA - > unlockInvalidation ( ) ; <nl> DA - > unlockInvalidation ( ) ; <nl> } <nl> } <nl>\n", "msg": "Lock invalidations of the call graph during COWArrayOpt .\n"}
{"diff_id": 28372, "repo": "catchorg/Catch2\n", "sha": "b0214ff862508ca77ce76b9028aaf8422d7083b9\n", "time": "2020-10-08T09:28:50Z\n", "diff": "mmm a / src / catch2 / internal / catch_output_redirect . cpp <nl> ppp b / src / catch2 / internal / catch_output_redirect . cpp <nl> namespace Catch { <nl> if ( tmpnam_s ( m_buffer ) ) { <nl> CATCH_RUNTIME_ERROR ( \" Could not get a temp filename \" ) ; <nl> } <nl> - if ( fopen_s ( & m_file , m_buffer , \" w \" ) ) { <nl> + if ( fopen_s ( & m_file , m_buffer , \" w + \" ) ) { <nl> char buffer [ 100 ] ; <nl> if ( strerror_s ( buffer , errno ) ) { <nl> CATCH_RUNTIME_ERROR ( \" Could not translate errno to a string \" ) ; <nl>\n", "msg": "Make experimental capture work on Windows with read - write temp file behavior\n"}
{"diff_id": 28525, "repo": "godotengine/godot\n", "sha": "855f4dc1930007f13f32bed5572aa812e32f9e63\n", "time": "2020-03-17T20:33:39Z\n", "diff": "mmm a / scene / main / viewport . cpp <nl> ppp b / scene / main / viewport . cpp <nl> Control * Viewport : : get_modal_stack_top ( ) const { <nl> } <nl> <nl> String Viewport : : get_configuration_warning ( ) const { <nl> - <nl> / * if ( get_parent ( ) & & ! Object : : cast_to < Control > ( get_parent ( ) ) & & ! render_target ) { <nl> <nl> return TTR ( \" This viewport is not set as render target . If you intend for it to display its contents directly to the screen , make it a child of a Control so it can obtain a size . Otherwise , make it a RenderTarget and assign its internal texture to some node for display . \" ) ; <nl> } * / <nl> <nl> + if ( size . x = = 0 | | size . y = = 0 ) { <nl> + return TTR ( \" This viewport can ' t render anything . \\ nConsider increasing the size . \" ) ; <nl> + } <nl> return String ( ) ; <nl> } <nl> <nl>\n", "msg": "Add size warning to Viewport Node\n"}
{"diff_id": 28635, "repo": "apple/swift\n", "sha": "3fa712d4d1caac32fc2c62f7117a1746bf63b880\n", "time": "2017-04-21T21:02:00Z\n", "diff": "mmm a / unittests / runtime / Metadata . cpp <nl> ppp b / unittests / runtime / Metadata . cpp <nl> ProtocolDescriptor ProtocolNoWitnessTable { <nl> . withDispatchStrategy ( ProtocolDispatchStrategy : : ObjC ) <nl> } ; <nl> <nl> - # if 0 / / disabled because of rdar : / / problem / 31759879 <nl> - <nl> TEST ( MetadataTest , getExistentialMetadata ) { <nl> const ProtocolDescriptor * protoList1 [ ] = { } ; <nl> RaceTest_ExpectEqual < const ExistentialTypeMetadata * > ( <nl> TEST ( MetadataTest , getExistentialMetadata ) { <nl> } ) ; <nl> } <nl> <nl> - # endif <nl> - <nl> static SWIFT_CC ( swift ) void destroySuperclass ( SWIFT_CONTEXT HeapObject * toDestroy ) { } <nl> <nl> struct { <nl>\n", "msg": "Revert \" disabled flaky test \"\n"}
{"diff_id": 28714, "repo": "apple/foundationdb\n", "sha": "f40f33f555b41791f2684bcdcb93a9c4a95b0397\n", "time": "2018-08-02T01:42:37Z\n", "diff": "mmm a / fdbserver / workloads / MemoryKeyValueStore . cpp <nl> ppp b / fdbserver / workloads / MemoryKeyValueStore . cpp <nl> Key MemoryKeyValueStore : : getKey ( KeySelectorRef selector ) const { <nl> / / Update the iterator position if necessary based on the value of orEqual <nl> int count = 0 ; <nl> if ( selector . offset < = 0 ) { <nl> - if ( ( selector . getKey ( ) = = mapItr - > first & & ! selector . orEqual ) | | selector . getKey ( ) ! = mapItr - > first ) { <nl> + if ( mapItr = = store . end ( ) | | <nl> + selector . getKey ( ) ! = mapItr - > first | | <nl> + ( selector . getKey ( ) = = mapItr - > first & & ! selector . orEqual ) ) { <nl> if ( mapItr = = store . begin ( ) ) <nl> return startKey ( ) ; <nl> <nl> Key MemoryKeyValueStore : : getKey ( KeySelectorRef selector ) const { <nl> } <nl> } <nl> else { <nl> - if ( selector . getKey ( ) = = mapItr - > first & & selector . orEqual ) { <nl> - if ( mapItr = = store . end ( ) ) <nl> - return endKey ( ) ; <nl> + if ( mapItr = = store . end ( ) ) <nl> + return endKey ( ) ; <nl> <nl> + if ( selector . getKey ( ) = = mapItr - > first & & selector . orEqual ) { <nl> mapItr + + ; <nl> } <nl> <nl>\n", "msg": "Do not attempt to dereference past - the - end iterators in MemoryKVS .\n", "score": 1}
{"diff_id": 28846, "repo": "xbmc/xbmc\n", "sha": "d9a01f2f0bbc2788fb6a6023ad7a3f7cc79290e3\n", "time": "2011-01-06T15:17:55Z\n", "diff": "mmm a / xbmc / cores / VideoRenderers / LinuxRendererGLES . cpp <nl> ppp b / xbmc / cores / VideoRenderers / LinuxRendererGLES . cpp <nl> void CLinuxRendererGLES : : RenderSinglePass ( int index , int field ) <nl> YUVFIELDS & fields = m_buffers [ index ] . fields ; <nl> YUVPLANES & planes = fields [ field ] ; <nl> <nl> - / / set scissors if we are not in fullscreen video <nl> - if ( ! ( g_graphicsContext . IsFullScreenVideo ( ) | | g_graphicsContext . IsCalibrating ( ) ) ) <nl> - g_graphicsContext . ClipToViewWindow ( ) ; <nl> - <nl> if ( m_reloadShaders ) <nl> { <nl> m_reloadShaders = 0 ; <nl> void CLinuxRendererGLES : : RenderMultiPass ( int index , int field ) <nl> YV12Image & im = m_buffers [ index ] . image ; <nl> YUVPLANES & planes = m_buffers [ index ] . fields [ field ] ; <nl> <nl> - / / set scissors if we are not in fullscreen video <nl> - if ( ! ( g_graphicsContext . IsFullScreenVideo ( ) | | g_graphicsContext . IsCalibrating ( ) ) ) <nl> - g_graphicsContext . ClipToViewWindow ( ) ; <nl> - <nl> if ( m_reloadShaders ) <nl> { <nl> m_reloadShaders = 0 ; <nl> void CLinuxRendererGLES : : RenderSoftware ( int index , int field ) <nl> { <nl> YUVPLANES & planes = m_buffers [ index ] . fields [ field ] ; <nl> <nl> - / / set scissors if we are not in fullscreen video <nl> - if ( ! ( g_graphicsContext . IsFullScreenVideo ( ) | | g_graphicsContext . IsCalibrating ( ) ) ) <nl> - g_graphicsContext . ClipToViewWindow ( ) ; <nl> - <nl> glDisable ( GL_DEPTH_TEST ) ; <nl> <nl> / / Y <nl>\n", "msg": "fixed : apply 8dcd0f59ad8773cfef17f7c350b43fb7d3ea7c43 to CLinuxRendererGLES\n"}
{"diff_id": 28941, "repo": "emscripten-core/emscripten\n", "sha": "7e1da84860345ce3dd5ac0fdee0ad3f4bda817af\n", "time": "2015-11-04T00:14:56Z\n", "diff": "mmm a / tools / optimizer / asm2wasm . cpp <nl> ppp b / tools / optimizer / asm2wasm . cpp <nl> <nl> <nl> # include \" simple_ast . h \" <nl> # include \" wasm . h \" <nl> + # include \" optimizer . h \" <nl> + <nl> + # include \" optimizer - shared . cpp \" <nl> <nl> IString GLOBAL ( \" global \" ) , NAN_ ( \" NaN \" ) , INFINITY_ ( \" Infinity \" ) , <nl> TOPMOST ( \" topmost \" ) , <nl> class Asm2WasmModule : public wasm : : Module { <nl> <nl> private : <nl> BasicType detectWasmType ( Ref ast ) { <nl> - if ( ast [ 0 ] = = BINARY | | ast [ 0 ] = = NUM ) return BasicType : : i32 ; <nl> - if ( ast [ 0 ] = = UNARY_PREFIX ) return BasicType : : f64 ; <nl> + AsmType asmType = detectType ( ast ) ; <nl> + if ( asmType = = ASM_INT ) return BasicType : : i32 ; <nl> + if ( asmType = = ASM_DOUBLE ) return BasicType : : f64 ; <nl> abort_on ( \" confused detectWasmType \" , ast ) ; <nl> } <nl> <nl> bool isInteger ( double num ) { <nl> return fmod ( num , 1 ) = = 0 & & double ( int ( num ) ) = = num ; <nl> } <nl> - <nl> - bool isIntegerCoercion ( Ref ast ) { <nl> - if ( ast [ 0 ] = = BINARY & & ( ast [ 1 ] = = OR | | ast [ 1 ] = = TRSHIFT ) ) return true ; <nl> - if ( ast [ 0 ] = = NUM ) return isInteger ( ast [ 1 ] - > getNumber ( ) ) ; <nl> - return false ; <nl> + bool isInteger ( Ref ast ) { <nl> + return ast [ 0 ] = = NUM & & isInteger ( ast [ 1 ] - > getNumber ( ) ) ; <nl> } <nl> - <nl> + <nl> bool isUnsignedCoercion ( Ref ast ) { <nl> if ( ast [ 0 ] = = BINARY & & ast [ 1 ] = = TRSHIFT ) return true ; <nl> return false ; <nl> class Asm2WasmModule : public wasm : : Module { <nl> if ( op = = TRSHIFT ) { binary = BinaryOp : : ShrU ; return true ; } <nl> if ( op = = EQ ) { relational = RelationalOp : : Eq ; return false ; } <nl> if ( op = = NE ) { relational = RelationalOp : : Ne ; return false ; } <nl> - bool isInteger = isIntegerCoercion ( left ) ; <nl> - assert ( isInteger = = isIntegerCoercion ( right ) ) ; <nl> + BasicType leftType = detectWasmType ( left ) ; <nl> + bool isInteger = leftType = = BasicType : : i32 ; <nl> bool isUnsigned = isUnsignedCoercion ( left ) ; <nl> assert ( isUnsigned = = isUnsignedCoercion ( right ) ) ; <nl> if ( op = = DIV ) { <nl>\n", "msg": "use optimizer infrastructure to detect asm types\n", "score": 1}
{"diff_id": 28981, "msg": "Disable unreachable code warning for TrickyTests . cpp\n", "msgGPT": "disable unreachable code warning for the last test when compiling as win32 | release.", "METEOR Score": "32.74439042039322", "BLEU Score": "0.5051597056956313", "ROUGE-L Score": "0.4545454499173554", "score": 1, "repo": "catchorg/Catch2\n", "sha": "85aa7707019879e8047eb0945342d8b324d5ae7b\n", "time": "2017-05-07T23:26:06Z\n", "diff": "mmm a / projects / SelfTest / TrickyTests . cpp <nl> ppp b / projects / SelfTest / TrickyTests . cpp <nl> <nl> # pragma clang diagnostic ignored \" - Wpadded \" <nl> # endif <nl> <nl> + # ifdef _MSC_VER <nl> + # pragma warning ( disable : 4702 ) / / Disable unreachable code warning for the last test <nl> + / / that is triggered when compiling as Win32 | Release <nl> + # endif <nl> + <nl> # include < stdio . h > <nl> <nl> # include \" catch . hpp \" <nl>\n"}
{"diff_id": 29045, "repo": "microsoft/CNTK\n", "sha": "67c6d6381beb123cc7014b5a91b2ef4217067a4d\n", "time": "2016-06-24T16:16:54Z\n", "diff": "mmm a / Source / ComputationNetworkLib / RNNNodes . cpp <nl> ppp b / Source / ComputationNetworkLib / RNNNodes . cpp <nl> <nl> <nl> namespace Microsoft { namespace MSR { namespace CNTK { <nl> <nl> + vector < size_t > numSequencesForFrame ; <nl> / / mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm - - <nl> / / RNNNode <nl> / / mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm - - <nl> void RNNNode < ElemType > : : ForwardProp ( const FrameRange & fr ) <nl> shapeYT = TensorShape ( shapeYT . GetDims ( ) ) ; <nl> <nl> / / create a vector with the correct number of timesteps ( shapeXT [ 2 ] ) containing the sequence count ( shapeXT [ 1 ] ) <nl> - vector < size_t > numSequencesForFrame ( shapeXT [ 2 ] , shapeXT [ 1 ] ) ; <nl> - m_transposedOutput - > RNNForward ( * m_transposedInput , paramW , shapeXT [ 0 ] , shapeYT [ 0 ] , numSequencesForFrame , m_rnnParameters , * m_reserve , * m_workspace ) ; <nl> + numSequencesForFrame = vector < size_t > ( shapeXT [ 2 ] , shapeXT [ 1 ] ) ; <nl> + try <nl> + { <nl> + m_transposedOutput - > RNNForward ( * m_transposedInput , paramW , shapeXT [ 0 ] , shapeYT [ 0 ] , numSequencesForFrame , m_rnnParameters , * m_reserve , * m_workspace ) ; <nl> + } <nl> + catch ( exception e ) <nl> + { <nl> + fprintf ( stderr , \" | m_transposedInput | = % ld \\ n \" , m_transposedInput - > GetNumElements ( ) ) ; <nl> + fprintf ( stderr , \" | m_reserve | = % ld \\ n \" , m_reserve - > GetNumElements ( ) ) ; <nl> + fprintf ( stderr , \" | m_workspace | = % ld \\ n \" , m_workspace - > GetNumElements ( ) ) ; <nl> + fprintf ( stderr , \" shapeXT = % s \\ n \" , ( ( std : : string ) shapeXT ) . c_str ( ) ) ; <nl> + fprintf ( stderr , \" shapeYT = % s \\ n \" , ( ( std : : string ) shapeYT ) . c_str ( ) ) ; <nl> + fprintf ( stderr , \" numSequencesForFrame = [ \" ) ; <nl> + for ( size_t x : numSequencesForFrame ) fprintf ( stderr , \" % d , \" , x ) ; <nl> + fprintf ( stderr , \" \\ n \" ) ; <nl> + throw e ; <nl> + } <nl> <nl> / / No one uses shapeY , but it is necessary <nl> TensorShape shapeY ; <nl> void RNNNode < ElemType > : : BackpropTo ( const size_t inputIndex , const FrameRange & fr <nl> m_transposedDInput - > Resize ( Input ( 0 ) - > Value ( ) . GetNumRows ( ) , m_transposedDOutput - > GetNumCols ( ) ) ; <nl> <nl> / / Do the work <nl> - m_transposedOutput - > RNNBackwardData ( * m_transposedDOutput , paramW , * m_transposedDInput , m_rnnParameters , * m_reserve , * m_workspace ) ; <nl> + try <nl> + { <nl> + m_transposedOutput - > RNNBackwardData ( * m_transposedDOutput , paramW , * m_transposedDInput , m_rnnParameters , * m_reserve , * m_workspace ) ; <nl> + } <nl> + catch ( exception e ) <nl> + { <nl> + fprintf ( stderr , \" | m_transposedDOutput | = % ld \\ n \" , m_transposedDOutput - > GetNumElements ( ) ) ; <nl> + fprintf ( stderr , \" | paramW | = % ld \\ n \" , paramW . GetNumElements ( ) ) ; <nl> + fprintf ( stderr , \" | m_transposedDInput | = % ld \\ n \" , m_transposedDInput - > GetNumElements ( ) ) ; <nl> + fprintf ( stderr , \" | m_reserve | = % ld \\ n \" , m_reserve - > GetNumElements ( ) ) ; <nl> + fprintf ( stderr , \" | m_workspace | = % ld \\ n \" , m_workspace - > GetNumElements ( ) ) ; <nl> + fprintf ( stderr , \" shapeXT = % s \\ n \" , ( ( std : : string ) shapeXT ) . c_str ( ) ) ; <nl> + fprintf ( stderr , \" shapeYT = % s \\ n \" , ( ( std : : string ) shapeYT ) . c_str ( ) ) ; <nl> + fprintf ( stderr , \" numSequencesForFrame = [ \" ) ; <nl> + for ( size_t x : numSequencesForFrame ) fprintf ( stderr , \" % d , \" , x ) ; <nl> + fprintf ( stderr , \" \\ n \" ) ; <nl> + throw e ; <nl> + } <nl> m_BackwardDataCalledYet = true ; <nl> } <nl> if ( inputIndex = = 1 ) / / parameters <nl> { <nl> Matrix < ElemType > & paramDW = Input ( 1 ) - > Gradient ( ) ; <nl> - m_transposedOutput - > RNNBackwardWeights ( * m_transposedInput , * m_transposedOutput , paramDW , m_rnnParameters , * m_reserve , * m_workspace ) ; <nl> + try <nl> + { <nl> + m_transposedOutput - > RNNBackwardWeights ( * m_transposedInput , * m_transposedOutput , paramDW , m_rnnParameters , * m_reserve , * m_workspace ) ; <nl> + } <nl> + catch ( exception e ) <nl> + { <nl> + fprintf ( stderr , \" | m_transposedInput | = % ld \\ n \" , m_transposedInput - > GetNumElements ( ) ) ; <nl> + fprintf ( stderr , \" | m_transposedOutput | = % ld \\ n \" , m_transposedOutput - > GetNumElements ( ) ) ; <nl> + fprintf ( stderr , \" | paramDW | = % ld \\ n \" , paramDW . GetNumElements ( ) ) ; <nl> + fprintf ( stderr , \" | m_reserve | = % ld \\ n \" , m_reserve - > GetNumElements ( ) ) ; <nl> + fprintf ( stderr , \" | m_workspace | = % ld \\ n \" , m_workspace - > GetNumElements ( ) ) ; <nl> + fprintf ( stderr , \" shapeXT = % s \\ n \" , ( ( std : : string ) shapeXT ) . c_str ( ) ) ; <nl> + fprintf ( stderr , \" shapeYT = % s \\ n \" , ( ( std : : string ) shapeYT ) . c_str ( ) ) ; <nl> + fprintf ( stderr , \" numSequencesForFrame = [ \" ) ; <nl> + for ( size_t x : numSequencesForFrame ) fprintf ( stderr , \" % d , \" , x ) ; <nl> + fprintf ( stderr , \" \\ n \" ) ; <nl> + throw e ; <nl> + } <nl> } <nl> else if ( inputIndex = = 0 ) / / data <nl> { <nl>\n", "msg": "Wrapped RNNNode Exceptions to produce useful debug info\n"}
{"diff_id": 29129, "repo": "bitcoin/bitcoin\n", "sha": "68649bef9395947f3a71e40daae053ca5c0aabca\n", "time": "2012-01-28T15:16:21Z\n", "diff": "mmm a / src / main . cpp <nl> ppp b / src / main . cpp <nl> CBlock * CreateNewBlock ( CReserveKey & reservekey ) <nl> if ( ! tx . FetchInputs ( txdb , mapTestPoolTmp , false , true , mapInputs , fInvalid ) ) <nl> continue ; <nl> <nl> - int64 nFees = tx . GetValueIn ( mapInputs ) - tx . GetValueOut ( ) ; <nl> - if ( nFees < nMinFee ) <nl> + int64 nTxFees = tx . GetValueIn ( mapInputs ) - tx . GetValueOut ( ) ; <nl> + if ( nTxFees < nMinFee ) <nl> continue ; <nl> <nl> nTxSigOps + = tx . GetP2SHSigOpCount ( mapInputs ) ; <nl> CBlock * CreateNewBlock ( CReserveKey & reservekey ) <nl> nBlockSize + = nTxSize ; <nl> + + nBlockTx ; <nl> nBlockSigOps + = nTxSigOps ; <nl> + nFees + = nTxFees ; <nl> <nl> / / Add transactions that depend on this one to the priority queue <nl> uint256 hash = tx . GetHash ( ) ; <nl>\n", "msg": "CreateNewBlock was not adding in transaction fees .\n"}
{"diff_id": 29182, "repo": "facebook/yoga\n", "sha": "02a2309b2a8208e652e351cf8a195c17694b1f01\n", "time": "2018-11-22T16:08:30Z\n", "diff": "mmm a / yoga / Yoga . cpp <nl> ppp b / yoga / Yoga . cpp <nl> static float YGNodeCalculateAvailableInnerDim ( <nl> return availableInnerDim ; <nl> } <nl> <nl> - static void YGNodeComputeFlexBasisForChildren ( <nl> + static float YGNodeComputeFlexBasisForChildren ( <nl> const YGNodeRef node , <nl> const float availableInnerWidth , <nl> const float availableInnerHeight , <nl> static void YGNodeComputeFlexBasisForChildren ( <nl> YGDirection direction , <nl> YGFlexDirection mainAxis , <nl> const YGConfigRef config , <nl> - bool performLayout , <nl> - float & totalOuterFlexBasis ) { <nl> + bool performLayout ) { <nl> + float totalOuterFlexBasis = 0 . 0f ; <nl> YGNodeRef singleFlexChild = nullptr ; <nl> YGVector children = node - > getChildren ( ) ; <nl> YGMeasureMode measureModeMainDim = <nl> static void YGNodeComputeFlexBasisForChildren ( <nl> child - > getLayout ( ) . computedFlexBasis + <nl> child - > getMarginForAxis ( mainAxis , availableInnerWidth ) ) ; <nl> } <nl> + <nl> + return totalOuterFlexBasis ; <nl> } <nl> <nl> / / This function assumes that all the children of node have their <nl> static void YGNodelayoutImpl ( <nl> const float availableInnerCrossDim = <nl> isMainAxisRow ? availableInnerHeight : availableInnerWidth ; <nl> <nl> - float totalOuterFlexBasis = 0 ; <nl> - <nl> / / STEP 3 : DETERMINE FLEX BASIS FOR EACH ITEM <nl> <nl> - YGNodeComputeFlexBasisForChildren ( <nl> + float totalOuterFlexBasis = YGNodeComputeFlexBasisForChildren ( <nl> node , <nl> availableInnerWidth , <nl> availableInnerHeight , <nl> static void YGNodelayoutImpl ( <nl> direction , <nl> mainAxis , <nl> config , <nl> - performLayout , <nl> - totalOuterFlexBasis ) ; <nl> + performLayout ) ; <nl> <nl> const bool flexBasisOverflows = measureModeMainDim = = YGMeasureModeUndefined <nl> ? false <nl>\n", "msg": "` YGNodeComputeFlexBasisForChildren ` : remove output param\n"}
{"diff_id": 29188, "repo": "mongodb/mongo\n", "sha": "9d53f3375a37145e62a0a5855d169164b0866325\n", "time": "2012-02-17T19:26:09Z\n", "diff": "mmm a / src / mongo / tools / files . cpp <nl> ppp b / src / mongo / tools / files . cpp <nl> class Files : public Tool { <nl> if ( cmd = = \" list \" ) { <nl> BSONObjBuilder b ; <nl> if ( filename . size ( ) ) { <nl> - b . appendRegex ( \" filename \" , ( ( string ) \" ^ \" + pcrecpp : : RE : : QuoteMeta ( filename ) ) ) ; <nl> + b . appendRegex ( \" filename \" , ( string ) \" ^ \" + <nl> + pcrecpp : : RE : : QuoteMeta ( filename ) ) ; <nl> } <nl> <nl> display ( & g , b . obj ( ) ) ; <nl>\n", "msg": "Changes to address code review comments for SERVER - 4952\n"}
{"diff_id": 29440, "repo": "bitcoin/bitcoin\n", "sha": "aa19b8ea44b292cd612c4ce01e08c83324fa8296\n", "time": "2017-05-10T15:47:45Z\n", "diff": "mmm a / src / policy / fees . cpp <nl> ppp b / src / policy / fees . cpp <nl> double TxConfirmStats : : EstimateMedianVal ( int confTarget , double sufficientTxVal , <nl> failBucket . leftMempool = failNum ; <nl> } <nl> <nl> - LogPrint ( BCLog : : ESTIMATEFEE , \" FeeEst : % d % s % . 0f % % decay % . 5f : need feerate : % g from ( % g - % g ) % . 2f % % % . 1f / ( % . 1f + % d mem + % . 1f out ) Fail : ( % g - % g ) % . 2f % % % . 1f / ( % . 1f + % d mem + % . 1f out ) \\ n \" , <nl> + LogPrint ( BCLog : : ESTIMATEFEE , \" FeeEst : % d % s % . 0f % % decay % . 5f : feerate : % g from ( % g - % g ) % . 2f % % % . 1f / ( % . 1f % d mem % . 1f out ) Fail : ( % g - % g ) % . 2f % % % . 1f / ( % . 1f % d mem % . 1f out ) \\ n \" , <nl> confTarget , requireGreater ? \" > \" : \" < \" , 100 . 0 * successBreakPoint , decay , <nl> median , passBucket . start , passBucket . end , <nl> 100 * passBucket . withinTarget / ( passBucket . totalConfirmed + passBucket . inMempool + passBucket . leftMempool ) , <nl>\n", "msg": "Clean up fee estimate debug printing\n"}
{"diff_id": 29517, "repo": "apple/swift\n", "sha": "378e94b901e196ef7f29e8900ed145cf8a9cb241\n", "time": "2016-02-02T05:50:01Z\n", "diff": "mmm a / lib / SILOptimizer / PassManager / PassManager . cpp <nl> ppp b / lib / SILOptimizer / PassManager / PassManager . cpp <nl> llvm : : cl : : opt < unsigned > SILNumOptPassesToRun ( <nl> \" sil - opt - pass - count \" , llvm : : cl : : init ( UINT_MAX ) , <nl> llvm : : cl : : desc ( \" Stop optimizing after < N > optimization passes \" ) ) ; <nl> <nl> - llvm : : cl : : opt < unsigned > SILFunctionPassPipelineLimit ( <nl> - \" sil - pipeline - limit \" , llvm : : cl : : init ( 10 ) , <nl> - llvm : : cl : : desc ( \" \" ) ) ; <nl> + llvm : : cl : : opt < unsigned > SILFunctionPassPipelineLimit ( \" sil - pipeline - limit \" , <nl> + llvm : : cl : : init ( 10 ) , <nl> + llvm : : cl : : desc ( \" \" ) ) ; <nl> <nl> llvm : : cl : : opt < std : : string > <nl> SILPrintOnlyFun ( \" sil - print - only - function \" , llvm : : cl : : init ( \" \" ) , <nl> void SILPassManager : : runFunctionPasses ( PassList FuncTransforms ) { <nl> auto * F = FunctionWorklist . back ( ) ; <nl> <nl> if ( CountOptimized [ F ] > SILFunctionPassPipelineLimit ) { <nl> - DEBUG ( llvm : : dbgs ( ) < < \" * * * Hit limit optimizing : \" < < F - > getName ( ) < < ' \\ n ' ) ; <nl> + DEBUG ( llvm : : dbgs ( ) < < \" * * * Hit limit optimizing : \" < < F - > getName ( ) <nl> + < < ' \\ n ' ) ; <nl> FunctionWorklist . pop_back ( ) ; <nl> continue ; <nl> } <nl>\n", "msg": "Formatting changes on recently added lines .\n"}
{"diff_id": 29670, "repo": "davisking/dlib\n", "sha": "08709e8ec121ec51d8e53513ff37f5c2e0bafea7\n", "time": "2018-10-26T03:23:53Z\n", "diff": "mmm a / dlib / sockets / sockets_kernel_2 . cpp <nl> ppp b / dlib / sockets / sockets_kernel_2 . cpp <nl> <nl> # include < fcntl . h > <nl> # include \" . . / set . h \" <nl> # include < netinet / tcp . h > <nl> + # include < string . h > <nl> <nl> <nl> <nl>\n", "msg": "Add header needed in some contexts\n"}
{"diff_id": 29745, "repo": "apple/swift\n", "sha": "29623177b087419bc3e132cfa454affab614e25f\n", "time": "2014-10-06T18:01:00Z\n", "diff": "mmm a / stdlib / runtime / Casting . cpp <nl> ppp b / stdlib / runtime / Casting . cpp <nl> <nl> # include \" Private . h \" <nl> # include \" stddef . h \" <nl> <nl> + / / FIXME : Clang defines max_align_t in stddef . h since 3 . 6 . <nl> + / / Replace this with max_align_t when we can use it . <nl> + typedef long double swift_max_align_t ; <nl> + <nl> # include < dlfcn . h > <nl> <nl> # include < cstring > <nl> # include < mutex > <nl> # include < sstream > <nl> - # include < type_traits > <nl> - <nl> - / / FIXME : Clang defines max_align_t in stddef . h since 3 . 6 . <nl> - / / Replace this with max_align_t when we can use it . <nl> - typedef long double swift_max_align_t ; <nl> - <nl> - # ifdef __APPLE__ <nl> - static_assert ( std : : is_same < swift_max_align_t , std : : max_align_t > : : value , <nl> - \" types should match exactly on OS X and iOS \" ) ; <nl> - # endif <nl> <nl> using namespace swift ; <nl> using namespace metadataimpl ; <nl>\n", "msg": "Revert \" Runtime : add a static assertion that swift_max_align_t is correct for \"\n"}
{"diff_id": 29776, "msg": "show n / a for mined transactions ( and send to self ) instead of empty field\n", "msgGPT": "added translation support for \"n/a\" in format tx to address method and handled send to self and generated cases in address color method.", "METEOR Score": "35.12468624901762", "BLEU Score": "0.2824892565958521", "ROUGE-L Score": "0.2857142807183674", "score": 1, "repo": "bitcoin/bitcoin\n", "sha": "d8f5c59a594f25d2e03616284068a1034fc5875b\n", "time": "2011-07-31T15:43:46Z\n", "diff": "mmm a / src / qt / transactiontablemodel . cpp <nl> ppp b / src / qt / transactiontablemodel . cpp <nl> QString TransactionTableModel : : formatTxToAddress ( const TransactionRecord * wtx , b <nl> case TransactionRecord : : SendToIP : <nl> return QString : : fromStdString ( wtx - > address ) ; <nl> case TransactionRecord : : SendToSelf : <nl> - return QString ( ) ; <nl> case TransactionRecord : : Generated : <nl> default : <nl> - return QString ( ) ; <nl> + return tr ( \" ( n / a ) \" ) ; <nl> } <nl> } <nl> <nl> QVariant TransactionTableModel : : addressColor ( const TransactionRecord * wtx ) const <nl> if ( label . isEmpty ( ) ) <nl> return COLOR_BAREADDRESS ; <nl> } break ; <nl> + case TransactionRecord : : SendToSelf : <nl> + case TransactionRecord : : Generated : <nl> + return COLOR_BAREADDRESS ; <nl> default : <nl> break ; <nl> } <nl>\n"}
{"diff_id": 29815, "repo": "apple/foundationdb\n", "sha": "d5cc2beb5f6e169f11a91db41c62c527c0091fe1\n", "time": "2019-07-16T17:33:25Z\n", "diff": "mmm a / fdbclient / ReadYourWrites . actor . cpp <nl> ppp b / fdbclient / ReadYourWrites . actor . cpp <nl> void ReadYourWritesTransaction : : updateConflictMap ( KeyRef const & key , WriteMap : : <nl> / / it . skip ( key ) ; <nl> / / ASSERT ( it . beginKey ( ) < = key & & key < it . endKey ( ) ) ; <nl> if ( it . is_unmodified_range ( ) | | ( it . is_operation ( ) & & ! it . is_independent ( ) ) ) { <nl> - approximateSize + = key . expectedSize ( ) + sizeof ( KeyRangeRef ) ; <nl> + approximateSize + = 2 * key . expectedSize ( ) + 1 + sizeof ( KeyRangeRef ) ; <nl> readConflicts . insert ( singleKeyRange ( key , arena ) , true ) ; <nl> } <nl> } <nl>\n", "msg": "Update fdbclient / ReadYourWrites . actor . cpp\n", "score": 1}
{"diff_id": 29948, "repo": "arangodb/arangodb\n", "sha": "d5d23d381f3135eafc05f45970bfd9e6b137ef47\n", "time": "2016-11-02T21:53:25Z\n", "diff": "mmm a / lib / Basics / FileUtils . cpp <nl> ppp b / lib / Basics / FileUtils . cpp <nl> bool copyDirectoryRecursive ( std : : string const & source , <nl> <nl> do { <nl> # else <nl> - struct dirent * d = ( struct dirent * ) TRI_Allocate ( <nl> - TRI_UNKNOWN_MEM_ZONE , ( offsetof ( struct dirent , d_name ) + PATH_MAX + 1 ) , <nl> - false ) ; <nl> - <nl> - if ( d = = nullptr ) { <nl> - error = \" directory \" + source + \" OOM \" ; <nl> - return false ; <nl> - } <nl> - <nl> DIR * filedir = opendir ( source . c_str ( ) ) ; <nl> <nl> if ( filedir = = nullptr ) { <nl> - TRI_Free ( TRI_UNKNOWN_MEM_ZONE , d ) ; <nl> error = \" directory \" + source + \" not found \" ; <nl> return false ; <nl> } <nl> <nl> - struct dirent * oneItem ; <nl> - while ( ( readdir_r ( filedir , d , & oneItem ) = = 0 ) & & ( oneItem ! = nullptr ) ) { <nl> + struct dirent * oneItem = nullptr ; <nl> + <nl> + / / do not use readdir_r ( ) here anymore as it is not safe and deprecated <nl> + / / in newer versions of libc : http : / / man7 . org / linux / man - pages / man3 / readdir_r . 3 . html <nl> + / / the man page recommends to use plain readdir ( ) because it can be expected <nl> + / / to be thread - safe in reality , and newer versions of POSIX may require its <nl> + / / thread - safety formally , and in addition obsolete readdir_r ( ) altogether <nl> + while ( ( oneItem = ( readdir ( filedir ) ) ) ! = nullptr ) { <nl> # endif <nl> / / Now iterate over the items . <nl> / / check its not the pointer to the upper directory : <nl> bool copyDirectoryRecursive ( std : : string const & source , <nl> <nl> # else <nl> } <nl> - TRI_Free ( TRI_UNKNOWN_MEM_ZONE , d ) ; <nl> closedir ( filedir ) ; <nl> <nl> # endif <nl>\n", "msg": "do not use readdir_r ( ) anymore as it is not safe\n"}
{"diff_id": 30122, "repo": "mongodb/mongo\n", "sha": "9dfa96663b9d74cb2de31b4d4f2e755d9992a71f\n", "time": "2008-12-17T21:27:53Z\n", "diff": "mmm a / db / javajs . cpp <nl> ppp b / db / javajs . cpp <nl> using namespace boost : : filesystem ; <nl> <nl> # ifdef J_USE_OBJ <nl> # include \" jsobj . h \" <nl> + # if defined ( _WIN32 ) <nl> + # pragma message ( \" warning : including jsobj . h \" ) <nl> + # else <nl> # warning including jsobj . h <nl> # endif <nl> + # endif <nl> <nl> # include \" . . / grid / message . h \" <nl> # include \" db . h \" <nl>\n", "msg": "Use # pragma message rather than # warning in windows\n"}
{"diff_id": 30141, "repo": "godotengine/godot\n", "sha": "ee37c2f4330e9bd247576b5834cd2660cb520e13\n", "time": "2016-09-03T03:31:39Z\n", "diff": "mmm a / modules / visual_script / visual_script_func_nodes . cpp <nl> ppp b / modules / visual_script / visual_script_func_nodes . cpp <nl> <nl> <nl> int VisualScriptFunctionCall : : get_output_sequence_port_count ( ) const { <nl> <nl> - if ( method_cache . flags & METHOD_FLAG_CONST ) <nl> + if ( method_cache . flags & METHOD_FLAG_CONST | | call_mode = = CALL_MODE_BASIC_TYPE ) <nl> return 0 ; <nl> else <nl> return 1 ; <nl> int VisualScriptFunctionCall : : get_output_sequence_port_count ( ) const { <nl> <nl> bool VisualScriptFunctionCall : : has_input_sequence_port ( ) const { <nl> <nl> - if ( method_cache . flags & METHOD_FLAG_CONST ) <nl> + if ( method_cache . flags & METHOD_FLAG_CONST | | call_mode = = CALL_MODE_BASIC_TYPE ) <nl> return false ; <nl> else <nl> return true ; <nl>\n", "msg": "Made basic call nodes unsequenced , since they are like gdscript and most return const .\n"}
{"diff_id": 30253, "msg": "ESP8266HTTPUpdate - improve error displaying\n", "msgGPT": "refactor esp8266http update handle update and run update functions to print error messages using stream string.", "METEOR Score": "30.529138674882905", "BLEU Score": "0.24768505865600945", "ROUGE-L Score": "0.29999999580000003", "score": 1, "repo": "esp8266/Arduino\n", "sha": "d8e3c766a33041158af3f97499742ee4eb522e0c\n", "time": "2015-12-06T10:07:25Z\n", "diff": "mmm a / libraries / ESP8266httpUpdate / src / ESP8266httpUpdate . cpp <nl> ppp b / libraries / ESP8266httpUpdate / src / ESP8266httpUpdate . cpp <nl> <nl> * / <nl> <nl> # include \" ESP8266httpUpdate . h \" <nl> + # include < StreamString . h > <nl> <nl> extern \" C \" uint32_t _SPIFFS_start ; <nl> extern \" C \" uint32_t _SPIFFS_end ; <nl> t_httpUpdate_return ESP8266HTTPUpdate : : handleUpdate ( HTTPClient * http , const cha <nl> * / <nl> bool ESP8266HTTPUpdate : : runUpdate ( Stream & in , uint32_t size , String md5 , int command ) { <nl> <nl> + StreamString error ; <nl> + <nl> if ( ! Update . begin ( size , command ) ) { <nl> - DEBUG_HTTP_UPDATE ( \" [ httpUpdate ] Update . begin failed ! \\ n \" ) ; <nl> + Update . printError ( error ) ; <nl> + error . trim ( ) ; / / remove line ending <nl> + DEBUG_HTTP_UPDATE ( \" [ httpUpdate ] Update . begin failed ! ( % s ) \\ n \" , error . c_str ( ) ) ; <nl> return false ; <nl> } <nl> <nl> bool ESP8266HTTPUpdate : : runUpdate ( Stream & in , uint32_t size , String md5 , int com <nl> } <nl> <nl> if ( Update . writeStream ( in ) ! = size ) { <nl> - DEBUG_HTTP_UPDATE ( \" [ httpUpdate ] Update . writeStream failed ! \\ n \" ) ; <nl> + Update . printError ( error ) ; <nl> + error . trim ( ) ; / / remove line ending <nl> + DEBUG_HTTP_UPDATE ( \" [ httpUpdate ] Update . writeStream failed ! ( % s ) \\ n \" , error . c_str ( ) ) ; <nl> return false ; <nl> } <nl> <nl> if ( ! Update . end ( ) ) { <nl> - DEBUG_HTTP_UPDATE ( \" [ httpUpdate ] Update . end failed ! \\ n \" ) ; <nl> + Update . printError ( error ) ; <nl> + error . trim ( ) ; / / remove line ending <nl> + DEBUG_HTTP_UPDATE ( \" [ httpUpdate ] Update . end failed ! ( % s ) \\ n \" , error . c_str ( ) ) ; <nl> return false ; <nl> } <nl> <nl>\n"}
{"diff_id": 30329, "msg": "TypeReconstruction : Rename LookupKind : : Crawler to ClangImporter .\n", "msgGPT": "add clang importer as a lookup kind option in the decls lookup source class.", "METEOR Score": "31.821268574244716", "BLEU Score": "0.464741537291072", "ROUGE-L Score": "0.17391303856332718", "score": 1, "repo": "apple/swift\n", "sha": "c93a60041b1e34c05a20d697f26e0e08c57052c9\n", "time": "2018-01-10T01:55:24Z\n", "diff": "mmm a / lib / IDE / TypeReconstruction . cpp <nl> ppp b / lib / IDE / TypeReconstruction . cpp <nl> class DeclsLookupSource { <nl> } <nl> <nl> public : <nl> - enum class LookupKind { SwiftModule , Crawler , Decl , Extension , Invalid } ; <nl> + enum class LookupKind { <nl> + SwiftModule , <nl> + ClangImporter , <nl> + Decl , <nl> + Extension , <nl> + Invalid <nl> + } ; <nl> <nl> typedef Optional < std : : string > PrivateDeclIdentifier ; <nl> <nl> - static DeclsLookupSource GetDeclsLookupSource ( ASTContext & ast , <nl> - ConstString module_name , <nl> - bool allow_crawler = true ) { <nl> + static DeclsLookupSource <nl> + GetDeclsLookupSource ( ASTContext & ast , ConstString module_name , <nl> + bool allow_clang_importer = true ) { <nl> assert ( ! module_name . empty ( ) ) ; <nl> static ConstString g_ObjectiveCModule ( MANGLING_MODULE_OBJC ) ; <nl> static ConstString g_BuiltinModule ( \" Builtin \" ) ; <nl> static ConstString g_CModule ( MANGLING_MODULE_CLANG_IMPORTER ) ; <nl> - if ( allow_crawler ) { <nl> + if ( allow_clang_importer ) { <nl> if ( module_name = = g_ObjectiveCModule | | module_name = = g_CModule ) <nl> return DeclsLookupSource ( & ast , module_name ) ; <nl> } <nl> class DeclsLookupSource { <nl> <nl> void lookupQualified ( DeclBaseName name , NLOptions options , <nl> LazyResolver * typeResolver , ValueDecls & result ) { <nl> - if ( _type = = LookupKind : : Crawler ) { <nl> - ASTContext * ast_ctx = _crawler . _ast ; <nl> + if ( _type = = LookupKind : : ClangImporter ) { <nl> + ASTContext * ast_ctx = _clang_crawler . _ast ; <nl> if ( ast_ctx ) { <nl> VisibleDeclsConsumer consumer ; <nl> ClangImporter * swift_clang_importer = <nl> class DeclsLookupSource { <nl> <nl> void lookupValue ( ModuleDecl : : AccessPathTy path , DeclBaseName name , NLKind kind , <nl> ValueDecls & result ) { <nl> - if ( _type = = LookupKind : : Crawler ) { <nl> - ASTContext * ast_ctx = _crawler . _ast ; <nl> + if ( _type = = LookupKind : : ClangImporter ) { <nl> + ASTContext * ast_ctx = _clang_crawler . _ast ; <nl> if ( ast_ctx ) { <nl> VisibleDeclsConsumer consumer ; <nl> ClangImporter * swift_clang_importer = <nl> class DeclsLookupSource { <nl> return _extension . _module - > lookupLocalType ( key ) ; <nl> case LookupKind : : Invalid : <nl> return nullptr ; <nl> - case LookupKind : : Crawler : <nl> + case LookupKind : : ClangImporter : <nl> return nullptr ; <nl> } <nl> <nl> class DeclsLookupSource { <nl> switch ( _type ) { <nl> case LookupKind : : Invalid : <nl> return ConstString ( \" Invalid \" ) ; <nl> - case LookupKind : : Crawler : <nl> - return ConstString ( \" Crawler \" ) ; <nl> + case LookupKind : : ClangImporter : <nl> + return ConstString ( \" ClangImporter \" ) ; <nl> case LookupKind : : SwiftModule : <nl> return ConstString ( _module - > getName ( ) . get ( ) ) ; <nl> case LookupKind : : Decl : <nl> class DeclsLookupSource { <nl> switch ( _type ) { <nl> case LookupKind : : Invalid : <nl> break ; <nl> - case LookupKind : : Crawler : <nl> - _crawler . _ast = rhs . _crawler . _ast ; <nl> + case LookupKind : : ClangImporter : <nl> + _clang_crawler . _ast = rhs . _clang_crawler . _ast ; <nl> break ; <nl> case LookupKind : : SwiftModule : <nl> _module = rhs . _module ; <nl> class DeclsLookupSource { <nl> switch ( _type ) { <nl> case LookupKind : : Invalid : <nl> break ; <nl> - case LookupKind : : Crawler : <nl> - _crawler . _ast = rhs . _crawler . _ast ; <nl> + case LookupKind : : ClangImporter : <nl> + _clang_crawler . _ast = rhs . _clang_crawler . _ast ; <nl> break ; <nl> case LookupKind : : SwiftModule : <nl> _module = rhs . _module ; <nl> class DeclsLookupSource { <nl> switch ( _type ) { <nl> case LookupKind : : Invalid : <nl> return false ; <nl> - case LookupKind : : Crawler : <nl> - return _crawler . _ast ! = nullptr ; <nl> + case LookupKind : : ClangImporter : <nl> + return _clang_crawler . _ast ! = nullptr ; <nl> case LookupKind : : SwiftModule : <nl> return _module ! = nullptr ; <nl> case LookupKind : : Decl : <nl> class DeclsLookupSource { <nl> ModuleDecl * _module ; <nl> struct { <nl> ASTContext * _ast ; <nl> - } _crawler ; <nl> + } _clang_crawler ; <nl> NominalTypeDecl * _decl ; <nl> struct { <nl> ModuleDecl * _module ; / / extension in this module <nl> class DeclsLookupSource { <nl> / / it is fine for the ASTContext to be null , so don ' t actually even <nl> / / lldbassert there <nl> if ( _a ) { <nl> - _crawler . _ast = _a ; <nl> - _type = LookupKind : : Crawler ; <nl> + _clang_crawler . _ast = _a ; <nl> + _type = LookupKind : : ClangImporter ; <nl> } else <nl> _type = LookupKind : : Invalid ; <nl> } <nl>\n"}
{"diff_id": 30426, "repo": "xbmc/xbmc\n", "sha": "c4fd22dd326af8a82c50d6f7d0df85a6518aa14b\n", "time": "2010-11-22T00:46:36Z\n", "diff": "mmm a / xbmc / lib / libPython / XBPyThread . cpp <nl> ppp b / xbmc / lib / libPython / XBPyThread . cpp <nl> void XBPyThread : : Process ( ) <nl> <nl> / / and add on whatever our default path is <nl> path + = PY_PATH_SEP ; <nl> + <nl> + # if ( defined USE_EXTERNAL_PYTHON ) <nl> + { <nl> + / / we want to use sys . path so it includes site - packages <nl> + / / if this fails , default to using Py_GetPath <nl> + PyObject * sysMod ( PyImport_ImportModule ( \" sys \" ) ) ; / / must call Py_DECREF when finished <nl> + PyObject * sysModDict ( PyModule_GetDict ( sysMod ) ) ; / / borrowed ref , no need to delete <nl> + PyObject * pathObj ( PyDict_GetItemString ( sysModDict , \" path \" ) ) ; / / borrowed ref , no need to delete <nl> + <nl> + if ( pathObj & & PyList_Check ( pathObj ) ) <nl> + { <nl> + for ( int i = 0 ; i < PyList_Size ( pathObj ) ; i + + ) <nl> + { <nl> + PyObject * e = PyList_GetItem ( pathObj , i ) ; / / borrowed ref , no need to delete <nl> + if ( e & & PyString_Check ( e ) ) <nl> + { <nl> + path + = PyString_AsString ( e ) ; / / returns internal data , don ' t delete or modify <nl> + path + = PY_PATH_SEP ; <nl> + } <nl> + } <nl> + } <nl> + else <nl> + { <nl> + path + = Py_GetPath ( ) ; <nl> + } <nl> + Py_DECREF ( sysMod ) ; / / release ref to sysMod <nl> + } <nl> + # else <nl> path + = Py_GetPath ( ) ; <nl> + # endif <nl> <nl> / / set current directory and python ' s path . <nl> if ( m_argv ! = NULL ) <nl>\n", "msg": "changed : allow use of site - packeges when using external python\n", "score": 1}
{"diff_id": 30513, "msg": "SERVER - 40333 Only clone collection options once for each shard in shardsvrShardCollection\n", "msgGPT": "refactor shard collection function to improve readability and performance.", "METEOR Score": "25.901843609452143", "BLEU Score": "0.3207616316881516", "ROUGE-L Score": "0.18181817698347122", "score": 1, "repo": "mongodb/mongo\n", "sha": "8a19243db63197056d6230daa92cf54a847912e4\n", "time": "2019-03-26T21:21:03Z\n", "diff": "mmm a / src / mongo / db / s / shardsvr_shard_collection . cpp <nl> ppp b / src / mongo / db / s / shardsvr_shard_collection . cpp <nl> void shardCollection ( OperationContext * opCtx , <nl> / / want to do this for mapReduce . <nl> if ( ! fromMapReduce ) { <nl> std : : vector < AsyncRequestsSender : : Request > requests ; <nl> + std : : set < ShardId > initializedShards ; <nl> for ( const auto & chunk : initialChunks . chunks ) { <nl> - if ( chunk . getShard ( ) = = dbPrimaryShardId ) <nl> + const auto & chunkShardId = chunk . getShard ( ) ; <nl> + if ( chunkShardId = = dbPrimaryShardId | | <nl> + initializedShards . find ( chunkShardId ) ! = initializedShards . end ( ) ) { <nl> continue ; <nl> + } <nl> + <nl> <nl> CloneCollectionOptionsFromPrimaryShard cloneCollectionOptionsFromPrimaryShardRequest ( <nl> nss ) ; <nl> void shardCollection ( OperationContext * opCtx , <nl> cloneCollectionOptionsFromPrimaryShardRequest . setDbName ( nss . db ( ) ) ; <nl> <nl> requests . emplace_back ( <nl> - chunk . getShard ( ) , <nl> + chunkShardId , <nl> cloneCollectionOptionsFromPrimaryShardRequest . toBSON ( <nl> BSON ( \" writeConcern \" < < ShardingCatalogClient : : kMajorityWriteConcern . toBSON ( ) ) ) ) ; <nl> + <nl> + initializedShards . emplace ( chunkShardId ) ; <nl> } <nl> <nl> if ( ! requests . empty ( ) ) { <nl> void shardCollection ( OperationContext * opCtx , <nl> <nl> forceShardFilteringMetadataRefresh ( opCtx , nss ) ; <nl> <nl> - std : : vector < ShardId > shardsRefreshed ; <nl> + std : : set < ShardId > shardsRefreshed ; <nl> for ( const auto & chunk : initialChunks . chunks ) { <nl> - if ( ( chunk . getShard ( ) = = dbPrimaryShardId ) | | <nl> - std : : find ( shardsRefreshed . begin ( ) , shardsRefreshed . end ( ) , chunk . getShard ( ) ) ! = <nl> - shardsRefreshed . end ( ) ) { <nl> + const auto & chunkShardId = chunk . getShard ( ) ; <nl> + if ( chunkShardId = = dbPrimaryShardId | | <nl> + shardsRefreshed . find ( chunkShardId ) ! = shardsRefreshed . end ( ) ) { <nl> continue ; <nl> } <nl> <nl> - auto shard = uassertStatusOK ( shardRegistry - > getShard ( opCtx , chunk . getShard ( ) ) ) ; <nl> + auto shard = uassertStatusOK ( shardRegistry - > getShard ( opCtx , chunkShardId ) ) ; <nl> auto refreshCmdResponse = uassertStatusOK ( shard - > runCommandWithFixedRetryAttempts ( <nl> opCtx , <nl> ReadPreferenceSetting { ReadPreference : : PrimaryOnly } , <nl> void shardCollection ( OperationContext * opCtx , <nl> Shard : : RetryPolicy : : kIdempotent ) ) ; <nl> <nl> uassertStatusOK ( refreshCmdResponse . commandStatus ) ; <nl> - shardsRefreshed . emplace_back ( chunk . getShard ( ) ) ; <nl> + shardsRefreshed . emplace ( chunkShardId ) ; <nl> } <nl> <nl> ShardingLogging : : get ( opCtx ) - > logChange ( <nl>\n"}
{"diff_id": 30540, "repo": "yuzu-emu/yuzu\n", "sha": "ecbc8137117d6d37b231fc2745b281b6e7077e16\n", "time": "2020-06-25T23:46:50Z\n", "diff": "mmm a / src / input_common / gcadapter / gc_adapter . cpp <nl> ppp b / src / input_common / gcadapter / gc_adapter . cpp <nl> GCPadStatus Adapter : : GetPadStatus ( int port , const std : : array < u8 , 37 > & adapter_pa <nl> } <nl> <nl> void Adapter : : PadToState ( const GCPadStatus & pad , GCState & state ) { <nl> - for ( auto button : PadButtonArray ) { <nl> + for ( auto const & button : PadButtonArray ) { <nl> u16 button_value = static_cast < u16 > ( button ) ; <nl> state . buttons . insert_or_assign ( button_value , pad . button & button_value ) ; <nl> } <nl> bool Adapter : : CheckDeviceAccess ( libusb_device * device ) { <nl> } <nl> <nl> if ( desc . idVendor ! = 0x057e | | desc . idProduct ! = 0x0337 ) { <nl> - / / This isn ’ t the device we are looking for . <nl> + / / This isnÂ ’ t the device we are looking for . <nl> return false ; <nl> } <nl> const int open_error = libusb_open ( device , & usb_adapter_handle ) ; <nl>\n", "msg": "const & to button in button array\n"}
{"diff_id": 30699, "repo": "EOSIO/eos\n", "sha": "d029bfe5b4721ed2789cac994c0cbec309f5942e\n", "time": "2019-10-23T21:38:41Z\n", "diff": "mmm a / plugins / net_plugin / net_plugin . cpp <nl> ppp b / plugins / net_plugin / net_plugin . cpp <nl> namespace eosio { <nl> <nl> block_id_type blk_id = bh . id ( ) ; <nl> if ( my_impl - > dispatcher - > have_block ( blk_id ) ) { <nl> + uint32_t blk_num = bh . block_num ( ) ; <nl> fc_dlog ( logger , \" canceling wait on $ { p } , already received block $ { num } \" , <nl> - ( \" p \" , peer_name ( ) ) ( \" num \" , block_header : : num_from_id ( blk_id ) ) ) ; <nl> - consecutive_rejected_blocks = 0 ; <nl> + ( \" p \" , peer_name ( ) ) ( \" num \" , blk_num ) ) ; <nl> + my_impl - > sync_master - > sync_recv_block ( shared_from_this ( ) , blk_id , blk_num ) ; <nl> cancel_wait ( ) ; <nl> <nl> pending_message_buffer . advance_read_ptr ( message_length ) ; <nl>\n", "msg": "Call sync_recv_block for already received block since accounting of blocks is required\n", "score": 1}
{"diff_id": 30771, "repo": "apple/foundationdb\n", "sha": "17e2630b210eaa1709578e157aa4787ffd533143\n", "time": "2019-08-22T21:21:13Z\n", "diff": "mmm a / fdbserver / worker . actor . cpp <nl> ppp b / fdbserver / worker . actor . cpp <nl> ACTOR Future < Void > fdbd ( <nl> std : : string whitelistBinPaths ) <nl> { <nl> state vector < Future < Void > > v ; <nl> + state Promise < Void > recoveredDiskFiles ; <nl> <nl> try { <nl> ServerCoordinators coordinators ( connFile ) ; <nl> ACTOR Future < Void > fdbd ( <nl> Reference < AsyncVar < Optional < ClusterControllerFullInterface > > > cc ( new AsyncVar < Optional < ClusterControllerFullInterface > > ) ; <nl> Reference < AsyncVar < Optional < ClusterInterface > > > ci ( new AsyncVar < Optional < ClusterInterface > > ) ; <nl> Reference < AsyncVar < ClusterControllerPriorityInfo > > asyncPriorityInfo ( new AsyncVar < ClusterControllerPriorityInfo > ( getCCPriorityInfo ( fitnessFilePath , processClass ) ) ) ; <nl> - state Promise < Void > recoveredDiskFiles ; / / Make this a state to tolerate out of order destruction of \" v \" . <nl> <nl> v . push_back ( reportErrors ( monitorAndWriteCCPriorityInfo ( fitnessFilePath , asyncPriorityInfo ) , \" MonitorAndWriteCCPriorityInfo \" ) ) ; <nl> v . push_back ( reportErrors ( processClass = = ProcessClass : : TesterClass ? monitorLeader ( connFile , cc ) : clusterController ( connFile , cc , asyncPriorityInfo , recoveredDiskFiles . getFuture ( ) , localities ) , \" ClusterController \" ) ) ; <nl>\n", "msg": "Move state variable to the head of the function\n"}
{"diff_id": 30778, "repo": "ClickHouse/ClickHouse\n", "sha": "c61049dc59def52aed0703c9aba38ee9e95fd9f5\n", "time": "2018-05-04T10:58:28Z\n", "diff": "mmm a / dbms / src / Functions / FunctionsMiscellaneous . cpp <nl> ppp b / dbms / src / Functions / FunctionsMiscellaneous . cpp <nl> class FunctionMakeDictionary : public IFunction <nl> const auto & arg = block . getByPosition ( arg_num ) ; <nl> auto & res = block . getByPosition ( result ) ; <nl> auto column = res . type - > createColumn ( ) ; <nl> - column - > insertRangeFrom ( * arg . column , 0 , arg . column - > size ( ) ) ; <nl> + typeid_cast < DataTypeWithDictionary & > ( * column ) . insertRangeFromFullColumn ( * arg . column , 0 , arg . column - > size ( ) ) ; <nl> res . column = std : : move ( column ) ; <nl> } <nl> } ; <nl>\n", "msg": "Fixed ColumnWithDictionsry insert functions . Added insertFromFullColumn and insertRangeFromFullColumn .\n"}
{"diff_id": 30795, "repo": "google/flatbuffers\n", "sha": "ab51b030939e02e55cac6f9e779d8696013819a9\n", "time": "2016-10-12T18:22:20Z\n", "diff": "mmm a / src / idl_parser . cpp <nl> ppp b / src / idl_parser . cpp <nl> CheckedError Parser : : Next ( ) { <nl> cursor_ + + ; <nl> / / TODO : make nested . <nl> while ( * cursor_ ! = ' * ' | | cursor_ [ 1 ] ! = ' / ' ) { <nl> + if ( * cursor_ = = ' \\ n ' ) line_ + + ; <nl> if ( ! * cursor_ ) return Error ( \" end of file in comment \" ) ; <nl> cursor_ + + ; <nl> } <nl>\n", "msg": "Fixed line numbers being off in multi - line comments .\n"}
{"diff_id": 31182, "repo": "xbmc/xbmc\n", "sha": "739cc59fc91cb077ec4bfc552532395f869fe842\n", "time": "2016-09-28T15:33:23Z\n", "diff": "mmm a / xbmc / video / dialogs / GUIDialogVideoInfo . cpp <nl> ppp b / xbmc / video / dialogs / GUIDialogVideoInfo . cpp <nl> void CGUIDialogVideoInfo : : OnGetArt ( ) <nl> { <nl> CFileItemPtr item ( new CFileItem ( \" thumb : / / Current \" , false ) ) ; <nl> item - > SetArt ( \" thumb \" , m_movieItem - > GetArt ( type ) ) ; <nl> + item - > SetIconImage ( \" DefaultPicture . png \" ) ; <nl> item - > SetLabel ( g_localizeStrings . Get ( 13512 ) ) ; <nl> items . Add ( item ) ; <nl> } <nl> void CGUIDialogVideoInfo : : OnGetArt ( ) <nl> { / / add the ' thumb ' type in <nl> CFileItemPtr item ( new CFileItem ( \" thumb : / / Thumb \" , false ) ) ; <nl> item - > SetArt ( \" thumb \" , currentArt [ \" thumb \" ] ) ; <nl> + item - > SetIconImage ( \" DefaultPicture . png \" ) ; <nl> item - > SetLabel ( g_localizeStrings . Get ( 13512 ) ) ; <nl> items . Add ( item ) ; <nl> } <nl> void CGUIDialogVideoInfo : : OnGetArt ( ) <nl> { <nl> CFileItemPtr item ( new CFileItem ( \" thumb : / / Local \" , false ) ) ; <nl> item - > SetArt ( \" thumb \" , localThumb ) ; <nl> + item - > SetIconImage ( \" DefaultPicture . png \" ) ; <nl> item - > SetLabel ( g_localizeStrings . Get ( 13514 ) ) ; <nl> items . Add ( item ) ; <nl> } <nl> void CGUIDialogVideoInfo : : OnGetFanart ( ) <nl> { <nl> CFileItemPtr itemCurrent ( new CFileItem ( \" fanart : / / Current \" , false ) ) ; <nl> itemCurrent - > SetArt ( \" thumb \" , m_movieItem - > GetArt ( \" fanart \" ) ) ; <nl> + itemCurrent - > SetIconImage ( \" DefaultPicture . png \" ) ; <nl> itemCurrent - > SetLabel ( g_localizeStrings . Get ( 20440 ) ) ; <nl> items . Add ( itemCurrent ) ; <nl> } <nl> void CGUIDialogVideoInfo : : OnGetFanart ( ) <nl> { <nl> CFileItemPtr itemLocal ( new CFileItem ( \" fanart : / / Local \" , false ) ) ; <nl> itemLocal - > SetArt ( \" thumb \" , strLocal ) ; <nl> + itemLocal - > SetIconImage ( \" DefaultPicture . png \" ) ; <nl> itemLocal - > SetLabel ( g_localizeStrings . Get ( 20438 ) ) ; <nl> <nl> / / ! @ todo Do we need to clear the cached image ? <nl>\n", "msg": "[ gui ] add some fallback icons for entries in Art selection dialog\n", "score": 1}
{"diff_id": 31203, "repo": "bitcoin/bitcoin\n", "sha": "8585bb8f058441b951b8012de8c0e45207528dec\n", "time": "2017-12-15T09:43:34Z\n", "diff": "mmm a / src / net . cpp <nl> ppp b / src / net . cpp <nl> void CConnman : : SetBanned ( const banmap_t & banMap ) <nl> void CConnman : : SweepBanned ( ) <nl> { <nl> int64_t now = GetTime ( ) ; <nl> - <nl> - LOCK ( cs_setBanned ) ; <nl> - banmap_t : : iterator it = setBanned . begin ( ) ; <nl> - while ( it ! = setBanned . end ( ) ) <nl> + bool notifyUI = false ; <nl> { <nl> - CSubNet subNet = ( * it ) . first ; <nl> - CBanEntry banEntry = ( * it ) . second ; <nl> - if ( now > banEntry . nBanUntil ) <nl> + LOCK ( cs_setBanned ) ; <nl> + banmap_t : : iterator it = setBanned . begin ( ) ; <nl> + while ( it ! = setBanned . end ( ) ) <nl> { <nl> - setBanned . erase ( it + + ) ; <nl> - setBannedIsDirty = true ; <nl> - LogPrint ( BCLog : : NET , \" % s : Removed banned node ip / subnet from banlist . dat : % s \\ n \" , __func__ , subNet . ToString ( ) ) ; <nl> + CSubNet subNet = ( * it ) . first ; <nl> + CBanEntry banEntry = ( * it ) . second ; <nl> + if ( now > banEntry . nBanUntil ) <nl> + { <nl> + setBanned . erase ( it + + ) ; <nl> + setBannedIsDirty = true ; <nl> + notifyUI = true ; <nl> + LogPrint ( BCLog : : NET , \" % s : Removed banned node ip / subnet from banlist . dat : % s \\ n \" , __func__ , subNet . ToString ( ) ) ; <nl> + } <nl> + else <nl> + + + it ; <nl> } <nl> - else <nl> - + + it ; <nl> + } <nl> + / / update UI <nl> + if ( notifyUI & & clientInterface ) { <nl> + clientInterface - > BannedListChanged ( ) ; <nl> } <nl> } <nl> <nl>\n", "msg": "Merge : Update ban - state in case of dirty - state during periodic sweep\n"}
{"diff_id": 31398, "repo": "apple/swift\n", "sha": "ba5de12177329ace7d104d004d88a17c2f799eb8\n", "time": "2016-04-11T09:56:30Z\n", "diff": "mmm a / lib / IDE / CommentConversion . cpp <nl> ppp b / lib / IDE / CommentConversion . cpp <nl> struct CommentToXMLConverter { <nl> # include \" swift / Markup / SimpleFields . def \" <nl> <nl> void printDocument ( const Document * D ) { <nl> - llvm_unreachable ( \" Can ' t print an swift : : markup : : Document as XML directly \" ) ; <nl> + llvm_unreachable ( \" Can ' t print a swift : : markup : : Document as XML directly \" ) ; <nl> } <nl> <nl> void printBlockQuote ( const BlockQuote * BQ ) { <nl> break ; <nl> <nl> void printDocument ( const Document * D ) { <nl> / / FIXME : Why keep doing this ? <nl> - llvm_unreachable ( \" Can ' t print an swift : : markup : : Document as XML directly \" ) ; <nl> + llvm_unreachable ( \" Can ' t print a swift : : markup : : Document as XML directly \" ) ; <nl> } <nl> <nl> void printBlockQuote ( const BlockQuote * BQ ) { <nl>\n", "msg": "[ gardening ] Fix recently introduced typo : \" an swift \" → \" a swift \"\n"}
{"diff_id": 31549, "repo": "apple/swift\n", "sha": "9b6aa30f3e89d750a275cd5572bc31bb34f2ac7d\n", "time": "2019-11-13T23:00:03Z\n", "diff": "mmm a / lib / Sema / TypeCheckProtocol . cpp <nl> ppp b / lib / Sema / TypeCheckProtocol . cpp <nl> static void diagnoseWitnessFixAccessLevel ( DiagnosticEngine & diags , <nl> if ( extAccess < requiredAccess ) { <nl> shouldMoveToAnotherExtension = true ; <nl> } else if ( extAccess = = requiredAccess ) { <nl> - auto declAttr = decl - > getAttrs ( ) . getAttribute < AccessControlAttr > ( ) ; <nl> - assert ( declAttr & & declAttr - > getAccess ( ) < requiredAccess & & <nl> - \" expect an explicitly specified access control level which is \" <nl> - \" less accessible than required . \" ) ; <nl> - ( void ) declAttr ; <nl> + assert ( decl - > getFormalAccess ( ) < requiredAccess & & <nl> + \" witness is accessible ? \" ) ; <nl> shouldUseDefaultAccess = true ; <nl> } <nl> } <nl>\n", "msg": "Relax an assert in witness access diagnostics\n"}
{"diff_id": 31601, "repo": "cocos2d/cocos2d-x\n", "sha": "4601331deee2a3f23e07cd527f023dfe5202a8ca\n", "time": "2015-01-16T01:50:22Z\n", "diff": "mmm a / cocos / scripting / lua - bindings / manual / LuaBasicConversions . cpp <nl> ppp b / cocos / scripting / lua - bindings / manual / LuaBasicConversions . cpp <nl> bool luaval_to_int32 ( lua_State * L , int lo , int * outValue , const char * funcName ) <nl> <nl> if ( ok ) <nl> { <nl> - * outValue = ( int ) ( unsigned int ) lua_tonumber ( L , lo ) ; <nl> + / * * <nl> + When we want to convert the number value from the Lua to int , we would call lua_tonumber to implement . It would <nl> + experience two phase conversion : int - > double , double - > int . But , for the 0x80000000 which the min value of int , the <nl> + int cast may return an undefined result , like 0x7fffffff . So we must use the ( int ) ( unsigned int ) lua_tonumber ( ) to get <nl> + predictable results for 0x80000000 . In this place , we didn ' t use lua_tointeger , because it may produce differen results <nl> + depending on the compiler , e . g : for iPhone4s , it also get wrong value for 0x80000000 . <nl> + * / <nl> + unsigned int estimateValue = ( unsigned int ) lua_tonumber ( L , lo ) ; <nl> + if ( estimateValue = = std : : numeric_limits < int > : : min ( ) ) <nl> + { <nl> + * outValue = ( int ) estimateValue ; <nl> + } <nl> + else <nl> + { <nl> + * outValue = ( int ) lua_tonumber ( L , lo ) ; <nl> + } <nl> } <nl> <nl> return ok ; <nl>\n", "msg": "Update the luaval_to_int32 conversional function to get correct value\n"}
{"diff_id": 31607, "repo": "ClickHouse/ClickHouse\n", "sha": "77fe0b7f0622e716f75d20ec1b4f9a5a5117f2ed\n", "time": "2020-03-27T15:23:11Z\n", "diff": "mmm a / dbms / src / Interpreters / SystemLog . cpp <nl> ppp b / dbms / src / Interpreters / SystemLog . cpp <nl> std : : shared_ptr < TSystemLog > createSystemLog ( <nl> else <nl> { <nl> String partition_by = config . getString ( config_prefix + \" . partition_by \" , \" toYYYYMM ( event_date ) \" ) ; <nl> - engine = \" ENGINE = MergeTree PARTITION BY ( \" + partition_by + \" ) ORDER BY ( event_date , event_time ) SETTINGS index_granularity = 1024 \" ; <nl> + engine = \" ENGINE = MergeTree PARTITION BY ( \" + partition_by + \" ) ORDER BY ( event_date , event_time ) \" <nl> + \" SETTINGS index_granularity = 1024 , min_bytes_for_wide_part = 10485760 \" ; / / / Use polymorphic parts for log tables by default <nl> } <nl> <nl> size_t flush_interval_milliseconds = config . getUInt64 ( config_prefix + \" . flush_interval_milliseconds \" , DEFAULT_SYSTEM_LOG_FLUSH_INTERVAL_MILLISECONDS ) ; <nl>\n", "msg": "turn on polymorphic parts for log tables\n"}
{"diff_id": 31756, "repo": "apple/swift\n", "sha": "b35b8451f41bd8c712f2bbabdfaa20f695963df8\n", "time": "2014-01-23T18:30:54Z\n", "diff": "mmm a / lib / Frontend / CompilerInvocation . cpp <nl> ppp b / lib / Frontend / CompilerInvocation . cpp <nl> static bool ParseFrontendArgs ( FrontendOptions & Opts , ArgList & Args , <nl> return true ; <nl> } <nl> <nl> - if ( Args . hasArg ( OPT_parse_sil ) | | <nl> - ( Opts . InputFilenames . size ( ) = = 1 & & <nl> - llvm : : sys : : path : : extension ( Opts . InputFilenames [ 0 ] ) = = SIL_EXTENSION ) ) <nl> + bool TreatAsSIL = Args . hasArg ( OPT_parse_sil ) ; <nl> + if ( ! TreatAsSIL & & Opts . InputFilenames . size ( ) = = 1 ) { <nl> + / / If we have exactly one input filename , and its extension is \" sil \" , <nl> + / / treat the input as SIL . <nl> + StringRef Input ( Opts . InputFilenames [ 0 ] ) ; <nl> + TreatAsSIL = llvm : : sys : : path : : extension ( Input ) . endswith ( SIL_EXTENSION ) ; <nl> + } <nl> + <nl> + if ( TreatAsSIL ) <nl> Opts . InputKind = SourceFileKind : : SIL ; <nl> else if ( Args . hasArg ( OPT_parse_as_library ) ) <nl> Opts . InputKind = SourceFileKind : : Library ; <nl>\n", "msg": "[ frontend ] Fixed an issue with auto - detecting SIL input .\n"}
{"diff_id": 31772, "repo": "cocos2d/cocos2d-x\n", "sha": "9cefb85bea379a80ef130982dc47087db83656cf\n", "time": "2013-08-05T09:05:42Z\n", "diff": "mmm a / cocos2dx / platform / android / nativeactivity . cpp <nl> ppp b / cocos2dx / platform / android / nativeactivity . cpp <nl> static void cocos_init ( cocos_dimensions d , AAssetManager * assetmanager ) { <nl> <nl> cocos2d : : FileUtilsAndroid : : setassetmanager ( assetmanager ) ; <nl> <nl> - if ( ! cocos2d : : Director : : sharedDirector ( ) - > getOpenGLView ( ) ) <nl> + if ( ! cocos2d : : Director : : getInstance ( ) - > getOpenGLView ( ) ) <nl> { <nl> - cocos2d : : EGLView * view = cocos2d : : EGLView : : sharedOpenGLView ( ) ; <nl> + cocos2d : : EGLView * view = cocos2d : : EGLView : : getInstance ( ) ; <nl> view - > setFrameSize ( d . w , d . h ) ; <nl> <nl> cocos_android_app_init ( ) ; <nl> static void engine_draw_frame ( struct engine * engine ) { <nl> return ; <nl> } <nl> <nl> - cocos2d : : Director : : sharedDirector ( ) - > mainLoop ( ) ; <nl> + cocos2d : : Director : : getInstance ( ) - > mainLoop ( ) ; <nl> LOG_RENDER_DEBUG ( \" engine_draw_frame : just called cocos ' mainLoop ( ) \" ) ; <nl> <nl> / * / / Just fill the screen with a color . * / <nl> static void engine_handle_cmd ( struct android_app * app , int32_t cmd ) { <nl> engine - > accelerometerSensor , ( 1000L / 60 ) * 1000 ) ; <nl> } <nl> <nl> - if ( cocos2d : : Director : : sharedDirector ( ) - > getOpenGLView ( ) ) { <nl> - cocos2d : : Application : : sharedApplication ( ) - > applicationWillEnterForeground ( ) ; <nl> + if ( cocos2d : : Director : : getInstance ( ) - > getOpenGLView ( ) ) { <nl> + cocos2d : : Application : : getInstance ( ) - > applicationWillEnterForeground ( ) ; <nl> } <nl> <nl> break ; <nl> static void engine_handle_cmd ( struct android_app * app , int32_t cmd ) { <nl> engine - > accelerometerSensor ) ; <nl> } <nl> <nl> - cocos2d : : Application : : sharedApplication ( ) - > applicationDidEnterBackground ( ) ; <nl> - cocos2d : : NotificationCenter : : sharedNotificationCenter ( ) - > postNotification ( EVENT_COME_TO_BACKGROUND , NULL ) ; <nl> + cocos2d : : Application : : getInstance ( ) - > applicationDidEnterBackground ( ) ; <nl> + cocos2d : : NotificationCenter : : getInstance ( ) - > postNotification ( EVENT_COME_TO_BACKGROUND , NULL ) ; <nl> <nl> / / Also stop animating . <nl> engine - > animating = 0 ; <nl>\n", "msg": "Use getInstance ( ) instead of various deprecated singleton access methods\n"}
{"diff_id": 31840, "msg": "Added support for thresholding CV_16U images .\n", "msgGPT": "add support for thresholding on 16-bit unsigned integer images.", "METEOR Score": "27.459096605037544", "BLEU Score": "0.5548321507660229", "ROUGE-L Score": "0.5333333285333334", "score": 1, "repo": "opencv/opencv\n", "sha": "ca245e995a4e59e24ae359f0edd1418117838762\n", "time": "2017-09-18T12:34:37Z\n", "diff": "mmm a / modules / imgproc / src / thresh . cpp <nl> ppp b / modules / imgproc / src / thresh . cpp <nl> thresh_8u ( const Mat & _src , Mat & _dst , uchar thresh , uchar maxval , int type ) <nl> } <nl> } <nl> <nl> + static void <nl> + thresh_16u ( const Mat & _src , Mat & _dst , ushort thresh , ushort maxval , int type ) <nl> + { <nl> + Size roi = _src . size ( ) ; <nl> + roi . width * = _src . channels ( ) ; <nl> + size_t src_step = _src . step ; <nl> + size_t dst_step = _dst . step ; <nl> + <nl> + if ( _src . isContinuous ( ) & & _dst . isContinuous ( ) ) <nl> + { <nl> + roi . width * = roi . height ; <nl> + roi . height = 1 ; <nl> + src_step = dst_step = roi . width ; <nl> + } <nl> + <nl> + / / HAVE_TEGRA_OPTIMIZATION not supported <nl> + <nl> + / / HAVE_IPP not supported <nl> + <nl> + int j = 0 ; <nl> + const ushort * src = _src . ptr < ushort > ( ) ; <nl> + ushort * dst = _dst . ptr < ushort > ( ) ; <nl> + <nl> + / / CV_SIMD128 not supported <nl> + # if CV_SIMD128 <nl> + bool useSIMD = checkHardwareSupport ( CV_CPU_SSE2 ) | | checkHardwareSupport ( CV_CPU_NEON ) ; <nl> + if ( useSIMD ) <nl> + { <nl> + int i ; <nl> + v_uint16x8 thresh_u = v_setall_u16 ( thresh ) ; <nl> + v_uint16x8 maxval16 = v_setall_u16 ( maxval ) ; <nl> + <nl> + switch ( type ) <nl> + { <nl> + case THRESH_BINARY : <nl> + for ( i = 0 ; i < roi . height ; i + + , src + = src_step , dst + = dst_step ) <nl> + { <nl> + for ( j = 0 ; j < = roi . width - 16 ; j + = 16 ) <nl> + { <nl> + v_uint16x8 v0 , v1 ; <nl> + v0 = v_load ( src + j ) ; <nl> + v1 = v_load ( src + j + 8 ) ; <nl> + v0 = thresh_u < v0 ; <nl> + v1 = thresh_u < v1 ; <nl> + v0 = v0 & maxval16 ; <nl> + v1 = v1 & maxval16 ; <nl> + v_store ( dst + j , v0 ) ; <nl> + v_store ( dst + j + 8 , v1 ) ; <nl> + } <nl> + } <nl> + break ; <nl> + <nl> + case THRESH_BINARY_INV : <nl> + for ( i = 0 ; i < roi . height ; i + + , src + = src_step , dst + = dst_step ) <nl> + { <nl> + j = 0 ; <nl> + for ( ; j < = roi . width - 16 ; j + = 16 ) <nl> + { <nl> + v_uint16x8 v0 , v1 ; <nl> + v0 = v_load ( src + j ) ; <nl> + v1 = v_load ( src + j + 8 ) ; <nl> + v0 = v0 < = thresh_u ; <nl> + v1 = v1 < = thresh_u ; <nl> + v0 = v0 & maxval16 ; <nl> + v1 = v1 & maxval16 ; <nl> + v_store ( dst + j , v0 ) ; <nl> + v_store ( dst + j + 8 , v1 ) ; <nl> + } <nl> + <nl> + for ( ; j < roi . width ; j + + ) <nl> + dst [ j ] = src [ j ] < = thresh ? maxval : 0 ; <nl> + } <nl> + break ; <nl> + <nl> + case THRESH_TRUNC : <nl> + for ( i = 0 ; i < roi . height ; i + + , src + = src_step , dst + = dst_step ) <nl> + { <nl> + j = 0 ; <nl> + for ( ; j < = roi . width - 16 ; j + = 16 ) <nl> + { <nl> + v_uint16x8 v0 , v1 ; <nl> + v0 = v_load ( src + j ) ; <nl> + v1 = v_load ( src + j + 8 ) ; <nl> + v0 = v_min ( v0 , thresh_u ) ; <nl> + v1 = v_min ( v1 , thresh_u ) ; <nl> + v_store ( dst + j , v0 ) ; <nl> + v_store ( dst + j + 8 , v1 ) ; <nl> + } <nl> + <nl> + for ( ; j < roi . width ; j + + ) <nl> + dst [ j ] = std : : min ( src [ j ] , thresh ) ; <nl> + } <nl> + break ; <nl> + <nl> + case THRESH_TOZERO : <nl> + for ( i = 0 ; i < roi . height ; i + + , src + = src_step , dst + = dst_step ) <nl> + { <nl> + j = 0 ; <nl> + for ( ; j < = roi . width - 16 ; j + = 16 ) <nl> + { <nl> + v_uint16x8 v0 , v1 ; <nl> + v0 = v_load ( src + j ) ; <nl> + v1 = v_load ( src + j + 8 ) ; <nl> + v0 = ( thresh_u < v0 ) & v0 ; <nl> + v1 = ( thresh_u < v1 ) & v1 ; <nl> + v_store ( dst + j , v0 ) ; <nl> + v_store ( dst + j + 8 , v1 ) ; <nl> + } <nl> + <nl> + for ( ; j < roi . width ; j + + ) <nl> + { <nl> + short v = src [ j ] ; <nl> + dst [ j ] = v > thresh ? v : 0 ; <nl> + } <nl> + } <nl> + break ; <nl> + <nl> + case THRESH_TOZERO_INV : <nl> + for ( i = 0 ; i < roi . height ; i + + , src + = src_step , dst + = dst_step ) <nl> + { <nl> + j = 0 ; <nl> + for ( ; j < = roi . width - 16 ; j + = 16 ) <nl> + { <nl> + v_uint16x8 v0 , v1 ; <nl> + v0 = v_load ( src + j ) ; <nl> + v1 = v_load ( src + j + 8 ) ; <nl> + v0 = ( v0 < = thresh_u ) & v0 ; <nl> + v1 = ( v1 < = thresh_u ) & v1 ; <nl> + v_store ( dst + j , v0 ) ; <nl> + v_store ( dst + j + 8 , v1 ) ; <nl> + } <nl> + <nl> + for ( ; j < roi . width ; j + + ) <nl> + { <nl> + short v = src [ j ] ; <nl> + dst [ j ] = v < = thresh ? v : 0 ; <nl> + } <nl> + } <nl> + break ; <nl> + } <nl> + } <nl> + else <nl> + # endif <nl> + { <nl> + int i ; <nl> + switch ( type ) <nl> + { <nl> + case THRESH_BINARY : <nl> + for ( i = 0 ; i < roi . height ; i + + , src + = src_step , dst + = dst_step ) <nl> + { <nl> + for ( j = 0 ; j < roi . width ; j + + ) <nl> + dst [ j ] = src [ j ] > thresh ? maxval : 0 ; <nl> + } <nl> + break ; <nl> + <nl> + case THRESH_BINARY_INV : <nl> + for ( i = 0 ; i < roi . height ; i + + , src + = src_step , dst + = dst_step ) <nl> + { <nl> + for ( j = 0 ; j < roi . width ; j + + ) <nl> + dst [ j ] = src [ j ] < = thresh ? maxval : 0 ; <nl> + } <nl> + break ; <nl> + <nl> + case THRESH_TRUNC : <nl> + for ( i = 0 ; i < roi . height ; i + + , src + = src_step , dst + = dst_step ) <nl> + { <nl> + for ( j = 0 ; j < roi . width ; j + + ) <nl> + dst [ j ] = std : : min ( src [ j ] , thresh ) ; <nl> + } <nl> + break ; <nl> + <nl> + case THRESH_TOZERO : <nl> + for ( i = 0 ; i < roi . height ; i + + , src + = src_step , dst + = dst_step ) <nl> + { <nl> + for ( j = 0 ; j < roi . width ; j + + ) <nl> + { <nl> + short v = src [ j ] ; <nl> + dst [ j ] = v > thresh ? v : 0 ; <nl> + } <nl> + } <nl> + break ; <nl> + <nl> + case THRESH_TOZERO_INV : <nl> + for ( i = 0 ; i < roi . height ; i + + , src + = src_step , dst + = dst_step ) <nl> + { <nl> + for ( j = 0 ; j < roi . width ; j + + ) <nl> + { <nl> + short v = src [ j ] ; <nl> + dst [ j ] = v < = thresh ? v : 0 ; <nl> + } <nl> + } <nl> + break ; <nl> + default : <nl> + CV_Error ( CV_StsBadArg , \" \" ) ; return ; <nl> + } <nl> + } <nl> + } <nl> + <nl> <nl> static void <nl> thresh_16s ( const Mat & _src , Mat & _dst , short thresh , short maxval , int type ) <nl> class ThresholdRunner : public ParallelLoopBody <nl> else if ( srcStripe . depth ( ) = = CV_16S ) <nl> { <nl> thresh_16s ( srcStripe , dstStripe , ( short ) thresh , ( short ) maxval , thresholdType ) ; <nl> + } <nl> + else if ( srcStripe . depth ( ) = = CV_16U ) <nl> + { <nl> + thresh_16u ( srcStripe , dstStripe , ( ushort ) thresh , ( ushort ) maxval , thresholdType ) ; <nl> } <nl> else if ( srcStripe . depth ( ) = = CV_32F ) <nl> { <nl> double cv : : threshold ( InputArray _src , OutputArray _dst , double thresh , double m <nl> thresh = ithresh ; <nl> maxval = imaxval ; <nl> } <nl> + else if ( src . depth ( ) = = CV_16U ) <nl> + { <nl> + int ithresh = cvFloor ( thresh ) ; <nl> + thresh = ithresh ; <nl> + int imaxval = cvRound ( maxval ) ; <nl> + if ( type = = THRESH_TRUNC ) <nl> + imaxval = ithresh ; <nl> + imaxval = saturate_cast < short > ( imaxval ) ; <nl> + <nl> + int ushrt_min = 0 ; <nl> + if ( ithresh < ushrt_min | | ithresh > = USHRT_MAX ) <nl> + { <nl> + if ( type = = THRESH_BINARY | | type = = THRESH_BINARY_INV | | <nl> + ( ( type = = THRESH_TRUNC | | type = = THRESH_TOZERO_INV ) & & ithresh < ushrt_min ) | | <nl> + ( type = = THRESH_TOZERO & & ithresh > = USHRT_MAX ) ) <nl> + { <nl> + int v = type = = THRESH_BINARY ? ( ithresh > = USHRT_MAX ? 0 : imaxval ) : <nl> + type = = THRESH_BINARY_INV ? ( ithresh > = USHRT_MAX ? imaxval : 0 ) : <nl> + / * type = = THRESH_TRUNC ? imaxval : * / 0 ; <nl> + dst . setTo ( v ) ; <nl> + } <nl> + else <nl> + src . copyTo ( dst ) ; <nl> + return thresh ; <nl> + } <nl> + thresh = ithresh ; <nl> + maxval = imaxval ; <nl> + } <nl> else if ( src . depth ( ) = = CV_32F ) <nl> ; <nl> else if ( src . depth ( ) = = CV_64F ) <nl>\n"}
{"diff_id": 31984, "repo": "mongodb/mongo\n", "sha": "0e4f02db8931419e8c648852daedcb02e97291b8\n", "time": "2017-06-12T18:16:39Z\n", "diff": "mmm a / src / mongo / db / repl / rs_rollback . cpp <nl> ppp b / src / mongo / db / repl / rs_rollback . cpp <nl> Status rollback_internal : : updateFixUpInfoFromLocalOplogEntry ( FixUpInfo & fixUpInf <nl> return Status : : OK ( ) ; <nl> <nl> if ( ourObj . objsize ( ) > 512 * 1024 * 1024 ) <nl> - throw RSFatalException ( str : : stream ( ) < < \" Rollback too large , oplog size : \" <nl> - < < ourObj . objsize ( ) ) ; <nl> + throw RSFatalException ( \" rollback too large \" ) ; <nl> <nl> DocID doc ; <nl> doc . ownedObj = ourObj . getOwned ( ) ; <nl> doc . ns = doc . ownedObj . getStringField ( \" ns \" ) ; <nl> if ( * doc . ns = = ' \\ 0 ' ) { <nl> - throw RSFatalException ( str : : stream ( ) < < \" Local op on rollback has no ns : \" <nl> + throw RSFatalException ( str : : stream ( ) < < \" local op on rollback has no ns : \" <nl> < < redact ( doc . ownedObj ) ) ; <nl> } <nl> <nl> BSONObj obj = doc . ownedObj . getObjectField ( * op = = ' u ' ? \" o2 \" : \" o \" ) ; <nl> if ( obj . isEmpty ( ) ) { <nl> - throw RSFatalException ( str : : stream ( ) < < \" Local op on rollback has no object field : \" <nl> + throw RSFatalException ( str : : stream ( ) < < \" local op on rollback has no object field : \" <nl> < < redact ( doc . ownedObj ) ) ; <nl> } <nl> <nl> Status rollback_internal : : updateFixUpInfoFromLocalOplogEntry ( FixUpInfo & fixUpInf <nl> string cmdname = first . fieldName ( ) ; <nl> Command * cmd = Command : : findCommand ( cmdname . c_str ( ) ) ; <nl> if ( cmd = = NULL ) { <nl> - severe ( ) < < \" Rollback no such command \" < < first . fieldName ( ) ; <nl> + severe ( ) < < \" rollback no such command \" < < first . fieldName ( ) ; <nl> return Status ( ErrorCodes : : UnrecoverableRollbackError , <nl> - str : : stream ( ) < < \" Rollback no such command \" < < first . fieldName ( ) , <nl> + str : : stream ( ) < < \" rollback no such command \" < < first . fieldName ( ) , <nl> 18751 ) ; <nl> } <nl> if ( cmdname = = \" create \" ) { <nl> Status rollback_internal : : updateFixUpInfoFromLocalOplogEntry ( FixUpInfo & fixUpInf <nl> } else if ( cmdname = = \" dropIndexes \" | | cmdname = = \" deleteIndexes \" ) { <nl> / / TODO : this is bad . we simply full resync the collection here , <nl> / / which could be very slow . <nl> - warning ( ) < < \" Rollback of dropIndexes is slow in this version of \" <nl> - < < \" mongod . \" ; <nl> + warning ( ) < < \" rollback of dropIndexes is slow in this version of \" <nl> + < < \" mongod \" ; <nl> string ns = nss . db ( ) . toString ( ) + ' . ' + first . valuestr ( ) ; <nl> fixUpInfo . collectionsToResyncData . insert ( ns ) ; <nl> return Status : : OK ( ) ; <nl> } else if ( cmdname = = \" renameCollection \" ) { <nl> / / TODO : slow . <nl> - warning ( ) < < \" Rollback of renameCollection is slow in this version of \" <nl> - < < \" mongod . \" ; <nl> + warning ( ) < < \" rollback of renameCollection is slow in this version of \" <nl> + < < \" mongod \" ; <nl> string from = first . valuestr ( ) ; <nl> string to = obj [ \" to \" ] . String ( ) ; <nl> fixUpInfo . collectionsToResyncData . insert ( from ) ; <nl> fixUpInfo . collectionsToResyncData . insert ( to ) ; <nl> return Status : : OK ( ) ; <nl> } else if ( cmdname = = \" dropDatabase \" ) { <nl> - string message = <nl> - \" Rollback : can ' t rollback drop database full resync will be required . \" ; <nl> - severe ( ) < < message ; <nl> + severe ( ) < < \" rollback : can ' t rollback drop database full resync \" <nl> + < < \" will be required \" ; <nl> log ( ) < < obj . toString ( ) ; <nl> - throw RSFatalException ( message ) ; <nl> + throw RSFatalException ( ) ; <nl> } else if ( cmdname = = \" collMod \" ) { <nl> const auto ns = NamespaceString ( cmd - > parseNs ( nss . db ( ) . toString ( ) , obj ) ) ; <nl> for ( auto field : obj ) { <nl> Status rollback_internal : : updateFixUpInfoFromLocalOplogEntry ( FixUpInfo & fixUpInf <nl> fixUpInfo . collectionsToResyncMetadata . insert ( ns . ns ( ) ) ; <nl> continue ; <nl> } <nl> - string message = \" Cannot rollback a collMod command : \" ; <nl> - severe ( ) < < message < < redact ( obj ) ; <nl> - throw RSFatalException ( message ) ; <nl> + <nl> + severe ( ) < < \" cannot rollback a collMod command : \" < < redact ( obj ) ; <nl> + throw RSFatalException ( ) ; <nl> } <nl> return Status : : OK ( ) ; <nl> } else if ( cmdname = = \" applyOps \" ) { <nl> Status rollback_internal : : updateFixUpInfoFromLocalOplogEntry ( FixUpInfo & fixUpInf <nl> } <nl> return Status : : OK ( ) ; <nl> } else { <nl> - std : : string message = str : : stream ( ) < < \" Can ' t rollback this command yet : \" ; <nl> - severe ( ) < < message < < redact ( obj ) ; <nl> - log ( ) < < \" cmdname = \" < < cmdname ; <nl> - throw RSFatalException ( str : : stream ( ) < < message < < \" cmdname = \" < < cmdname ) ; <nl> + severe ( ) < < \" can ' t rollback this command yet : \" < < redact ( obj ) ; <nl> + log ( ) < < \" cmdname = \" < < cmdname ; <nl> + throw RSFatalException ( ) ; <nl> } <nl> } <nl> <nl> NamespaceString nss ( doc . ns ) ; <nl> if ( nss . isSystemDotIndexes ( ) ) { <nl> if ( * op ! = ' i ' ) { <nl> - std : : string message = str : : stream ( ) < < \" Unexpected operation type ' \" < < * op <nl> - < < \" ' on system . indexes operation , \" <nl> - < < \" document : \" ; <nl> - severe ( ) < < message < < redact ( doc . ownedObj ) ; <nl> - throw RSFatalException ( message ) ; <nl> + severe ( ) < < \" Unexpected operation type ' \" < < * op < < \" ' on system . indexes operation , \" <nl> + < < \" document : \" < < redact ( doc . ownedObj ) ; <nl> + throw RSFatalException ( ) ; <nl> } <nl> string objNs ; <nl> auto status = bsonExtractStringField ( obj , \" ns \" , & objNs ) ; <nl> if ( ! status . isOK ( ) ) { <nl> severe ( ) < < \" Missing collection namespace in system . indexes operation , document : \" <nl> < < redact ( doc . ownedObj ) ; <nl> - throw RSFatalException ( \" Missing collection namespace in system . indexes operation . \" ) ; <nl> + throw RSFatalException ( ) ; <nl> } <nl> NamespaceString objNss ( objNs ) ; <nl> if ( ! objNss . isValid ( ) ) { <nl> severe ( ) < < \" Invalid collection namespace in system . indexes operation , document : \" <nl> < < redact ( doc . ownedObj ) ; <nl> - throw RSFatalException ( <nl> - str : : stream ( ) <nl> - < < \" Invalid collection namespace in system . indexes operation , namespace : \" <nl> - < < doc . ns ) ; <nl> + throw RSFatalException ( ) ; <nl> } <nl> string indexName ; <nl> status = bsonExtractStringField ( obj , \" name \" , & indexName ) ; <nl> if ( ! status . isOK ( ) ) { <nl> severe ( ) < < \" Missing index name in system . indexes operation , document : \" <nl> < < redact ( doc . ownedObj ) ; <nl> - throw RSFatalException ( \" Missing index name in system . indexes operation . \" ) ; <nl> + throw RSFatalException ( ) ; <nl> } <nl> using ValueType = multimap < string , string > : : value_type ; <nl> ValueType pairToInsert = std : : make_pair ( objNs , indexName ) ; <nl> Status rollback_internal : : updateFixUpInfoFromLocalOplogEntry ( FixUpInfo & fixUpInf <nl> <nl> doc . _id = obj [ \" _id \" ] ; <nl> if ( doc . _id . eoo ( ) ) { <nl> - std : : string message = str : : stream ( ) < < \" Cannot rollback op with no _id . ns : \" < < doc . ns ; <nl> - severe ( ) < < message < < \" , document : \" < < redact ( doc . ownedObj ) ; <nl> - throw RSFatalException ( message ) ; <nl> + severe ( ) < < \" cannot rollback op with no _id . ns : \" < < doc . ns <nl> + < < \" , document : \" < < redact ( doc . ownedObj ) ; <nl> + throw RSFatalException ( ) ; <nl> } <nl> <nl> fixUpInfo . docsToRefetch . insert ( doc ) ; <nl> void syncFixUp ( OperationContext * opCtx , <nl> BSONObj good = rollbackSource . findOne ( NamespaceString ( doc . ns ) , doc . _id . wrap ( ) ) ; <nl> totalSize + = good . objsize ( ) ; <nl> if ( totalSize > = 300 * 1024 * 1024 ) { <nl> - throw RSFatalException ( \" replSet too much data to roll back . \" ) ; <nl> + throw RSFatalException ( \" replSet too much data to roll back \" ) ; <nl> } <nl> <nl> / / Note good might be empty , indicating we should delete it . <nl> void syncFixUp ( OperationContext * opCtx , <nl> if ( ex . getCode ( ) = = ErrorCodes : : CommandNotSupportedOnView ) <nl> continue ; <nl> <nl> - log ( ) < < \" Rollback couldn ' t re - get from ns : \" < < doc . ns < < \" _id : \" < < redact ( doc . _id ) <nl> + log ( ) < < \" rollback couldn ' t re - get from ns : \" < < doc . ns < < \" _id : \" < < redact ( doc . _id ) <nl> < < ' ' < < numFetched < < ' / ' < < fixUpInfo . docsToRefetch . size ( ) < < \" : \" <nl> < < redact ( ex ) ; <nl> throw ; <nl> void syncFixUp ( OperationContext * opCtx , <nl> while ( PlanExecutor : : ADVANCED = = ( execState = exec - > getNext ( & curObj , NULL ) ) ) { <nl> auto status = removeSaver . goingToDelete ( curObj ) ; <nl> if ( ! status . isOK ( ) ) { <nl> - severe ( ) < < \" Rolling back createCollection on \" < < * it <nl> - < < \" failed to write document to remove saver file : \" <nl> - < < redact ( status ) ; <nl> - throw RSFatalException ( <nl> - \" Rolling back createCollection . Failed to write document to remove saver \" <nl> - \" file . \" ) ; <nl> + severe ( ) < < \" rolling back createCollection on \" < < * it <nl> + < < \" failed to write document to remove saver file : \" < < status ; <nl> + throw RSFatalException ( ) ; <nl> } <nl> } <nl> if ( execState ! = PlanExecutor : : IS_EOF ) { <nl> if ( execState = = PlanExecutor : : FAILURE & & <nl> WorkingSetCommon : : isValidStatusMemberObject ( curObj ) ) { <nl> Status errorStatus = WorkingSetCommon : : getMemberObjectStatus ( curObj ) ; <nl> - severe ( ) < < \" Rolling back createCollection on \" < < * it < < \" failed with \" <nl> - < < redact ( errorStatus ) < < \" . A full resync is necessary . \" ; <nl> - throw RSFatalException ( <nl> - \" Rolling back createCollection failed . A full resync is necessary . \" ) ; <nl> + severe ( ) < < \" rolling back createCollection on \" < < * it < < \" failed with \" <nl> + < < errorStatus < < \" . A full resync is necessary . \" ; <nl> } else { <nl> - severe ( ) < < \" Rolling back createCollection on \" < < * it <nl> + severe ( ) < < \" rolling back createCollection on \" < < * it <nl> < < \" failed . A full resync is necessary . \" ; <nl> - throw RSFatalException ( <nl> - \" Rolling back createCollection failed . A full resync is necessary . \" ) ; <nl> } <nl> + <nl> + throw RSFatalException ( ) ; <nl> } <nl> <nl> WriteUnitOfWork wunit ( opCtx ) ; <nl> void syncFixUp ( OperationContext * opCtx , <nl> for ( auto it = fixUpInfo . indexesToDrop . begin ( ) ; it ! = fixUpInfo . indexesToDrop . end ( ) ; it + + ) { <nl> const NamespaceString nss ( it - > first ) ; <nl> const string & indexName = it - > second ; <nl> - log ( ) < < \" Rollback drop index : collection : \" < < nss . toString ( ) < < \" . index : \" < < indexName ; <nl> + log ( ) < < \" rollback drop index : collection : \" < < nss . toString ( ) < < \" . index : \" < < indexName ; <nl> <nl> Lock : : DBLock dbLock ( opCtx , nss . db ( ) , MODE_X ) ; <nl> auto db = dbHolder ( ) . get ( opCtx , nss . db ( ) ) ; <nl> void syncFixUp ( OperationContext * opCtx , <nl> auto indexDescriptor = <nl> indexCatalog - > findIndexByName ( opCtx , indexName , includeUnfinishedIndexes ) ; <nl> if ( ! indexDescriptor ) { <nl> - warning ( ) < < \" Rollback failed to drop index \" < < indexName < < \" in \" < < nss . toString ( ) <nl> - < < \" : index not found . \" ; <nl> + warning ( ) < < \" rollback failed to drop index \" < < indexName < < \" in \" < < nss . toString ( ) <nl> + < < \" : index not found \" ; <nl> continue ; <nl> } <nl> WriteUnitOfWork wunit ( opCtx ) ; <nl> auto status = indexCatalog - > dropIndex ( opCtx , indexDescriptor ) ; <nl> if ( ! status . isOK ( ) ) { <nl> - severe ( ) < < \" Rollback failed to drop index \" < < indexName < < \" in \" < < nss . toString ( ) <nl> - < < \" : \" < < redact ( status ) ; <nl> - throw RSFatalException ( str : : stream ( ) < < \" Rollback failed to drop index \" < < indexName <nl> - < < \" in \" <nl> - < < nss . toString ( ) ) ; <nl> + severe ( ) < < \" rollback failed to drop index \" < < indexName < < \" in \" < < nss . toString ( ) <nl> + < < \" : \" < < status ; <nl> + throw RSFatalException ( ) ; <nl> } <nl> wunit . commit ( ) ; <nl> } <nl> void syncFixUp ( OperationContext * opCtx , <nl> if ( now - lastProgressUpdate > progressUpdateGap ) { <nl> log ( ) < < deletes < < \" delete and \" < < updates <nl> < < \" update operations processed out of \" < < goodVersions . size ( ) <nl> - < < \" total operations . \" ; <nl> + < < \" total operations \" ; <nl> lastProgressUpdate = now ; <nl> } <nl> const DocID & doc = idAndDoc . first ; <nl> void syncFixUp ( OperationContext * opCtx , <nl> if ( found ) { <nl> auto status = removeSaver - > goingToDelete ( obj ) ; <nl> if ( ! status . isOK ( ) ) { <nl> - severe ( ) < < \" Rollback cannot write document in namespace \" < < doc . ns <nl> + severe ( ) < < \" rollback cannot write document in namespace \" < < doc . ns <nl> < < \" to archive file : \" < < redact ( status ) ; <nl> - throw RSFatalException ( str : : stream ( ) <nl> - < < \" Rollback cannot write document in namespace \" <nl> - < < doc . ns <nl> - < < \" to archive file . \" ) ; <nl> + throw RSFatalException ( ) ; <nl> } <nl> } else { <nl> - error ( ) < < \" Rollback cannot find object : \" < < pattern < < \" in namespace \" <nl> + error ( ) < < \" rollback cannot find object : \" < < pattern < < \" in namespace \" <nl> < < doc . ns ; <nl> } <nl> } <nl> void syncFixUp ( OperationContext * opCtx , <nl> const auto findOneStart = clock - > now ( ) ; <nl> RecordId loc = Helpers : : findOne ( opCtx , collection , pattern , false ) ; <nl> if ( clock - > now ( ) - findOneStart > Milliseconds ( 200 ) ) <nl> - warning ( ) < < \" Roll back slow no _id index for \" < < doc . ns <nl> + warning ( ) < < \" roll back slow no _id index for \" < < doc . ns <nl> < < \" perhaps ? \" ; <nl> / / would be faster but requires index : <nl> / / RecordId loc = Helpers : : findById ( nsd , pattern ) ; <nl> void syncFixUp ( OperationContext * opCtx , <nl> / / Replicated capped collections have many ways to become <nl> / / inconsistent . We rely on age - out to make these problems go away <nl> / / eventually . <nl> - warning ( ) < < \" Ignoring failure to roll back change to capped \" <nl> + warning ( ) < < \" ignoring failure to roll back change to capped \" <nl> < < \" collection \" < < doc . ns < < \" with _id \" <nl> < < redact ( idAndDoc . first . _id . toString ( <nl> / * includeFieldName * / false ) ) <nl> void syncFixUp ( OperationContext * opCtx , <nl> update ( opCtx , ctx . db ( ) , request ) ; <nl> } <nl> } catch ( const DBException & e ) { <nl> - log ( ) < < \" Exception in rollback ns : \" < < doc . ns < < ' ' < < pattern . toString ( ) < < ' ' <nl> + log ( ) < < \" exception in rollback ns : \" < < doc . ns < < ' ' < < pattern . toString ( ) < < ' ' <nl> < < redact ( e ) < < \" ndeletes : \" < < deletes ; <nl> throw ; <nl> } <nl> void syncFixUp ( OperationContext * opCtx , <nl> <nl> Status status = getGlobalAuthorizationManager ( ) - > initialize ( opCtx ) ; <nl> if ( ! status . isOK ( ) ) { <nl> - severe ( ) < < \" Failed to reinitialize auth data after rollback : \" < < redact ( status ) ; <nl> + severe ( ) < < \" Failed to reinitialize auth data after rollback : \" < < status ; <nl> fassertFailedNoTrace ( 40366 ) ; <nl> } <nl> <nl> Status _syncRollback ( OperationContext * opCtx , <nl> } catch ( const RSFatalException & e ) { <nl> return Status ( ErrorCodes : : UnrecoverableRollbackError , <nl> str : : stream ( ) <nl> - < < \" Need to rollback , but unable to determine common point between \" <nl> + < < \" need to rollback , but unable to determine common point between \" <nl> \" local and remote oplog : \" <nl> < < e . what ( ) , <nl> 18752 ) ; <nl> void rollback ( OperationContext * opCtx , <nl> / / above . <nl> invariant ( ex . getCode ( ) ! = ErrorCodes : : UnrecoverableRollbackError ) ; <nl> <nl> - warning ( ) < < \" Rollback cannot complete at this time ( retrying later ) : \" < < redact ( ex ) <nl> - < < \" appliedThrough = \" < < replCoord - > getMyLastAppliedOpTime ( ) < < \" minvalid = \" <nl> + warning ( ) < < \" rollback cannot complete at this time ( retrying later ) : \" < < redact ( ex ) <nl> + < < \" appliedThrough = \" < < replCoord - > getMyLastAppliedOpTime ( ) < < \" minvalid = \" <nl> < < replicationProcess - > getConsistencyMarkers ( ) - > getMinValid ( opCtx ) ; <nl> <nl> / / Sleep a bit to allow upstream node to coalesce , if that was the cause of the failure . If <nl>\n", "msg": "Revert \" SERVER - 27412 : Updates the error messages for RSFatalExceptions in rs_rollback to be more descriptive \"\n"}
{"diff_id": 32361, "msg": "Add [ [ maybe_unused ] ] for msg parameter in handle_error_code .\n", "msgGPT": "add attribute [[maybe_unused]] to the unused parameter in handle_error_code function to silence compiler warnings.", "METEOR Score": "39.11615565640187", "BLEU Score": "0.4322369379364893", "ROUGE-L Score": "0.36363635880165296", "score": 1, "repo": "ClickHouse/ClickHouse\n", "sha": "3f2f663bfadee3ec89b679a5b10cc34f4f757fa0\n", "time": "2020-12-12T14:43:11Z\n", "diff": "mmm a / src / Common / Exception . cpp <nl> ppp b / src / Common / Exception . cpp <nl> namespace ErrorCodes <nl> <nl> / / / Aborts the process if error code is LOGICAL_ERROR . <nl> / / / Increments error codes statistics . <nl> - void handle_error_code ( const std : : string & msg , int code ) / / NOLINT <nl> + void handle_error_code ( [ [ maybe_unused ] ] const std : : string & msg , int code ) <nl> { <nl> / / In debug builds and builds with sanitizers , treat LOGICAL_ERROR as an assertion failure . <nl> / / Log the message before we fail . <nl>\n"}
{"diff_id": 32405, "repo": "facebook/folly\n", "sha": "800f602cf57b3cdf97cd82b6fcd7ba01b48f686c\n", "time": "2019-09-16T15:30:37Z\n", "diff": "mmm a / folly / json . cpp <nl> ppp b / folly / json . cpp <nl> std : : string toJson ( dynamic const & dyn ) { <nl> std : : string toPrettyJson ( dynamic const & dyn ) { <nl> json : : serialization_opts opts ; <nl> opts . pretty_formatting = true ; <nl> + opts . sort_keys = true ; <nl> return json : : serialize ( dyn , opts ) ; <nl> } <nl> <nl>\n", "msg": "toPrettyJson ( ) sorts keys for deterministic output\n", "score": 1}
{"diff_id": 32461, "repo": "arangodb/arangodb\n", "sha": "69ebf08abed080f384bc6b48ef781821913e00e8\n", "time": "2016-10-10T15:49:01Z\n", "diff": "mmm a / arangod / Aql / TraversalNode . cpp <nl> ppp b / arangod / Aql / TraversalNode . cpp <nl> TraversalNode : : TraversalNode ( ExecutionPlan * plan , size_t id , <nl> _edgeColls . emplace_back ( std : : make_unique < aql : : Collection > ( <nl> n , _vocbase , TRI_TRANSACTION_READ ) ) ; <nl> } else { <nl> + _directions . emplace_back ( dir ) ; <nl> _edgeColls . emplace_back ( std : : make_unique < aql : : Collection > ( <nl> n , _vocbase , TRI_TRANSACTION_READ ) ) ; <nl> - _directions . emplace_back ( dir ) ; <nl> } <nl> } ; <nl> <nl> TraversalNode : : TraversalNode ( ExecutionPlan * plan , size_t id , <nl> names = c - > realNamesForRead ( ) ; <nl> } <nl> for ( auto const & name : names ) { <nl> - addEdgeColl ( name , baseDirection ) ; <nl> + addEdgeColl ( name , dir ) ; <nl> } <nl> } <nl> } else { <nl>\n", "msg": "Fixed creation of SmartCollections with correct directions .\n"}
{"diff_id": 32541, "repo": "xbmc/xbmc\n", "sha": "e0864d158e2f56af0a628b413da67f09f829824a\n", "time": "2017-12-21T16:45:02Z\n", "diff": "mmm a / xbmc / weather / Weather . cpp <nl> ppp b / xbmc / weather / Weather . cpp <nl> std : : string CWeather : : BusyInfo ( int info ) const <nl> <nl> std : : string CWeather : : TranslateInfo ( int info ) const <nl> { <nl> - if ( info = = WEATHER_LABEL_CURRENT_COND ) return m_info . currentConditions ; <nl> - else if ( info = = WEATHER_IMAGE_CURRENT_ICON ) return m_info . currentIcon ; <nl> - else if ( info = = WEATHER_LABEL_CURRENT_TEMP ) return m_info . currentTemperature ; <nl> - else if ( info = = WEATHER_LABEL_CURRENT_FEEL ) return m_info . currentFeelsLike ; <nl> - else if ( info = = WEATHER_LABEL_CURRENT_UVID ) return m_info . currentUVIndex ; <nl> - else if ( info = = WEATHER_LABEL_CURRENT_WIND ) return m_info . currentWind ; <nl> - else if ( info = = WEATHER_LABEL_CURRENT_DEWP ) return m_info . currentDewPoint ; <nl> - else if ( info = = WEATHER_LABEL_CURRENT_HUMI ) return m_info . currentHumidity ; <nl> - else if ( info = = WEATHER_LABEL_LOCATION ) return m_info . location ; <nl> - return \" \" ; <nl> + switch ( info ) { <nl> + case WEATHER_LABEL_CURRENT_COND : <nl> + return m_info . currentConditions ; <nl> + case WEATHER_IMAGE_CURRENT_ICON : <nl> + return m_info . currentIcon ; <nl> + case WEATHER_LABEL_CURRENT_TEMP : <nl> + return m_info . currentTemperature ; <nl> + case WEATHER_LABEL_CURRENT_FEEL : <nl> + return m_info . currentFeelsLike ; <nl> + case WEATHER_LABEL_CURRENT_UVID : <nl> + return m_info . currentUVIndex ; <nl> + case WEATHER_LABEL_CURRENT_WIND : <nl> + return m_info . currentWind ; <nl> + case WEATHER_LABEL_CURRENT_DEWP : <nl> + return m_info . currentDewPoint ; <nl> + case WEATHER_LABEL_CURRENT_HUMI : <nl> + return m_info . currentHumidity ; <nl> + case WEATHER_LABEL_LOCATION : <nl> + return m_info . location ; <nl> + default : <nl> + return \" \" ; <nl> + } <nl> } <nl> <nl> / * ! <nl>\n", "msg": "[ weather ] [ refactor ] use switch case instead of if / else if\n"}
{"diff_id": 32573, "repo": "xbmc/xbmc\n", "sha": "6c5dccf156a2f9075531a6f18cd40afb7a15f074\n", "time": "2012-12-17T09:57:53Z\n", "diff": "mmm a / xbmc / pvr / windows / GUIWindowPVRGuide . cpp <nl> ppp b / xbmc / pvr / windows / GUIWindowPVRGuide . cpp <nl> void CGUIWindowPVRGuide : : ResetObservers ( void ) <nl> <nl> void CGUIWindowPVRGuide : : Notify ( const Observable & obs , const ObservableMessage msg ) <nl> { <nl> - if ( msg = = ObservableMessageEpg | | ObservableMessageEpgContainer ) <nl> + if ( msg = = ObservableMessageEpg | | msg = = ObservableMessageEpgContainer ) <nl> { <nl> m_bUpdateRequired = true ; <nl> <nl>\n", "msg": "[ epg ] fix for wrong if condition in fix d83260197dee56d72e3c2c22602e986aba337c81\n"}
{"diff_id": 32604, "repo": "yuzu-emu/yuzu\n", "sha": "4654f896184fa1b97df5920ef775f033c2b2fcbb\n", "time": "2018-09-26T00:06:21Z\n", "diff": "mmm a / src / core / file_sys / fsmitm_romfsbuild . cpp <nl> ppp b / src / core / file_sys / fsmitm_romfsbuild . cpp <nl> static u32 romfs_calc_path_hash ( u32 parent , std : : string path , u32 start , std : : si <nl> return hash ; <nl> } <nl> <nl> - static u32 romfs_get_hash_table_count ( u32 num_entries ) { <nl> + static u64 romfs_get_hash_table_count ( u64 num_entries ) { <nl> if ( num_entries < 3 ) { <nl> return 3 ; <nl> - } else if ( num_entries < 19 ) { <nl> + } <nl> + <nl> + if ( num_entries < 19 ) { <nl> return num_entries | 1 ; <nl> } <nl> - u32 count = num_entries ; <nl> + <nl> + u64 count = num_entries ; <nl> while ( count % 2 = = 0 | | count % 3 = = 0 | | count % 5 = = 0 | | count % 7 = = 0 | | <nl> count % 11 = = 0 | | count % 13 = = 0 | | count % 17 = = 0 ) { <nl> count + + ; <nl> void RomFSBuildContext : : VisitDirectory ( VirtualDir root_romfs , <nl> const auto child = std : : make_shared < RomFSBuildDirectoryContext > ( ) ; <nl> / / Set child ' s path . <nl> child - > cur_path_ofs = parent - > path_len + 1 ; <nl> - child - > path_len = child - > cur_path_ofs + kv . first . size ( ) ; <nl> + child - > path_len = child - > cur_path_ofs + static_cast < u32 > ( kv . first . size ( ) ) ; <nl> child - > path = parent - > path + \" / \" + kv . first ; <nl> <nl> / / Sanity check on path_len <nl> void RomFSBuildContext : : VisitDirectory ( VirtualDir root_romfs , <nl> const auto child = std : : make_shared < RomFSBuildFileContext > ( ) ; <nl> / / Set child ' s path . <nl> child - > cur_path_ofs = parent - > path_len + 1 ; <nl> - child - > path_len = child - > cur_path_ofs + kv . first . size ( ) ; <nl> + child - > path_len = child - > cur_path_ofs + static_cast < u32 > ( kv . first . size ( ) ) ; <nl> child - > path = parent - > path + \" / \" + kv . first ; <nl> <nl> / / Sanity check on path_len <nl> RomFSBuildContext : : RomFSBuildContext ( VirtualDir base_ ) : base ( std : : move ( base_ ) ) <nl> RomFSBuildContext : : ~ RomFSBuildContext ( ) = default ; <nl> <nl> std : : map < u64 , VirtualFile > RomFSBuildContext : : Build ( ) { <nl> - const auto dir_hash_table_entry_count = romfs_get_hash_table_count ( num_dirs ) ; <nl> - const auto file_hash_table_entry_count = romfs_get_hash_table_count ( num_files ) ; <nl> + const u64 dir_hash_table_entry_count = romfs_get_hash_table_count ( num_dirs ) ; <nl> + const u64 file_hash_table_entry_count = romfs_get_hash_table_count ( num_files ) ; <nl> dir_hash_table_size = 4 * dir_hash_table_entry_count ; <nl> file_hash_table_size = 4 * file_hash_table_entry_count ; <nl> <nl>\n", "msg": "fsmitm_romfsbuild : Avoid type truncation warnings\n"}
{"diff_id": 32693, "repo": "xbmc/xbmc\n", "sha": "e3e99d9385f773c80dae404f94f471715a152dee\n", "time": "2020-09-29T07:50:25Z\n", "diff": "mmm a / xbmc / FileItem . cpp <nl> ppp b / xbmc / FileItem . cpp <nl> void CFileItem : : SetFromVideoInfoTag ( const CVideoInfoTag & video ) <nl> FillInMimeType ( false ) ; <nl> } <nl> <nl> - void CFileItem : : SetFromMusicInfoTag ( const MUSIC_INFO : : CMusicInfoTag & music ) <nl> + namespace <nl> { <nl> - if ( ! music . GetTitle ( ) . empty ( ) ) <nl> - SetLabel ( music . GetTitle ( ) ) ; <nl> - if ( ! music . GetURL ( ) . empty ( ) ) <nl> - m_strPath = music . GetURL ( ) ; <nl> - m_bIsFolder = URIUtils : : HasSlashAtEnd ( m_strPath ) ; <nl> + class CPropertySaveHelper <nl> + { <nl> + public : <nl> + CPropertySaveHelper ( CFileItem & item , const std : : string & property , const std : : string & value ) <nl> + : m_item ( item ) , m_property ( property ) , m_value ( value ) <nl> + { <nl> + } <nl> + <nl> + bool NeedsSave ( ) const { return ! m_value . empty ( ) | | m_item . HasProperty ( m_property ) ; } <nl> <nl> - static const std : : string ORIGINAL_THUMB = \" OriginalThumb \" ; <nl> - const std : : string thumb = music . GetStationArt ( ) ; <nl> - if ( ! thumb . empty ( ) ) <nl> + std : : string GetValueToSave ( const std : : string & currentValue ) const <nl> { <nl> - / / Overwrite whatever thumb we have ; remember what we had originally . <nl> - if ( ! HasProperty ( ORIGINAL_THUMB ) ) <nl> - SetProperty ( ORIGINAL_THUMB , GetArt ( \" thumb \" ) ) ; <nl> + std : : string value ; <nl> <nl> - SetArt ( \" thumb \" , music . GetStationArt ( ) ) ; <nl> + if ( ! m_value . empty ( ) ) <nl> + { <nl> + / / Overwrite whatever we have ; remember what we had originally . <nl> + if ( ! m_item . HasProperty ( m_property ) ) <nl> + m_item . SetProperty ( m_property , currentValue ) ; <nl> + <nl> + value = m_value ; <nl> + } <nl> + else if ( m_item . HasProperty ( m_property ) ) <nl> + { <nl> + / / Restore original value <nl> + value = m_item . GetProperty ( m_property ) . asString ( ) ; <nl> + m_item . ClearProperty ( m_property ) ; <nl> + } <nl> + <nl> + return value ; <nl> + } <nl> + <nl> + private : <nl> + CFileItem & m_item ; <nl> + const std : : string m_property ; <nl> + const std : : string m_value ; <nl> + } ; <nl> + } / / unnamed namespace <nl> + <nl> + void CFileItem : : SetFromMusicInfoTag ( const MUSIC_INFO : : CMusicInfoTag & music ) <nl> + { <nl> + const std : : string path = GetPath ( ) ; <nl> + if ( path . empty ( ) ) <nl> + { <nl> + SetPath ( music . GetURL ( ) ) ; <nl> } <nl> - else if ( HasProperty ( ORIGINAL_THUMB ) ) <nl> + else <nl> { <nl> - / / Restore original thumb <nl> - SetArt ( \" thumb \" , GetProperty ( ORIGINAL_THUMB ) . asString ( ) ) ; <nl> - ClearProperty ( ORIGINAL_THUMB ) ; <nl> + const CPropertySaveHelper dynpath ( * this , \" OriginalDynPath \" , music . GetURL ( ) ) ; <nl> + if ( dynpath . NeedsSave ( ) ) <nl> + SetDynPath ( dynpath . GetValueToSave ( m_strDynPath ) ) ; <nl> } <nl> <nl> + const CPropertySaveHelper label ( * this , \" OriginalLabel \" , music . GetTitle ( ) ) ; <nl> + if ( label . NeedsSave ( ) ) <nl> + SetLabel ( label . GetValueToSave ( GetLabel ( ) ) ) ; <nl> + <nl> + const CPropertySaveHelper thumb ( * this , \" OriginalThumb \" , music . GetStationArt ( ) ) ; <nl> + if ( thumb . NeedsSave ( ) ) <nl> + SetArt ( \" thumb \" , thumb . GetValueToSave ( GetArt ( \" thumb \" ) ) ) ; <nl> + <nl> * GetMusicInfoTag ( ) = music ; <nl> FillInDefaultIcon ( ) ; <nl> FillInMimeType ( false ) ; <nl>\n", "msg": "[ fileitem ] Fix CFileItem : : SetFromMusicInfoTag to backup and restore original item label and dynpath , not only the thumb .\n", "score": 1}
{"diff_id": 32780, "repo": "apple/swift\n", "sha": "c67b5b662682cbedcd7d9be6fef5c877c59eeef8\n", "time": "2017-02-10T15:41:55Z\n", "diff": "mmm a / lib / IRGen / IRGenSIL . cpp <nl> ppp b / lib / IRGen / IRGenSIL . cpp <nl> class IRGenSILFunction : <nl> copy . push_back ( alloca . getAddress ( ) ) ; <nl> } <nl> <nl> + / / / Determine whether a generic variable has been inlined . <nl> + static bool isInlinedGeneric ( VarDecl * VarDecl , const SILDebugScope * DS ) { <nl> + if ( ! DS - > InlinedCallSite ) <nl> + return false ; <nl> + if ( VarDecl - > hasType ( ) ) <nl> + return VarDecl - > getType ( ) - > hasArchetype ( ) ; <nl> + return VarDecl - > getInterfaceType ( ) - > hasTypeParameter ( ) ; <nl> + } <nl> + <nl> / / / Emit debug info for a function argument or a local variable . <nl> template < typename StorageType > <nl> void emitDebugVariableDeclaration ( StorageType Storage , <nl> DebugTypeInfo Ty , <nl> SILType SILTy , <nl> const SILDebugScope * DS , <nl> - ValueDecl * VarDecl , <nl> + VarDecl * VarDecl , <nl> StringRef Name , <nl> unsigned ArgNo = 0 , <nl> IndirectionKind Indirection = DirectValue ) { <nl> / / Force all archetypes referenced by the type to be bound by this point . <nl> / / TODO : just make sure that we have a path to them that the debug info <nl> / / can follow . <nl> + <nl> + / / FIXME : The debug info type of all inlined instances of a variable must be <nl> + / / the same as the type of the abstract variable . <nl> + if ( isInlinedGeneric ( VarDecl , DS ) ) <nl> + return ; <nl> + <nl> auto runtimeTy = getRuntimeReifiedType ( IGM , <nl> Ty . getType ( ) - > getCanonicalType ( ) ) ; <nl> if ( ! IGM . IRGen . Opts . Optimize & & runtimeTy - > hasArchetype ( ) ) <nl> void IRGenSILFunction : : visitAllocBoxInst ( swift : : AllocBoxInst * i ) { <nl> CurSILFn - > getDeclContext ( ) , Decl , <nl> i - > getBoxType ( ) - > getFieldType ( IGM . getSILModule ( ) , 0 ) . getSwiftType ( ) , <nl> type , / * Unwrap = * / false ) ; <nl> + <nl> + if ( isInlinedGeneric ( Decl , i - > getDebugScope ( ) ) ) <nl> + return ; <nl> + <nl> IGM . DebugInfo - > emitVariableDeclaration ( <nl> Builder , <nl> emitShadowCopy ( boxWithAddr . getAddress ( ) , i - > getDebugScope ( ) , Name , 0 ) , <nl>\n", "msg": "Debug info fixes to enable inlining of generics\n"}
{"diff_id": 32882, "msg": "Explicitly show viewport 0 in the SpatialEditorPlugin if the container is large enough .\n", "msgGPT": "fix the loop index in SpatialEditorViewportContainer::_notification() to properly show/hide viewports.", "METEOR Score": "27.604559745628986", "BLEU Score": "0.388983049064541", "ROUGE-L Score": "0.08333332847222251", "score": 1, "repo": "godotengine/godot\n", "sha": "df06087057efb6bd23fd9246ea76a007dbddef6c\n", "time": "2018-09-30T17:09:31Z\n", "diff": "mmm a / editor / plugins / spatial_editor_plugin . cpp <nl> ppp b / editor / plugins / spatial_editor_plugin . cpp <nl> void SpatialEditorViewportContainer : : _notification ( int p_what ) { <nl> <nl> case VIEW_USE_1_VIEWPORT : { <nl> <nl> + viewports [ 0 ] - > show ( ) ; <nl> for ( int i = 1 ; i < 4 ; i + + ) { <nl> <nl> viewports [ i ] - > hide ( ) ; <nl> void SpatialEditorViewportContainer : : _notification ( int p_what ) { <nl> } break ; <nl> case VIEW_USE_2_VIEWPORTS : { <nl> <nl> - for ( int i = 1 ; i < 4 ; i + + ) { <nl> + for ( int i = 0 ; i < 4 ; i + + ) { <nl> <nl> if ( i = = 1 | | i = = 3 ) <nl> viewports [ i ] - > hide ( ) ; <nl> void SpatialEditorViewportContainer : : _notification ( int p_what ) { <nl> } break ; <nl> case VIEW_USE_2_VIEWPORTS_ALT : { <nl> <nl> - for ( int i = 1 ; i < 4 ; i + + ) { <nl> + for ( int i = 0 ; i < 4 ; i + + ) { <nl> <nl> if ( i = = 1 | | i = = 3 ) <nl> viewports [ i ] - > hide ( ) ; <nl> void SpatialEditorViewportContainer : : _notification ( int p_what ) { <nl> } break ; <nl> case VIEW_USE_3_VIEWPORTS : { <nl> <nl> - for ( int i = 1 ; i < 4 ; i + + ) { <nl> + for ( int i = 0 ; i < 4 ; i + + ) { <nl> <nl> if ( i = = 1 ) <nl> viewports [ i ] - > hide ( ) ; <nl> void SpatialEditorViewportContainer : : _notification ( int p_what ) { <nl> } break ; <nl> case VIEW_USE_3_VIEWPORTS_ALT : { <nl> <nl> - for ( int i = 1 ; i < 4 ; i + + ) { <nl> + for ( int i = 0 ; i < 4 ; i + + ) { <nl> <nl> if ( i = = 1 ) <nl> viewports [ i ] - > hide ( ) ; <nl> void SpatialEditorViewportContainer : : _notification ( int p_what ) { <nl> } break ; <nl> case VIEW_USE_4_VIEWPORTS : { <nl> <nl> - for ( int i = 1 ; i < 4 ; i + + ) { <nl> + for ( int i = 0 ; i < 4 ; i + + ) { <nl> <nl> viewports [ i ] - > show ( ) ; <nl> } <nl>\n"}
{"diff_id": 33005, "repo": "apple/foundationdb\n", "sha": "807204e67698db88130052ea5ee2a401f6471dde\n", "time": "2020-02-12T22:57:40Z\n", "diff": "mmm a / fdbclient / MultiVersionTransaction . actor . cpp <nl> ppp b / fdbclient / MultiVersionTransaction . actor . cpp <nl> void DLApi : : init ( ) { <nl> loadClientFunction ( & api - > transactionReset , lib , fdbCPath , \" fdb_transaction_reset \" ) ; <nl> loadClientFunction ( & api - > transactionCancel , lib , fdbCPath , \" fdb_transaction_cancel \" ) ; <nl> loadClientFunction ( & api - > transactionAddConflictRange , lib , fdbCPath , \" fdb_transaction_add_conflict_range \" ) ; <nl> - loadClientFunction ( & api - > transactionGetStorageByteSample , lib , fdbCPath , \" fdb_transaction_get_storage_byte_sample \" ) ; <nl> + loadClientFunction ( & api - > transactionGetStorageByteSample , lib , fdbCPath , \" fdb_transaction_get_storage_byte_sample \" , headerVersion > = 700 ) ; <nl> <nl> loadClientFunction ( & api - > futureGetInt64 , lib , fdbCPath , headerVersion > = 620 ? \" fdb_future_get_int64 \" : \" fdb_future_get_version \" ) ; <nl> loadClientFunction ( & api - > futureGetError , lib , fdbCPath , \" fdb_future_get_error \" ) ; <nl>\n", "msg": "Update fdbclient / MultiVersionTransaction . actor . cpp\n"}
{"diff_id": 33017, "repo": "apple/swift\n", "sha": "4d0dbe6368cb552385ec9e2f7cf72ce830257759\n", "time": "2019-12-06T23:55:58Z\n", "diff": "mmm a / lib / Sema / TypeCheckDeclOverride . cpp <nl> ppp b / lib / Sema / TypeCheckDeclOverride . cpp <nl> SmallVector < OverrideMatch , 2 > OverrideMatcher : : match ( <nl> if ( members . empty ( ) | | name ! = membersName ) { <nl> membersName = name ; <nl> members . clear ( ) ; <nl> + / / FIXME : This suggests we need to use TypeChecker ' s high - level lookup <nl> + / / entrypoints . But first we need one that supports additive qualified <nl> + / / lookup . <nl> + for ( auto * ctx : superContexts ) { <nl> + ctx - > synthesizeSemanticMembersIfNeeded ( membersName ) ; <nl> + } <nl> dc - > lookupQualified ( superContexts , membersName , <nl> NL_QualifiedDefault , members ) ; <nl> } <nl>\n", "msg": "Synthesize semantic members for override matching\n"}
{"diff_id": 33018, "repo": "TheAlgorithms/C-Plus-Plus\n", "sha": "8252816dcc6799c14fb40c6f6bf206013be3add0\n", "time": "2020-06-23T19:07:36Z\n", "diff": "mmm a / data_structures / disjoint_set . cpp <nl> ppp b / data_structures / disjoint_set . cpp <nl> <nl> + / * * <nl> + * <nl> + * \\ file <nl> + * \\ brief [ Disjoint Sets Data Structure <nl> + * ( Disjoint Sets ) ] ( https : / / en . wikipedia . org / wiki / Disjoint - set_data_structure ) <nl> + * <nl> + * \\ author <nl> + * <nl> + * \\ details <nl> + * A disjoint set data structure ( also called union find or merge find set ) <nl> + * is a data structure that tracks a set of elements partitioned into a number <nl> + * of disjoint ( non - overlapping ) subsets . <nl> + * Some situations where disjoint sets can be used are - <nl> + * to find connected components of a graph , kruskal ' s algorithm for finding <nl> + * Minimum Spanning Tree etc . <nl> + * There are two operation which we perform on disjoint sets - <nl> + * 1 ) Union <nl> + * 2 ) Find <nl> + * <nl> + * / <nl> + <nl> # include < iostream > <nl> # include < vector > <nl> <nl> using std : : cout ; <nl> using std : : endl ; <nl> using std : : vector ; <nl> <nl> - vector < int > root , rnk ; <nl> + vector < int > root , rank ; <nl> <nl> + / * * <nl> + * <nl> + * Function to create a set <nl> + * @ param n number of element <nl> + * <nl> + * / <nl> void CreateSet ( int n ) { <nl> root = vector < int > ( n + 1 ) ; <nl> - rnk = vector < int > ( n + 1 , 1 ) ; <nl> + rank = vector < int > ( n + 1 , 1 ) ; <nl> for ( int i = 1 ; i < = n ; + + i ) { <nl> root [ i ] = i ; <nl> } <nl> } <nl> <nl> + / * * <nl> + * <nl> + * Find operation takes a number x and returns the set to which this number <nl> + * belongs to . <nl> + * @ param x element of some set <nl> + * @ return set to which x belongs to <nl> + * <nl> + * / <nl> int Find ( int x ) { <nl> if ( root [ x ] = = x ) { <nl> return x ; <nl> int Find ( int x ) { <nl> return root [ x ] = Find ( root [ x ] ) ; <nl> } <nl> <nl> + / * * <nl> + * <nl> + * A utility function to check if x and y are from same set or not <nl> + * @ param x element of some set <nl> + * @ param y element of some set <nl> + * <nl> + * / <nl> bool InSameUnion ( int x , int y ) { return Find ( x ) = = Find ( y ) ; } <nl> <nl> + / * * <nl> + * <nl> + * Union operation combines two disjoint sets to make a single set <nl> + * in this union function we pass two elements and check if they are <nl> + * from different sets then combine those sets <nl> + * @ param x element of some set <nl> + * @ param y element of some set <nl> + * <nl> + * / <nl> void Union ( int x , int y ) { <nl> int a = Find ( x ) , b = Find ( y ) ; <nl> if ( a ! = b ) { <nl> - if ( rnk [ a ] < rnk [ b ] ) { <nl> + if ( rank [ a ] < rank [ b ] ) { <nl> root [ a ] = b ; <nl> - } else if ( rnk [ a ] > rnk [ b ] ) { <nl> + } else if ( rank [ a ] > rank [ b ] ) { <nl> root [ b ] = a ; <nl> } else { <nl> root [ a ] = b ; <nl> - + + rnk [ b ] ; <nl> + + + rank [ b ] ; <nl> } <nl> } <nl> } <nl> <nl> + / * * Main function * / <nl> int main ( ) { <nl> / / tests CreateSet & Find <nl> int n = 100 ; <nl>\n", "msg": "fixed Code quality and added docs\n"}
{"diff_id": 33295, "repo": "apple/swift\n", "sha": "0752c26287fa30e5125f24558292c0580ec81d2b\n", "time": "2013-12-20T17:11:23Z\n", "diff": "mmm a / lib / Sema / TypeCheckProtocol . cpp <nl> ppp b / lib / Sema / TypeCheckProtocol . cpp <nl> namespace { <nl> TypeVariableType * SelfTypeVar = nullptr ; <nl> <nl> DeclContext * DC ; <nl> + ProtocolDecl * Proto ; <nl> TypeWitnessMap & TypeWitnesses ; <nl> llvm : : DenseMap < TypeVariableType * , AssociatedTypeDecl * > & OpenedAssocTypes ; <nl> <nl> public : <nl> - RequirementTypeOpener ( DeclContext * dc , <nl> - TypeWitnessMap & typeWitnesses , <nl> - llvm : : DenseMap < TypeVariableType * , AssociatedTypeDecl * > <nl> - & openedAssocTypes ) <nl> - : DC ( dc ) , TypeWitnesses ( typeWitnesses ) , OpenedAssocTypes ( openedAssocTypes ) <nl> + RequirementTypeOpener ( <nl> + DeclContext * dc , ProtocolDecl * proto , <nl> + TypeWitnessMap & typeWitnesses , <nl> + llvm : : DenseMap < TypeVariableType * , AssociatedTypeDecl * > <nl> + & openedAssocTypes ) <nl> + : DC ( dc ) , Proto ( proto ) , TypeWitnesses ( typeWitnesses ) , <nl> + OpenedAssocTypes ( openedAssocTypes ) <nl> { <nl> } <nl> <nl> namespace { <nl> auto known = TypeWitnesses . find ( assocType ) ; <nl> if ( known ! = TypeWitnesses . end ( ) ) <nl> replacementType = known - > second . Replacement ; <nl> - else <nl> + else if ( cast < ProtocolDecl > ( assocType - > getDeclContext ( ) ) = = Proto ) <nl> OpenedAssocTypes [ memberTypeVar ] = assocType ; <nl> <nl> / / Let the member type variable float ; we don ' t want to <nl> matchWitness ( TypeChecker & tc , ProtocolDecl * protocol , DeclContext * dc , <nl> / / mapped to their archetypes directly . <nl> llvm : : DenseMap < TypeVariableType * , AssociatedTypeDecl * > openedAssocTypes ; <nl> DeclContext * reqDC = req - > getPotentialGenericDeclContext ( ) ; <nl> - RequirementTypeOpener reqTypeOpener ( reqDC , typeWitnesses , openedAssocTypes ) ; <nl> + RequirementTypeOpener reqTypeOpener ( reqDC , protocol , typeWitnesses , <nl> + openedAssocTypes ) ; <nl> Type reqType , openedFullReqType ; <nl> std : : tie ( openedFullReqType , reqType ) <nl> = cs . getTypeOfMemberReference ( model , req , <nl> checkConformsToProtocol ( TypeChecker & TC , Type T , ProtocolDecl * Proto , <nl> <nl> / / Set any missing type witnesses . <nl> for ( auto typeWitness : TypeWitnesses ) { <nl> - / / FIXME : Hack when we ' ve deduced an associated type we shouldn ' t . <nl> - if ( ! conformance - > hasTypeWitness ( typeWitness . first ) & & <nl> - cast < ProtocolDecl > ( typeWitness . first - > getDeclContext ( ) ) = = Proto ) <nl> + if ( ! conformance - > hasTypeWitness ( typeWitness . first ) ) <nl> conformance - > setTypeWitness ( typeWitness . first , typeWitness . second ) ; <nl> } <nl> <nl>\n", "msg": "Don ' t record opened associated types from the wrong protocol .\n"}
{"diff_id": 33351, "repo": "qbittorrent/qBittorrent\n", "sha": "4ec176b683c6c64f6c0fe00db0db927421c420dd\n", "time": "2013-07-01T09:47:24Z\n", "diff": "mmm a / src / qtlibtorrent / qtorrenthandle . cpp <nl> ppp b / src / qtlibtorrent / qtorrenthandle . cpp <nl> void QTorrentHandle : : prioritize_files ( const vector < int > & files ) const { <nl> file_progress ( progress ) ; <nl> qDebug ( ) < < Q_FUNC_INFO < < \" Changing files priorities . . . \" ; <nl> torrent_handle : : prioritize_files ( files ) ; <nl> - qDebug ( ) < < Q_FUNC_INFO < < \" Moving unwanted files to . unwanted folder . . . \" ; <nl> + qDebug ( ) < < Q_FUNC_INFO < < \" Moving unwanted files to . unwanted folder and conversely . . . \" ; <nl> for ( uint i = 0 ; i < files . size ( ) ; + + i ) { <nl> / / Move unwanted files to a . unwanted subfolder <nl> - if ( files [ i ] = = 0 & & progress [ i ] < filesize_at ( i ) ) { <nl> - QString old_path = filepath_at ( i ) ; <nl> + if ( files [ i ] = = 0 ) { <nl> + QString old_abspath = QDir ( save_path ( ) ) . absoluteFilePath ( filepath_at ( i ) ) ; <nl> + QString parent_abspath = fsutils : : branchPath ( old_abspath ) ; <nl> / / Make sure the file does not already exists <nl> - if ( QFile : : exists ( QDir ( save_path ( ) ) . absoluteFilePath ( old_path ) ) ) { <nl> - qWarning ( ) < < \" File \" < < old_path < < \" already exists at destination . \" ; <nl> - qWarning ( ) < < \" We do not move it to . unwanted folder \" ; <nl> - continue ; <nl> - } <nl> - QString old_name = filename_at ( i ) ; <nl> - QString parent_path = fsutils : : branchPath ( old_path ) ; <nl> - if ( parent_path . isEmpty ( ) | | QDir ( parent_path ) . dirName ( ) ! = \" . unwanted \" ) { <nl> - QString unwanted_abspath = QDir : : cleanPath ( save_path ( ) + \" / \" + parent_path + \" / . unwanted \" ) ; <nl> + if ( QDir ( parent_abspath ) . dirName ( ) ! = \" . unwanted \" ) { <nl> + QString unwanted_abspath = parent_abspath + \" / . unwanted \" ; <nl> + QString new_abspath = unwanted_abspath + \" / \" + filename_at ( i ) ; <nl> qDebug ( ) < < \" Unwanted path is \" < < unwanted_abspath ; <nl> + if ( QFile : : exists ( new_abspath ) ) { <nl> + qWarning ( ) < < \" File \" < < new_abspath < < \" already exists at destination . \" ; <nl> + continue ; <nl> + } <nl> bool created = QDir ( ) . mkpath ( unwanted_abspath ) ; <nl> # ifdef Q_WS_WIN <nl> qDebug ( ) < < \" unwanted folder was created : \" < < created ; <nl> void QTorrentHandle : : prioritize_files ( const vector < int > & files ) const { <nl> # else <nl> Q_UNUSED ( created ) ; <nl> # endif <nl> + QString parent_path = fsutils : : branchPath ( filepath_at ( i ) ) ; <nl> if ( ! parent_path . isEmpty ( ) & & ! parent_path . endsWith ( \" / \" ) ) <nl> parent_path + = \" / \" ; <nl> - rename_file ( i , parent_path + \" . unwanted / \" + old_name ) ; <nl> + rename_file ( i , parent_path + \" . unwanted / \" + filename_at ( i ) ) ; <nl> } <nl> } <nl> / / Move wanted files back to their original folder <nl> - qDebug ( ) < < Q_FUNC_INFO < < \" Moving wanted files back from . unwanted folder \" ; <nl> if ( files [ i ] > 0 ) { <nl> QString parent_relpath = fsutils : : branchPath ( filepath_at ( i ) ) ; <nl> if ( QDir ( parent_relpath ) . dirName ( ) = = \" . unwanted \" ) { <nl>\n", "msg": "Make possible to move file to . unwanted directory after downloading\n", "score": 1}
{"diff_id": 33382, "repo": "xbmc/xbmc\n", "sha": "9db289036012695934df1bcbc71704ac1919fc37\n", "time": "2010-11-13T14:06:13Z\n", "diff": "mmm a / xbmc / Application . cpp <nl> ppp b / xbmc / Application . cpp <nl> bool CApplication : : Initialize ( ) <nl> <nl> / / Init DPMS , before creating the corresponding setting control . <nl> m_dpms = new DPMSSupport ( ) ; <nl> - g_guiSettings . GetSetting ( \" powermanagement . displaysoff \" ) - > SetVisible ( <nl> - m_dpms - > IsSupported ( ) ) ; <nl> + g_guiSettings . GetSetting ( \" powermanagement . displaysoff \" ) - > SetVisible ( m_dpms - > IsSupported ( ) ) ; <nl> <nl> g_windowManager . Add ( new CGUIWindowHome ) ; / / window id = 0 <nl> g_windowManager . Add ( new CGUIWindowPrograms ) ; / / window id = 1 <nl> bool CApplication : : Initialize ( ) <nl> / * window id ' s 3000 - 3100 are reserved for python * / <nl> <nl> / / Make sure we have at least the default skin <nl> - if ( ! LoadSkin ( g_guiSettings . GetString ( \" lookandfeel . skin \" ) ) ) <nl> + if ( ! LoadSkin ( g_guiSettings . GetString ( \" lookandfeel . skin \" ) ) & & ! LoadSkin ( DEFAULT_SKIN ) ) <nl> { <nl> - if ( ! LoadSkin ( DEFAULT_SKIN ) ) <nl> - { <nl> CLog : : Log ( LOGERROR , \" Default skin ' % s ' not found ! Terminating . . \" , DEFAULT_SKIN ) ; <nl> FatalErrorHandler ( true , true , true ) ; <nl> - } <nl> } <nl> <nl> SAFE_DELETE ( m_splash ) ; <nl> bool CApplication : : Initialize ( ) <nl> <nl> / / check if we should use the login screen <nl> if ( g_settings . UsingLoginScreen ( ) ) <nl> - { <nl> g_windowManager . ActivateWindow ( WINDOW_LOGIN_SCREEN ) ; <nl> - } <nl> else <nl> - { <nl> g_windowManager . ActivateWindow ( g_SkinInfo - > GetFirstWindow ( ) ) ; <nl> - } <nl> <nl> g_sysinfo . Refresh ( ) ; <nl> <nl>\n", "msg": "cosmetics : clean up application . cpp\n"}
{"diff_id": 33663, "repo": "facebook/folly\n", "sha": "c16a3f3775fa166503b4a07150a709c6787c1471\n", "time": "2017-03-24T22:05:11Z\n", "diff": "mmm a / folly / io / async / Request . cpp <nl> ppp b / folly / io / async / Request . cpp <nl> bool RequestContext : : hasContextData ( const std : : string & val ) const { <nl> } <nl> <nl> RequestData * RequestContext : : getContextData ( const std : : string & val ) { <nl> - return get_ref_default ( * data_ . rlock ( ) , val , nullptr ) . get ( ) ; <nl> + const std : : unique_ptr < RequestData > dflt { nullptr } ; <nl> + return get_ref_default ( * data_ . rlock ( ) , val , dflt ) . get ( ) ; <nl> } <nl> <nl> const RequestData * RequestContext : : getContextData ( <nl> const std : : string & val ) const { <nl> - return get_ref_default ( * data_ . rlock ( ) , val , nullptr ) . get ( ) ; <nl> + const std : : unique_ptr < RequestData > dflt { nullptr } ; <nl> + return get_ref_default ( * data_ . rlock ( ) , val , dflt ) . get ( ) ; <nl> } <nl> <nl> void RequestContext : : onSet ( ) { <nl>\n", "msg": "Avoid passing temporary to get_ref_default ( )\n"}
{"diff_id": 33718, "repo": "EOSIO/eos\n", "sha": "5abc5fd3e68a612b05a7e7de77f5eef8dd9b1842\n", "time": "2019-01-12T11:58:05Z\n", "diff": "mmm a / programs / cleos / main . cpp <nl> ppp b / programs / cleos / main . cpp <nl> chain : : action create_newaccount ( const name & creator , const name & newaccount , aut <nl> eosio : : chain : : newaccount { <nl> . creator = creator , <nl> . name = newaccount , <nl> - . owner = ! owner . which ( ) ? authority ( owner . get < public_key_type > ( ) ) : authority ( owner . get < permission_level > ( ) ) , <nl> - . active = ! active . which ( ) ? authority ( active . get < public_key_type > ( ) ) : authority ( active . get < permission_level > ( ) ) <nl> + . owner = owner . contains < public_key_type > ( ) ? authority ( owner . get < public_key_type > ( ) ) : authority ( owner . get < permission_level > ( ) ) , <nl> + . active = active . contains < public_key_type > ( ) ? authority ( active . get < public_key_type > ( ) ) : authority ( active . get < permission_level > ( ) ) <nl> } <nl> } ; <nl> } <nl>\n", "msg": "Check the type of given authority explicitly during account creation\n", "score": 1}
{"diff_id": 33952, "repo": "yuzu-emu/yuzu\n", "sha": "24bd068a0882d3956b10edbbf43888b5cbfadee5\n", "time": "2020-08-03T13:31:51Z\n", "diff": "mmm a / src / core / hle / service / nvflinger / buffer_queue . cpp <nl> ppp b / src / core / hle / service / nvflinger / buffer_queue . cpp <nl> BufferQueue : : ~ BufferQueue ( ) = default ; <nl> void BufferQueue : : SetPreallocatedBuffer ( u32 slot , const IGBPBuffer & igbp_buffer ) { <nl> LOG_WARNING ( Service , \" Adding graphics buffer { } \" , slot ) ; <nl> <nl> - Buffer buffer { } ; <nl> - buffer . slot = slot ; <nl> - buffer . igbp_buffer = igbp_buffer ; <nl> - buffer . status = Buffer : : Status : : Free ; <nl> free_buffers . push_back ( slot ) ; <nl> + queue . push_back ( { <nl> + . slot = slot , <nl> + . status = Buffer : : Status : : Free , <nl> + . igbp_buffer = igbp_buffer , <nl> + } ) ; <nl> <nl> - queue . emplace_back ( buffer ) ; <nl> buffer_wait_event . writable - > Signal ( ) ; <nl> } <nl> <nl>\n", "msg": "buffer_queue : Make use of designated initializers\n"}
{"diff_id": 33995, "repo": "facebook/hhvm\n", "sha": "1119b332e99f465527192ddaee940e799418443f\n", "time": "2016-03-17T17:30:42Z\n", "diff": "mmm a / hphp / runtime / vm / jit / vasm - xls . cpp <nl> ppp b / hphp / runtime / vm / jit / vasm - xls . cpp <nl> void renameOperands ( Vunit & unit , const VxlsContext & ctx , <nl> ) ; <nl> } <nl> <nl> + / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / <nl> + / / Flags liveness optimization . <nl> + <nl> + template < typename Inst , typename F > <nl> + void optimize ( Vunit & unit , Inst & inst , Vlabel b , size_t i , F sf_live ) { } <nl> + <nl> + template < typename xor_op , typename ldimm_op , typename F > <nl> + void optimize_ldimm ( Vunit & unit , ldimm_op & ldimm , <nl> + Vlabel b , size_t i , F sf_live ) { <nl> + if ( ! sf_live ( ) & & ldimm . s . q ( ) = = 0 & & ldimm . d . isGP ( ) ) { <nl> + decltype ( xor_op : : d ) d = ldimm . d ; <nl> + unit . blocks [ b ] . code [ i ] = xor_op { d , d , d , RegSF { 0 } } ; <nl> + } <nl> + } <nl> + <nl> + template < typename F > <nl> + void optimize ( Vunit & unit , ldimmb & inst , Vlabel b , size_t i , F sf_live ) { <nl> + optimize_ldimm < xorb > ( unit , inst , b , i , sf_live ) ; <nl> + } <nl> + template < typename F > <nl> + void optimize ( Vunit & unit , ldimml & inst , Vlabel b , size_t i , F sf_live ) { <nl> + optimize_ldimm < xorl > ( unit , inst , b , i , sf_live ) ; <nl> + } <nl> + template < typename F > <nl> + void optimize ( Vunit & unit , ldimmq & inst , Vlabel b , size_t i , F sf_live ) { <nl> + optimize_ldimm < xorq > ( unit , inst , b , i , sf_live ) ; <nl> + } <nl> + <nl> + template < typename F > <nl> + void optimize ( Vunit & unit , lea & inst , Vlabel b , size_t i , F sf_live ) { <nl> + if ( ! sf_live ( ) & & inst . d = = rsp ( ) ) { <nl> + assertx ( inst . s . base = = inst . d & & ! inst . s . index . isValid ( ) ) ; <nl> + unit . blocks [ b ] . code [ i ] = addqi { inst . s . disp , inst . d , inst . d , RegSF { 0 } } ; <nl> + } <nl> + } <nl> + <nl> + / * <nl> + * Perform optimizations on instructions in ` unit ' at which no flags registers <nl> + * are live . <nl> + * / <nl> + void optimizeSFLiveness ( Vunit & unit , const VxlsContext & ctx , <nl> + const jit : : vector < Variable * > & variables ) { <nl> + / / Currently , all our optimizations are only relevant on x64 . <nl> + if ( arch ( ) ! = Arch : : X64 ) return ; <nl> + <nl> + / / sf_var is the physical SF register , computed from the union of VregSF <nl> + / / registers by computeLiveness ( ) and buildIntervals ( ) . <nl> + auto const sf_var = variables [ VregSF ( RegSF { 0 } ) ] ; <nl> + auto const sf_ivl = sf_var ? sf_var - > ivl ( ) : nullptr ; <nl> + <nl> + for ( auto const b : ctx . blocks ) { <nl> + auto & code = unit . blocks [ b ] . code ; <nl> + <nl> + for ( size_t i = 0 ; i < code . size ( ) ; + + i ) { <nl> + auto & inst = code [ i ] ; <nl> + <nl> + auto const sf_live = [ & ] { <nl> + return sf_ivl & & <nl> + ! sf_ivl - > ranges . empty ( ) & & <nl> + sf_ivl - > covers ( inst . pos ) ; <nl> + } ; <nl> + <nl> + switch ( inst . op ) { <nl> + # define O ( name , . . . ) \\ <nl> + case Vinstr : : name : \\ <nl> + optimize ( unit , inst . name # # _ , b , i , sf_live ) ; \\ <nl> + break ; <nl> + <nl> + VASM_OPCODES <nl> + # undef O <nl> + } <nl> + } <nl> + } <nl> + } <nl> + <nl> / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / <nl> / / Copy insertion . <nl> <nl> void insertCopiesAt ( const VxlsContext & ctx , <nl> insertCodeAt ( code , j , copies , pos ) ; <nl> } <nl> <nl> - / * <nl> - * Get the appropriate Vinstr for a constant load of a particular constraint . <nl> - * / <nl> - template < class VregT , class ldimm_op , class xor_op , class int_t > <nl> - Vinstr ldcns ( const Interval * ivl , PhysReg dst , bool sf_live ) { <nl> - auto const use_xor = ( ivl - > var - > val . val = = 0 & & dst . isGP ( ) & & ! sf_live ) ; <nl> - if ( use_xor ) { <nl> - VregT d = dst ; <nl> - return xor_op { d , d , d , RegSF { 0 } } ; <nl> - } else { <nl> - return ldimm_op { int_t ( ivl - > var - > val . val ) , dst } ; <nl> - } <nl> - } <nl> - <nl> / * <nl> * Insert constant loads or loads from spill spacemmmwith spill space starting <nl> * at ` slots ' mmmfor ` loads ' into ` code ' before code [ j ] , corresponding to XLS <nl> Vinstr ldcns ( const Interval * ivl , PhysReg dst , bool sf_live ) { <nl> * Updates ` j ' to refer to the same instruction after the code insertions . <nl> * / <nl> void insertLoadsAt ( jit : : vector < Vinstr > & code , unsigned & j , <nl> - const CopyPlan & plan , MemoryRef slots , <nl> - unsigned pos , const Interval * sf_ivl ) { <nl> + const CopyPlan & plan , MemoryRef slots , unsigned pos ) { <nl> jit : : vector < Vinstr > loads ; <nl> <nl> - auto const sf_live = sf_ivl & & <nl> - ! sf_ivl - > ranges . empty ( ) & & <nl> - sf_ivl - > covers ( pos ) ; <nl> - <nl> for_each_load ( plan , [ & ] ( PhysReg dst , const Interval * ivl ) { <nl> if ( ivl - > constant ( ) ) { <nl> if ( ivl - > var - > val . isUndef ) return ; <nl> void insertLoadsAt ( jit : : vector < Vinstr > & code , unsigned & j , <nl> switch ( ivl - > var - > val . kind ) { <nl> case Vconst : : Quad : <nl> case Vconst : : Double : <nl> - return ldcns < Vreg64 , ldimmq , xorq , uint64_t > ( ivl , dst , sf_live ) ; <nl> + return ldimmq { uint64_t ( ivl - > var - > val . val ) , dst } ; <nl> case Vconst : : Long : <nl> - return ldcns < Vreg32 , ldimml , xorl , int32_t > ( ivl , dst , sf_live ) ; <nl> + return ldimml { int32_t ( ivl - > var - > val . val ) , dst } ; <nl> case Vconst : : Byte : <nl> - return ldcns < Vreg8 , ldimmb , xorb , uint8_t > ( ivl , dst , sf_live ) ; <nl> + return ldimmb { uint8_t ( ivl - > var - > val . val ) , dst } ; <nl> } <nl> not_reached ( ) ; <nl> } ( ) ) ; <nl> void insertLoadsAt ( jit : : vector < Vinstr > & code , unsigned & j , <nl> void insertCopies ( Vunit & unit , const VxlsContext & ctx , <nl> const jit : : vector < Variable * > & variables , <nl> const ResolutionPlan & resolution ) { <nl> - / / sf_ivl is the physical SF register , computed from the union of VregSF <nl> - / / registers by computeLiveness ( ) and buildIntervals ( ) . Its safe to lower <nl> - / / ldimm { 0 , r } to xor { r , r , r } when SF is not live . <nl> - auto const sf_var = variables [ VregSF ( RegSF { 0 } ) ] ; <nl> - auto const sf_ivl = sf_var ? sf_var - > ivl ( ) : nullptr ; <nl> - <nl> - / / insert copies inside blocks <nl> + / / Insert copies inside blocks . <nl> for ( auto const b : ctx . blocks ) { <nl> auto & block = unit . blocks [ b ] ; <nl> auto & code = block . code ; <nl> void insertCopies ( Vunit & unit , const VxlsContext & ctx , <nl> auto c = resolution . copies . find ( pos - 1 ) ; <nl> if ( c ! = resolution . copies . end ( ) ) { <nl> insertCopiesAt ( ctx , code , j , c - > second , pos - 1 ) ; <nl> - insertLoadsAt ( code , j , c - > second , slots , pos - 1 , sf_ivl ) ; <nl> + insertLoadsAt ( code , j , c - > second , slots , pos - 1 ) ; <nl> } <nl> <nl> / / Insert copies and loads at instructions . <nl> c = resolution . copies . find ( pos ) ; <nl> if ( c ! = resolution . copies . end ( ) ) { <nl> insertCopiesAt ( ctx , code , j , c - > second , pos ) ; <nl> - insertLoadsAt ( code , j , c - > second , slots , pos , sf_ivl ) ; <nl> + insertLoadsAt ( code , j , c - > second , slots , pos ) ; <nl> } <nl> assertx ( resolution . spills . count ( pos ) = = 0 ) ; <nl> <nl> void insertCopies ( Vunit & unit , const VxlsContext & ctx , <nl> / / We interleave copies and loads in ` edge_copies ' , so here and below <nl> / / we process them separately ( and pass ` true ' to avoid asserting ) . <nl> insertCopiesAt ( ctx , code , j , c - > second , pos ) ; <nl> - insertLoadsAt ( code , j , c - > second , slots , pos , sf_ivl ) ; <nl> + insertLoadsAt ( code , j , c - > second , slots , pos ) ; <nl> } <nl> } else { <nl> / / copies will go at start of successor <nl> void insertCopies ( Vunit & unit , const VxlsContext & ctx , <nl> auto const slots = ctx . sp [ ctx . spill_offsets [ s ] ] ; <nl> <nl> insertCopiesAt ( ctx , code , j , c - > second , pos ) ; <nl> - insertLoadsAt ( code , j , c - > second , slots , pos , sf_ivl ) ; <nl> + insertLoadsAt ( code , j , c - > second , slots , pos ) ; <nl> } <nl> } <nl> } <nl> void allocateRegisters ( Vunit & unit , const Abi & abi ) { <nl> printVariables ( \" after inserting copies \" , unit , ctx , variables ) ; <nl> ) ; <nl> <nl> - / / Perform some cleanup , then insert instructions for creating spill space . <nl> + / / Perform optimizations based on flags liveness , then do some cleanup . <nl> + optimizeSFLiveness ( unit , ctx , variables ) ; <nl> peephole ( unit , ctx ) ; <nl> + <nl> + / / Insert instructions for creating spill space . <nl> allocateSpillSpace ( unit , ctx , spill_info ) ; <nl> <nl> printUnit ( kVasmRegAllocLevel , \" after vasm - xls \" , unit ) ; <nl>\n", "msg": "Add a lea { } - > addi { } SF liveness opt in vasm - xls\n"}
{"diff_id": 34028, "repo": "facebook/hhvm\n", "sha": "a325ad063f949bb3ba7bbdbd43ea0dba165e8466\n", "time": "2019-02-07T03:13:53Z\n", "diff": "mmm a / hphp / runtime / vm / jit / vasm - graph - color . cpp <nl> ppp b / hphp / runtime / vm / jit / vasm - graph - color . cpp <nl> <nl> <nl> # include \" hphp / ppc64 - asm / asm - ppc64 . h \" <nl> <nl> + # include \" hphp / util / copy - ptr . h \" <nl> # include \" hphp / util / dataflow - worklist . h \" <nl> + # include \" hphp / util / match . h \" <nl> <nl> # include < boost / range / adaptor / reversed . hpp > <nl> <nl> enum RegClass { <nl> SpillWide / / 128 - bit spill slot <nl> } ; <nl> <nl> + / / Color is a discriminated union representing an unassigned color , a spill <nl> + / / slot , or a physical register . Which subset is valid depends on the Vreg ' s <nl> + / / RegClass . <nl> + struct None { } ; <nl> + struct SpillSlot { size_t slot ; } ; <nl> + struct SpillSlotWide { size_t slot ; } ; <nl> + using Color = boost : : variant < None , PhysReg , SpillSlot , SpillSlotWide > ; <nl> + <nl> / / State about each Vreg . Instead of separate data - structures , all Vreg <nl> / / information is concentrated in this one data - structure . <nl> struct RegInfo { <nl> struct RegInfo { <nl> / / ensure that this Vreg will be assigned the same physical register at all <nl> / / uses and defs ( except copies ) . <nl> PhysReg precolor = InvalidReg ; <nl> + / / Color assigned to this Vreg <nl> + Color color ; <nl> / / Can this Vreg be potentially rematerialized ( instead of reloaded ) by this <nl> / / instruction ? <nl> folly : : Optional < Vinstr > remat ; <nl> std : : string show ( RegClass r ) { <nl> always_assert ( false ) ; <nl> } <nl> <nl> + std : : string show ( Color c ) { <nl> + return match < std : : string > ( <nl> + c , <nl> + [ ] ( None ) { return \" - \" ; } , <nl> + [ ] ( PhysReg r ) { return show ( r ) ; } , <nl> + [ ] ( SpillSlot s ) { return folly : : sformat ( \" S { } \" , s . slot ) ; } , <nl> + [ ] ( SpillSlotWide s ) { return folly : : sformat ( \" SW { } \" , s . slot ) ; } <nl> + ) ; <nl> + } <nl> + <nl> std : : string show ( const BlockVector & v ) { <nl> using namespace folly : : gen ; <nl> return folly : : sformat ( <nl> std : : string show ( const PhiWeightVector & v ) { <nl> } <nl> <nl> std : : string show ( const Vunit & unit , const RegInfo & info ) { <nl> + auto const color = [ & ] { <nl> + if ( info . precolor ! = InvalidReg ) { <nl> + return folly : : sformat ( \" { } ( { } ) \" , show ( info . color ) , show ( info . precolor ) ) ; <nl> + } <nl> + return show ( info . color ) ; <nl> + } ( ) ; <nl> return folly : : sformat ( <nl> - \" Class : { : 10 } , Pre - Color : { } , Mat : ( { } ) \" , <nl> + \" Class : { : 10 } , Color : { : 15 } , Mat : ( { } ) \" , <nl> show ( info . regClass ) , <nl> - info . precolor ! = InvalidReg ? show ( info . precolor ) : \" - \" , <nl> + color , <nl> info . remat ? show ( unit , * info . remat ) : \" - \" <nl> ) ; <nl> } <nl> bool is_spill ( RegClass cls ) { <nl> return cls = = RegClass : : Spill | | cls = = RegClass : : SpillWide ; <nl> } <nl> <nl> + bool is_colorable ( RegClass cls ) { <nl> + switch ( cls ) { <nl> + case RegClass : : AnyNarrow : <nl> + case RegClass : : GP : <nl> + case RegClass : : SIMD : <nl> + case RegClass : : SIMDWide : <nl> + return true ; <nl> + case RegClass : : SF : <nl> + case RegClass : : Spill : <nl> + case RegClass : : SpillWide : <nl> + return false ; <nl> + case RegClass : : Any : <nl> + break ; <nl> + } <nl> + always_assert ( false ) ; <nl> + } <nl> + <nl> + / / Wrappers around boost : : get < > . Will assert if you try to retrieve a value from <nl> + / / the color that isn ' t present ( so check before calling ) . <nl> + bool is_color_none ( Color c ) { return boost : : get < None > ( & c ) ; } <nl> + <nl> + PhysReg color_reg ( Color c ) { <nl> + auto const r = boost : : get < PhysReg > ( & c ) ; <nl> + assertx ( r ) ; <nl> + return * r ; <nl> + } <nl> + <nl> + SpillSlot color_spill_slot ( Color c ) { <nl> + auto const s = boost : : get < SpillSlot > ( & c ) ; <nl> + assertx ( s ) ; <nl> + return * s ; <nl> + } <nl> + <nl> + SpillSlotWide color_spill_slot_wide ( Color c ) { <nl> + auto const s = boost : : get < SpillSlotWide > ( & c ) ; <nl> + assertx ( s ) ; <nl> + return * s ; <nl> + } <nl> + <nl> / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / <nl> / / State utilities <nl> <nl> void insert_spills ( State & state ) { <nl> assertx ( check ( state . unit ) ) ; <nl> } <nl> <nl> + / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / <nl> + / / Coloring <nl> + <nl> + / * <nl> + * Compared to spilling , coloring is rather straightforward . As already <nl> + * mentioned , now that the spiller has lowered the register pressure everywhere <nl> + * to below the number of physical registers , the unit should be trivially <nl> + * colorable . To color the unit , all we have to do is visit the blocks in any <nl> + * dominance preserving order ( we use RPO ) and choose a free color for each Vreg <nl> + * that the instruction defines . Its guaranteed that they ' ll always be a free <nl> + * color , regardless of previous choices . Thus coloring can be accomplished in a <nl> + * single linear pass . Once a Vreg becomes dead , its color is released . <nl> + * <nl> + * We only color physical registers here . We defer assigning spill slots to the <nl> + * optimization phase because its fairly trivial to use that to assign the slots <nl> + * optimally . <nl> + * <nl> + * Constrained instructions are the only real complexity , since we do not have <nl> + * the freedom to choose arbitrary colors for them . Instead , we rely on the fact <nl> + * that we split all the live ranges of Vregs before each constrained <nl> + * instruction . Therefore we can assume that all colors are free and choose the <nl> + * colors for the uses and defs of the constrained instruction as dictated by <nl> + * their precolors . Once we have selected the colors for the constrained <nl> + * instruction , we then color the preceding copy instruction which broke the <nl> + * live range . The copy isn ' t constrained , so we can select colors for <nl> + * unassigned Vregs from the set that wasn ' t used by the constrained <nl> + * instruction . <nl> + * <nl> + * This logic only works if each RegClass can only select from non - overlapping <nl> + * sets of physical registers . If there ' s overlapping pools of physical <nl> + * registers , it introduces additional constraints which the colorer cannot <nl> + * satisfy . Namely , assume that RegClass : : AnyNarrow choose from both GP and SIMD <nl> + * registers . We want to color a particular register with RegClass : : Any , so we <nl> + * select a GP register ( as opposed to a SIMD ) . It happens to be the last GP <nl> + * register . Later on , we attempt to color a RegClass : : GP register , but we can ' t <nl> + * because there ' s none free . If instead we had selected a SIMD earlier , it <nl> + * would have been colorable . In other words , having overlapping physical <nl> + * register pools means you no longer have a free choice for colors . So , we have <nl> + * to restrict RegClass : : AnyNarrow to a single register pool , namely GP . <nl> + * <nl> + * We select the free colors arbitrarily . Note that while the algorithm <nl> + * guarantees the unit is colorable regardless of choice , it does not guarantee <nl> + * the choices will result in a good coloring . Indeed , most colorings are pretty <nl> + * bad . We rely on a separate optimization of the colorings afterwards to remove <nl> + * most of the copies . <nl> + * / <nl> + <nl> + / / FreeRegs is responsible for tracking which physical registers are free and <nl> + / / assigning them . It only deals with physical registers and not spill slots . <nl> + <nl> + struct FreeRegs { <nl> + explicit FreeRegs ( const State & state ) <nl> + : state { & state } <nl> + , gp { state . gpUnreserved } <nl> + , simd { state . simdUnreserved } { } <nl> + <nl> + / / Choose ( with no particular heuristics ) a free physical register appropriate <nl> + / / for the given register class and return it as a color ( or None if there ' s <nl> + / / none available ) . This merely chooses the register , and does not mark it as <nl> + / / taken . <nl> + Color choose ( RegClass cls ) const { <nl> + switch ( cls ) { <nl> + case RegClass : : GP : <nl> + case RegClass : : AnyNarrow : { <nl> + auto const r = gp . choose ( ) ; <nl> + return r = = InvalidReg ? None { } : Color { r } ; <nl> + } <nl> + case RegClass : : SIMD : <nl> + case RegClass : : SIMDWide : { <nl> + auto const r = simd . choose ( ) ; <nl> + return r = = InvalidReg ? None { } : Color { r } ; <nl> + } <nl> + case RegClass : : Any : <nl> + case RegClass : : Spill : <nl> + case RegClass : : SpillWide : <nl> + case RegClass : : SF : <nl> + break ; <nl> + } <nl> + always_assert ( false ) ; <nl> + } <nl> + <nl> + / / Mark the given physical register as taken . The register should not already <nl> + / / be reserved . The RegClass should be appropriate for that register . <nl> + void reserve ( PhysReg r , RegClass cls ) { <nl> + switch ( cls ) { <nl> + case RegClass : : GP : <nl> + case RegClass : : AnyNarrow : { <nl> + assertx ( gp . contains ( r ) ) ; <nl> + gp - = r ; <nl> + return ; <nl> + } <nl> + case RegClass : : SIMD : <nl> + case RegClass : : SIMDWide : { <nl> + assertx ( simd . contains ( r ) ) ; <nl> + simd - = r ; <nl> + return ; <nl> + } <nl> + case RegClass : : Any : <nl> + case RegClass : : Spill : <nl> + case RegClass : : SpillWide : <nl> + case RegClass : : SF : <nl> + break ; <nl> + } <nl> + always_assert ( false ) ; <nl> + } <nl> + <nl> + / / Mark the given physical register as available . The register should be <nl> + / / already marked as taken . The RegClass should be appropriate for that <nl> + / / register . <nl> + void release ( PhysReg r , RegClass cls ) { <nl> + switch ( cls ) { <nl> + case RegClass : : GP : <nl> + case RegClass : : AnyNarrow : { <nl> + assertx ( ! gp . contains ( r ) ) ; <nl> + gp | = r ; <nl> + return ; <nl> + } <nl> + case RegClass : : SIMD : <nl> + case RegClass : : SIMDWide : { <nl> + assertx ( ! simd . contains ( r ) ) ; <nl> + simd | = r ; <nl> + return ; <nl> + } <nl> + case RegClass : : Any : <nl> + case RegClass : : Spill : <nl> + case RegClass : : SpillWide : <nl> + case RegClass : : SF : <nl> + break ; <nl> + } <nl> + always_assert ( false ) ; <nl> + } <nl> + <nl> + / / Mark all physical registers as available . <nl> + void releaseAll ( ) { <nl> + gp = state - > gpUnreserved ; <nl> + simd = state - > simdUnreserved ; <nl> + } <nl> + <nl> + / / Return false if any physical registers are taken . <nl> + bool allAvailable ( ) const { <nl> + return <nl> + gp = = state - > gpUnreserved & & <nl> + simd = = state - > simdUnreserved ; <nl> + } <nl> + <nl> + / / Check if the given physical register ( with appropriate RegClass ) is taken . <nl> + bool available ( PhysReg r , RegClass cls ) const { <nl> + switch ( cls ) { <nl> + case RegClass : : GP : <nl> + case RegClass : : AnyNarrow : <nl> + return gp . contains ( r ) ; <nl> + case RegClass : : SIMD : <nl> + case RegClass : : SIMDWide : <nl> + return simd . contains ( r ) ; <nl> + case RegClass : : Any : <nl> + case RegClass : : Spill : <nl> + case RegClass : : SpillWide : <nl> + case RegClass : : SF : <nl> + break ; <nl> + } <nl> + always_assert ( false ) ; <nl> + } <nl> + <nl> + / / Set operations : <nl> + <nl> + FreeRegs operator - ( const FreeRegs & other ) const { <nl> + assertx ( state = = other . state ) ; <nl> + auto temp = * this ; <nl> + temp . gp - = other . gp ; <nl> + temp . simd - = other . simd ; <nl> + return temp ; <nl> + } <nl> + <nl> + FreeRegs operator & ( const FreeRegs & other ) const { <nl> + assertx ( state = = other . state ) ; <nl> + auto temp = * this ; <nl> + temp . gp & = other . gp ; <nl> + temp . simd & = other . simd ; <nl> + return temp ; <nl> + } <nl> + <nl> + private : <nl> + const State * state ; <nl> + RegSet gp ; <nl> + RegSet simd ; <nl> + } ; <nl> + <nl> + / / Helper function to assert that a Color is not None ( which means we couldn ' t <nl> + / / find a free one , which is a bug ) . <nl> + void assert_found_color ( Vreg r , Color c ) { <nl> + always_assert_flog ( <nl> + ! is_color_none ( c ) , <nl> + \" Unable to find free color for { } \" , <nl> + show ( r ) <nl> + ) ; <nl> + } <nl> + <nl> + / / Helper function to assert that the precolor for a particular Vreg is <nl> + / / available ( if not , its a bug ) . <nl> + void assert_precolor_avail ( const FreeRegs & regs , const RegInfo & info , Vreg r ) { <nl> + always_assert_flog ( <nl> + regs . available ( info . precolor , info . regClass ) , <nl> + \" { } is pre - colored to { } , but it is not available \" , <nl> + show ( r ) , show ( info . precolor ) <nl> + ) ; <nl> + } <nl> + <nl> + / / Release the allocated colors from any Vregs ( from the given candidate set ) <nl> + / / which are dead at the given position . <nl> + void release_dead_regs ( const State & state , FreeRegs & free , <nl> + const VregSet & candidates , <nl> + Vlabel block , size_t instIdx ) { <nl> + candidates . forEach ( <nl> + [ & ] ( Vreg r ) { <nl> + if ( r . isPhys ( ) ) return ; <nl> + auto const & info = reg_info ( state , r ) ; <nl> + if ( ! is_colorable ( info . regClass ) ) return ; <nl> + / / Since we walk the unit in a dominance preserving order , every Vreg <nl> + / / defined at this point should have a color assigned . <nl> + assertx ( ! is_color_none ( info . color ) ) ; <nl> + auto const reg = color_reg ( info . color ) ; <nl> + assertx ( ! free . available ( reg , info . regClass ) ) ; <nl> + if ( live_in_at ( state , r , block , instIdx + 1 ) ) return ; <nl> + free . release ( reg , info . regClass ) ; <nl> + } <nl> + ) ; <nl> + } <nl> + <nl> + / / Color the defs of the given instruction ( which is unconstrained ) at the given <nl> + / / position . <nl> + void color_unconstrained ( State & state , FreeRegs & free , <nl> + const Vinstr & inst , Vlabel block , <nl> + size_t instIdx ) { <nl> + assertx ( ! is_constrained_inst ( state , inst ) ) ; <nl> + <nl> + auto const & unit = state . unit ; <nl> + <nl> + auto const acrosses = acrossesSet ( unit , inst ) - state . reservedRegs ; <nl> + auto const uses = usesSet ( unit , inst ) - state . reservedRegs - acrosses ; <nl> + auto const defs = defsSet ( unit , inst ) - state . reservedRegs ; <nl> + <nl> + / / Make sure the uses of the instruction are all colored already ( which should <nl> + / / be the case because we walk the unit in dominance preserving order ) . <nl> + if ( debug ) { <nl> + auto const checkColored = [ & ] ( Vreg r ) { <nl> + auto const & info = reg_info ( state , r ) ; <nl> + if ( ! is_colorable ( info . regClass ) ) return ; <nl> + always_assert ( ! is_color_none ( info . color ) ) ; <nl> + } ; <nl> + uses . forEach ( checkColored ) ; <nl> + acrosses . forEach ( checkColored ) ; <nl> + } <nl> + <nl> + / / First release any colors held by now dead uses . This doesn ' t include <nl> + / / acrosses , which we removed from the uses set above . <nl> + release_dead_regs ( state , free , uses , block , instIdx ) ; <nl> + <nl> + defs . forEach ( <nl> + [ & ] ( Vreg r ) { <nl> + auto & info = reg_info ( state , r ) ; <nl> + / / This Vreg is being defined here , so it better not have a color already . <nl> + if ( ! is_colorable ( info . regClass ) ) return ; <nl> + assertx ( is_color_none ( info . color ) ) ; <nl> + / / Pick a color , assert we found something ( which we always should ) and <nl> + / / then reserve it . <nl> + info . color = free . choose ( info . regClass ) ; <nl> + assert_found_color ( r , info . color ) ; <nl> + free . reserve ( color_reg ( info . color ) , info . regClass ) ; <nl> + } <nl> + ) ; <nl> + <nl> + / / Release any now dead defs or acrosses . <nl> + release_dead_regs ( state , free , acrosses , block , instIdx ) ; <nl> + release_dead_regs ( state , free , defs , block , instIdx ) ; <nl> + } <nl> + <nl> + / / Color constrained instructions is a bit more complicated because we need to <nl> + / / ensure that Vregs with precolors are colored to the appropriate physical <nl> + / / register . We might have inserted a copy / copyargs instruction immediately <nl> + / / before the constrained instruction to break Vreg live ranges . If so , we need <nl> + / / to color both the copy and the constrained instruction simultaneously . <nl> + void color_constrained ( State & state , FreeRegs & finalFree , <nl> + const Vinstr & inst , const Vinstr * copy , <nl> + Vlabel block , size_t firstIdx ) { <nl> + assertx ( is_constrained_inst ( state , inst ) ) ; <nl> + assertx ( ! copy | | <nl> + copy - > op = = Vinstr : : copy | | <nl> + copy - > op = = Vinstr : : copyargs ) ; <nl> + assertx ( ! copy | | ! is_constrained_inst ( state , * copy ) ) ; <nl> + <nl> + auto const & unit = state . unit ; <nl> + <nl> + / / Index of the constrained instruction <nl> + auto const instIdx = firstIdx + ( copy ? 1 : 0 ) ; <nl> + <nl> + / / finalFree is the state of free registers coming into the copy / constrained <nl> + / / instruction pair . If there ' s no copy , its already empty . If there ' s a copy , <nl> + / / it won ' t be , but we ' ll adjust it after coloring the copy instruction . <nl> + auto usesFree = finalFree ; <nl> + auto defsFree = finalFree ; <nl> + / / Start out by assuming all physical registers are available . This is safe to <nl> + / / assume because the copy / copyargs ( if necessary ) broke the live ranges of <nl> + / / all Vregs , giving us complete freedom to reassign things . <nl> + usesFree . releaseAll ( ) ; <nl> + defsFree . releaseAll ( ) ; <nl> + <nl> + auto uses = usesSet ( unit , inst ) - state . reservedRegs ; <nl> + auto acrosses = acrossesSet ( unit , inst ) - state . reservedRegs ; <nl> + auto const defs = defsSet ( unit , inst ) - state . reservedRegs ; <nl> + <nl> + / / Just like with spilling , we might need to treat some uses as acrosses to <nl> + / / model register pressure properly . <nl> + fix_constrained_inst_uses ( state , defs , uses , acrosses , block , instIdx ) ; <nl> + <nl> + / / We color the constrained instruction first , not the copy . Once we color the <nl> + / / constrained instruction , we then color the copy with what is left . This <nl> + / / ensures the colorability . <nl> + <nl> + / / Does the Vreg live thru the instruction ? IE , is it an across , or live - out ? <nl> + auto const isLiveThru = [ & ] ( Vreg r ) { <nl> + return acrosses [ r ] | | live_in_at ( state , r , block , instIdx + 1 ) ; <nl> + } ; <nl> + <nl> + / / Assign colors to the precolored subset of the given Vregs , using \" free \" to <nl> + / / choose available colors . If \" other \" is provided , and the Vreg is live - thru <nl> + / / the instruction , then also mark it as reserved in \" other \" . <nl> + auto const constrained = [ & ] ( const VregSet & regs , <nl> + FreeRegs & free , <nl> + FreeRegs * other ) { <nl> + regs . forEach ( <nl> + [ & ] ( Vreg r ) { <nl> + auto & info = reg_info ( state , r ) ; <nl> + assertx ( ! is_spill ( info . regClass ) ) ; <nl> + if ( info . precolor = = InvalidReg ) return ; <nl> + if ( ! is_colorable ( info . regClass ) ) return ; <nl> + <nl> + assertx ( is_color_none ( info . color ) ) ; <nl> + assert_precolor_avail ( free , info , r ) ; <nl> + info . color = info . precolor ; <nl> + free . reserve ( info . precolor , info . regClass ) ; <nl> + <nl> + if ( ! other ) return ; <nl> + if ( ! isLiveThru ( r ) ) return ; <nl> + <nl> + assert_precolor_avail ( * other , info , r ) ; <nl> + other - > reserve ( info . precolor , info . regClass ) ; <nl> + } <nl> + ) ; <nl> + } ; <nl> + / / Color the precolored uses , also reserving them in defsFree if live - thru . <nl> + constrained ( uses , usesFree , & defsFree ) ; <nl> + / / Color the precolored defs , not using any colors used by live - thru Vregs in <nl> + / / the uses . <nl> + constrained ( defs , defsFree , nullptr ) ; <nl> + <nl> + / / Assign colors to the non - precolored subset of the given Vregs . Use \" free \" <nl> + / / to select Vregs , preferring Vregs not taken in \" avoid \" <nl> + auto const unconstrained = [ & ] ( const VregSet & regs , <nl> + FreeRegs & free , <nl> + FreeRegs & avoid , <nl> + bool skipLiveThru ) { <nl> + regs . forEach ( <nl> + [ & ] ( Vreg r ) { <nl> + auto & info = reg_info ( state , r ) ; <nl> + assertx ( ! is_spill ( info . regClass ) ) ; <nl> + if ( info . precolor ! = InvalidReg ) return ; <nl> + if ( info . regClass = = RegClass : : SF ) return ; <nl> + assertx ( is_color_none ( info . color ) ) ; <nl> + <nl> + if ( skipLiveThru & & isLiveThru ( r ) ) return ; <nl> + <nl> + / / Choose a color . First pick among the Vregs available in free , but <nl> + / / taken in avoid . If we can ' t find a color there , just choose from free <nl> + / / ( which should always succeed ) . <nl> + auto const color = [ & ] { <nl> + auto const preferred = ( free - avoid ) . choose ( info . regClass ) ; <nl> + if ( ! is_color_none ( preferred ) ) return preferred ; <nl> + return free . choose ( info . regClass ) ; <nl> + } ( ) ; <nl> + assert_found_color ( r , color ) ; <nl> + <nl> + info . color = color ; <nl> + free . reserve ( color_reg ( color ) , info . regClass ) ; <nl> + } <nl> + ) ; <nl> + } ; <nl> + / / Color the non - precolored uses which aren ' t live - thru . Try to avoid free <nl> + / / registers available for defs . <nl> + unconstrained ( uses , usesFree , defsFree , true ) ; <nl> + / / Color the non - precolored defs . Try to avoid free registers available for <nl> + / / uses . <nl> + unconstrained ( defs , defsFree , usesFree , false ) ; <nl> + <nl> + / / Finally color the non - precolored uses which are live - thru . Use the <nl> + / / registers which are free in both usesFree and defsFree ( which should always <nl> + / / exist ) . <nl> + uses . forEach ( <nl> + [ & ] ( Vreg r ) { <nl> + auto & info = reg_info ( state , r ) ; <nl> + assertx ( ! is_spill ( info . regClass ) ) ; <nl> + if ( info . precolor ! = InvalidReg ) return ; <nl> + if ( info . regClass = = RegClass : : SF ) return ; <nl> + if ( ! isLiveThru ( r ) ) return ; <nl> + <nl> + assertx ( is_color_none ( info . color ) ) ; <nl> + <nl> + auto const color = ( usesFree & defsFree ) . choose ( info . regClass ) ; <nl> + assert_found_color ( r , color ) ; <nl> + <nl> + info . color = color ; <nl> + usesFree . reserve ( color_reg ( color ) , info . regClass ) ; <nl> + defsFree . reserve ( color_reg ( color ) , info . regClass ) ; <nl> + } <nl> + ) ; <nl> + <nl> + / / Now that we ' ve colored the constrained instruction , color the copy ( if it <nl> + / / exists ) . Since the copy is unconstrained , we can color its defs any way we <nl> + / / want . <nl> + if ( copy ) { <nl> + assertx ( acrossesSet ( unit , * copy ) . none ( ) ) ; <nl> + <nl> + auto const copyUses = usesSet ( unit , * copy ) - state . reservedRegs ; <nl> + if ( debug ) { <nl> + copyUses . forEach ( <nl> + [ & ] ( Vreg r ) { <nl> + auto const & info = reg_info ( state , r ) ; <nl> + if ( ! is_colorable ( info . regClass ) ) return ; <nl> + always_assert ( ! is_color_none ( info . color ) ) ; <nl> + } <nl> + ) ; <nl> + } <nl> + <nl> + FreeRegs copyDefsFree { state } ; <nl> + <nl> + visitDefs ( <nl> + unit , * copy , <nl> + [ & ] ( Vreg r ) { <nl> + if ( r . isPhys ( ) ) return ; <nl> + <nl> + auto & info = reg_info ( state , r ) ; <nl> + if ( ! is_colorable ( info . regClass ) ) return ; <nl> + <nl> + / / If this def was used by the constrained instruction , its already been <nl> + / / colored . Reserve the color its been assigned . <nl> + if ( ! is_color_none ( info . color ) ) { <nl> + auto const reg = color_reg ( info . color ) ; <nl> + always_assert ( copyDefsFree . available ( reg , info . regClass ) ) ; <nl> + copyDefsFree . reserve ( reg , info . regClass ) ; <nl> + return ; <nl> + } <nl> + <nl> + / / This def isn ' t assigned a color yet , which means it wasn ' t used by <nl> + / / the constrained instruction . If its live - in to the constrained <nl> + / / instruction , we have to assign it a color which isn ' t used by the <nl> + / / constrained instruction at all ( and not used by the copy either ) . <nl> + if ( live_in_at ( state , r , block , instIdx ) ) { <nl> + info . color = <nl> + ( copyDefsFree & defsFree & usesFree ) . choose ( info . regClass ) ; <nl> + assert_found_color ( r , info . color ) ; <nl> + auto const reg = color_reg ( info . color ) ; <nl> + copyDefsFree . reserve ( reg , info . regClass ) ; <nl> + defsFree . reserve ( reg , info . regClass ) ; <nl> + usesFree . reserve ( reg , info . regClass ) ; <nl> + return ; <nl> + } <nl> + <nl> + / / This def is dead after the copy . It won ' t interfere with the <nl> + / / constrained instruction , so we can give it any color that isn ' t <nl> + / / already used by the copy . However , we ' d like to give it a color which <nl> + / / isn ' t used by the constrained instruction to give other Vregs maximum <nl> + / / freedom in their choices . <nl> + auto const color = [ & ] { <nl> + / / First try a color which isn ' t used anywhere <nl> + auto const preferred1 = <nl> + ( copyDefsFree - usesFree - defsFree ) . choose ( info . regClass ) ; <nl> + if ( ! is_color_none ( preferred1 ) ) return preferred1 ; <nl> + / / Then try one which isn ' t used by the copy or the constrained <nl> + / / instruction ' s uses . <nl> + auto const preferred2 = <nl> + ( copyDefsFree - usesFree ) . choose ( info . regClass ) ; <nl> + if ( ! is_color_none ( preferred2 ) ) return preferred2 ; <nl> + / / If that fails , just choose one not used by the copy ( which is the <nl> + / / bare minimum required ) . <nl> + return copyDefsFree . choose ( info . regClass ) ; <nl> + } ( ) ; <nl> + assert_found_color ( r , color ) ; <nl> + info . color = color ; <nl> + copyDefsFree . reserve ( color_reg ( color ) , info . regClass ) ; <nl> + } <nl> + ) ; <nl> + <nl> + / / Release any uses of the copy which are now dead from the original <nl> + / / FreeRegs ( reflecting the state before the copy and constrained <nl> + / / instruction ) . Since the point of the copy was to break all the Vreg live <nl> + / / ranges , this should release all physical registers . <nl> + release_dead_regs ( state , finalFree , copyUses , block , firstIdx ) ; <nl> + } <nl> + <nl> + / / At this point finalFree reflects the register allocation state after the <nl> + / / copy ( if any ) and before the constrained instruction . Since its a <nl> + / / pre - requisite for proper coloring that all physical registers are available <nl> + / / for selection before a constrained instruction , we can assert the state has <nl> + / / everything available . Either there was no copy , and there were no live <nl> + / / Vregs , or there was a copy and we just released everything above . <nl> + always_assert ( finalFree . allAvailable ( ) ) ; <nl> + <nl> + / / The new state is whats free after the defs . <nl> + finalFree = defsFree ; <nl> + / / Release any now dead acrosses or defs after the constrained instruction . <nl> + release_dead_regs ( state , finalFree , acrosses , block , instIdx ) ; <nl> + release_dead_regs ( state , finalFree , defs , block , instIdx ) ; <nl> + } <nl> + <nl> + void assign_colors ( State & state ) { <nl> + auto const & unit = state . unit ; <nl> + <nl> + / / Walk the unit in RPO order . This is dominance preserving , so we ' ll always <nl> + / / encounter a Vreg ' s def before any of its usages . This means we can color in <nl> + / / a single pass over the unit . <nl> + for ( auto const b : state . rpo ) { <nl> + / / Start with all physical registers being available . <nl> + FreeRegs free { state } ; <nl> + <nl> + / / Then reserve all the registers already assigned to live - in Vregs . <nl> + state . liveIn [ b ] . forEach ( <nl> + [ & ] ( Vreg r ) { <nl> + auto const & info = reg_info ( state , r ) ; <nl> + if ( ! is_colorable ( info . regClass ) ) return ; <nl> + assertx ( ! is_color_none ( info . color ) ) ; <nl> + auto const reg = color_reg ( info . color ) ; <nl> + always_assert ( free . available ( reg , info . regClass ) ) ; <nl> + free . reserve ( reg , info . regClass ) ; <nl> + } <nl> + ) ; <nl> + <nl> + auto const & block = unit . blocks [ b ] ; <nl> + for ( size_t i = 0 ; i < block . code . size ( ) ; + + i ) { <nl> + auto const & inst = block . code [ i ] ; <nl> + <nl> + if ( inst . op = = Vinstr : : copy | | inst . op = = Vinstr : : copyargs ) { <nl> + / / Constrained instructions need special coloring logic to ensure that <nl> + / / the precolors are satisfied . A constrained instruction may have a <nl> + / / copy / copyargs in front of it ( to break Vreg live ranges ) and we want <nl> + / / to color both simultaneously as a pair . So , if we have a <nl> + / / copy / copyargs , peak ahead and see if the next is a constrained <nl> + / / instruction . <nl> + assertx ( ! is_constrained_inst ( state , inst ) ) ; <nl> + assertx ( i + 1 < block . code . size ( ) ) ; <nl> + <nl> + auto const & next = block . code [ i + 1 ] ; <nl> + if ( is_constrained_inst ( state , next ) ) { <nl> + / / The next is a constrained instruction , color both as a pair . <nl> + color_constrained ( state , free , next , & inst , b , i ) ; <nl> + i + + ; / / Skip over the next . <nl> + } else { <nl> + / / Its not . Color this copy normally and we ' ll deal with the next the <nl> + / / next trip around . <nl> + color_unconstrained ( state , free , inst , b , i ) ; <nl> + } <nl> + } else if ( is_constrained_inst ( state , inst ) ) { <nl> + / / A constrained instruction is not guaranteed to have a copy / copyargs <nl> + / / in front of it ( if nothing was live ) , so handle that case here . <nl> + assertx ( inst . op ! = Vinstr : : copy & & inst . op ! = Vinstr : : copyargs ) ; <nl> + color_constrained ( state , free , inst , nullptr , b , i ) ; <nl> + } else { <nl> + / / Normal unconstrained instruction . <nl> + color_unconstrained ( state , free , inst , b , i ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + assertx ( check ( state . unit ) ) ; <nl> + } <nl> + <nl> / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / <nl> <nl> } <nl> void allocateRegistersWithGraphColor ( Vunit & unit , const Abi & abi ) { <nl> infer_register_classes ( state ) ; <nl> insert_spills ( state ) ; <nl> <nl> + / / The spiller ' s SSA restoration may have invalidated liveness information , so <nl> + / / recalculate it . <nl> + calculate_liveness ( state ) ; <nl> + assign_colors ( state ) ; <nl> + <nl> printUnit ( kVasmRegAllocLevel , \" after vasm - graph - color \" , unit ) ; <nl> <nl> always_assert ( false ) ; <nl>\n", "msg": "Implement coloring in vasm - graph - color\n"}
{"diff_id": 34036, "repo": "apple/swift\n", "sha": "db6f0772b4af105294b4c08ad33e1e3efb2a40cc\n", "time": "2014-02-24T20:57:36Z\n", "diff": "mmm a / lib / Frontend / Frontend . cpp <nl> ppp b / lib / Frontend / Frontend . cpp <nl> void swift : : CompilerInstance : : setTargetConfigurations ( IRGenOptions & IRGenOpts , <nl> case llvm : : Triple : : ArchType : : arm : <nl> LangOpts . TargetConfigOptions [ \" arch \" ] = \" ARM \" ; <nl> break ; <nl> - case llvm : : Triple : : ArchType : : arm64 : <nl> - LangOpts . TargetConfigOptions [ \" arch \" ] = \" ARM64 \" ; <nl> - break ; <nl> case llvm : : Triple : : ArchType : : x86 : <nl> LangOpts . TargetConfigOptions [ \" arch \" ] = \" I386 \" ; <nl> break ; <nl> void swift : : CompilerInstance : : setTargetConfigurations ( IRGenOptions & IRGenOpts , <nl> LangOpts . TargetConfigOptions [ \" arch \" ] = \" X64 \" ; <nl> break ; <nl> default : <nl> - assert ( false & & \" Unsupported target architecture \" ) ; <nl> + / / FIXME : Use ` case llvm : : Triple : : arm64 ` when underlying LLVM is new enough <nl> + if ( StringRef ( \" arm64 \" ) = = llvm : : Triple : : getArchTypeName ( triple . getArch ( ) ) ) <nl> + LangOpts . TargetConfigOptions [ \" arch \" ] = \" ARM64 \" ; <nl> + break ; <nl> + llvm_unreachable ( \" Unsupported target architecture \" ) ; <nl> } <nl> } <nl> <nl>\n", "msg": "Allow Swift to be compiled with open - source LLVM\n"}
{"diff_id": 34070, "repo": "mongodb/mongo\n", "sha": "c55f35b894f145d14e7f3b4b431f4139c80a3778\n", "time": "2016-11-15T19:42:44Z\n", "diff": "mmm a / src / mongo / db / repl / replication_coordinator_impl . cpp <nl> ppp b / src / mongo / db / repl / replication_coordinator_impl . cpp <nl> void ReplicationCoordinatorImpl : : _startDataReplication ( OperationContext * txn , <nl> drCopy . reset ( ) ; <nl> lk . lock ( ) ; <nl> <nl> - if ( ErrorCodes : : CallbackCanceled = = status | | <nl> - ErrorCodes : : ShutdownInProgress = = status ) { <nl> - <nl> + if ( status = = ErrorCodes : : CallbackCanceled ) { <nl> log ( ) < < \" Initial Sync has been cancelled : \" < < status . getStatus ( ) ; <nl> return ; <nl> - } else if ( ! _inShutdown ) { <nl> - fassertNoTrace ( 40088 , status . getStatus ( ) ) ; <nl> } else if ( ! status . isOK ( ) ) { <nl> - log ( ) < < \" Initial Sync failed during shutdown due to \" < < status . getStatus ( ) ; <nl> - return ; <nl> + if ( _inShutdown ) { <nl> + log ( ) < < \" Initial Sync failed during shutdown due to \" < < status . getStatus ( ) ; <nl> + return ; <nl> + } else { <nl> + error ( ) < < \" Initial sync failed , shutting down now . Restart the server to \" <nl> + \" attempt a new initial sync . \" ; <nl> + fassertFailedWithStatusNoTrace ( 40088 , status . getStatus ( ) ) ; <nl> + } <nl> } <nl> <nl> const auto lastApplied = status . getValue ( ) ; <nl>\n", "msg": "SERVER - 26530 Add helpful log message for user when initial sync fails\n", "score": 1}
{"diff_id": 34300, "repo": "apple/swift\n", "sha": "a2c05130ef9f433e2a64249a8a82a800901aadb2\n", "time": "2017-11-20T06:23:56Z\n", "diff": "mmm a / lib / AST / ProtocolConformance . cpp <nl> ppp b / lib / AST / ProtocolConformance . cpp <nl> ProtocolConformance : : subst ( Type substType , <nl> / / the underlying class type . <nl> auto targetClass = <nl> inheritedConformance - > getType ( ) - > getClassOrBoundGenericClass ( ) ; <nl> - auto superclassType = substType ; <nl> - while ( superclassType - > getClassOrBoundGenericClass ( ) ! = targetClass ) <nl> - superclassType = superclassType - > getSuperclass ( ) ; <nl> + auto superclassType = substType - > getSuperclassForDecl ( targetClass ) ; <nl> <nl> / / Substitute into the superclass . <nl> - newBase = inheritedConformance - > subst ( superclassType , subs , <nl> - conformances ) ; <nl> + newBase = inheritedConformance - > subst ( superclassType , subs , conformances ) ; <nl> } else { <nl> newBase = inheritedConformance ; <nl> } <nl>\n", "msg": "[ AST ] Use getSuperclassForDecl ( ) appropriately .\n"}
{"diff_id": 34333, "msg": "Enhancements and fixes for PopupMenu ' s submenus .\n", "msgGPT": "remove unused code and fix indentation in popup menu class.", "METEOR Score": "19.82141282939416", "BLEU Score": "0.39309679294666566", "ROUGE-L Score": "0.31578946869806096", "score": 1, "repo": "godotengine/godot\n", "sha": "dc80a29dc565700079308553a6da94d70b22139f\n", "time": "2017-12-15T20:30:42Z\n", "diff": "mmm a / scene / gui / popup_menu . cpp <nl> ppp b / scene / gui / popup_menu . cpp <nl> String PopupMenu : : _get_accel_text ( int p_item ) const { <nl> else if ( items [ p_item ] . accel ) <nl> return keycode_get_string ( items [ p_item ] . accel ) ; <nl> return String ( ) ; <nl> - <nl> - / * <nl> - String atxt ; <nl> - if ( p_accel & KEY_MASK_SHIFT ) <nl> - atxt + = \" Shift + \" ; <nl> - if ( p_accel & KEY_MASK_ALT ) <nl> - atxt + = \" Alt + \" ; <nl> - if ( p_accel & KEY_MASK_CTRL ) <nl> - atxt + = \" Ctrl + \" ; <nl> - if ( p_accel & KEY_MASK_META ) <nl> - atxt + = \" Meta + \" ; <nl> - <nl> - p_accel & = KEY_CODE_MASK ; <nl> - <nl> - atxt + = String : : chr ( p_accel ) . to_upper ( ) ; <nl> - <nl> - return atxt ; <nl> - * / <nl> } <nl> <nl> Size2 PopupMenu : : get_minimum_size ( ) const { <nl> int PopupMenu : : _get_mouse_over ( const Point2 & p_over ) const { <nl> <nl> Ref < Font > font = get_font ( \" font \" ) ; <nl> int vseparation = get_constant ( \" vseparation \" ) ; <nl> - / / int hseparation = get_constant ( \" hseparation \" ) ; <nl> float font_h = font - > get_height ( ) ; <nl> <nl> for ( int i = 0 ; i < items . size ( ) ; i + + ) { <nl> void PopupMenu : : _gui_input ( const Ref < InputEvent > & p_event ) { <nl> <nl> mouse_over = i ; <nl> update ( ) ; <nl> + <nl> + if ( items [ i ] . submenu ! = \" \" & & submenu_over ! = i ) { <nl> + submenu_over = i ; <nl> + submenu_timer - > start ( ) ; <nl> + } <nl> break ; <nl> } <nl> } <nl> void PopupMenu : : _gui_input ( const Ref < InputEvent > & p_event ) { <nl> <nl> mouse_over = i ; <nl> update ( ) ; <nl> + <nl> + if ( items [ i ] . submenu ! = \" \" & & submenu_over ! = i ) { <nl> + submenu_over = i ; <nl> + submenu_timer - > start ( ) ; <nl> + } <nl> break ; <nl> } <nl> } <nl> void PopupMenu : : _notification ( int p_what ) { <nl> } break ; <nl> case NOTIFICATION_MOUSE_EXIT : { <nl> <nl> + if ( mouse_over > = 0 & & ( items [ mouse_over ] . submenu = = \" \" | | submenu_over ! = - 1 ) ) { <nl> + mouse_over = - 1 ; <nl> + update ( ) ; <nl> + } <nl> + } break ; <nl> + case NOTIFICATION_POPUP_HIDE : { <nl> + <nl> if ( mouse_over > = 0 ) { <nl> mouse_over = - 1 ; <nl> update ( ) ; <nl> void PopupMenu : : set_invalidate_click_until_motion ( ) { <nl> PopupMenu : : PopupMenu ( ) { <nl> <nl> mouse_over = - 1 ; <nl> + submenu_over = - 1 ; <nl> <nl> set_focus_mode ( FOCUS_ALL ) ; <nl> set_as_toplevel ( true ) ; <nl>\n"}
{"diff_id": 34438, "repo": "opencv/opencv\n", "sha": "a07d7a70a0c9f151acfbc80ae8552198b7128255\n", "time": "2015-02-23T13:12:42Z\n", "diff": "mmm a / modules / imgcodecs / src / grfmt_tiff . cpp <nl> ppp b / modules / imgcodecs / src / grfmt_tiff . cpp <nl> bool TiffEncoder : : writeLibTiff ( const Mat & img , const std : : vector < int > & params ) <nl> | | ! TIFFSetField ( pTiffHandle , TIFFTAG_SAMPLESPERPIXEL , channels ) <nl> | | ! TIFFSetField ( pTiffHandle , TIFFTAG_PLANARCONFIG , PLANARCONFIG_CONTIG ) <nl> | | ! TIFFSetField ( pTiffHandle , TIFFTAG_ROWSPERSTRIP , rowsPerStrip ) <nl> - | | ! TIFFSetField ( pTiffHandle , TIFFTAG_PREDICTOR , predictor ) <nl> + / / | | ! TIFFSetField ( pTiffHandle , TIFFTAG_PREDICTOR , predictor ) <nl> ) <nl> { <nl> TIFFClose ( pTiffHandle ) ; <nl> return false ; <nl> } <nl> <nl> + if ( compression ! = COMPRESSION_NONE & & ! TIFFSetField ( pTiffHandle , TIFFTAG_PREDICTOR , predictor ) ) <nl> + { <nl> + TIFFClose ( pTiffHandle ) ; <nl> + return false ; <nl> + } <nl> + <nl> / / row buffer , because TIFFWriteScanline modifies the original data ! <nl> size_t scanlineSize = TIFFScanlineSize ( pTiffHandle ) ; <nl> AutoBuffer < uchar > _buffer ( scanlineSize + 32 ) ; <nl>\n", "msg": "added support for uncompressed parameters to tiff image format as described here : expertland . net / question / b6o3n6p9a72341db823b48nl98m91dx8n1 / detail . html\n"}
{"diff_id": 34510, "repo": "Tencent/rapidjson\n", "sha": "a040fc3347f2ffeca7e4e3c71aefeaa37840af56\n", "time": "2018-03-08T12:28:51Z\n", "diff": "mmm a / test / unittest / valuetest . cpp <nl> ppp b / test / unittest / valuetest . cpp <nl> TEST ( Value , Int ) { <nl> EXPECT_EQ ( 5678 , z . Get < int > ( ) ) ; <nl> EXPECT_EQ ( 5679 , z . Set ( 5679 ) . Get < int > ( ) ) ; <nl> EXPECT_EQ ( 5680 , z . Set < int > ( 5680 ) . Get < int > ( ) ) ; <nl> + <nl> + # ifdef _MSC_VER <nl> + / / long as int on MSC platforms <nl> + RAPIDJSON_STATIC_ASSERT ( sizeof ( long ) = = sizeof ( int ) ) ; <nl> + z . SetInt ( 1234 ) ; <nl> + EXPECT_TRUE ( z . Is < long > ( ) ) ; <nl> + EXPECT_EQ ( 1234l , z . Get < long > ( ) ) ; <nl> + # endif <nl> } <nl> <nl> TEST ( Value , Uint ) { <nl> TEST ( Value , Uint ) { <nl> EXPECT_EQ ( 2147483648u , z . Get < unsigned > ( ) ) ; <nl> EXPECT_EQ ( 2147483649u , z . Set ( 2147483649u ) . Get < unsigned > ( ) ) ; <nl> EXPECT_EQ ( 2147483650u , z . Set < unsigned > ( 2147483650u ) . Get < unsigned > ( ) ) ; <nl> + <nl> + # ifdef _MSC_VER <nl> + / / unsigned long as unsigned on MSC platforms <nl> + RAPIDJSON_STATIC_ASSERT ( sizeof ( unsigned long ) = = sizeof ( unsigned ) ) ; <nl> + z . SetUint ( 1234 ) ; <nl> + EXPECT_TRUE ( z . Is < unsigned long > ( ) ) ; <nl> + EXPECT_EQ ( 1234ul , z . Get < unsigned > ( ) ) ; <nl> + # endif <nl> } <nl> <nl> TEST ( Value , Int64 ) { <nl>\n", "msg": "Add unittest for long as int in MSC platforms\n"}
{"diff_id": 34566, "repo": "MarlinFirmware/Marlin\n", "sha": "8cb04816b53ef73733a81fb1ace4622ea2c75c70\n", "time": "2016-03-26T02:31:56Z\n", "diff": "mmm a / Marlin / ultralcd . cpp <nl> ppp b / Marlin / ultralcd . cpp <nl> static void lcd_control_menu ( ) { <nl> * <nl> * / <nl> <nl> - # if ENABLED ( PIDTEMP ) | | ENABLED ( PIDTEMPBED ) <nl> + # if ENABLED ( PID_AUTOTUNE_MENU ) <nl> <nl> # if ENABLED ( PIDTEMP ) <nl> int autotune_temp [ EXTRUDERS ] = { 150 } ; <nl> static void lcd_control_menu ( ) { <nl> enqueue_and_echo_command_now ( cmd ) ; <nl> } <nl> <nl> - # endif / / PIDTEMP | | PIDTEMPBED <nl> + # endif / / PID_AUTOTUNE_MENU <nl> <nl> # if ENABLED ( PIDTEMP ) <nl> <nl> static void lcd_control_menu ( ) { <nl> PID_PARAM ( Kd , e ) = scalePID_d ( raw_Kd ) ; <nl> updatePID ( ) ; <nl> } <nl> - # define _PIDTEMP_FUNCTIONS ( eindex ) \\ <nl> + # define _PIDTEMP_BASE_FUNCTIONS ( eindex ) \\ <nl> void copy_and_scalePID_i_E # # eindex ( ) { copy_and_scalePID_i ( eindex ) ; } \\ <nl> - void copy_and_scalePID_d_E # # eindex ( ) { copy_and_scalePID_d ( eindex ) ; } \\ <nl> - void lcd_autotune_callback_E # # eindex ( ) { _lcd_autotune ( eindex ) ; } <nl> + void copy_and_scalePID_d_E # # eindex ( ) { copy_and_scalePID_d ( eindex ) ; } <nl> + <nl> + # if ENABLED ( PID_AUTOTUNE_MENU ) <nl> + # define _PIDTEMP_FUNCTIONS ( eindex ) \\ <nl> + _PIDTEMP_BASE_FUNCTIONS ( eindex ) ; \\ <nl> + void lcd_autotune_callback_E # # eindex ( ) { _lcd_autotune ( eindex ) ; } <nl> + # else <nl> + # define _PIDTEMP_FUNCTIONS ( eindex ) _PIDTEMP_BASE_FUNCTIONS ( eindex ) ; <nl> + # endif <nl> <nl> _PIDTEMP_FUNCTIONS ( 0 ) ; <nl> # if ENABLED ( PID_PARAMS_PER_EXTRUDER ) <nl> static void lcd_control_temperature_menu ( ) { <nl> # define _PID_MENU_ITEMS ( ELABEL , eindex ) _PID_BASE_MENU_ITEMS ( ELABEL , eindex ) <nl> # endif <nl> <nl> - # define PID_MENU_ITEMS ( ELABEL , eindex ) \\ <nl> - _PID_MENU_ITEMS ( ELABEL , eindex ) ; \\ <nl> - MENU_MULTIPLIER_ITEM_EDIT_CALLBACK ( int3 , MSG_PID_AUTOTUNE ELABEL , & autotune_temp [ eindex ] , 150 , heater_maxtemp [ eindex ] - 15 , lcd_autotune_callback_E # # eindex ) <nl> + # if ENABLED ( PID_AUTOTUNE_MENU ) <nl> + # define PID_MENU_ITEMS ( ELABEL , eindex ) \\ <nl> + _PID_MENU_ITEMS ( ELABEL , eindex ) ; \\ <nl> + MENU_MULTIPLIER_ITEM_EDIT_CALLBACK ( int3 , MSG_PID_AUTOTUNE ELABEL , & autotune_temp [ eindex ] , 150 , heater_maxtemp [ eindex ] - 15 , lcd_autotune_callback_E # # eindex ) <nl> + # else <nl> + # define PID_MENU_ITEMS ( ELABEL , eindex ) _PID_MENU_ITEMS ( ELABEL , eindex ) <nl> + # endif <nl> <nl> # if ENABLED ( PID_PARAMS_PER_EXTRUDER ) & & EXTRUDERS > 1 <nl> PID_MENU_ITEMS ( MSG_E1 , 0 ) ; <nl>\n", "msg": "Apply PID_AUTOTUNE_MENU option to ultralcd . cpp\n"}
{"diff_id": 34683, "repo": "microsoft/CNTK\n", "sha": "aa664df36d2d48b0ed51145562acdd50482d4efb\n", "time": "2016-09-04T23:58:00Z\n", "diff": "mmm a / Source / ComputationNetworkLib / RecurrentNodes . cpp <nl> ppp b / Source / ComputationNetworkLib / RecurrentNodes . cpp <nl> <nl> <nl> namespace Microsoft { namespace MSR { namespace CNTK { <nl> <nl> - template < class ElemType , int direction > <nl> - void DelayedValueNodeBase < ElemType , direction > : : Init ( const TensorShape & sampleLayout , ElemType initialActivationValue ) <nl> - { <nl> - m_initialActivationValue = initialActivationValue ; <nl> - m_timeStep = 1 ; <nl> - CreateMatrixIfNull ( m_value ) ; <nl> - SetDims ( sampleLayout , HasMBLayout ( ) / * false at this point * / ) ; <nl> - m_value - > SetValue ( m_initialActivationValue ) ; / / is this needed ? <nl> + template < class ElemType , int direction > <nl> + void DelayedValueNodeBase < ElemType , direction > : : Init ( const TensorShape & sampleLayout , ElemType initialActivationValue ) <nl> + { <nl> + m_initialActivationValue = initialActivationValue ; <nl> + m_timeStep = 1 ; <nl> + CreateMatrixIfNull ( m_value ) ; <nl> + SetDims ( sampleLayout , HasMBLayout ( ) / * false at this point * / ) ; <nl> + m_value - > SetValue ( m_initialActivationValue ) ; / / is this needed ? <nl> + } <nl> + <nl> + template < class ElemType , int direction > <nl> + / * virtual * / void DelayedValueNodeBase < ElemType , direction > : : CopyTo ( ComputationNodeBasePtr nodeP , const std : : wstring & newName , const CopyNodeFlags flags ) const / * override * / <nl> + { <nl> + Base : : CopyTo ( nodeP , newName , flags ) ; <nl> + if ( flags & CopyNodeFlags : : copyNodeValue ) <nl> + { <nl> + auto node = dynamic_pointer_cast < DelayedValueNodeBase < ElemType , direction / * , SequenceStart_or_End * / > > ( nodeP ) ; <nl> + node - > m_timeStep = m_timeStep ; <nl> + node - > m_initialActivationValue = m_initialActivationValue ; <nl> + node - > m_delayedValue . SetValue ( m_delayedValue ) ; <nl> + if ( m_delayedActivationMBLayout ) <nl> + ( node - > m_delayedActivationMBLayout = make_shared < MBLayout > ( ) ) - > CopyFrom ( m_delayedActivationMBLayout ) ; <nl> + else <nl> + node - > m_delayedActivationMBLayout = nullptr ; <nl> } <nl> + } <nl> + <nl> + template < class ElemType , int direction > <nl> + / * virtual * / void DelayedValueNodeBase < ElemType , direction > : : Load ( File & fstream , size_t modelVersion ) / * override * / <nl> + { <nl> + / / the node has already been initialized e . g . w . r . t . direction <nl> + Base : : Load ( fstream , modelVersion ) ; <nl> <nl> - template < class ElemType , int direction > <nl> - / * virtual * / void DelayedValueNodeBase < ElemType , direction > : : CopyTo ( ComputationNodeBasePtr nodeP , const std : : wstring & newName , const CopyNodeFlags flags ) const / * override * / <nl> + fstream > > m_timeStep ; <nl> + <nl> + if ( modelVersion > CNTK_MODEL_VERSION_3 ) <nl> { <nl> - Base : : CopyTo ( nodeP , newName , flags ) ; <nl> - if ( flags & CopyNodeFlags : : copyNodeValue ) <nl> - { <nl> - auto node = dynamic_pointer_cast < DelayedValueNodeBase < ElemType , direction / * , SequenceStart_or_End * / > > ( nodeP ) ; <nl> - node - > m_timeStep = m_timeStep ; <nl> - node - > m_initialActivationValue = m_initialActivationValue ; <nl> - node - > m_delayedValue . SetValue ( m_delayedValue ) ; <nl> - if ( m_delayedActivationMBLayout ) <nl> - ( node - > m_delayedActivationMBLayout = make_shared < MBLayout > ( ) ) - > CopyFrom ( m_delayedActivationMBLayout ) ; <nl> - else <nl> - node - > m_delayedActivationMBLayout = nullptr ; <nl> - } <nl> + TensorShape sampleLayout ; <nl> + sampleLayout . Load ( fstream ) ; <nl> + SetDims ( sampleLayout , HasMBLayout ( ) / * may be true on reload ( roll - back ) * / ) ; <nl> } <nl> - <nl> - template < class ElemType , int direction > <nl> - / * virtual * / void DelayedValueNodeBase < ElemType , direction > : : Load ( File & fstream , size_t modelVersion ) / * override * / <nl> + else <nl> { <nl> - / / the node has already been initialized e . g . w . r . t . direction <nl> - Base : : Load ( fstream , modelVersion ) ; <nl> - <nl> - fstream > > m_timeStep ; <nl> - <nl> - if ( modelVersion > CNTK_MODEL_VERSION_3 ) <nl> - { <nl> - TensorShape sampleLayout ; <nl> - sampleLayout . Load ( fstream ) ; <nl> - SetDims ( sampleLayout , HasMBLayout ( ) / * may be true on reload ( roll - back ) * / ) ; <nl> - } <nl> - else <nl> - { <nl> - size_t rows , colsDummy ; <nl> - fstream > > rows > > colsDummy ; <nl> - / / legacy format : if # rows matches then assume current tensor shape is up to date <nl> - / / BUGBUG : This fails for non - column tensors . It should be sufficient to set <nl> - / / these to 0 and rely on Validate ( ) , but some unknown nodes in the loop don ' t do that right . <nl> - SetDims ( TensorShape ( rows ) , HasMBLayout ( ) / * may be true on reload ( roll - back ) * / ) ; / / tensor shape will be overwritten in Validate ( ) <nl> - } <nl> - m_delayedValue . Resize ( m_sampleLayout . GetNumElements ( ) , 0 ) ; / / Note : If we try to access history in first minibatch , we shall crash . It would be a consequence of a missing sentence - begin flag <nl> - <nl> - if ( modelVersion > = CNTK_MODEL_VERSION_2 ) <nl> - fstream > > m_initialActivationValue ; <nl> + size_t rows , colsDummy ; <nl> + fstream > > rows > > colsDummy ; <nl> + / / legacy format : if # rows matches then assume current tensor shape is up to date <nl> + / / BUGBUG : This fails for non - column tensors . It should be sufficient to set <nl> + / / these to 0 and rely on Validate ( ) , but some unknown nodes in the loop don ' t do that right . <nl> + SetDims ( TensorShape ( rows ) , HasMBLayout ( ) / * may be true on reload ( roll - back ) * / ) ; / / tensor shape will be overwritten in Validate ( ) <nl> } <nl> + m_delayedValue . Resize ( m_sampleLayout . GetNumElements ( ) , 0 ) ; / / Note : If we try to access history in first minibatch , we shall crash . It would be a consequence of a missing sentence - begin flag <nl> <nl> - template < class ElemType , int direction > <nl> - / * virtual * / void DelayedValueNodeBase < ElemType , direction > : : Save ( File & fstream ) const / * override * / <nl> - { <nl> - Base : : Save ( fstream ) ; <nl> + if ( modelVersion > = CNTK_MODEL_VERSION_2 ) <nl> + fstream > > m_initialActivationValue ; <nl> + } <nl> <nl> - fstream < < m_timeStep ; <nl> + template < class ElemType , int direction > <nl> + / * virtual * / void DelayedValueNodeBase < ElemType , direction > : : Save ( File & fstream ) const / * override * / <nl> + { <nl> + Base : : Save ( fstream ) ; <nl> + <nl> + fstream < < m_timeStep ; <nl> # if CURRENT_CNTK_MODEL_VERSION > CNTK_MODEL_VERSION_3 <nl> - m_sampleLayout . Save ( fstream ) ; <nl> + m_sampleLayout . Save ( fstream ) ; <nl> # else <nl> - fstream < < GetSampleLayout ( ) . GetNumElements ( ) < < ( size_t ) 0 ; / / used to be ( rows , cols ) ; no need since inferred in Validate ( ) , and wrong for non - matrix tensors <nl> + fstream < < GetSampleLayout ( ) . GetNumElements ( ) < < ( size_t ) 0 ; / / used to be ( rows , cols ) ; no need since inferred in Validate ( ) , and wrong for non - matrix tensors <nl> # endif <nl> <nl> - fstream < < m_initialActivationValue ; <nl> - } <nl> + fstream < < m_initialActivationValue ; <nl> + } <nl> <nl> - / / This function assumes BeginForwardProp / EndForwardProp ( ) to be called before / after the iteration loop . <nl> - / / TODO : In the future , there may be value for one more way of handling the boundary condition : Fill as ' NoInput ' . Then we can use this to implement rolling windows ( albeit inefficiently ) . Would require to unshare the layout . <nl> - template < class ElemType , int direction > <nl> - / * virtual * / void DelayedValueNodeBase < ElemType , direction > : : ForwardProp ( const FrameRange & fr ) / * override * / <nl> - { <nl> - assert ( m_pMBLayout ) ; <nl> + / / This function assumes BeginForwardProp / EndForwardProp ( ) to be called before / after the iteration loop . <nl> + / / TODO : In the future , there may be value for one more way of handling the boundary condition : Fill as ' NoInput ' . Then we can use this to implement rolling windows ( albeit inefficiently ) . Would require to unshare the layout . <nl> + template < class ElemType , int direction > <nl> + / * virtual * / void DelayedValueNodeBase < ElemType , direction > : : ForwardProp ( const FrameRange & fr ) / * override * / <nl> + { <nl> + assert ( m_pMBLayout ) ; <nl> <nl> - / / special case : DelayedValueNodes may be used outside of loops <nl> - / / TODO : this should be a bulk operation ; this implementation is a quick hack <nl> - int dir = direction ; / / ( this avoids a ' conditional expression is constant ' warning ) <nl> - if ( fr . IsAllFrames ( ) ) <nl> - { <nl> - / / recursive call to ourselves <nl> - FrameRangeIteration range ( m_pMBLayout , - dir ) ; <nl> - for ( auto t = range . begin ( ) ; t ! = range . end ( ) ; t + + ) <nl> - ForwardProp ( t ) ; <nl> - return ; <nl> - } <nl> + / / special case : DelayedValueNodes may be used outside of loops <nl> + / / TODO : this should be a bulk operation ; this implementation is a quick hack <nl> + int dir = direction ; / / ( this avoids a ' conditional expression is constant ' warning ) <nl> + if ( fr . IsAllFrames ( ) ) <nl> + { <nl> + / / recursive call to ourselves <nl> + FrameRangeIteration range ( m_pMBLayout , - dir ) ; <nl> + for ( auto t = range . begin ( ) ; t ! = range . end ( ) ; t + + ) <nl> + ForwardProp ( t ) ; <nl> + return ; <nl> + } <nl> <nl> - / / we forward prop from the previous frame to this frame <nl> - FrameRange frDelayed = fr . WithTimeOffset ( direction * m_timeStep ) ; <nl> + / / we forward prop from the previous frame to this frame <nl> + FrameRange frDelayed = fr . WithTimeOffset ( direction * m_timeStep ) ; <nl> <nl> - size_t T = GetNumTimeSteps ( ) ; <nl> - size_t T_delayedActivation = m_delayedActivationMBLayout ? m_delayedActivationMBLayout - > GetNumTimeSteps ( ) : 0 ; / / ( note : should never happen in full - sequence mode ) <nl> + size_t T = GetNumTimeSteps ( ) ; <nl> + size_t T_delayedActivation = m_delayedActivationMBLayout ? m_delayedActivationMBLayout - > GetNumTimeSteps ( ) : 0 ; / / ( note : should never happen in full - sequence mode ) <nl> <nl> - / / compute logical position of delayed value <nl> - assert ( m_timeStep > 0 ) ; <nl> + / / compute logical position of delayed value <nl> + assert ( m_timeStep > 0 ) ; <nl> <nl> - size_t t = fr . t ( ) ; <nl> - int t_delayed = ( int ) ( t + direction * m_timeStep ) ; / / this might end up outside the current window <nl> + size_t t = fr . t ( ) ; <nl> + int t_delayed = ( int ) ( t + direction * m_timeStep ) ; / / this might end up outside the current window <nl> <nl> - Matrix < ElemType > inp ( ( DEVICEID_TYPE ) m_value - > GetDeviceId ( ) ) ; <nl> + Matrix < ElemType > inp ( ( DEVICEID_TYPE ) m_value - > GetDeviceId ( ) ) ; <nl> <nl> - / / if any sequence at this time step has a boundary flag , then process one by one <nl> - / / TODO : Would there be an efficiency gain from grouping consecutive sequences with identical flags ? <nl> - / / assert ( m_pShiftedMBLayout - > Is ( t , SequenceStart_or_End ) = = m_pMBLayout - > IsBeyondStartOrEnd ( frDelayed ) ) ; <nl> - if ( m_pMBLayout - > IsBeyondStartOrEnd ( frDelayed ) ) <nl> + / / if any sequence at this time step has a boundary flag , then process one by one <nl> + / / TODO : Would there be an efficiency gain from grouping consecutive sequences with identical flags ? <nl> + / / assert ( m_pShiftedMBLayout - > Is ( t , SequenceStart_or_End ) = = m_pMBLayout - > IsBeyondStartOrEnd ( frDelayed ) ) ; <nl> + if ( m_pMBLayout - > IsBeyondStartOrEnd ( frDelayed ) ) <nl> + { <nl> + for ( size_t id = 0 ; id < GetNumParallelSequences ( ) ; id + + ) <nl> { <nl> - for ( size_t id = 0 ; id < GetNumParallelSequences ( ) ; id + + ) <nl> - { <nl> - if ( m_pMBLayout - > IsGap ( fr . Sequence ( id ) ) ) / / if output is in a gap then don ' t bother filling it <nl> - continue ; <nl> + if ( m_pMBLayout - > IsGap ( fr . Sequence ( id ) ) ) / / if output is in a gap then don ' t bother filling it <nl> + continue ; <nl> <nl> - Matrix < ElemType > out = ValueFor ( fr . Sequence ( id ) ) ; <nl> + Matrix < ElemType > out = ValueFor ( fr . Sequence ( id ) ) ; <nl> <nl> - / / assert ( m_pShiftedMBLayout - > Is ( id , t , SequenceStart_or_End ) = = m_pMBLayout - > IsBeyondStartOrEnd ( frDelayed . Sequence ( id ) ) ) ; <nl> - if ( m_pMBLayout - > IsBeyondStartOrEnd ( frDelayed . Sequence ( id ) ) ) <nl> - out . SetValue ( m_initialActivationValue ) ; / / crossed a boundary <nl> - else / / not a boundary : just copy the delayed value <nl> - { <nl> - / / inside the sequence : access delayed value <nl> - if ( t_delayed < 0 ) <nl> - inp = DataWithMBLayoutFor ( m_delayedValue , FrameRange ( m_delayedActivationMBLayout , t_delayed + T_delayedActivation ) . Sequence ( id ) , m_delayedActivationMBLayout ) ; / / delay reaches in previous minibatch <nl> - else if ( t_delayed > = T ) <nl> - inp = DataWithMBLayoutFor ( m_delayedValue , FrameRange ( m_delayedActivationMBLayout , t_delayed - T ) . Sequence ( id ) , m_delayedActivationMBLayout ) ; / / delay reaches in previous minibatch <nl> - else <nl> - inp = Input ( 0 ) - > ValueFor ( frDelayed . Sequence ( id ) ) ; <nl> - / / inp = Input ( 0 ) - > ValueFor ( FrameRange ( m_pMBLayout , t_delayed ) . Sequence ( id ) ) ; <nl> - <nl> - out . AssignValuesOf ( inp ) ; <nl> - } <nl> + / / assert ( m_pShiftedMBLayout - > Is ( id , t , SequenceStart_or_End ) = = m_pMBLayout - > IsBeyondStartOrEnd ( frDelayed . Sequence ( id ) ) ) ; <nl> + if ( m_pMBLayout - > IsBeyondStartOrEnd ( frDelayed . Sequence ( id ) ) ) <nl> + out . SetValue ( m_initialActivationValue ) ; / / crossed a boundary <nl> + else / / not a boundary : just copy the delayed value <nl> + { <nl> + / / inside the sequence : access delayed value <nl> + if ( t_delayed < 0 ) <nl> + inp = DataWithMBLayoutFor ( m_delayedValue , FrameRange ( m_delayedActivationMBLayout , t_delayed + T_delayedActivation ) . Sequence ( id ) , m_delayedActivationMBLayout ) ; / / delay reaches in previous minibatch <nl> + else if ( t_delayed > = T ) <nl> + inp = DataWithMBLayoutFor ( m_delayedValue , FrameRange ( m_delayedActivationMBLayout , t_delayed - T ) . Sequence ( id ) , m_delayedActivationMBLayout ) ; / / delay reaches in previous minibatch <nl> + else <nl> + inp = Input ( 0 ) - > ValueFor ( frDelayed . Sequence ( id ) ) ; <nl> + / / inp = Input ( 0 ) - > ValueFor ( FrameRange ( m_pMBLayout , t_delayed ) . Sequence ( id ) ) ; <nl> + <nl> + out . AssignValuesOf ( inp ) ; <nl> } <nl> } <nl> - else / / frame has no boundary flags : use ValueFor directly ( still may have a gap here ) <nl> - { <nl> - Matrix < ElemType > out = ValueFor ( fr ) ; <nl> + } <nl> + else / / frame has no boundary flags : use ValueFor directly ( still may have a gap here ) <nl> + { <nl> + Matrix < ElemType > out = ValueFor ( fr ) ; <nl> <nl> - if ( t_delayed < 0 ) <nl> + if ( t_delayed < 0 ) <nl> + { <nl> + if ( m_delayedValue . IsEmpty ( ) ) <nl> { <nl> - if ( m_delayedValue . IsEmpty ( ) ) <nl> - { <nl> - if ( IsPartOfLoop ( ) ) <nl> - InvalidArgument ( \" The delay node tries to access past values that are out of bound , possibly because there is no sentence start marker in the MBLayout . \" ) ; <nl> - else / / use first frame <nl> - inp = Input ( 0 ) - > ValueFor ( FrameRange ( m_pMBLayout , 0 ) ) ; <nl> - } <nl> - else <nl> - inp = DataWithMBLayoutFor ( m_delayedValue , FrameRange ( m_delayedActivationMBLayout , t_delayed + T_delayedActivation ) , m_delayedActivationMBLayout ) ; <nl> + if ( IsPartOfLoop ( ) ) <nl> + InvalidArgument ( \" The delay node tries to access past values that are out of bound , possibly because there is no sentence start marker in the MBLayout . \" ) ; <nl> + else / / use first frame <nl> + inp = Input ( 0 ) - > ValueFor ( FrameRange ( m_pMBLayout , 0 ) ) ; <nl> } <nl> + else <nl> + inp = DataWithMBLayoutFor ( m_delayedValue , FrameRange ( m_delayedActivationMBLayout , t_delayed + T_delayedActivation ) , m_delayedActivationMBLayout ) ; <nl> + } <nl> <nl> - else if ( t_delayed > = T ) <nl> + else if ( t_delayed > = T ) <nl> + { <nl> + if ( m_delayedValue . IsEmpty ( ) ) <nl> { <nl> - if ( m_delayedValue . IsEmpty ( ) ) <nl> - { <nl> - if ( IsPartOfLoop ( ) ) <nl> - InvalidArgument ( \" The delay node tries to access future values that are out of bound , possibly because there is no sentence end marker in the MBLayout . \" ) ; <nl> - else / / use last frame <nl> - inp = Input ( 0 ) - > ValueFor ( FrameRange ( m_pMBLayout , T - 1 ) ) ; <nl> - } <nl> - else <nl> - inp = DataWithMBLayoutFor ( m_delayedValue , FrameRange ( m_delayedActivationMBLayout , t_delayed - T ) , m_delayedActivationMBLayout ) ; <nl> + if ( IsPartOfLoop ( ) ) <nl> + InvalidArgument ( \" The delay node tries to access future values that are out of bound , possibly because there is no sentence end marker in the MBLayout . \" ) ; <nl> + else / / use last frame <nl> + inp = Input ( 0 ) - > ValueFor ( FrameRange ( m_pMBLayout , T - 1 ) ) ; <nl> } <nl> else <nl> - inp = Input ( 0 ) - > ValueFor ( frDelayed ) ; <nl> - / / inp = Input ( 0 ) - > ValueFor ( FrameRange ( m_pMBLayout , t_delayed ) ) ; <nl> - <nl> - out . AssignValuesOf ( inp ) ; <nl> + inp = DataWithMBLayoutFor ( m_delayedValue , FrameRange ( m_delayedActivationMBLayout , t_delayed - T ) , m_delayedActivationMBLayout ) ; <nl> } <nl> - } <nl> - <nl> - template < class ElemType , int direction > <nl> - / * virtual * / void DelayedValueNodeBase < ElemType , direction > : : EndForwardProp ( ) / * override * / / / called after last iteration step of ForwardProp ( ) <nl> - { <nl> - / / In truncated BPTT , we carry over left - to - right state across minibatches . <nl> - / / It is kept in m_delayedValue , m_delayedActivationMBLayout . <nl> - / / This could be optimized as follows : <nl> - / / - only keep the required number of frames ( m_timeStep ) <nl> - / / - we don ' t need to keep anything in full - sequence mode <nl> - / / - we don ' t need to keep anything if all sequences are closed ( sentence end ) <nl> - / / This condition includes full - sequence mode . <nl> - / / TODO : Can we optimize this and only copy if there is a sequence spanning across the end of the MB ? And add a check to BeginForwardProp ( ) to make sure we got one if there is a boundary at the start ? <nl> - m_delayedValue . SetValue ( Input ( 0 ) - > Value ( ) ) ; <nl> - if ( ! m_delayedActivationMBLayout ) <nl> - m_delayedActivationMBLayout = make_shared < MBLayout > ( ) ; <nl> - m_delayedActivationMBLayout - > CopyFrom ( m_pMBLayout ) ; <nl> + else <nl> + inp = Input ( 0 ) - > ValueFor ( frDelayed ) ; <nl> + / / inp = Input ( 0 ) - > ValueFor ( FrameRange ( m_pMBLayout , t_delayed ) ) ; <nl> <nl> - Base : : EndForwardProp ( ) ; <nl> + out . AssignValuesOf ( inp ) ; <nl> } <nl> + } <nl> <nl> - template < class ElemType , int direction > <nl> - / * virtual * / void DelayedValueNodeBase < ElemType , direction > : : / * ComputationNode : : * / BackpropTo ( const size_t inputIndex , const FrameRange & fr ) / * override * / <nl> - { <nl> - / / move the target matrix to the target device , since below it is accessed as slices which cannot move <nl> - / / TODO : change below accesses to TensorView , then this is no longer needed . <nl> - Input ( 0 ) - > Gradient ( ) . TransferToDeviceIfNotThere ( m_deviceId , / * isBeingMoved = * / true ) ; <nl> + template < class ElemType , int direction > <nl> + / * virtual * / void DelayedValueNodeBase < ElemType , direction > : : EndForwardProp ( ) / * override * / / / called after last iteration step of ForwardProp ( ) <nl> + { <nl> + / / In truncated BPTT , we carry over left - to - right state across minibatches . <nl> + / / It is kept in m_delayedValue , m_delayedActivationMBLayout . <nl> + / / This could be optimized as follows : <nl> + / / - only keep the required number of frames ( m_timeStep ) <nl> + / / - we don ' t need to keep anything in full - sequence mode <nl> + / / - we don ' t need to keep anything if all sequences are closed ( sentence end ) <nl> + / / This condition includes full - sequence mode . <nl> + / / TODO : Can we optimize this and only copy if there is a sequence spanning across the end of the MB ? And add a check to BeginForwardProp ( ) to make sure we got one if there is a boundary at the start ? <nl> + m_delayedValue . SetValue ( Input ( 0 ) - > Value ( ) ) ; <nl> + if ( ! m_delayedActivationMBLayout ) <nl> + m_delayedActivationMBLayout = make_shared < MBLayout > ( ) ; <nl> + m_delayedActivationMBLayout - > CopyFrom ( m_pMBLayout ) ; <nl> + <nl> + Base : : EndForwardProp ( ) ; <nl> + } <nl> + <nl> + template < class ElemType , int direction > <nl> + / * virtual * / void DelayedValueNodeBase < ElemType , direction > : : / * ComputationNode : : * / BackpropTo ( const size_t inputIndex , const FrameRange & fr ) / * override * / <nl> + { <nl> + / / move the target matrix to the target device , since below it is accessed as slices which cannot move <nl> + / / TODO : change below accesses to TensorView , then this is no longer needed . <nl> + Input ( 0 ) - > Gradient ( ) . TransferToDeviceIfNotThere ( m_deviceId , / * isBeingMoved = * / true ) ; <nl> <nl> - assert ( inputIndex = = 0 ) ; <nl> - inputIndex ; <nl> + assert ( inputIndex = = 0 ) ; <nl> + inputIndex ; <nl> <nl> - / / special case : DelayedValueNodes may be used outside of loops <nl> - / / TODO : this should be a bulk operation ; this implementation is a quick hack <nl> - int dir = direction ; / / ( this avoids a ' conditional expression is constant ' warning ) <nl> - if ( fr . IsAllFrames ( ) ) <nl> - { <nl> - / / recursive call to ourselves <nl> - FrameRangeIteration range ( m_pMBLayout , - dir ) ; <nl> - for ( auto t = range . rbegin ( ) ; t ! = range . rend ( ) ; t + + ) / / note : reverse iterator <nl> - BackpropTo ( inputIndex , t ) ; <nl> - return ; <nl> - } <nl> + / / special case : DelayedValueNodes may be used outside of loops <nl> + / / TODO : this should be a bulk operation ; this implementation is a quick hack <nl> + int dir = direction ; / / ( this avoids a ' conditional expression is constant ' warning ) <nl> + if ( fr . IsAllFrames ( ) ) <nl> + { <nl> + / / recursive call to ourselves <nl> + FrameRangeIteration range ( m_pMBLayout , - dir ) ; <nl> + for ( auto t = range . rbegin ( ) ; t ! = range . rend ( ) ; t + + ) / / note : reverse iterator <nl> + BackpropTo ( inputIndex , t ) ; <nl> + return ; <nl> + } <nl> <nl> - / / we backpropagated into the delayed frame <nl> - FrameRange frDelayed = fr . WithTimeOffset ( direction * m_timeStep ) ; <nl> + / / we backpropagated into the delayed frame <nl> + FrameRange frDelayed = fr . WithTimeOffset ( direction * m_timeStep ) ; <nl> <nl> - / / if delayed input is within valid time range then add its gradient <nl> - size_t t = fr . t ( ) ; <nl> - int t_delayed = ( int ) ( t + direction * m_timeStep ) ; / / this might end up outside the current window <nl> - if ( t_delayed > = 0 & & t_delayed < GetNumTimeSteps ( ) ) <nl> + / / if delayed input is within valid time range then add its gradient <nl> + size_t t = fr . t ( ) ; <nl> + int t_delayed = ( int ) ( t + direction * m_timeStep ) ; / / this might end up outside the current window <nl> + if ( t_delayed > = 0 & & t_delayed < GetNumTimeSteps ( ) ) <nl> + { <nl> + / / Boundary frames must not propagate . Gaps must also not propagate . <nl> + / / if there is a boundary in this frame , we treat each stream separately ; otherwise we do all in one go <nl> + / / assert ( m_pShiftedMBLayout - > Is ( t , SequenceStart_or_End | MinibatchPackingFlags : : NoFeature ) = = <nl> + / / m_pMBLayout - > IsGap ( fr ) | | m_pMBLayout - > IsBeyondStartOrEnd ( frDelayed ) ) ; <nl> + if ( m_pMBLayout - > IsGap ( fr ) | | m_pMBLayout - > IsBeyondStartOrEnd ( frDelayed ) ) / / true if at least one parallel sequence has a boundary or gap <nl> { <nl> - / / Boundary frames must not propagate . Gaps must also not propagate . <nl> - / / if there is a boundary in this frame , we treat each stream separately ; otherwise we do all in one go <nl> - / / assert ( m_pShiftedMBLayout - > Is ( t , SequenceStart_or_End | MinibatchPackingFlags : : NoFeature ) = = <nl> - / / m_pMBLayout - > IsGap ( fr ) | | m_pMBLayout - > IsBeyondStartOrEnd ( frDelayed ) ) ; <nl> - if ( m_pMBLayout - > IsGap ( fr ) | | m_pMBLayout - > IsBeyondStartOrEnd ( frDelayed ) ) / / true if at least one parallel sequence has a boundary or gap <nl> + size_t mNbr = m_pMBLayout - > GetNumParallelSequences ( ) ; <nl> + for ( size_t id = 0 ; id < mNbr ; id + + ) <nl> { <nl> - size_t mNbr = m_pMBLayout - > GetNumParallelSequences ( ) ; <nl> - for ( size_t id = 0 ; id < mNbr ; id + + ) <nl> + / / assert ( m_pShiftedMBLayout - > Is ( id , t , SequenceStart_or_End | MinibatchPackingFlags : : NoFeature ) = = <nl> + / / m_pMBLayout - > IsGap ( fr . Sequence ( id ) ) | | m_pMBLayout - > IsBeyondStartOrEnd ( frDelayed . Sequence ( id ) ) ) ; <nl> + if ( ! ( m_pMBLayout - > IsGap ( fr . Sequence ( id ) ) | | m_pMBLayout - > IsBeyondStartOrEnd ( frDelayed . Sequence ( id ) ) ) ) / / don ' t propagate boundary frames or gaps <nl> { <nl> - / / assert ( m_pShiftedMBLayout - > Is ( id , t , SequenceStart_or_End | MinibatchPackingFlags : : NoFeature ) = = <nl> - / / m_pMBLayout - > IsGap ( fr . Sequence ( id ) ) | | m_pMBLayout - > IsBeyondStartOrEnd ( frDelayed . Sequence ( id ) ) ) ; <nl> - if ( ! ( m_pMBLayout - > IsGap ( fr . Sequence ( id ) ) | | m_pMBLayout - > IsBeyondStartOrEnd ( frDelayed . Sequence ( id ) ) ) ) / / don ' t propagate boundary frames or gaps <nl> - { <nl> - Matrix < ElemType > frm = GradientFor ( fr . Sequence ( id ) ) ; <nl> - / / TODO : use delayed FrameRange here as well <nl> - / / Matrix < ElemType > to = Input ( 0 ) - > GradientFor ( FrameRange ( m_pMBLayout , t_delayed ) . Sequence ( id ) ) ; <nl> - Matrix < ElemType > to = Input ( 0 ) - > GradientFor ( frDelayed . Sequence ( id ) ) ; <nl> - to + = frm ; <nl> - } <nl> + Matrix < ElemType > frm = GradientFor ( fr . Sequence ( id ) ) ; <nl> + / / TODO : use delayed FrameRange here as well <nl> + / / Matrix < ElemType > to = Input ( 0 ) - > GradientFor ( FrameRange ( m_pMBLayout , t_delayed ) . Sequence ( id ) ) ; <nl> + Matrix < ElemType > to = Input ( 0 ) - > GradientFor ( frDelayed . Sequence ( id ) ) ; <nl> + to + = frm ; <nl> } <nl> } <nl> - else / / operate on entire time step in one go ( over all parallel sequences ) <nl> - { <nl> - Matrix < ElemType > frm = GradientFor ( fr ) ; <nl> - / / TODO : use something like fr . WithDelay ( t ) instead , instead of recreating FrameRanges <nl> - / / Matrix < ElemType > to = Input ( 0 ) - > GradientFor ( FrameRange ( m_pMBLayout , t_delayed ) ) ; <nl> - Matrix < ElemType > to = Input ( 0 ) - > GradientFor ( frDelayed ) ; <nl> - to + = frm ; <nl> - } <nl> + } <nl> + else / / operate on entire time step in one go ( over all parallel sequences ) <nl> + { <nl> + Matrix < ElemType > frm = GradientFor ( fr ) ; <nl> + / / TODO : use something like fr . WithDelay ( t ) instead , instead of recreating FrameRanges <nl> + / / Matrix < ElemType > to = Input ( 0 ) - > GradientFor ( FrameRange ( m_pMBLayout , t_delayed ) ) ; <nl> + Matrix < ElemType > to = Input ( 0 ) - > GradientFor ( frDelayed ) ; <nl> + to + = frm ; <nl> } <nl> } <nl> + } <nl> + <nl> + template < class ElemType , int direction > <nl> + / * virtual * / void DelayedValueNodeBase < ElemType , direction > : : / * ComputationNodeBase : : * / Validate ( bool isFinalValidationPass ) / * override * / <nl> + { <nl> + ValidateUnaryMap ( isFinalValidationPass ) ; <nl> + } <nl> <nl> - template < class ElemType , int direction > <nl> - / * virtual * / void DelayedValueNodeBase < ElemType , direction > : : / * ComputationNodeBase : : * / Validate ( bool isFinalValidationPass ) / * override * / <nl> + template < class ElemType , int direction > <nl> + / * virtual * / NodeStatePtr DelayedValueNodeBase < ElemType , direction > : : / * IStatefulNode : : * / ExportState ( ) / * override * / <nl> + { <nl> + NodeStatePtr pExportedState ; <nl> + size_t nT = m_pMBLayout - > GetNumTimeSteps ( ) ; <nl> + size_t nU = m_pMBLayout - > GetNumParallelSequences ( ) ; <nl> + int dir = direction ; <nl> + if ( m_timeStep ! = 1 ) <nl> { <nl> - ValidateUnaryMap ( isFinalValidationPass ) ; <nl> + / / not support yet ; give user a hint <nl> + RuntimeError ( \" Currently importing / exporting state info for timeStep > 1 is not supported . Contact erw @ microsoft . com for more detail \" ) ; <nl> } <nl> - <nl> - template < class ElemType , int direction > <nl> - / * virtual * / NodeStatePtr DelayedValueNodeBase < ElemType , direction > : : / * IStatefulNode : : * / ExportState ( ) / * override * / <nl> + if ( dir = = - 1 ) / / we look into past <nl> { <nl> - NodeStatePtr pExportedState ; <nl> - size_t nT = m_pMBLayout - > GetNumTimeSteps ( ) ; <nl> - size_t nU = m_pMBLayout - > GetNumParallelSequences ( ) ; <nl> - int dir = direction ; <nl> - if ( m_timeStep ! = 1 ) <nl> + if ( ! m_pMBLayout - > HasSequenceBeyondEnd ( ) ) / / only need to export state if anything crosses the MB boundary <nl> { <nl> - / / not support yet ; give user a hint <nl> - RuntimeError ( \" Currently importing / exporting state info for timeStep > 1 is not supported . Contact erw @ microsoft . com for more detail \" ) ; <nl> + auto pState = make_shared < DelayedValueNodeState < ElemType > > ( m_deviceId ) ; <nl> + pState - > CacheDelayedMBLayout ( m_delayedActivationMBLayout ) ; <nl> + / / return an empty one <nl> } <nl> - if ( dir = = - 1 ) / / we look into past <nl> + else <nl> { <nl> - if ( ! m_pMBLayout - > HasSequenceBeyondEnd ( ) ) / / only need to export state if anything crosses the MB boundary <nl> - { <nl> - auto pState = make_shared < DelayedValueNodeState < ElemType > > ( m_deviceId ) ; <nl> - pState - > CacheDelayedMBLayout ( m_delayedActivationMBLayout ) ; <nl> - / / return an empty one <nl> - } <nl> - else <nl> - { <nl> - auto pState = make_shared < DelayedValueNodeState < ElemType > > ( m_deviceId ) ; <nl> - pState - > CacheState ( m_delayedValue . ColumnSlice ( ( nT - 1 ) * nU , nU ) ) ; <nl> - pState - > CacheDelayedMBLayout ( m_delayedActivationMBLayout ) ; <nl> - pExportedState = pState ; <nl> - } <nl> + auto pState = make_shared < DelayedValueNodeState < ElemType > > ( m_deviceId ) ; <nl> + pState - > CacheState ( m_delayedValue . ColumnSlice ( ( nT - 1 ) * nU , nU ) ) ; <nl> + pState - > CacheDelayedMBLayout ( m_delayedActivationMBLayout ) ; <nl> + pExportedState = pState ; <nl> } <nl> - else if ( dir = = 1 ) / / we look into future <nl> + } <nl> + else if ( dir = = 1 ) / / we look into future <nl> + { <nl> + if ( ! m_pMBLayout - > HasSequenceBeyondBegin ( ) ) / / only need to export state if anything crosses the MB boundary <nl> { <nl> - if ( ! m_pMBLayout - > HasSequenceBeyondBegin ( ) ) / / only need to export state if anything crosses the MB boundary <nl> - { <nl> - auto pState = make_shared < DelayedValueNodeState < ElemType > > ( m_deviceId ) ; <nl> - pState - > CacheDelayedMBLayout ( m_delayedActivationMBLayout ) ; <nl> - pExportedState = pState ; <nl> - } <nl> - else <nl> - { <nl> - auto pState = make_shared < DelayedValueNodeState < ElemType > > ( m_deviceId ) ; <nl> - pState - > CacheState ( m_delayedValue . ColumnSlice ( ( nT - 1 ) * nU , nU ) ) ; <nl> - pState - > CacheDelayedMBLayout ( m_delayedActivationMBLayout ) ; <nl> - pExportedState = pState ; <nl> - } <nl> + auto pState = make_shared < DelayedValueNodeState < ElemType > > ( m_deviceId ) ; <nl> + pState - > CacheDelayedMBLayout ( m_delayedActivationMBLayout ) ; <nl> + pExportedState = pState ; <nl> } <nl> else <nl> { <nl> - LogicError ( \" Unrecognized direction in DelayedValueNodeBase \" ) ; <nl> + auto pState = make_shared < DelayedValueNodeState < ElemType > > ( m_deviceId ) ; <nl> + pState - > CacheState ( m_delayedValue . ColumnSlice ( ( nT - 1 ) * nU , nU ) ) ; <nl> + pState - > CacheDelayedMBLayout ( m_delayedActivationMBLayout ) ; <nl> + pExportedState = pState ; <nl> } <nl> - return pExportedState ; <nl> } <nl> - <nl> - template < class ElemType , int direction > <nl> - / * virtual * / void DelayedValueNodeBase < ElemType , direction > : : / * IStatefulNode : : * / ImportState ( const NodeStatePtr & pImportedState ) / * override * / <nl> + else <nl> { <nl> - DelayedNodeStatePtr pState = dynamic_pointer_cast < DelayedValueNodeState < ElemType > > ( pImportedState ) ; <nl> - <nl> - if ( ! pState ) <nl> - LogicError ( \" Expecting DelayValueNodeState after downcasting \" ) ; <nl> + LogicError ( \" Unrecognized direction in DelayedValueNodeBase \" ) ; <nl> + } <nl> + return pExportedState ; <nl> + } <nl> <nl> - pState - > ExportDelayedMBLayout ( m_delayedActivationMBLayout ) ; / / pstate copy to m_delayedActivationMBLayout <nl> - if ( pState - > IsEmpty ( ) ) <nl> - { <nl> - return ; <nl> - } <nl> + template < class ElemType , int direction > <nl> + / * virtual * / void DelayedValueNodeBase < ElemType , direction > : : / * IStatefulNode : : * / ImportState ( const NodeStatePtr & pImportedState ) / * override * / <nl> + { <nl> + DelayedNodeStatePtr pState = dynamic_pointer_cast < DelayedValueNodeState < ElemType > > ( pImportedState ) ; <nl> <nl> - const Matrix < ElemType > & delayedActivation = pState - > ExportCachedActivity ( ) ; <nl> - size_t nT = m_delayedActivationMBLayout - > GetNumTimeSteps ( ) ; <nl> - size_t nU = m_delayedActivationMBLayout - > GetNumParallelSequences ( ) ; <nl> + if ( ! pState ) <nl> + LogicError ( \" Expecting DelayValueNodeState after downcasting \" ) ; <nl> <nl> - int dir = direction ; <nl> - if ( dir = = - 1 ) / / looking backward <nl> - m_delayedValue . SetColumnSlice ( delayedActivation , ( nT - 1 ) * nU , nU ) ; <nl> - else if ( dir = = 1 ) <nl> - m_delayedValue . SetColumnSlice ( delayedActivation , 0 , nU ) ; <nl> - else <nl> - LogicError ( \" Unrecognized direction in DelayedValueNodeBase \" ) ; <nl> + pState - > ExportDelayedMBLayout ( m_delayedActivationMBLayout ) ; / / pstate copy to m_delayedActivationMBLayout <nl> + if ( pState - > IsEmpty ( ) ) <nl> + { <nl> + return ; <nl> } <nl> <nl> + const Matrix < ElemType > & delayedActivation = pState - > ExportCachedActivity ( ) ; <nl> + size_t nT = m_delayedActivationMBLayout - > GetNumTimeSteps ( ) ; <nl> + size_t nU = m_delayedActivationMBLayout - > GetNumParallelSequences ( ) ; <nl> + <nl> + int dir = direction ; <nl> + if ( dir = = - 1 ) / / looking backward <nl> + m_delayedValue . SetColumnSlice ( delayedActivation , ( nT - 1 ) * nU , nU ) ; <nl> + else if ( dir = = 1 ) <nl> + m_delayedValue . SetColumnSlice ( delayedActivation , 0 , nU ) ; <nl> + else <nl> + LogicError ( \" Unrecognized direction in DelayedValueNodeBase \" ) ; <nl> + } <nl> + <nl> # ifdef COMING_SOON <nl> <nl> / / mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm - - <nl>\n", "msg": "fixed indentation of RecurrentNodes . cpp\n"}
{"diff_id": 34743, "repo": "apple/swift\n", "sha": "40f675641ad1636b3701f09a8cca33c050a9e83f\n", "time": "2014-04-03T20:31:12Z\n", "diff": "mmm a / lib / ClangImporter / ImportType . cpp <nl> ppp b / lib / ClangImporter / ImportType . cpp <nl> namespace { <nl> auto pointeeType = Impl . importType ( pointeeQualType , <nl> ImportTypeKind : : Normal ) ; <nl> <nl> - if ( ! pointeeType | | type - > isVoidPointerType ( ) ) { <nl> + / / If we can ' t represent the pointee in Swift , don ' t try to use a bridged <nl> + / / pointer type . <nl> + if ( ! pointeeType ) <nl> + return Type ( ) ; <nl> + <nl> + if ( type - > isVoidPointerType ( ) ) { <nl> / / Pointers to unmappable or void types map to C * VoidPointer . <nl> if ( pointeeQualType . isConstQualified ( ) ) <nl> return Impl . getNamedSwiftType ( Impl . getStdlibModule ( ) , <nl>\n", "msg": "ClangImporter : Don ' t bridge pointers to forward - declared types .\n"}
{"diff_id": 34804, "repo": "xbmc/xbmc\n", "sha": "c2fd5d8b39090c2985883345b53bb352622c5e1e\n", "time": "2013-04-05T08:32:58Z\n", "diff": "mmm a / xbmc / cores / VideoRenderers / WinRenderer . cpp <nl> ppp b / xbmc / cores / VideoRenderers / WinRenderer . cpp <nl> void CWinRenderer : : ScaleFixedPipeline ( ) <nl> <nl> if ( ! cbcontrol ) <nl> { <nl> - hr = pD3DDev - > SetTextureStageState ( 0 , D3DTSS_COLOROP , D3DTOP_SELECTARG1 ) ; <nl> - hr = pD3DDev - > SetTextureStageState ( 0 , D3DTSS_COLORARG1 , D3DTA_TEXTURE ) ; <nl> - hr = pD3DDev - > SetTextureStageState ( 0 , D3DTSS_ALPHAOP , D3DTOP_SELECTARG1 ) ; <nl> - hr = pD3DDev - > SetTextureStageState ( 0 , D3DTSS_ALPHAARG1 , D3DTA_TEXTURE ) ; <nl> - hr = pD3DDev - > SetTextureStageState ( 1 , D3DTSS_COLOROP , D3DTOP_DISABLE ) ; <nl> - hr = pD3DDev - > SetTextureStageState ( 1 , D3DTSS_ALPHAOP , D3DTOP_DISABLE ) ; <nl> + pD3DDev - > SetTextureStageState ( 0 , D3DTSS_COLOROP , D3DTOP_SELECTARG1 ) ; <nl> + pD3DDev - > SetTextureStageState ( 0 , D3DTSS_COLORARG1 , D3DTA_TEXTURE ) ; <nl> + pD3DDev - > SetTextureStageState ( 0 , D3DTSS_ALPHAOP , D3DTOP_SELECTARG1 ) ; <nl> + pD3DDev - > SetTextureStageState ( 0 , D3DTSS_ALPHAARG1 , D3DTA_TEXTURE ) ; <nl> + pD3DDev - > SetTextureStageState ( 1 , D3DTSS_COLOROP , D3DTOP_DISABLE ) ; <nl> + pD3DDev - > SetTextureStageState ( 1 , D3DTSS_ALPHAOP , D3DTOP_DISABLE ) ; <nl> } <nl> else <nl> { <nl> - hr = pD3DDev - > SetTextureStageState ( 0 , D3DTSS_COLOROP , D3DTOP_MODULATE2X ) ; <nl> - hr = pD3DDev - > SetTextureStageState ( 0 , D3DTSS_COLORARG1 , D3DTA_TEXTURE ) ; <nl> - hr = pD3DDev - > SetTextureStageState ( 0 , D3DTSS_COLORARG2 , D3DTA_DIFFUSE ) ; <nl> - hr = pD3DDev - > SetTextureStageState ( 0 , D3DTSS_ALPHAOP , D3DTOP_SELECTARG1 ) ; <nl> - hr = pD3DDev - > SetTextureStageState ( 0 , D3DTSS_ALPHAARG1 , D3DTA_DIFFUSE ) ; <nl> - <nl> - hr = pD3DDev - > SetTextureStageState ( 1 , D3DTSS_COLOROP , D3DTOP_ADDSIGNED ) ; <nl> - hr = pD3DDev - > SetTextureStageState ( 1 , D3DTSS_COLORARG1 , D3DTA_CURRENT ) ; <nl> - hr = pD3DDev - > SetTextureStageState ( 1 , D3DTSS_COLORARG2 , D3DTA_SPECULAR ) ; <nl> - hr = pD3DDev - > SetTextureStageState ( 1 , D3DTSS_ALPHAOP , D3DTOP_SELECTARG1 ) ; <nl> - hr = pD3DDev - > SetTextureStageState ( 1 , D3DTSS_ALPHAARG1 , D3DTA_CURRENT ) ; <nl> - <nl> - hr = pD3DDev - > SetTextureStageState ( 2 , D3DTSS_COLOROP , D3DTOP_DISABLE ) ; <nl> - hr = pD3DDev - > SetTextureStageState ( 2 , D3DTSS_ALPHAOP , D3DTOP_DISABLE ) ; <nl> + pD3DDev - > SetTextureStageState ( 0 , D3DTSS_COLOROP , D3DTOP_MODULATE2X ) ; <nl> + pD3DDev - > SetTextureStageState ( 0 , D3DTSS_COLORARG1 , D3DTA_TEXTURE ) ; <nl> + pD3DDev - > SetTextureStageState ( 0 , D3DTSS_COLORARG2 , D3DTA_DIFFUSE ) ; <nl> + pD3DDev - > SetTextureStageState ( 0 , D3DTSS_ALPHAOP , D3DTOP_SELECTARG1 ) ; <nl> + pD3DDev - > SetTextureStageState ( 0 , D3DTSS_ALPHAARG1 , D3DTA_DIFFUSE ) ; <nl> + <nl> + pD3DDev - > SetTextureStageState ( 1 , D3DTSS_COLOROP , D3DTOP_ADDSIGNED ) ; <nl> + pD3DDev - > SetTextureStageState ( 1 , D3DTSS_COLORARG1 , D3DTA_CURRENT ) ; <nl> + pD3DDev - > SetTextureStageState ( 1 , D3DTSS_COLORARG2 , D3DTA_SPECULAR ) ; <nl> + pD3DDev - > SetTextureStageState ( 1 , D3DTSS_ALPHAOP , D3DTOP_SELECTARG1 ) ; <nl> + pD3DDev - > SetTextureStageState ( 1 , D3DTSS_ALPHAARG1 , D3DTA_CURRENT ) ; <nl> + <nl> + pD3DDev - > SetTextureStageState ( 2 , D3DTSS_COLOROP , D3DTOP_DISABLE ) ; <nl> + pD3DDev - > SetTextureStageState ( 2 , D3DTSS_ALPHAOP , D3DTOP_DISABLE ) ; <nl> } <nl> <nl> - hr = pD3DDev - > SetRenderState ( D3DRS_CULLMODE , D3DCULL_NONE ) ; <nl> - hr = pD3DDev - > SetRenderState ( D3DRS_LIGHTING , FALSE ) ; <nl> - hr = pD3DDev - > SetRenderState ( D3DRS_ZENABLE , FALSE ) ; <nl> - hr = pD3DDev - > SetRenderState ( D3DRS_STENCILENABLE , FALSE ) ; <nl> - hr = pD3DDev - > SetRenderState ( D3DRS_ALPHABLENDENABLE , FALSE ) ; <nl> - hr = pD3DDev - > SetRenderState ( D3DRS_ALPHATESTENABLE , FALSE ) ; <nl> - hr = pD3DDev - > SetRenderState ( D3DRS_SCISSORTESTENABLE , FALSE ) ; <nl> - hr = pD3DDev - > SetRenderState ( D3DRS_COLORWRITEENABLE , D3DCOLORWRITEENABLE_ALPHA | D3DCOLORWRITEENABLE_BLUE | D3DCOLORWRITEENABLE_GREEN | D3DCOLORWRITEENABLE_RED ) ; <nl> - <nl> - hr = pD3DDev - > SetSamplerState ( 0 , D3DSAMP_MAGFILTER , m_TextureFilter ) ; <nl> - hr = pD3DDev - > SetSamplerState ( 0 , D3DSAMP_MINFILTER , m_TextureFilter ) ; <nl> - hr = pD3DDev - > SetSamplerState ( 0 , D3DSAMP_ADDRESSU , D3DTADDRESS_CLAMP ) ; <nl> - hr = pD3DDev - > SetSamplerState ( 0 , D3DSAMP_ADDRESSV , D3DTADDRESS_CLAMP ) ; <nl> - <nl> - hr = pD3DDev - > SetFVF ( D3DFVF_XYZRHW | D3DFVF_DIFFUSE | D3DFVF_SPECULAR | D3DFVF_TEX1 ) ; <nl> + pD3DDev - > SetRenderState ( D3DRS_CULLMODE , D3DCULL_NONE ) ; <nl> + pD3DDev - > SetRenderState ( D3DRS_LIGHTING , FALSE ) ; <nl> + pD3DDev - > SetRenderState ( D3DRS_ZENABLE , FALSE ) ; <nl> + pD3DDev - > SetRenderState ( D3DRS_STENCILENABLE , FALSE ) ; <nl> + pD3DDev - > SetRenderState ( D3DRS_ALPHABLENDENABLE , FALSE ) ; <nl> + pD3DDev - > SetRenderState ( D3DRS_ALPHATESTENABLE , FALSE ) ; <nl> + pD3DDev - > SetRenderState ( D3DRS_SCISSORTESTENABLE , FALSE ) ; <nl> + pD3DDev - > SetRenderState ( D3DRS_COLORWRITEENABLE , D3DCOLORWRITEENABLE_ALPHA | D3DCOLORWRITEENABLE_BLUE | D3DCOLORWRITEENABLE_GREEN | D3DCOLORWRITEENABLE_RED ) ; <nl> + <nl> + pD3DDev - > SetSamplerState ( 0 , D3DSAMP_MAGFILTER , m_TextureFilter ) ; <nl> + pD3DDev - > SetSamplerState ( 0 , D3DSAMP_MINFILTER , m_TextureFilter ) ; <nl> + pD3DDev - > SetSamplerState ( 0 , D3DSAMP_ADDRESSU , D3DTADDRESS_CLAMP ) ; <nl> + pD3DDev - > SetSamplerState ( 0 , D3DSAMP_ADDRESSV , D3DTADDRESS_CLAMP ) ; <nl> + <nl> + pD3DDev - > SetFVF ( D3DFVF_XYZRHW | D3DFVF_DIFFUSE | D3DFVF_SPECULAR | D3DFVF_TEX1 ) ; <nl> <nl> if ( FAILED ( hr = pD3DDev - > DrawPrimitiveUP ( D3DPT_TRIANGLEFAN , 2 , vertex , sizeof ( VERTEX ) ) ) ) <nl> CLog : : Log ( LOGERROR , __FUNCTION__ \" : DrawPrimitiveUP failed . % s \" , CRenderSystemDX : : GetErrorDescription ( hr ) . c_str ( ) ) ; <nl>\n", "msg": "[ WinRenderer ] Remove redundant assignments .\n"}
{"diff_id": 35061, "repo": "apple/swift\n", "sha": "631760b6e0172889ab867e84f93de5d42397c8ab\n", "time": "2017-02-06T05:23:44Z\n", "diff": "mmm a / lib / AST / ArchetypeBuilder . cpp <nl> ppp b / lib / AST / ArchetypeBuilder . cpp <nl> Type ArchetypeBuilder : : PotentialArchetype : : getTypeInContext ( <nl> ParentArchetype - > registerNestedType ( getName ( ) , arch ) ; <nl> } else { <nl> / / Create a top - level archetype . <nl> - arch = ArchetypeType : : getNew ( ctx , genericEnv , getName ( ) , Protos , <nl> + Identifier name = <nl> + genericParams [ getGenericParamKey ( ) . findIndexIn ( genericParams ) ] - > getName ( ) ; <nl> + arch = ArchetypeType : : getNew ( ctx , genericEnv , name , Protos , <nl> superclass , layout ) ; <nl> <nl> / / Register the archetype with the generic environment . <nl>\n", "msg": "[ Archetype builder ] Use the names of the given generic parameters\n"}
{"diff_id": 35088, "repo": "tensorflow/tensorflow\n", "sha": "2cd36d7c2a8c254d1132ac1cb5764363fd3f84fe\n", "time": "2019-03-30T00:03:47Z\n", "diff": "mmm a / lib / Analysis / AffineStructures . cpp <nl> ppp b / lib / Analysis / AffineStructures . cpp <nl> static void swapId ( FlatAffineConstraints * A , unsigned posA , unsigned posB ) { <nl> std : : swap ( A - > getId ( posA ) , A - > getId ( posB ) ) ; <nl> } <nl> <nl> - / / / Merge and align the identifiers of A and B so that both constraint systems <nl> - / / / get the union of the contained identifiers that is dimension - wise and <nl> - / / / symbol - wise unique ; both constraint systems are updated so that they have <nl> - / / / the union of all identifiers , with A ' s original identifiers appearing first <nl> - / / / followed by any of B ' s identifiers that didn ' t appear in A . Local <nl> - / / / identifiers of each system are by design separate / local and are placed one <nl> - / / / after other ( A ' s followed by B ' s ) . <nl> + / / / Merge and align the identifiers of A and B starting at ' offset ' , so that <nl> + / / / both constraint systems get the union of the contained identifiers that is <nl> + / / / dimension - wise and symbol - wise unique ; both constraint systems are updated <nl> + / / / so that they have the union of all identifiers , with A ' s original <nl> + / / / identifiers appearing first followed by any of B ' s identifiers that didn ' t <nl> + / / / appear in A . Local identifiers of each system are by design separate / local <nl> + / / / and are placed one after other ( A ' s followed by B ' s ) . <nl> / / Eg : Input : A has ( ( % i % j ) [ % M % N ] ) and B has ( % k , % j ) [ % P , % N , % M ] ) <nl> / / Output : both A , B have ( % i , % j , % k ) [ % M , % N , % P ] <nl> / / <nl> / / TODO ( mlir - team ) : expose this function at some point . <nl> - static void mergeAndAlignIds ( FlatAffineConstraints * A , <nl> + static void mergeAndAlignIds ( unsigned offset , FlatAffineConstraints * A , <nl> FlatAffineConstraints * B ) { <nl> + assert ( offset < = A - > getNumDimIds ( ) & & offset < = B - > getNumDimIds ( ) ) ; <nl> / / A merge / align isn ' t meaningful if a cst ' s ids aren ' t distinct . <nl> assert ( areIdsUnique ( * A ) & & \" A ' s id values aren ' t unique \" ) ; <nl> assert ( areIdsUnique ( * B ) & & \" B ' s id values aren ' t unique \" ) ; <nl> <nl> - assert ( std : : all_of ( A - > getIds ( ) . begin ( ) , <nl> + assert ( std : : all_of ( A - > getIds ( ) . begin ( ) + offset , <nl> A - > getIds ( ) . begin ( ) + A - > getNumDimAndSymbolIds ( ) , <nl> [ ] ( Optional < Value * > id ) { return id . hasValue ( ) ; } ) ) ; <nl> <nl> - assert ( std : : all_of ( B - > getIds ( ) . begin ( ) , <nl> + assert ( std : : all_of ( B - > getIds ( ) . begin ( ) + offset , <nl> B - > getIds ( ) . begin ( ) + B - > getNumDimAndSymbolIds ( ) , <nl> [ ] ( Optional < Value * > id ) { return id . hasValue ( ) ; } ) ) ; <nl> <nl> static void mergeAndAlignIds ( FlatAffineConstraints * A , <nl> } <nl> <nl> SmallVector < Value * , 4 > aDimValues , aSymValues ; <nl> - A - > getIdValues ( 0 , A - > getNumDimIds ( ) , & aDimValues ) ; <nl> + A - > getIdValues ( offset , A - > getNumDimIds ( ) , & aDimValues ) ; <nl> A - > getIdValues ( A - > getNumDimIds ( ) , A - > getNumDimAndSymbolIds ( ) , & aSymValues ) ; <nl> { <nl> / / Merge dims from A into B . <nl> - unsigned d = 0 ; <nl> + unsigned d = offset ; <nl> for ( auto * aDimValue : aDimValues ) { <nl> unsigned loc ; <nl> if ( B - > findId ( * aDimValue , & loc ) ) { <nl> + assert ( loc > = offset & & \" A ' s dim appears in B ' s aligned range \" ) ; <nl> assert ( loc < B - > getNumDimIds ( ) & & <nl> \" A ' s dim appears in B ' s non - dim position \" ) ; <nl> swapId ( B , d , loc ) ; <nl> bool FlatAffineConstraints : : composeMap ( AffineValueMap * vMap ) { <nl> vMap - > getOperands ( ) . end ( ) ) ; <nl> localCst . setIdValues ( 0 , localCst . getNumDimAndSymbolIds ( ) , values ) ; <nl> / / Align localCst and this . <nl> - mergeAndAlignIds ( & localCst , this ) ; <nl> + mergeAndAlignIds ( / * offset = * / 0 , & localCst , this ) ; <nl> / / Finally , append localCst to this constraint set . <nl> append ( localCst ) ; <nl> } <nl> bool FlatAffineConstraints : : addAffineForOpDomain ( <nl> } <nl> / / Merge and align with localVarCst . <nl> if ( localVarCst . getNumLocalIds ( ) > 0 ) { <nl> - mergeAndAlignIds ( this , & localVarCst ) ; <nl> + mergeAndAlignIds ( / * offset = * / 0 , this , & localVarCst ) ; <nl> append ( localVarCst ) ; <nl> } <nl> <nl> bool FlatAffineConstraints : : addSliceBounds ( ArrayRef < Value * > values , <nl> } <nl> } <nl> } <nl> - mergeAndAlignIds ( this , & localVarCst ) ; <nl> + mergeAndAlignIds ( / * offset = * / 0 , this , & localVarCst ) ; <nl> append ( localVarCst ) ; <nl> } <nl> <nl> bool FlatAffineConstraints : : unionBoundingBox ( <nl> Optional < FlatAffineConstraints > otherCopy ; <nl> if ( ! areIdsAligned ( * this , otherCst ) ) { <nl> otherCopy . emplace ( FlatAffineConstraints ( otherCst ) ) ; <nl> - mergeAndAlignIds ( this , & otherCopy . getValue ( ) ) ; <nl> + mergeAndAlignIds ( / * offset = * / numDims , this , & otherCopy . getValue ( ) ) ; <nl> } <nl> <nl> const auto & other = otherCopy ? * otherCopy : otherCst ; <nl>\n", "msg": "Adds offset argument to specified range of ids know to be aligned when calling mergeAndAlignIds ( used by FlatAffineConstraints ) .\n", "score": 1}
{"diff_id": 35094, "repo": "x64dbg/x64dbg\n", "sha": "562d68d672a6e8d418cce16db5158b735df9758d\n", "time": "2016-05-20T15:26:10Z\n", "diff": "mmm a / src / dbg / value . cpp <nl> ppp b / src / dbg / value . cpp <nl> bool valfromstring_noexpr ( const char * string , duint * value , bool silent , bool ba <nl> * value = 0 ; <nl> return true ; <nl> } <nl> - else if ( string [ 0 ] = = ' [ ' | | ( isdigit ( string [ 0 ] ) & & string [ 1 ] = = ' : ' & & string [ 2 ] = = ' [ ' ) ) / / memory location <nl> + else if ( string [ 0 ] = = ' [ ' <nl> + | | ( isdigit ( string [ 0 ] ) & & string [ 1 ] = = ' : ' & & string [ 2 ] = = ' [ ' ) <nl> + | | ( string [ 1 ] = = ' s ' & & ( string [ 0 ] = = ' c ' | | string [ 0 ] = = ' d ' | | string [ 0 ] = = ' e ' | | string [ 0 ] = = ' f ' | | string [ 0 ] = = ' g ' | | string [ 0 ] = = ' s ' ) & & string [ 2 ] = = ' : ' & & string [ 3 ] = = ' [ ' ) ) / / memory location <nl> { <nl> if ( ! DbgIsDebugging ( ) ) <nl> { <nl> bool valfromstring_noexpr ( const char * string , duint * value , bool silent , bool ba <nl> int len = ( int ) strlen ( string ) ; <nl> <nl> int read_size = sizeof ( duint ) ; <nl> - int add = 1 ; <nl> + int prefix_size = 1 ; <nl> + size_t seg_offset = 0 ; <nl> if ( string [ 1 ] = = ' : ' ) / / n : [ ( number of bytes to read ) <nl> { <nl> - add + = 2 ; <nl> + prefix_size = 3 ; <nl> int new_size = string [ 0 ] - ' 0 ' ; <nl> if ( new_size < read_size ) <nl> read_size = new_size ; <nl> } <nl> + else if ( string [ 1 ] = = ' s ' & & string [ 2 ] = = ' : ' ) <nl> + { <nl> + prefix_size = 4 ; <nl> + if ( string [ 0 ] = = ' f ' ) / / fs : [ . . . ] <nl> + { / / TODO : get real segment offset instead of assuming them <nl> + # ifdef _WIN64 <nl> + seg_offset = 0 ; <nl> + # else / / x86 <nl> + seg_offset = ( size_t ) GetTEBLocation ( hActiveThread ) ; <nl> + # endif / / _WIN64 <nl> + } <nl> + else if ( string [ 0 ] = = ' g ' ) / / gs : [ . . . ] <nl> + { <nl> + # ifdef _WIN64 <nl> + seg_offset = ( size_t ) GetTEBLocation ( hActiveThread ) ; <nl> + # else / / x86 <nl> + seg_offset = 0 ; <nl> + # endif / / _WIN64 <nl> + } <nl> + } <nl> <nl> String ptrstring ; <nl> - for ( auto i = add , depth = 1 ; i < len ; i + + ) <nl> + for ( auto i = prefix_size , depth = 1 ; i < len ; i + + ) <nl> { <nl> if ( string [ i ] = = ' [ ' ) <nl> depth + + ; <nl> bool valfromstring_noexpr ( const char * string , duint * value , bool silent , bool ba <nl> } <nl> duint addr = * value ; <nl> * value = 0 ; <nl> - if ( ! MemRead ( addr , value , read_size ) ) <nl> + if ( ! MemRead ( addr + seg_offset , value , read_size ) ) <nl> { <nl> if ( ! silent ) <nl> dputs ( \" failed to read memory \" ) ; <nl> duint valvatofileoffset ( duint va ) <nl> return ( duint ) offset ; <nl> } <nl> return 0 ; <nl> - } <nl> \\ No newline at end of file <nl> + } <nl>\n", "msg": "Make it possible to reference segment registers\n"}
{"diff_id": 35115, "repo": "MarlinFirmware/Marlin\n", "sha": "bbe2cb75adce137bfd11cd1283ca4e0f9c0ca647\n", "time": "2020-04-17T02:51:05Z\n", "diff": "mmm a / Marlin / src / module / planner . cpp <nl> ppp b / Marlin / src / module / planner . cpp <nl> bool Planner : : _populate_block ( block_t * const block , bool split_move , <nl> sin_theta_d2 = SQRT ( 0 . 5f * ( 1 . 0f - junction_cos_theta ) ) ; / / Trig half angle identity . Always positive . <nl> <nl> vmax_junction_sqr = ( junction_acceleration * junction_deviation_mm * sin_theta_d2 ) / ( 1 . 0f - sin_theta_d2 ) ; <nl> - if ( block - > millimeters < 1 ) { <nl> <nl> - / / Fast acos approximation , minus the error bar to be safe <nl> - const float junction_theta = ( RADIANS ( - 40 ) * sq ( junction_cos_theta ) - RADIANS ( 50 ) ) * junction_cos_theta + RADIANS ( 90 ) - 0 . 18f ; <nl> + if ( block - > millimeters < 1 ) { <nl> + / / Fast acos approximation ( max . error + - 0 . 033 rads ) <nl> + / / Based on MinMax polynomial published by W . Randolph Franklin , see <nl> + / / https : / / wrf . ecse . rpi . edu / Research / Short_Notes / arcsin / onlyelem . html <nl> + / / ( acos ( x ) = pi / 2 - asin ( x ) ) <nl> + <nl> + const float neg = junction_cos_theta < 0 ? - 1 : 1 , <nl> + t = neg * junction_cos_theta , <nl> + asinx = 0 . 032843707f <nl> + + t * ( - 1 . 451838349f <nl> + + t * ( 29 . 66153956f <nl> + + t * ( - 131 . 1123477f <nl> + + t * ( 262 . 8130562f <nl> + + t * ( - 242 . 7199627f + t * 84 . 31466202f ) ) ) ) ) , <nl> + junction_theta = RADIANS ( 90 ) - neg * asinx ; <nl> <nl> / / If angle is greater than 135 degrees ( octagon ) , find speed for approximate arc <nl> if ( junction_theta > RADIANS ( 135 ) ) { <nl> + / / NOTE : MinMax acos approximation and thereby also junction_theta top out at pi - 0 . 033 , which avoids division by 0 <nl> const float limit_sqr = block - > millimeters / ( RADIANS ( 180 ) - junction_theta ) * junction_acceleration ; <nl> NOMORE ( vmax_junction_sqr , limit_sqr ) ; <nl> } <nl>\n", "msg": "More accurate Junction Deviation fast - acos ( )\n"}
{"diff_id": 35173, "repo": "qbittorrent/qBittorrent\n", "sha": "5e487089208056f8dbd0eba2812651019e705f85\n", "time": "2012-02-18T18:38:21Z\n", "diff": "mmm a / src / loglistwidget . cpp <nl> ppp b / src / loglistwidget . cpp <nl> void LogListWidget : : keyPressEvent ( QKeyEvent * event ) <nl> <nl> void LogListWidget : : appendLine ( const QString & line ) <nl> { <nl> - QListWidgetItem * item = new QListWidgetItem ( this ) ; <nl> + QListWidgetItem * item = new QListWidgetItem ; <nl> / / We need to use QLabel here to support rich text <nl> QLabel * lbl = new QLabel ( line ) ; <nl> lbl - > setContentsMargins ( 4 , 2 , 4 , 2 ) ; <nl>\n", "msg": "Prevent log window buffer from filling up ( Closes )\n"}
{"diff_id": 35191, "msg": "Add partitioned logs to BackupContainer\n", "msgGPT": "refactor log file listing function to support partitioned and non-partitioned logs.", "METEOR Score": "23.56043562873154", "BLEU Score": "0.27223829037245595", "ROUGE-L Score": "0.23529411307958487", "score": 1, "repo": "apple/foundationdb\n", "sha": "ec352c03c9fa971785eef1bb49e4b4490327561c\n", "time": "2020-03-21T03:13:38Z\n", "diff": "mmm a / fdbclient / BackupContainer . actor . cpp <nl> ppp b / fdbclient / BackupContainer . actor . cpp <nl> std : : string BackupDescription : : toJSON ( ) const { <nl> * file written will be after the start version of the snapshot ' s execution . <nl> * <nl> * Log files are at file paths like <nl> - * / logs / . . . / log , startVersion , endVersion , blockSize <nl> + * / plogs / . . . log , startVersion , endVersion , UID , blocksize , tagID <nl> + * / logs / . . . / log , startVersion , endVersion , UID , blockSize <nl> * where . . . is a multi level path which sorts lexically into version order and results in approximately 1 <nl> - * unique folder per day containing about 5 , 000 files . <nl> + * unique folder per day containing about 5 , 000 files . Logs after 7 . 0 are stored in \" plogs \" <nl> + * directory and are partitioned according to tagIDs ( 0 , 1 , 2 , . . . ) . Logs before 7 . 0 are <nl> + * stored in \" logs \" directory and are not partitioned . <nl> + * <nl> * <nl> * BACKWARD COMPATIBILITY <nl> * <nl> class BackupContainerFileSystem : public IBackupContainer { <nl> } <nl> <nl> / / The innermost folder covers 100 , 000 seconds ( 1e11 versions ) which is 5 , 000 mutation log files at current settings . <nl> - static std : : string logVersionFolderString ( Version v , bool mlogs ) { <nl> - return format ( \" % s / % s / \" , ( mlogs ? \" mlogs \" : \" logs \" ) , versionFolderString ( v , 11 ) . c_str ( ) ) ; <nl> + static std : : string logVersionFolderString ( Version v , bool partitioned ) { <nl> + return format ( \" % s / % s / \" , ( partitioned ? \" plogs \" : \" logs \" ) , versionFolderString ( v , 11 ) . c_str ( ) ) ; <nl> } <nl> <nl> - Future < Reference < IBackupFile > > writeLogFile ( Version beginVersion , Version endVersion , int blockSize ) override { <nl> + Future < Reference < IBackupFile > > writeLogFile ( Version beginVersion , Version endVersion , int blockSize ) final { <nl> return writeFile ( logVersionFolderString ( beginVersion , false ) + <nl> format ( \" log , % lld , % lld , % s , % d \" , beginVersion , endVersion , <nl> deterministicRandom ( ) - > randomUniqueID ( ) . toString ( ) . c_str ( ) , blockSize ) ) ; <nl> } <nl> <nl> Future < Reference < IBackupFile > > writeTaggedLogFile ( Version beginVersion , Version endVersion , int blockSize , <nl> - uint16_t tagId ) override { <nl> + uint16_t tagId ) final { <nl> return writeFile ( logVersionFolderString ( beginVersion , true ) + <nl> format ( \" log , % lld , % lld , % s , % d , % d \" , beginVersion , endVersion , <nl> deterministicRandom ( ) - > randomUniqueID ( ) . toString ( ) . c_str ( ) , blockSize , tagId ) ) ; <nl> class BackupContainerFileSystem : public IBackupContainer { <nl> return writeKeyspaceSnapshotFile_impl ( Reference < BackupContainerFileSystem > : : addRef ( this ) , fileNames , totalBytes ) ; <nl> } ; <nl> <nl> - / / List log files , unsorted , which contain data at any version > = beginVersion and < = targetVersion <nl> - Future < std : : vector < LogFile > > listLogFiles ( Version beginVersion = 0 , Version targetVersion = std : : numeric_limits < Version > : : max ( ) ) { <nl> - / / The first relevant log file could have a begin version less than beginVersion based on the knobs which determine log file range size , <nl> - / / so start at an earlier version adjusted by how many versions a file could contain . <nl> + / / List log files , unsorted , which contain data at any version > = beginVersion and < = targetVersion . <nl> + / / \" partitioned \" flag indicates if new partitioned mutation logs or old logs should be listed . <nl> + Future < std : : vector < LogFile > > listLogFiles ( Version beginVersion , Version targetVersion , bool partitioned ) { <nl> + / / The first relevant log file could have a begin version less than beginVersion based on the knobs which <nl> + / / determine log file range size , so start at an earlier version adjusted by how many versions a file could <nl> + / / contain . <nl> / / <nl> / / Get the cleaned ( without slashes ) first and last folders that could contain relevant results . <nl> - bool mlogs = false ; / / tagged mutation logs <nl> std : : string firstPath = cleanFolderString ( <nl> logVersionFolderString ( std : : max < Version > ( 0 , beginVersion - CLIENT_KNOBS - > BACKUP_MAX_LOG_RANGES * <nl> CLIENT_KNOBS - > LOG_RANGE_BLOCK_SIZE ) , <nl> - mlogs ) ) ; <nl> - std : : string lastPath = cleanFolderString ( logVersionFolderString ( targetVersion , mlogs ) ) ; <nl> + partitioned ) ) ; <nl> + std : : string lastPath = cleanFolderString ( logVersionFolderString ( targetVersion , partitioned ) ) ; <nl> <nl> std : : function < bool ( std : : string const & ) > pathFilter = [ = ] ( const std : : string & folderPath ) { <nl> / / Remove slashes in the given folder path so that the ' / ' positions in the version folder string do not matter <nl> class BackupContainerFileSystem : public IBackupContainer { <nl> | | ( cleaned > firstPath & & cleaned < lastPath ) ; <nl> } ; <nl> <nl> - return map ( listFiles ( \" logs / \" , pathFilter ) , [ = ] ( const FilesAndSizesT & files ) { <nl> + return map ( listFiles ( ( partitioned ? \" plogs / \" : \" logs / \" ) , pathFilter ) , [ = ] ( const FilesAndSizesT & files ) { <nl> std : : vector < LogFile > results ; <nl> LogFile lf ; <nl> for ( auto & f : files ) { <nl> class BackupContainerFileSystem : public IBackupContainer { <nl> ACTOR static Future < BackupFileList > dumpFileList_impl ( Reference < BackupContainerFileSystem > bc , Version begin , Version end ) { <nl> state Future < std : : vector < RangeFile > > fRanges = bc - > listRangeFiles ( begin , end ) ; <nl> state Future < std : : vector < KeyspaceSnapshotFile > > fSnapshots = bc - > listKeyspaceSnapshots ( begin , end ) ; <nl> - state Future < std : : vector < LogFile > > fLogs = bc - > listLogFiles ( begin , end ) ; <nl> + state std : : vector < LogFile > logs ; <nl> + state std : : vector < LogFile > pLogs ; <nl> <nl> - wait ( success ( fRanges ) & & success ( fSnapshots ) & & success ( fLogs ) ) ; <nl> + wait ( success ( fRanges ) & & success ( fSnapshots ) & & <nl> + store ( logs , bc - > listLogFiles ( begin , end , false ) ) & & <nl> + store ( pLogs , bc - > listLogFiles ( begin , end , true ) ) ) ; <nl> + logs . insert ( logs . end ( ) , std : : make_move_iterator ( pLogs . begin ( ) ) , std : : make_move_iterator ( pLogs . end ( ) ) ) ; <nl> <nl> - return BackupFileList ( { fRanges . get ( ) , fLogs . get ( ) , fSnapshots . get ( ) } ) ; <nl> + return BackupFileList ( { fRanges . get ( ) , std : : move ( logs ) , fSnapshots . get ( ) } ) ; <nl> } <nl> <nl> Future < BackupFileList > dumpFileList ( Version begin , Version end ) override { <nl> class BackupContainerFileSystem : public IBackupContainer { <nl> } <nl> <nl> state std : : vector < LogFile > logs ; <nl> - wait ( store ( logs , bc - > listLogFiles ( scanBegin , scanEnd ) ) & & store ( desc . snapshots , bc - > listKeyspaceSnapshots ( ) ) ) ; <nl> + state std : : vector < LogFile > pLogs ; <nl> + wait ( store ( logs , bc - > listLogFiles ( scanBegin , scanEnd , false ) ) & & <nl> + store ( pLogs , bc - > listLogFiles ( scanBegin , scanEnd , true ) ) & & <nl> + store ( desc . snapshots , bc - > listKeyspaceSnapshots ( ) ) ) ; <nl> + / / FIXME : check partitioned logs & maybe enable the below line <nl> + / / logs . insert ( logs . end ( ) , std : : make_move_iterator ( pLogs . begin ( ) ) , std : : make_move_iterator ( pLogs . end ( ) ) ) ; <nl> <nl> / / List logs in version order so log continuity can be analyzed <nl> std : : sort ( logs . begin ( ) , logs . end ( ) ) ; <nl> class BackupContainerFileSystem : public IBackupContainer { <nl> state BackupDescription desc = wait ( bc - > describeBackup ( false , expireEndVersion ) ) ; <nl> <nl> / / Resolve relative versions using max log version <nl> - expireEndVersion = resolveRelativeVersion ( desc . maxLogEnd , expireEndVersion , \" ExpireEndVersion \" , invalid_option_value ( ) ) ; <nl> - restorableBeginVersion = resolveRelativeVersion ( desc . maxLogEnd , restorableBeginVersion , \" RestorableBeginVersion \" , invalid_option_value ( ) ) ; <nl> + expireEndVersion = <nl> + resolveRelativeVersion ( desc . maxLogEnd , expireEndVersion , \" ExpireEndVersion \" , invalid_option_value ( ) ) ; <nl> + restorableBeginVersion = resolveRelativeVersion ( desc . maxLogEnd , restorableBeginVersion , <nl> + \" RestorableBeginVersion \" , invalid_option_value ( ) ) ; <nl> <nl> / / It would be impossible to have restorability to any version < expireEndVersion after expiring to that version <nl> if ( restorableBeginVersion < expireEndVersion ) <nl> class BackupContainerFileSystem : public IBackupContainer { <nl> . detail ( \" ScanBeginVersion \" , scanBegin ) ; <nl> <nl> state std : : vector < LogFile > logs ; <nl> + state std : : vector < LogFile > pLogs ; / / partitioned mutation logs <nl> state std : : vector < RangeFile > ranges ; <nl> <nl> if ( progress ! = nullptr ) { <nl> progress - > step = \" Listing files \" ; <nl> } <nl> / / Get log files or range files that contain any data at or before expireEndVersion <nl> - wait ( store ( logs , bc - > listLogFiles ( scanBegin , expireEndVersion - 1 ) ) & & store ( ranges , bc - > listRangeFiles ( scanBegin , expireEndVersion - 1 ) ) ) ; <nl> + wait ( store ( logs , bc - > listLogFiles ( scanBegin , expireEndVersion - 1 , false ) ) & & <nl> + store ( pLogs , bc - > listLogFiles ( scanBegin , expireEndVersion - 1 , true ) ) & & <nl> + store ( ranges , bc - > listRangeFiles ( scanBegin , expireEndVersion - 1 ) ) ) ; <nl> + logs . insert ( logs . end ( ) , std : : make_move_iterator ( pLogs . begin ( ) ) , std : : make_move_iterator ( pLogs . end ( ) ) ) ; <nl> <nl> / / The new logBeginVersion will be taken from the last log file , if there is one <nl> state Optional < Version > newLogBeginVersion ; <nl> class BackupContainerFileSystem : public IBackupContainer { <nl> return Optional < RestorableFileSet > ( restorable ) ; <nl> } <nl> <nl> - state std : : vector < LogFile > logs = wait ( bc - > listLogFiles ( snapshot . get ( ) . beginVersion , targetVersion ) ) ; <nl> + / / FIXME : check if there are tagged logs . for each tag , there is no version gap . <nl> + state std : : vector < LogFile > logs = wait ( bc - > listLogFiles ( snapshot . get ( ) . beginVersion , targetVersion , false ) ) ; <nl> <nl> / / List logs in version order so log continuity can be analyzed <nl> std : : sort ( logs . begin ( ) , logs . end ( ) ) ; <nl> class BackupContainerFileSystem : public IBackupContainer { <nl> return Optional < RestorableFileSet > ( ) ; <nl> } <nl> <nl> - Future < Optional < RestorableFileSet > > getRestoreSet ( Version targetVersion ) override { <nl> + Future < Optional < RestorableFileSet > > getRestoreSet ( Version targetVersion ) final { <nl> return getRestoreSet_impl ( Reference < BackupContainerFileSystem > : : addRef ( this ) , targetVersion ) ; <nl> } <nl> <nl> class BackupContainerFileSystem : public IBackupContainer { <nl> <nl> class BackupContainerLocalDirectory : public BackupContainerFileSystem , ReferenceCounted < BackupContainerLocalDirectory > { <nl> public : <nl> - void addref ( ) override { return ReferenceCounted < BackupContainerLocalDirectory > : : addref ( ) ; } <nl> - void delref ( ) override { return ReferenceCounted < BackupContainerLocalDirectory > : : delref ( ) ; } <nl> + void addref ( ) final { return ReferenceCounted < BackupContainerLocalDirectory > : : addref ( ) ; } <nl> + void delref ( ) final { return ReferenceCounted < BackupContainerLocalDirectory > : : delref ( ) ; } <nl> <nl> static std : : string getURLFormat ( ) { return \" file : / / < / path / to / base / dir / > \" ; } <nl> <nl> class BackupContainerLocalDirectory : public BackupContainerFileSystem , Referenc <nl> return results ; <nl> } <nl> <nl> - Future < Void > create ( ) override { <nl> + Future < Void > create ( ) final { <nl> / / Nothing should be done here because create ( ) can be called by any process working with the container URL , such as fdbbackup . <nl> / / Since \" local directory \" containers are by definition local to the machine they are accessed from , <nl> / / the container ' s creation ( in this case the creation of a directory ) must be ensured prior to every file creation , <nl> class BackupContainerLocalDirectory : public BackupContainerFileSystem , Referenc <nl> } <nl> <nl> / / The container exists if the folder it resides in exists <nl> - Future < bool > exists ( ) override { <nl> + Future < bool > exists ( ) final { <nl> return directoryExists ( m_path ) ; <nl> } <nl> <nl> - Future < Reference < IAsyncFile > > readFile ( std : : string path ) override { <nl> + Future < Reference < IAsyncFile > > readFile ( std : : string path ) final { <nl> int flags = IAsyncFile : : OPEN_NO_AIO | IAsyncFile : : OPEN_READONLY | IAsyncFile : : OPEN_UNCACHED ; <nl> / / Simulation does not properly handle opening the same file from multiple machines using a shared filesystem , <nl> / / so create a symbolic link to make each file opening appear to be unique . This could also work in production <nl> class BackupContainerLocalDirectory : public BackupContainerFileSystem , Referenc <nl> int blockSize = 0 ; <nl> / / Extract block size from the filename , if present <nl> size_t lastComma = path . find_last_of ( ' , ' ) ; <nl> - if ( lastComma ! = path . npos ) { <nl> + if ( lastComma ! = path . npos ) { <nl> blockSize = atoi ( path . substr ( lastComma + 1 ) . c_str ( ) ) ; <nl> } <nl> - if ( blockSize < = 0 ) { <nl> + if ( blockSize < = 0 ) { <nl> blockSize = deterministicRandom ( ) - > randomInt ( 1e4 , 1e6 ) ; <nl> } <nl> if ( deterministicRandom ( ) - > random01 ( ) < . 01 ) { <nl> class BackupContainerLocalDirectory : public BackupContainerFileSystem , Referenc <nl> std : : string m_finalFullPath ; <nl> } ; <nl> <nl> - Future < Reference < IBackupFile > > writeFile ( std : : string path ) override { <nl> + Future < Reference < IBackupFile > > writeFile ( std : : string path ) final { <nl> int flags = IAsyncFile : : OPEN_NO_AIO | IAsyncFile : : OPEN_CREATE | IAsyncFile : : OPEN_ATOMIC_WRITE_AND_CREATE | IAsyncFile : : OPEN_READWRITE ; <nl> std : : string fullPath = joinPath ( m_path , path ) ; <nl> platform : : createDirectory ( parentDirectory ( fullPath ) ) ; <nl> class BackupContainerLocalDirectory : public BackupContainerFileSystem , Referenc <nl> } ) ; <nl> } <nl> <nl> - Future < Void > deleteFile ( std : : string path ) override { <nl> + Future < Void > deleteFile ( std : : string path ) final { <nl> : : deleteFile ( joinPath ( m_path , path ) ) ; <nl> return Void ( ) ; <nl> } <nl> <nl> - Future < FilesAndSizesT > listFiles ( std : : string path , std : : function < bool ( std : : string const & ) > ) { <nl> + Future < FilesAndSizesT > listFiles ( std : : string path , std : : function < bool ( std : : string const & ) > ) final { <nl> FilesAndSizesT results ; <nl> <nl> std : : vector < std : : string > files ; <nl> class BackupContainerLocalDirectory : public BackupContainerFileSystem , Referenc <nl> return results ; <nl> } <nl> <nl> - Future < Void > deleteContainer ( int * pNumDeleted ) override { <nl> + Future < Void > deleteContainer ( int * pNumDeleted ) final { <nl> / / In order to avoid deleting some random directory due to user error , first describe the backup <nl> / / and make sure it has something in it . <nl> return map ( describeBackup ( false , invalidVersion ) , [ = ] ( BackupDescription const & desc ) { <nl> class BackupContainerBlobStore : public BackupContainerFileSystem , ReferenceCoun <nl> } <nl> } <nl> <nl> - void addref ( ) override { return ReferenceCounted < BackupContainerBlobStore > : : addref ( ) ; } <nl> - void delref ( ) override { return ReferenceCounted < BackupContainerBlobStore > : : delref ( ) ; } <nl> + void addref ( ) final { return ReferenceCounted < BackupContainerBlobStore > : : addref ( ) ; } <nl> + void delref ( ) final { return ReferenceCounted < BackupContainerBlobStore > : : delref ( ) ; } <nl> <nl> static std : : string getURLFormat ( ) { <nl> return BlobStoreEndpoint : : getURLFormat ( true ) + \" ( Note : The ' bucket ' parameter is required . ) \" ; <nl> class BackupContainerBlobStore : public BackupContainerFileSystem , ReferenceCoun <nl> <nl> virtual ~ BackupContainerBlobStore ( ) { } <nl> <nl> - Future < Reference < IAsyncFile > > readFile ( std : : string path ) override { <nl> + Future < Reference < IAsyncFile > > readFile ( std : : string path ) final { <nl> return Reference < IAsyncFile > ( <nl> new AsyncFileReadAheadCache ( <nl> Reference < IAsyncFile > ( new AsyncFileBlobStoreRead ( m_bstore , m_bucket , dataPath ( path ) ) ) , <nl> class BackupContainerBlobStore : public BackupContainerFileSystem , ReferenceCoun <nl> return map ( m_file - > sync ( ) , [ = ] ( Void _ ) { self - > m_file . clear ( ) ; return Void ( ) ; } ) ; <nl> } <nl> <nl> - void addref ( ) override { return ReferenceCounted < BackupFile > : : addref ( ) ; } <nl> - void delref ( ) override { return ReferenceCounted < BackupFile > : : delref ( ) ; } <nl> + void addref ( ) final { return ReferenceCounted < BackupFile > : : addref ( ) ; } <nl> + void delref ( ) final { return ReferenceCounted < BackupFile > : : delref ( ) ; } <nl> + <nl> private : <nl> Reference < IAsyncFile > m_file ; <nl> } ; <nl> <nl> - Future < Reference < IBackupFile > > writeFile ( std : : string path ) override { <nl> + Future < Reference < IBackupFile > > writeFile ( std : : string path ) final { <nl> return Reference < IBackupFile > ( new BackupFile ( path , Reference < IAsyncFile > ( new AsyncFileBlobStoreWrite ( m_bstore , m_bucket , dataPath ( path ) ) ) ) ) ; <nl> } <nl> <nl> - Future < Void > deleteFile ( std : : string path ) override { <nl> + Future < Void > deleteFile ( std : : string path ) final { <nl> return m_bstore - > deleteObject ( m_bucket , dataPath ( path ) ) ; <nl> } <nl> <nl> class BackupContainerBlobStore : public BackupContainerFileSystem , ReferenceCoun <nl> return files ; <nl> } <nl> <nl> - Future < FilesAndSizesT > listFiles ( std : : string path , std : : function < bool ( std : : string const & ) > pathFilter ) { <nl> + Future < FilesAndSizesT > listFiles ( std : : string path , std : : function < bool ( std : : string const & ) > pathFilter ) final { <nl> return listFiles_impl ( Reference < BackupContainerBlobStore > : : addRef ( this ) , path , pathFilter ) ; <nl> } <nl> <nl> class BackupContainerBlobStore : public BackupContainerFileSystem , ReferenceCoun <nl> return Void ( ) ; <nl> } <nl> <nl> - Future < Void > create ( ) override { <nl> + Future < Void > create ( ) final { <nl> return create_impl ( Reference < BackupContainerBlobStore > : : addRef ( this ) ) ; <nl> } <nl> <nl> / / The container exists if the index entry in the blob bucket exists <nl> - Future < bool > exists ( ) override { <nl> + Future < bool > exists ( ) final { <nl> return m_bstore - > objectExists ( m_bucket , indexEntry ( ) ) ; <nl> } <nl> <nl> class BackupContainerBlobStore : public BackupContainerFileSystem , ReferenceCoun <nl> return Void ( ) ; <nl> } <nl> <nl> - Future < Void > deleteContainer ( int * pNumDeleted ) override { <nl> + Future < Void > deleteContainer ( int * pNumDeleted ) final { <nl> return deleteContainer_impl ( Reference < BackupContainerBlobStore > : : addRef ( this ) , pNumDeleted ) ; <nl> } <nl> <nl>\n"}
{"diff_id": 35254, "repo": "tensorflow/tensorflow\n", "sha": "15150c62937eb5095e703edc096cd14849999811\n", "time": "2019-10-25T16:37:42Z\n", "diff": "mmm a / third_party / mlir / lib / Parser / Parser . cpp <nl> ppp b / third_party / mlir / lib / Parser / Parser . cpp <nl> Value * OperationParser : : createForwardRefPlaceholder ( SMLoc loc , Type type ) { <nl> / / / <nl> ParseResult OperationParser : : parseOperation ( ) { <nl> auto loc = getToken ( ) . getLoc ( ) ; <nl> - SmallVector < std : : pair < StringRef , SMLoc > , 1 > resultIDs ; <nl> - size_t numExpectedResults ; <nl> + SmallVector < std : : tuple < StringRef , unsigned , SMLoc > , 1 > resultIDs ; <nl> + size_t numExpectedResults = 0 ; <nl> if ( getToken ( ) . is ( Token : : percent_identifier ) ) { <nl> - / / Parse the first result id . <nl> - resultIDs . emplace_back ( getTokenSpelling ( ) , loc ) ; <nl> - consumeToken ( Token : : percent_identifier ) ; <nl> - <nl> - / / If the next token is a ' : ' , we parse the expected result count . <nl> - if ( consumeIf ( Token : : colon ) ) { <nl> - / / Check that the next token is an integer . <nl> - if ( ! getToken ( ) . is ( Token : : integer ) ) <nl> - return emitError ( \" expected integer number of results \" ) ; <nl> - <nl> - / / Check that number of results is > 0 . <nl> - auto val = getToken ( ) . getUInt64IntegerValue ( ) ; <nl> - if ( ! val . hasValue ( ) | | val . getValue ( ) < 1 ) <nl> - return emitError ( \" expected named operation to have atleast 1 result \" ) ; <nl> - consumeToken ( Token : : integer ) ; <nl> - numExpectedResults = * val ; <nl> - } else { <nl> - / / Otherwise , this is a comma separated list of result ids . <nl> - if ( consumeIf ( Token : : comma ) ) { <nl> - auto parseNextResult = [ & ] ( ) - > ParseResult { <nl> - / / Parse the next result id . <nl> - if ( ! getToken ( ) . is ( Token : : percent_identifier ) ) <nl> - return emitError ( \" expected valid ssa identifier \" ) ; <nl> - <nl> - resultIDs . emplace_back ( getTokenSpelling ( ) , getToken ( ) . getLoc ( ) ) ; <nl> - consumeToken ( Token : : percent_identifier ) ; <nl> - return success ( ) ; <nl> - } ; <nl> - <nl> - if ( parseCommaSeparatedList ( parseNextResult ) ) <nl> - return failure ( ) ; <nl> + / / Parse the group of result ids . <nl> + auto parseNextResult = [ & ] ( ) - > ParseResult { <nl> + / / Parse the next result id . <nl> + if ( ! getToken ( ) . is ( Token : : percent_identifier ) ) <nl> + return emitError ( \" expected valid ssa identifier \" ) ; <nl> + <nl> + Token nameTok = getToken ( ) ; <nl> + consumeToken ( Token : : percent_identifier ) ; <nl> + <nl> + / / If the next token is a ' : ' , we parse the expected result count . <nl> + size_t expectedSubResults = 1 ; <nl> + if ( consumeIf ( Token : : colon ) ) { <nl> + / / Check that the next token is an integer . <nl> + if ( ! getToken ( ) . is ( Token : : integer ) ) <nl> + return emitError ( \" expected integer number of results \" ) ; <nl> + <nl> + / / Check that number of results is > 0 . <nl> + auto val = getToken ( ) . getUInt64IntegerValue ( ) ; <nl> + if ( ! val . hasValue ( ) | | val . getValue ( ) < 1 ) <nl> + return emitError ( \" expected named operation to have atleast 1 result \" ) ; <nl> + consumeToken ( Token : : integer ) ; <nl> + expectedSubResults = * val ; <nl> } <nl> - numExpectedResults = resultIDs . size ( ) ; <nl> - } <nl> + <nl> + resultIDs . emplace_back ( nameTok . getSpelling ( ) , expectedSubResults , <nl> + nameTok . getLoc ( ) ) ; <nl> + numExpectedResults + = expectedSubResults ; <nl> + return success ( ) ; <nl> + } ; <nl> + if ( parseCommaSeparatedList ( parseNextResult ) ) <nl> + return failure ( ) ; <nl> <nl> if ( parseToken ( Token : : equal , \" expected ' = ' after SSA name \" ) ) <nl> return failure ( ) ; <nl> ParseResult OperationParser : : parseOperation ( ) { <nl> < < op - > getNumResults ( ) < < \" results but was provided \" <nl> < < numExpectedResults < < \" to bind \" ; <nl> <nl> - / / If the number of result names matches the number of operation results , we <nl> - / / can directly use the provided names . <nl> - if ( resultIDs . size ( ) = = op - > getNumResults ( ) ) { <nl> - for ( unsigned i = 0 , e = op - > getNumResults ( ) ; i ! = e ; + + i ) <nl> - if ( addDefinition ( { resultIDs [ i ] . first , 0 , resultIDs [ i ] . second } , <nl> - op - > getResult ( i ) ) ) <nl> - return failure ( ) ; <nl> - } else { <nl> - / / Otherwise , we use the same name for all results . <nl> - StringRef name = resultIDs . front ( ) . first ; <nl> - for ( unsigned i = 0 , e = op - > getNumResults ( ) ; i ! = e ; + + i ) <nl> - if ( addDefinition ( { name , i , loc } , op - > getResult ( i ) ) ) <nl> + / / Add definitions for each of the result groups . <nl> + unsigned opResI = 0 ; <nl> + for ( std : : tuple < StringRef , unsigned , SMLoc > & resIt : resultIDs ) { <nl> + for ( unsigned subRes : llvm : : seq < unsigned > ( 0 , std : : get < 1 > ( resIt ) ) ) { <nl> + if ( addDefinition ( { std : : get < 0 > ( resIt ) , subRes , std : : get < 2 > ( resIt ) } , <nl> + op - > getResult ( opResI + + ) ) ) <nl> return failure ( ) ; <nl> + } <nl> } <nl> } <nl> <nl>\n", "msg": "Add support for parsing multiple result name groups .\n"}
{"diff_id": 35405, "repo": "apple/swift\n", "sha": "2b5b6d0c4cbc016386e9fa8ef323e735f683d6d1\n", "time": "2014-03-01T00:51:23Z\n", "diff": "mmm a / lib / Sema / TypeCheckDecl . cpp <nl> ppp b / lib / Sema / TypeCheckDecl . cpp <nl> class DeclChecker : public DeclVisitor < DeclChecker > { <nl> } <nl> <nl> / / Diagnose any abstract constructors from our superclass that have <nl> - / / not been overridden . <nl> + / / not been overridden or inherited . <nl> bool diagnosed = false ; <nl> for ( auto superclassMember : TC . lookupConstructors ( superclassTy , CD ) ) { <nl> / / We only care about abstract constructors . <nl> class DeclChecker : public DeclVisitor < DeclChecker > { <nl> if ( overriddenCtors . count ( superclassCtor ) > 0 ) <nl> continue ; <nl> <nl> + / / If the superclass constructor is a complete object initializer <nl> + / / that is inherited into the current class , it ' s okay . <nl> + if ( superclassCtor - > isCompleteObjectInit ( ) & & <nl> + CD - > inheritsSuperclassInitializers ( & TC ) ) <nl> + continue ; <nl> + <nl> / / Complain that we don ' t have an overriding constructor . <nl> if ( ! diagnosed ) { <nl> TC . diagnose ( CD , diag : : abstract_incomplete_implementation , <nl>\n", "msg": "A complete object initializer can satisfy an @ abstract initializer requirement for a subclass .\n"}
{"diff_id": 35509, "repo": "yuzu-emu/yuzu\n", "sha": "01f297f2e01873a36769de728c3cac32c667e3e1\n", "time": "2020-07-16T22:49:42Z\n", "diff": "mmm a / src / video_core / renderer_vulkan / vk_rasterizer . cpp <nl> ppp b / src / video_core / renderer_vulkan / vk_rasterizer . cpp <nl> VkViewport GetViewportState ( const VKDevice & device , const Maxwell & regs , std : : si <nl> const auto & src = regs . viewport_transform [ index ] ; <nl> const float width = src . scale_x * 2 . 0f ; <nl> const float height = src . scale_y * 2 . 0f ; <nl> + const float reduce_z = regs . depth_mode = = Maxwell : : DepthMode : : MinusOneToOne ? 1 . 0f : 0 . 0f ; <nl> <nl> - VkViewport viewport ; <nl> - viewport . x = src . translate_x - src . scale_x ; <nl> - viewport . y = src . translate_y - src . scale_y ; <nl> - viewport . width = width ! = 0 . 0f ? width : 1 . 0f ; <nl> - viewport . height = height ! = 0 . 0f ? height : 1 . 0f ; <nl> + VkViewport viewport { <nl> + . x = src . translate_x - src . scale_x , <nl> + . y = src . translate_y - src . scale_y , <nl> + . width = width ! = 0 . 0f ? width : 1 . 0f , <nl> + . height = height ! = 0 . 0f ? height : 1 . 0f , <nl> + . minDepth = src . translate_z - src . scale_z * reduce_z , <nl> + . maxDepth = src . translate_z + src . scale_z , <nl> + } ; <nl> <nl> - const float reduce_z = regs . depth_mode = = Maxwell : : DepthMode : : MinusOneToOne ? 1 . 0f : 0 . 0f ; <nl> - viewport . minDepth = src . translate_z - src . scale_z * reduce_z ; <nl> - viewport . maxDepth = src . translate_z + src . scale_z ; <nl> if ( ! device . IsExtDepthRangeUnrestrictedSupported ( ) ) { <nl> viewport . minDepth = std : : clamp ( viewport . minDepth , 0 . 0f , 1 . 0f ) ; <nl> viewport . maxDepth = std : : clamp ( viewport . maxDepth , 0 . 0f , 1 . 0f ) ; <nl> } <nl> + <nl> return viewport ; <nl> } <nl> <nl> void RasterizerVulkan : : Clear ( ) { <nl> <nl> const u32 color_attachment = regs . clear_buffers . RT ; <nl> scheduler . Record ( [ color_attachment , clear_value , clear_rect ] ( vk : : CommandBuffer cmdbuf ) { <nl> - VkClearAttachment attachment ; <nl> - attachment . aspectMask = VK_IMAGE_ASPECT_COLOR_BIT ; <nl> - attachment . colorAttachment = color_attachment ; <nl> - attachment . clearValue = clear_value ; <nl> + const VkClearAttachment attachment { <nl> + . aspectMask = VK_IMAGE_ASPECT_COLOR_BIT , <nl> + . colorAttachment = color_attachment , <nl> + . clearValue = clear_value , <nl> + } ; <nl> cmdbuf . ClearAttachments ( attachment , clear_rect ) ; <nl> } ) ; <nl> } <nl> void RasterizerVulkan : : DispatchCompute ( GPUVAddr code_addr ) { <nl> query_cache . UpdateCounters ( ) ; <nl> <nl> const auto & launch_desc = system . GPU ( ) . KeplerCompute ( ) . launch_description ; <nl> - ComputePipelineCacheKey key ; <nl> - key . shader = code_addr ; <nl> - key . shared_memory_size = launch_desc . shared_alloc ; <nl> - key . workgroup_size = { launch_desc . block_dim_x , launch_desc . block_dim_y , <nl> - launch_desc . block_dim_z } ; <nl> - <nl> - auto & pipeline = pipeline_cache . GetComputePipeline ( key ) ; <nl> + auto & pipeline = pipeline_cache . GetComputePipeline ( { <nl> + . shader = code_addr , <nl> + . shared_memory_size = launch_desc . shared_alloc , <nl> + . workgroup_size = <nl> + { <nl> + launch_desc . block_dim_x , <nl> + launch_desc . block_dim_y , <nl> + launch_desc . block_dim_z , <nl> + } , <nl> + } ) ; <nl> <nl> / / Compute dispatches can ' t be executed inside a renderpass <nl> scheduler . RequestOutsideRenderPassOperationContext ( ) ; <nl> std : : tuple < VkFramebuffer , VkExtent2D > RasterizerVulkan : : ConfigureFramebuffers ( <nl> const auto [ fbentry , is_cache_miss ] = framebuffer_cache . try_emplace ( key ) ; <nl> auto & framebuffer = fbentry - > second ; <nl> if ( is_cache_miss ) { <nl> - VkFramebufferCreateInfo framebuffer_ci ; <nl> - framebuffer_ci . sType = VK_STRUCTURE_TYPE_FRAMEBUFFER_CREATE_INFO ; <nl> - framebuffer_ci . pNext = nullptr ; <nl> - framebuffer_ci . flags = 0 ; <nl> - framebuffer_ci . renderPass = key . renderpass ; <nl> - framebuffer_ci . attachmentCount = static_cast < u32 > ( key . views . size ( ) ) ; <nl> - framebuffer_ci . pAttachments = key . views . data ( ) ; <nl> - framebuffer_ci . width = key . width ; <nl> - framebuffer_ci . height = key . height ; <nl> - framebuffer_ci . layers = key . layers ; <nl> - framebuffer = device . GetLogical ( ) . CreateFramebuffer ( framebuffer_ci ) ; <nl> + framebuffer = device . GetLogical ( ) . CreateFramebuffer ( { <nl> + . sType = VK_STRUCTURE_TYPE_FRAMEBUFFER_CREATE_INFO , <nl> + . pNext = nullptr , <nl> + . flags = 0 , <nl> + . renderPass = key . renderpass , <nl> + . attachmentCount = static_cast < u32 > ( key . views . size ( ) ) , <nl> + . pAttachments = key . views . data ( ) , <nl> + . width = key . width , <nl> + . height = key . height , <nl> + . layers = key . layers , <nl> + } ) ; <nl> } <nl> <nl> return { * framebuffer , VkExtent2D { key . width , key . height } } ; <nl> VkBuffer RasterizerVulkan : : DefaultBuffer ( ) { <nl> return * default_buffer ; <nl> } <nl> <nl> - VkBufferCreateInfo ci ; <nl> - ci . sType = VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO ; <nl> - ci . pNext = nullptr ; <nl> - ci . flags = 0 ; <nl> - ci . size = DEFAULT_BUFFER_SIZE ; <nl> - ci . usage = VK_BUFFER_USAGE_TRANSFER_DST_BIT | VK_BUFFER_USAGE_VERTEX_BUFFER_BIT | <nl> - VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT ; <nl> - ci . sharingMode = VK_SHARING_MODE_EXCLUSIVE ; <nl> - ci . queueFamilyIndexCount = 0 ; <nl> - ci . pQueueFamilyIndices = nullptr ; <nl> - default_buffer = device . GetLogical ( ) . CreateBuffer ( ci ) ; <nl> + default_buffer = device . GetLogical ( ) . CreateBuffer ( { <nl> + . sType = VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO , <nl> + . pNext = nullptr , <nl> + . flags = 0 , <nl> + . size = DEFAULT_BUFFER_SIZE , <nl> + . usage = VK_BUFFER_USAGE_TRANSFER_DST_BIT | VK_BUFFER_USAGE_VERTEX_BUFFER_BIT | <nl> + VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT , <nl> + . sharingMode = VK_SHARING_MODE_EXCLUSIVE , <nl> + . queueFamilyIndexCount = 0 , <nl> + . pQueueFamilyIndices = nullptr , <nl> + } ) ; <nl> default_buffer_commit = memory_manager . Commit ( default_buffer , false ) ; <nl> <nl> scheduler . RequestOutsideRenderPassOperationContext ( ) ; <nl>\n", "msg": "vk_rasterizer : Make use of designated initializers where applicable\n"}
{"diff_id": 35623, "repo": "godotengine/godot\n", "sha": "3fac4ef336c3846f423a6243f34e8d9d6eeac85e\n", "time": "2017-11-13T19:45:13Z\n", "diff": "mmm a / modules / gdscript / gd_editor . cpp <nl> ppp b / modules / gdscript / gd_editor . cpp <nl> String GDScriptLanguage : : make_function ( const String & p_class , const String & p_na <nl> } <nl> s + = \" \" ; <nl> } <nl> - s + = \" ) : \\ n \\ tpass # replace with function body \\ n \" ; <nl> + s + = \" ) : \\ n \" + _get_indentation ( ) + \" pass # replace with function body \\ n \" ; <nl> <nl> return s ; <nl> } <nl>\n", "msg": "Fixed signal connection dialog ignoring indentation settings when creating a function .\n"}
{"diff_id": 35629, "repo": "tensorflow/tensorflow\n", "sha": "88a3f5c15335ed7ba0f665976bf6087b5e883f17\n", "time": "2019-11-18T12:35:35Z\n", "diff": "mmm a / third_party / mlir / lib / Dialect / StandardOps / Ops . cpp <nl> ppp b / third_party / mlir / lib / Dialect / StandardOps / Ops . cpp <nl> static LogicalResult verify ( DimOp op ) { <nl> <nl> OpFoldResult DimOp : : fold ( ArrayRef < Attribute > operands ) { <nl> / / Constant fold dim when the size along the index referred to is a constant . <nl> - auto opType = getOperand ( ) - > getType ( ) ; <nl> + auto opType = memrefOrTensor ( ) - > getType ( ) ; <nl> int64_t indexSize = - 1 ; <nl> if ( auto tensorType = opType . dyn_cast < RankedTensorType > ( ) ) <nl> indexSize = tensorType . getShape ( ) [ getIndex ( ) ] ; <nl> OpFoldResult DimOp : : fold ( ArrayRef < Attribute > operands ) { <nl> if ( indexSize > = 0 ) <nl> return IntegerAttr : : get ( IndexType : : get ( getContext ( ) ) , indexSize ) ; <nl> <nl> + / / Fold dim to the size argument of a SubViewOp . <nl> + auto memref = memrefOrTensor ( ) - > getDefiningOp ( ) ; <nl> + if ( auto subview = dyn_cast_or_null < SubViewOp > ( memref ) ) { <nl> + auto sizes = subview . getDynamicSizes ( ) ; <nl> + if ( ! sizes . empty ( ) ) <nl> + return * ( sizes . begin ( ) + getIndex ( ) ) ; <nl> + } <nl> + <nl> return { } ; <nl> } <nl> <nl>\n", "msg": "Implement folding of pattern dim ( subview ( _ ) [ . . . ] [ s1 , . . . , sn ] [ . . . ] , i ) - > si .\n"}
{"diff_id": 35702, "repo": "godotengine/godot\n", "sha": "fd31cebcbeebd2084ccd2d795895ad9c728d859d\n", "time": "2019-12-10T06:19:11Z\n", "diff": "mmm a / drivers / gles2 / rasterizer_storage_gles2 . cpp <nl> ppp b / drivers / gles2 / rasterizer_storage_gles2 . cpp <nl> void RasterizerStorageGLES2 : : _render_target_allocate ( RenderTarget * rt ) { <nl> <nl> bool used_depth = false ; <nl> if ( j = = 0 & & i = = 0 ) { / / use always <nl> - glFramebufferTexture2D ( GL_FRAMEBUFFER , GL_DEPTH_ATTACHMENT , GL_TEXTURE_2D , rt - > depth , 0 ) ; <nl> + if ( config . support_depth_texture ) { <nl> + glFramebufferTexture2D ( GL_FRAMEBUFFER , GL_DEPTH_ATTACHMENT , GL_TEXTURE_2D , rt - > depth , 0 ) ; <nl> + } else { <nl> + glFramebufferRenderbuffer ( GL_FRAMEBUFFER , GL_DEPTH_ATTACHMENT , GL_RENDERBUFFER , rt - > depth ) ; <nl> + } <nl> used_depth = true ; <nl> } <nl> <nl>\n", "msg": "Use renderbuffer depth for post - process buffers when appropriate\n"}
{"diff_id": 35838, "repo": "godotengine/godot\n", "sha": "13eee31461eb5431b39e213ad2349752ca5779b2\n", "time": "2019-03-11T05:08:08Z\n", "diff": "mmm a / drivers / gles2 / rasterizer_storage_gles2 . cpp <nl> ppp b / drivers / gles2 / rasterizer_storage_gles2 . cpp <nl> void RasterizerStorageGLES2 : : sky_set_texture ( RID p_sky , RID p_panorama , int p_ra <nl> glGenTextures ( 1 , & sky - > radiance ) ; <nl> glBindTexture ( GL_TEXTURE_CUBE_MAP , sky - > radiance ) ; <nl> <nl> - int size = p_radiance_size / 4 ; / / divide by four because its a cubemap ( this is an approximation because GLES3 uses a dual paraboloid ) <nl> + int size = p_radiance_size / 2 ; / / divide by two because its a cubemap ( this is an approximation because GLES3 uses a dual paraboloid ) <nl> <nl> GLenum internal_format = GL_RGB ; <nl> GLenum format = GL_RGB ; <nl> void RasterizerStorageGLES2 : : sky_set_texture ( RID p_sky , RID p_panorama , int p_ra <nl> int mipmaps = 6 ; <nl> int lod = 0 ; <nl> int mm_level = mipmaps ; <nl> - size = p_radiance_size / 4 ; <nl> + size = p_radiance_size / 2 ; <nl> shaders . cubemap_filter . set_conditional ( CubemapFilterShaderGLES2 : : USE_SOURCE_PANORAMA , true ) ; <nl> shaders . cubemap_filter . set_conditional ( CubemapFilterShaderGLES2 : : USE_DIRECT_WRITE , true ) ; <nl> shaders . cubemap_filter . bind ( ) ; <nl>\n", "msg": "increase size of radiance map in gles2\n"}
{"diff_id": 36059, "repo": "xbmc/xbmc\n", "sha": "4b9adf6cc30966d4a1a4121ac19d17dc585829b5\n", "time": "2013-03-11T01:27:39Z\n", "diff": "mmm a / xbmc / interfaces / legacy / File . cpp <nl> ppp b / xbmc / interfaces / legacy / File . cpp <nl> namespace XBMCAddon <nl> bool File : : write ( XbmcCommons : : Buffer & buffer ) <nl> { <nl> DelayedCallGuard dg ( languageHook ) ; <nl> - unsigned long totalBytesWritten = 0 ; <nl> while ( buffer . remaining ( ) > 0 ) <nl> { <nl> int bytesWritten = file - > Write ( buffer . curPosition ( ) , buffer . remaining ( ) ) ; <nl> - totalBytesWritten + = bytesWritten ; <nl> if ( bytesWritten = = 0 ) / / this could be a failure ( see HDFile , and XFileUtils ) or <nl> / / it could mean something else when a negative number means an error <nl> / / ( see CCurlFile ) . There is no consistency so we can only assume we ' re <nl>\n", "msg": "minor change and clarification to the File . write return value .\n", "score": 1}
{"diff_id": 36164, "repo": "bitcoin/bitcoin\n", "sha": "dc77dce07cd1f528b7bd2b4c9594cd4647866b08\n", "time": "2012-01-23T17:04:34Z\n", "diff": "mmm a / src / bitcoinrpc . cpp <nl> ppp b / src / bitcoinrpc . cpp <nl> Value addmultisigaddress ( const Array & params , bool fHelp ) <nl> if ( address . IsScript ( ) ) <nl> throw runtime_error ( <nl> strprintf ( \" % s is a pay - to - script address \" , ks . c_str ( ) ) ) ; <nl> - if ( ! pwalletMain - > GetKey ( address , pubkeys [ i ] ) ) <nl> + std : : vector < unsigned char > vchPubKey ; <nl> + if ( ! pwalletMain - > GetPubKey ( address , vchPubKey ) ) <nl> throw runtime_error ( <nl> strprintf ( \" no full public key for address % s \" , ks . c_str ( ) ) ) ; <nl> + if ( vchPubKey . empty ( ) | | ! pubkeys [ i ] . SetPubKey ( vchPubKey ) ) <nl> + throw runtime_error ( \" Invalid public key : \" + ks ) ; <nl> } <nl> <nl> / / Case 2 : hex public key <nl>\n", "msg": "Fixed addmultisigaddress if looking up public keys from locked wallets .\n", "score": 1}
{"diff_id": 36179, "repo": "apple/swift\n", "sha": "72cb7e8424836b73e3b1dd06be4516be006aef10\n", "time": "2014-01-26T05:23:09Z\n", "diff": "mmm a / lib / Sema / TypeCheckDecl . cpp <nl> ppp b / lib / Sema / TypeCheckDecl . cpp <nl> static void convertStoredVarToStoredObjC ( VarDecl * VD ) { <nl> auto * MRE = new ( Context ) MemberRefExpr ( DRE , SourceLoc ( ) , VD , SourceLoc ( ) , <nl> / * implicit * / true ) ; <nl> ASTNode Return = new ( Context ) ReturnStmt ( SourceLoc ( ) , MRE , / * implicit * / true ) ; <nl> - Get - > setBody ( BraceStmt : : create ( Context , SourceLoc ( ) , Return , SourceLoc ( ) ) ) ; <nl> + Get - > setBody ( BraceStmt : : create ( Context , Loc , Return , Loc ) ) ; <nl> <nl> <nl> / / Okay , the getter is set up , create the setter next . <nl> static void convertStoredVarToStoredObjC ( VarDecl * VD ) { <nl> MRE = new ( Context ) MemberRefExpr ( SelfDRE , SourceLoc ( ) , VD , SourceLoc ( ) , <nl> / * implicit * / true ) ; <nl> ASTNode Assign = new ( Context ) AssignExpr ( MRE , SourceLoc ( ) , ValueDRE , true ) ; <nl> - Set - > setBody ( BraceStmt : : create ( Context , SourceLoc ( ) , Assign , SourceLoc ( ) ) ) ; <nl> + Set - > setBody ( BraceStmt : : create ( Context , Loc , Assign , Loc ) ) ; <nl> <nl> <nl> / / Okay , we have both the getter and setter . Set them in VD . <nl> VD - > setStorageObjCAccessors ( Get , Set ) ; <nl> } <nl> <nl> + / / / Check the specified ClassDecl to see if it has any stored properties that <nl> + / / / need to be accessed with ObjC indirection . If so , they are upgraded to have <nl> + / / / StoredObjC StorageKind . <nl> + static void setupObjCStorageProperties ( ClassDecl * CD , TypeChecker & TC ) { <nl> + if ( ! CD - > getASTContext ( ) . LangOpts . EnableNewObjCProperties ) <nl> + return ; <nl> + <nl> + SmallVector < Decl * , 4 > members ; <nl> + <nl> + / / Check all of our stored properties to see if they need to be accessed <nl> + / / dynamically with get / set accessors . <nl> + for ( auto VD : CD - > getStoredProperties ( ) ) { <nl> + / / If this is a stored ObjC ivar and should have an objc getter and <nl> + / / setter , then change its storage kind to reflect that . <nl> + if ( VD - > getStorageKind ( ) ! = VarDecl : : Stored | | <nl> + ! VD - > usesObjCGetterAndSetter ( ) ) <nl> + continue ; <nl> + <nl> + / / If this is the first property we need to upgrade in this class , copy the <nl> + / / members list , so we can add to it . <nl> + / / FIXME : Painfully inefficient to do the copy here . <nl> + if ( members . empty ( ) ) <nl> + members . append ( CD - > getMembers ( ) . begin ( ) , CD - > getMembers ( ) . end ( ) ) ; <nl> + <nl> + convertStoredVarToStoredObjC ( VD ) ; <nl> + <nl> + / / Add the getter and setter to the members list for the class to keep our <nl> + / / AST properly formed . <nl> + members . push_back ( VD - > getGetter ( ) ) ; <nl> + members . push_back ( VD - > getSetter ( ) ) ; <nl> + <nl> + / / Type check the body of the getter and setter . <nl> + TC . typeCheckDecl ( VD - > getGetter ( ) , true ) ; <nl> + TC . typeCheckDecl ( VD - > getSetter ( ) , true ) ; <nl> + } <nl> + <nl> + / / If there were any upgraded properties , set the members of the class , <nl> + / / including the new getters and setters . <nl> + if ( ! members . empty ( ) ) <nl> + CD - > setMembers ( CD - > getASTContext ( ) . AllocateCopy ( members ) , CD - > getBraces ( ) ) ; <nl> + } <nl> + <nl> + <nl> namespace { <nl> <nl> class DeclChecker : public DeclVisitor < DeclChecker > { <nl> class DeclChecker : public DeclVisitor < DeclChecker > { <nl> ( classContext & & classContext - > isObjC ( ) ) | | <nl> ( protocolContext & & protocolContext - > isObjC ( ) ) ) ; <nl> } <nl> - <nl> - <nl> - / / If this is a stored ObjC ivar and should have an objc getter and <nl> - / / setter , then change its storage kind to reflect that . <nl> - if ( VD - > getASTContext ( ) . LangOpts . EnableNewObjCProperties & & <nl> - VD - > usesObjCGetterAndSetter ( ) & & <nl> - VD - > getStorageKind ( ) = = VarDecl : : Stored ) { <nl> - convertStoredVarToStoredObjC ( VD ) ; <nl> - <nl> - / / Type check the body of the getter and setter . <nl> - visit ( VD - > getGetter ( ) ) ; <nl> - visit ( VD - > getSetter ( ) ) ; <nl> - } <nl> } <nl> <nl> return ; <nl> class DeclChecker : public DeclVisitor < DeclChecker > { <nl> <nl> / / If this class requires all of its stored properties to have <nl> / / in - class initializers , diagnose this now . <nl> - if ( CD - > requiresStoredPropertyInits ( ) ) { <nl> + if ( CD - > requiresStoredPropertyInits ( ) ) <nl> checkRequiredInClassInits ( CD ) ; <nl> - } <nl> <nl> if ( ! IsSecondPass ) { <nl> TC . addImplicitConstructors ( CD ) ; <nl> TC . addImplicitDestructor ( CD ) ; <nl> + setupObjCStorageProperties ( CD , TC ) ; <nl> } <nl> if ( ! IsFirstPass ) { <nl> checkExplicitConformance ( CD , CD - > getDeclaredTypeInContext ( ) ) ; <nl>\n", "msg": "Progress on - enable - new - objc - properties : move the code that handles\n"}
{"diff_id": 36293, "repo": "ClickHouse/ClickHouse\n", "sha": "0055bd1a1b024551a31696f3704262452b3b8c52\n", "time": "2019-07-30T22:22:45Z\n", "diff": "mmm a / dbms / programs / server / TCPHandler . cpp <nl> ppp b / dbms / programs / server / TCPHandler . cpp <nl> void TCPHandler : : runImpl ( ) <nl> connection_context = server . context ( ) ; <nl> connection_context . makeSessionContext ( ) ; <nl> <nl> - Settings global_settings = connection_context . getSettings ( ) ; <nl> + / / / These timeouts can be changed after receiving query . <nl> <nl> - socket ( ) . setReceiveTimeout ( global_settings . receive_timeout ) ; <nl> - socket ( ) . setSendTimeout ( global_settings . send_timeout ) ; <nl> + auto global_receive_timeout = connection_context . getSettingsRef ( ) . receive_timeout ; <nl> + auto global_send_timeout = connection_context . getSettingsRef ( ) . send_timeout ; <nl> + <nl> + socket ( ) . setReceiveTimeout ( global_receive_timeout ) ; <nl> + socket ( ) . setSendTimeout ( global_send_timeout ) ; <nl> socket ( ) . setNoDelay ( true ) ; <nl> <nl> in = std : : make_shared < ReadBufferFromPocoSocket > ( socket ( ) ) ; <nl> void TCPHandler : : runImpl ( ) <nl> return ; <nl> } <nl> <nl> + / / / User will be authenticated here . It will also set settings from user profile into connection_context . <nl> try <nl> { <nl> receiveHello ( ) ; <nl> void TCPHandler : : runImpl ( ) <nl> connection_context . setCurrentDatabase ( default_database ) ; <nl> } <nl> <nl> + Settings connection_settings = connection_context . getSettings ( ) ; <nl> + <nl> sendHello ( ) ; <nl> <nl> connection_context . setProgressCallback ( [ this ] ( const Progress & value ) { return this - > updateProgress ( value ) ; } ) ; <nl> void TCPHandler : : runImpl ( ) <nl> / / / We are waiting for a packet from the client . Thus , every ` poll_interval ` seconds check whether we need to shut down . <nl> { <nl> Stopwatch idle_time ; <nl> - while ( ! static_cast < ReadBufferFromPocoSocket & > ( * in ) . poll ( global_settings . poll_interval * 1000000 ) & & ! server . isCancelled ( ) ) <nl> + while ( ! static_cast < ReadBufferFromPocoSocket & > ( * in ) . poll ( connection_settings . poll_interval * 1000000 ) & & ! server . isCancelled ( ) ) <nl> { <nl> - if ( idle_time . elapsedSeconds ( ) > global_settings . idle_connection_timeout ) <nl> + if ( idle_time . elapsedSeconds ( ) > connection_settings . idle_connection_timeout ) <nl> { <nl> LOG_TRACE ( log , \" Closing idle connection \" ) ; <nl> return ; <nl> void TCPHandler : : runImpl ( ) <nl> CurrentThread : : attachInternalTextLogsQueue ( state . logs_queue , client_logs_level . value ) ; <nl> } <nl> <nl> - query_context - > setExternalTablesInitializer ( [ & global_settings , this ] ( Context & context ) <nl> + query_context - > setExternalTablesInitializer ( [ & connection_settings , this ] ( Context & context ) <nl> { <nl> if ( & context ! = & * query_context ) <nl> throw Exception ( \" Unexpected context in external tables initializer \" , ErrorCodes : : LOGICAL_ERROR ) ; <nl> <nl> / / / Get blocks of temporary tables <nl> - readData ( global_settings ) ; <nl> + readData ( connection_settings ) ; <nl> <nl> / / / Reset the input stream , as we received an empty block while receiving external table data . <nl> / / / So , the stream has been marked as cancelled and we can ' t read from it anymore . <nl> void TCPHandler : : runImpl ( ) <nl> <nl> / / / Does the request require receive data from client ? <nl> if ( state . need_receive_data_for_insert ) <nl> - processInsertQuery ( global_settings ) ; <nl> + processInsertQuery ( connection_settings ) ; <nl> else if ( state . io . pipeline . initialized ( ) ) <nl> processOrdinaryQueryWithProcessors ( query_context - > getSettingsRef ( ) . max_threads ) ; <nl> else <nl> void TCPHandler : : runImpl ( ) <nl> } <nl> <nl> <nl> - void TCPHandler : : readData ( const Settings & global_settings ) <nl> + void TCPHandler : : readData ( const Settings & connection_settings ) <nl> { <nl> const auto receive_timeout = query_context - > getSettingsRef ( ) . receive_timeout . value ; <nl> <nl> / / / Poll interval should not be greater than receive_timeout <nl> - const size_t default_poll_interval = global_settings . poll_interval . value * 1000000 ; <nl> + const size_t default_poll_interval = connection_settings . poll_interval . value * 1000000 ; <nl> size_t current_poll_interval = static_cast < size_t > ( receive_timeout . totalMicroseconds ( ) ) ; <nl> constexpr size_t min_poll_interval = 5000 ; / / 5 ms <nl> size_t poll_interval = std : : max ( min_poll_interval , std : : min ( default_poll_interval , current_poll_interval ) ) ; <nl> void TCPHandler : : readData ( const Settings & global_settings ) <nl> } <nl> <nl> <nl> - void TCPHandler : : processInsertQuery ( const Settings & global_settings ) <nl> + void TCPHandler : : processInsertQuery ( const Settings & connection_settings ) <nl> { <nl> / * * Made above the rest of the lines , so that in case of ` writePrefix ` function throws an exception , <nl> * client receive exception before sending data . <nl> void TCPHandler : : processInsertQuery ( const Settings & global_settings ) <nl> / / / Send block to the client - table structure . <nl> sendData ( state . io . out - > getHeader ( ) ) ; <nl> <nl> - readData ( global_settings ) ; <nl> + readData ( connection_settings ) ; <nl> state . io . out - > writeSuffix ( ) ; <nl> state . io . onFinish ( ) ; <nl> } <nl>\n", "msg": "Allow user to override poll_interval and idle_connection_timeout\n"}
{"diff_id": 36335, "repo": "godotengine/godot\n", "sha": "d80e979a484af7a36053fe87e62fd86984ebeec3\n", "time": "2020-01-02T16:54:41Z\n", "diff": "mmm a / scene / 3d / camera . cpp <nl> ppp b / scene / 3d / camera . cpp <nl> Vector3 Camera : : project_position ( const Point2 & p_point , float p_z_depth ) const { <nl> <nl> ERR_FAIL_COND_V_MSG ( ! is_inside_tree ( ) , Vector3 ( ) , \" Camera is not inside scene . \" ) ; <nl> <nl> - if ( p_z_depth = = 0 ) { <nl> + if ( p_z_depth = = 0 & & mode ! = PROJECTION_ORTHOGONAL ) { <nl> return get_global_transform ( ) . origin ; <nl> } <nl> - <nl> Size2 viewport_size = get_viewport ( ) - > get_visible_rect ( ) . size ; <nl> <nl> CameraMatrix cm ; <nl>\n", "msg": "Update Camera . project_position to not return get_global_transform ( ) . origin if projection mode is orthogonal\n", "score": 1}
{"diff_id": 36401, "repo": "godotengine/godot\n", "sha": "0f00384c93e07c6612456de489067f2cb883ecee\n", "time": "2018-01-10T20:46:41Z\n", "diff": "mmm a / platform / windows / os_windows . cpp <nl> ppp b / platform / windows / os_windows . cpp <nl> LRESULT OS_Windows : : WndProc ( HWND hWnd , UINT uMsg , WPARAM wParam , LPARAM lParam ) <nl> case WM_MOUSEWHEEL : <nl> case WM_MOUSEHWHEEL : <nl> case WM_LBUTTONDBLCLK : <nl> - case WM_RBUTTONDBLCLK : <nl> + case WM_MBUTTONDBLCLK case WM_RBUTTONDBLCLK : <nl> / * case WM_XBUTTONDOWN : <nl> case WM_XBUTTONUP : * / { <nl> <nl> LRESULT OS_Windows : : WndProc ( HWND hWnd , UINT uMsg , WPARAM wParam , LPARAM lParam ) <nl> mb - > set_button_index ( 2 ) ; <nl> mb - > set_doubleclick ( true ) ; <nl> } break ; <nl> + case WM_MBUTTONDBLCLK : { <nl> + <nl> + mb - > set_pressed ( true ) ; <nl> + mb - > set_button_index ( 3 ) ; <nl> + mb - > set_doubleclick ( true ) ; <nl> + } break ; <nl> case WM_MOUSEWHEEL : { <nl> <nl> mb - > set_pressed ( true ) ; <nl>\n", "msg": "Added middle button doubleclick , fixes\n"}
{"diff_id": 36449, "repo": "facebook/folly\n", "sha": "e4eb39f3f45b4722a898a8b2b29d06a8c7f8fe95\n", "time": "2020-12-20T19:57:59Z\n", "diff": "similarity index 99 % <nl> rename from folly / stats / detail / test / RadixSortTest . cpp <nl> rename to folly / stats / detail / test / DoubleRadixSortTest . cpp <nl> mmm a / folly / stats / detail / test / RadixSortTest . cpp <nl> ppp b / folly / stats / detail / test / DoubleRadixSortTest . cpp <nl> <nl> * limitations under the License . <nl> * / <nl> <nl> + # include < folly / stats / detail / DoubleRadixSort . h > <nl> + <nl> # include < folly / Random . h > <nl> # include < folly / portability / GTest . h > <nl> - # include < folly / stats / detail / DoubleRadixSort . h > <nl> <nl> using namespace folly : : detail ; <nl> <nl>\n", "msg": "Match DoubleRadixSort test name to file name\n", "score": 1}
{"diff_id": 36621, "repo": "CRYTEK/CRYENGINE\n", "sha": "b3d3ee7c8bfbea89135bd3ae3925392dc5fdba69\n", "time": "2018-07-24T09:20:18Z\n", "diff": "mmm a / Code / CryEngine / RenderDll / XRenderD3D9 / CompiledRenderObject . cpp <nl> ppp b / Code / CryEngine / RenderDll / XRenderD3D9 / CompiledRenderObject . cpp <nl> void CCompiledRenderObject : : CompilePerDrawCB ( CRenderObject * pRenderObject ) <nl> dissolve <nl> ) ; <nl> <nl> + / / Fill terrain texture info if present <nl> + SSectorTextureSet TerrainSectorTextureInfo ; <nl> + float RenderObjMaxViewDistance = 0 . 0f ; <nl> if ( SRenderObjData * pOD = pRenderObject - > GetObjData ( ) ) <nl> { <nl> - SSectorTextureSet TerrainSectorTextureInfo ; <nl> if ( pOD - > m_pTerrainSectorTextureInfo ) <nl> TerrainSectorTextureInfo = * pOD - > m_pTerrainSectorTextureInfo ; <nl> - <nl> - / / Fill terrain texture info if present <nl> - cb - > CD_BlendTerrainColInfo [ 0 ] = pRenderObject - > m_data . m_pTerrainSectorTextureInfo - > fTexOffsetX ; <nl> - cb - > CD_BlendTerrainColInfo [ 1 ] = pRenderObject - > m_data . m_pTerrainSectorTextureInfo - > fTexOffsetY ; <nl> - cb - > CD_BlendTerrainColInfo [ 2 ] = pRenderObject - > m_data . m_pTerrainSectorTextureInfo - > fTexScale ; <nl> - cb - > CD_BlendTerrainColInfo [ 3 ] = pRenderObject - > m_data . m_fMaxViewDistance ; / / Obj view max distance <nl> + <nl> + RenderObjMaxViewDistance = pOD - > m_fMaxViewDistance ; / / Obj view max distance <nl> } <nl> + cb - > CD_BlendTerrainColInfo [ 0 ] = TerrainSectorTextureInfo . fTexOffsetX ; <nl> + cb - > CD_BlendTerrainColInfo [ 1 ] = TerrainSectorTextureInfo . fTexOffsetY ; <nl> + cb - > CD_BlendTerrainColInfo [ 2 ] = TerrainSectorTextureInfo . fTexScale ; <nl> + cb - > CD_BlendTerrainColInfo [ 3 ] = RenderObjMaxViewDistance ; <nl> <nl> / / Fill terrain layer info if present <nl> + Matrix44f TerrainLayerInfo = Matrix44f ( ZERO ) ; <nl> if ( float * pData = ( float * ) m_pRenderElement - > m_CustomData ) <nl> { <nl> - cb - > CD_TerrainLayerInfo = * ( Matrix44f * ) pData ; <nl> + TerrainLayerInfo = * ( Matrix44f * ) pData ; <nl> } <nl> + cb - > CD_TerrainLayerInfo = TerrainLayerInfo ; <nl> <nl> cb - > CD_CustomData1 = silhouetteColor ; <nl> cb - > CD_CustomData2 . x = alias_cast < float > ( pRenderObject - > m_editorSelectionID ) ; <nl>\n", "msg": "! XI Integrating CL 1732623 to ce_main_stabilization\n"}
{"diff_id": 36637, "repo": "yuzu-emu/yuzu\n", "sha": "05a6f1f676386074ce28c2459b689d92c08a3171\n", "time": "2018-12-05T05:16:49Z\n", "diff": "mmm a / src / core / hle / service / ldr / ldr . cpp <nl> ppp b / src / core / hle / service / ldr / ldr . cpp <nl> class RelocatableObject final : public ServiceFramework < RelocatableObject > { <nl> using SHA256Hash = std : : array < u8 , 0x20 > ; <nl> <nl> struct NROHeader { <nl> - u32_le entrypoint_insn ; <nl> + INSERT_PADDING_WORDS ( 1 ) ; <nl> u32_le mod_offset ; <nl> INSERT_PADDING_WORDS ( 2 ) ; <nl> u32_le magic ; <nl> - INSERT_PADDING_WORDS ( 1 ) ; <nl> + u32_le version ; <nl> u32_le nro_size ; <nl> - INSERT_PADDING_WORDS ( 1 ) ; <nl> + u32_le flags ; <nl> u32_le text_offset ; <nl> u32_le text_size ; <nl> u32_le ro_offset ; <nl>\n", "msg": "service / ldr : Amend layout of the NRO header\n"}
{"diff_id": 36728, "repo": "apple/swift\n", "sha": "d4cebb5947a75f436ef8c92701d7bb5cba8a852c\n", "time": "2017-02-18T09:18:10Z\n", "diff": "mmm a / unittests / Basic / DiverseStackTest . cpp <nl> ppp b / unittests / Basic / DiverseStackTest . cpp <nl> struct ThreeByteType : ParentType { <nl> <nl> struct RandomValueGenerator { <nl> std : : mt19937 gen ; <nl> - std : : uniform_int_distribution < uint8_t > randomEightBitValueGenerator ; <nl> + std : : uniform_int_distribution < int > randomEightBitValueGenerator { <nl> + 0 , std : : numeric_limits < uint8_t > : : max ( ) } ; <nl> std : : uniform_int_distribution < uint16_t > randomSixteenBitValueGenerator ; <nl> <nl> / / Randomly generated bits . This is frozen to ensure that the test doesn ' t <nl>\n", "msg": "Don ' t use a uint8_t random distruction in DiverseStack unit tests\n"}
{"diff_id": 36729, "repo": "microsoft/CNTK\n", "sha": "91c0fd06a9da3e74adc667a935567f2432f1d802\n", "time": "2017-07-05T12:22:33Z\n", "diff": "mmm a / Source / SGDLib / SGD . cpp <nl> ppp b / Source / SGDLib / SGD . cpp <nl> void SGD < ElemType > : : TrainOrAdaptModel ( int startEpoch , ComputationNetworkPtr net , <nl> m_lastFinishedEpochTrainLoss = epochCriterion . Average ( ) ; <nl> for ( size_t j = 0 ; j < epochEvalErrors . size ( ) ; j + + ) <nl> epochEvalErrors [ j ] . LogCriterion ( evaluationNodes [ j ] - > NodeName ( ) ) ; <nl> - fprintf ( stderr , \" totalSamplesSeen = % d ; learningRatePerSample = % . 8g ; epochTime = % . 6gs \\ n \" , ( int ) totalTrainingSamplesSeen , learnRatePerSample , epochTime ) ; <nl> + fprintf ( stderr , \" totalSamplesSeen = % zu ; learningRatePerSample = % . 8g ; epochTime = % . 6gs \\ n \" , totalTrainingSamplesSeen , learnRatePerSample , epochTime ) ; <nl> # if 0 <nl> / / TODO : This was only printed if > 1 eval criterion . Why ? Needed ? <nl> LOGPRINTF ( stderr , \" Finished Epoch [ % 2d of % d ] : Criterion Node [ % ls ] Per Sample = % . 8g \\ n \" , <nl>\n", "msg": "' totalSamplesSeen ' cast as Int64 instead of Int32 to avoid overflow\n"}
{"diff_id": 37000, "repo": "arangodb/arangodb\n", "sha": "4fecd85e4c5cd8ab30892f667f7761cd9b5a8cda\n", "time": "2014-08-26T07:45:32Z\n", "diff": "mmm a / arangod / Aql / OptimizerRules . cpp <nl> ppp b / arangod / Aql / OptimizerRules . cpp <nl> class FilterToEnumCollFinder : public WalkerWorker < ExecutionNode > { <nl> / / TODO : who is going to free _ranges ? ? <nl> } ; <nl> <nl> + ~ FilterToEnumCollFinder ( ) { <nl> + delete _ranges ; <nl> + } <nl> + <nl> bool before ( ExecutionNode * en ) { <nl> _canThrow = ( _canThrow | | en - > canThrow ( ) ) ; / / can any node walked over throw ? <nl> <nl>\n", "msg": "Add a destructor to delete _ranges in FilterToEnumCollFinder .\n", "score": 1}
{"diff_id": 37143, "repo": "godotengine/godot\n", "sha": "feb4002017b335ad5cb9f7508697a78b2503ea5c\n", "time": "2020-09-24T15:41:40Z\n", "diff": "mmm a / scene / resources / style_box . cpp <nl> ppp b / scene / resources / style_box . cpp <nl> void StyleBoxFlat : : _bind_methods ( ) { <nl> <nl> ADD_GROUP ( \" Shadow \" , \" shadow_ \" ) ; <nl> ADD_PROPERTY ( PropertyInfo ( Variant : : COLOR , \" shadow_color \" ) , \" set_shadow_color \" , \" get_shadow_color \" ) ; <nl> - ADD_PROPERTY ( PropertyInfo ( Variant : : INT , \" shadow_size \" ) , \" set_shadow_size \" , \" get_shadow_size \" ) ; <nl> + ADD_PROPERTY ( PropertyInfo ( Variant : : INT , \" shadow_size \" , PROPERTY_HINT_RANGE , \" 0 , 100 , 1 , or_greater \" ) , \" set_shadow_size \" , \" get_shadow_size \" ) ; <nl> ADD_PROPERTY ( PropertyInfo ( Variant : : VECTOR2 , \" shadow_offset \" ) , \" set_shadow_offset \" , \" get_shadow_offset \" ) ; <nl> <nl> ADD_GROUP ( \" Anti Aliasing \" , \" anti_aliasing_ \" ) ; <nl>\n", "msg": "Add a property hint to StyleBoxFlat ` shadow_size ` for editor usability\n", "score": 1}
{"diff_id": 37159, "repo": "mongodb/mongo\n", "sha": "de3be2307dc314a3a5f62d45a96ed8036ca3b62f\n", "time": "2010-12-27T20:00:11Z\n", "diff": "mmm a / s / chunk . cpp <nl> ppp b / s / chunk . cpp <nl> namespace mongo { <nl> <nl> fromconn . done ( ) ; <nl> <nl> - if ( worked ) { <nl> - _manager - > _reload ( ) ; <nl> - return true ; <nl> - } <nl> + / / if succeeded , needs to reload to pick up the new location <nl> + / / if failed , mongos may be stale <nl> + / / reload is excessive here as the failure could be simply because collection metadata is taken <nl> + _manager - > _reload ( ) ; <nl> <nl> - return false ; <nl> + return worked ; <nl> } <nl> <nl> bool Chunk : : splitIfShould ( long dataWritten ) { <nl>\n", "msg": "a failure in migrate can be because of chunk boundaries being stale\n"}
{"diff_id": 37275, "repo": "opencv/opencv\n", "sha": "ac481e61749fcac0000c5a063b003d36528c7e55\n", "time": "2015-12-24T20:34:34Z\n", "diff": "mmm a / modules / calib3d / src / calibration . cpp <nl> ppp b / modules / calib3d / src / calibration . cpp <nl> CV_IMPL int cvRodrigues2 ( const CvMat * src , CvMat * dst , CvMat * jacobian ) <nl> <nl> if ( src - > cols = = 1 | | src - > rows = = 1 ) <nl> { <nl> - double rx , ry , rz , theta ; <nl> int step = src - > rows > 1 ? src - > step / elem_size : 1 ; <nl> <nl> if ( src - > rows + src - > cols * CV_MAT_CN ( src - > type ) - 1 ! = 3 ) <nl> CV_IMPL int cvRodrigues2 ( const CvMat * src , CvMat * dst , CvMat * jacobian ) <nl> if ( dst - > rows ! = 3 | | dst - > cols ! = 3 | | CV_MAT_CN ( dst - > type ) ! = 1 ) <nl> CV_Error ( CV_StsBadSize , \" Output matrix must be 3x3 , single - channel floating point matrix \" ) ; <nl> <nl> + Point3d r ; <nl> if ( depth = = CV_32F ) <nl> { <nl> - rx = src - > data . fl [ 0 ] ; <nl> - ry = src - > data . fl [ step ] ; <nl> - rz = src - > data . fl [ step * 2 ] ; <nl> + r . x = src - > data . fl [ 0 ] ; <nl> + r . y = src - > data . fl [ step ] ; <nl> + r . z = src - > data . fl [ step * 2 ] ; <nl> } <nl> else <nl> { <nl> - rx = src - > data . db [ 0 ] ; <nl> - ry = src - > data . db [ step ] ; <nl> - rz = src - > data . db [ step * 2 ] ; <nl> + r . x = src - > data . db [ 0 ] ; <nl> + r . y = src - > data . db [ step ] ; <nl> + r . z = src - > data . db [ step * 2 ] ; <nl> } <nl> - theta = std : : sqrt ( rx * rx + ry * ry + rz * rz ) ; <nl> + <nl> + double theta = norm ( r ) ; <nl> <nl> if ( theta < DBL_EPSILON ) <nl> { <nl> CV_IMPL int cvRodrigues2 ( const CvMat * src , CvMat * dst , CvMat * jacobian ) <nl> } <nl> else <nl> { <nl> - const double I [ ] = { 1 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 1 } ; <nl> - <nl> double c = cos ( theta ) ; <nl> double s = sin ( theta ) ; <nl> double c1 = 1 . - c ; <nl> double itheta = theta ? 1 . / theta : 0 . ; <nl> <nl> - rx * = itheta ; ry * = itheta ; rz * = itheta ; <nl> + r * = itheta ; <nl> <nl> - double rrt [ ] = { rx * rx , rx * ry , rx * rz , rx * ry , ry * ry , ry * rz , rx * rz , ry * rz , rz * rz } ; <nl> - double _r_x_ [ ] = { 0 , - rz , ry , rz , 0 , - rx , - ry , rx , 0 } ; <nl> - double R [ 9 ] ; <nl> - CvMat matR = cvMat ( 3 , 3 , CV_64F , R ) ; <nl> + Matx33d rrt ( r . x * r . x , r . x * r . y , r . x * r . z , r . x * r . y , r . y * r . y , r . y * r . z , r . x * r . z , r . y * r . z , r . z * r . z ) ; <nl> + Matx33d r_x ( 0 , - r . z , r . y , <nl> + r . z , 0 , - r . x , <nl> + - r . y , r . x , 0 ) ; <nl> <nl> / / R = cos ( theta ) * I + ( 1 - cos ( theta ) ) * r * rT + sin ( theta ) * [ r_x ] <nl> - / / where [ r_x ] is [ 0 - rz ry ; rz 0 - rx ; - ry rx 0 ] <nl> - for ( k = 0 ; k < 9 ; k + + ) <nl> - R [ k ] = c * I [ k ] + c1 * rrt [ k ] + s * _r_x_ [ k ] ; <nl> + Matx33d R = c * Matx33d : : eye ( ) + c1 * rrt + s * r_x ; <nl> <nl> - cvConvert ( & matR , dst ) ; <nl> + Mat ( R ) . convertTo ( cvarrToMat ( dst ) , dst - > type ) ; <nl> <nl> if ( jacobian ) <nl> { <nl> - double drrt [ ] = { rx + rx , ry , rz , ry , 0 , 0 , rz , 0 , 0 , <nl> - 0 , rx , 0 , rx , ry + ry , rz , 0 , rz , 0 , <nl> - 0 , 0 , rx , 0 , 0 , ry , rx , ry , rz + rz } ; <nl> + const double I [ ] = { 1 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 1 } ; <nl> + double drrt [ ] = { r . x + r . x , r . y , r . z , r . y , 0 , 0 , r . z , 0 , 0 , <nl> + 0 , r . x , 0 , r . x , r . y + r . y , r . z , 0 , r . z , 0 , <nl> + 0 , 0 , r . x , 0 , 0 , r . y , r . x , r . y , r . z + r . z } ; <nl> double d_r_x_ [ ] = { 0 , 0 , 0 , 0 , 0 , - 1 , 0 , 1 , 0 , <nl> 0 , 0 , 1 , 0 , 0 , 0 , - 1 , 0 , 0 , <nl> 0 , - 1 , 0 , 1 , 0 , 0 , 0 , 0 , 0 } ; <nl> for ( i = 0 ; i < 3 ; i + + ) <nl> { <nl> - double ri = i = = 0 ? rx : i = = 1 ? ry : rz ; <nl> + double ri = i = = 0 ? r . x : i = = 1 ? r . y : r . z ; <nl> double a0 = - s * ri , a1 = ( s - 2 * c1 * itheta ) * ri , a2 = c1 * itheta ; <nl> double a3 = ( c - s * itheta ) * ri , a4 = s * itheta ; <nl> for ( k = 0 ; k < 9 ; k + + ) <nl> - J [ i * 9 + k ] = a0 * I [ k ] + a1 * rrt [ k ] + a2 * drrt [ i * 9 + k ] + <nl> - a3 * _r_x_ [ k ] + a4 * d_r_x_ [ i * 9 + k ] ; <nl> + J [ i * 9 + k ] = a0 * I [ k ] + a1 * rrt . val [ k ] + a2 * drrt [ i * 9 + k ] + <nl> + a3 * r_x . val [ k ] + a4 * d_r_x_ [ i * 9 + k ] ; <nl> } <nl> } <nl> } <nl> } <nl> else if ( src - > cols = = 3 & & src - > rows = = 3 ) <nl> { <nl> - double R [ 9 ] , U [ 9 ] , V [ 9 ] , W [ 3 ] , rx , ry , rz ; <nl> - CvMat matR = cvMat ( 3 , 3 , CV_64F , R ) ; <nl> - CvMat matU = cvMat ( 3 , 3 , CV_64F , U ) ; <nl> - CvMat matV = cvMat ( 3 , 3 , CV_64F , V ) ; <nl> - CvMat matW = cvMat ( 3 , 1 , CV_64F , W ) ; <nl> + Matx33d U , Vt ; <nl> + Vec3d W ; <nl> double theta , s , c ; <nl> int step = dst - > rows > 1 ? dst - > step / elem_size : 1 ; <nl> <nl> CV_IMPL int cvRodrigues2 ( const CvMat * src , CvMat * dst , CvMat * jacobian ) <nl> ( dst - > rows ! = 3 | | dst - > cols ! = 1 | | CV_MAT_CN ( dst - > type ) ! = 1 ) ) <nl> CV_Error ( CV_StsBadSize , \" Output matrix must be 1x3 or 3x1 \" ) ; <nl> <nl> - cvConvert ( src , & matR ) ; <nl> - if ( ! cvCheckArr ( & matR , CV_CHECK_RANGE + CV_CHECK_QUIET , - 100 , 100 ) ) <nl> + Matx33d R = cvarrToMat ( src ) ; <nl> + <nl> + if ( ! checkRange ( R , true , NULL , - 100 , 100 ) ) <nl> { <nl> cvZero ( dst ) ; <nl> if ( jacobian ) <nl> CV_IMPL int cvRodrigues2 ( const CvMat * src , CvMat * dst , CvMat * jacobian ) <nl> return 0 ; <nl> } <nl> <nl> - cvSVD ( & matR , & matW , & matU , & matV , CV_SVD_MODIFY_A + CV_SVD_U_T + CV_SVD_V_T ) ; <nl> - cvGEMM ( & matU , & matV , 1 , 0 , 0 , & matR , CV_GEMM_A_T ) ; <nl> + SVD : : compute ( R , W , U , Vt ) ; <nl> + R = U * Vt ; <nl> <nl> - rx = R [ 7 ] - R [ 5 ] ; <nl> - ry = R [ 2 ] - R [ 6 ] ; <nl> - rz = R [ 3 ] - R [ 1 ] ; <nl> + Point3d r ( R ( 2 , 1 ) - R ( 1 , 2 ) , R ( 0 , 2 ) - R ( 2 , 0 ) , R ( 1 , 0 ) - R ( 0 , 1 ) ) ; <nl> <nl> - s = std : : sqrt ( ( rx * rx + ry * ry + rz * rz ) * 0 . 25 ) ; <nl> - c = ( R [ 0 ] + R [ 4 ] + R [ 8 ] - 1 ) * 0 . 5 ; <nl> + s = std : : sqrt ( ( r . x * r . x + r . y * r . y + r . z * r . z ) * 0 . 25 ) ; <nl> + c = ( R ( 0 , 0 ) + R ( 1 , 1 ) + R ( 2 , 2 ) - 1 ) * 0 . 5 ; <nl> c = c > 1 . ? 1 . : c < - 1 . ? - 1 . : c ; <nl> theta = acos ( c ) ; <nl> <nl> CV_IMPL int cvRodrigues2 ( const CvMat * src , CvMat * dst , CvMat * jacobian ) <nl> double t ; <nl> <nl> if ( c > 0 ) <nl> - rx = ry = rz = 0 ; <nl> + r = Point3d ( 0 , 0 , 0 ) ; <nl> else <nl> { <nl> - t = ( R [ 0 ] + 1 ) * 0 . 5 ; <nl> - rx = std : : sqrt ( MAX ( t , 0 . ) ) ; <nl> - t = ( R [ 4 ] + 1 ) * 0 . 5 ; <nl> - ry = std : : sqrt ( MAX ( t , 0 . ) ) * ( R [ 1 ] < 0 ? - 1 . : 1 . ) ; <nl> - t = ( R [ 8 ] + 1 ) * 0 . 5 ; <nl> - rz = std : : sqrt ( MAX ( t , 0 . ) ) * ( R [ 2 ] < 0 ? - 1 . : 1 . ) ; <nl> - if ( fabs ( rx ) < fabs ( ry ) & & fabs ( rx ) < fabs ( rz ) & & ( R [ 5 ] > 0 ) ! = ( ry * rz > 0 ) ) <nl> - rz = - rz ; <nl> - theta / = std : : sqrt ( rx * rx + ry * ry + rz * rz ) ; <nl> - rx * = theta ; <nl> - ry * = theta ; <nl> - rz * = theta ; <nl> + t = ( R ( 0 , 0 ) + 1 ) * 0 . 5 ; <nl> + r . x = std : : sqrt ( MAX ( t , 0 . ) ) ; <nl> + t = ( R ( 1 , 1 ) + 1 ) * 0 . 5 ; <nl> + r . y = std : : sqrt ( MAX ( t , 0 . ) ) * ( R ( 0 , 1 ) < 0 ? - 1 . : 1 . ) ; <nl> + t = ( R ( 2 , 2 ) + 1 ) * 0 . 5 ; <nl> + r . z = std : : sqrt ( MAX ( t , 0 . ) ) * ( R ( 0 , 2 ) < 0 ? - 1 . : 1 . ) ; <nl> + if ( fabs ( r . x ) < fabs ( r . y ) & & fabs ( r . x ) < fabs ( r . z ) & & ( R ( 1 , 2 ) > 0 ) ! = ( r . y * r . z > 0 ) ) <nl> + r . z = - r . z ; <nl> + theta / = norm ( r ) ; <nl> + r * = theta ; <nl> } <nl> <nl> if ( jacobian ) <nl> CV_IMPL int cvRodrigues2 ( const CvMat * src , CvMat * dst , CvMat * jacobian ) <nl> / / var2 = [ om ; theta ] <nl> double dvar2dvar [ ] = <nl> { <nl> - vth , 0 , 0 , rx , 0 , <nl> - 0 , vth , 0 , ry , 0 , <nl> - 0 , 0 , vth , rz , 0 , <nl> + vth , 0 , 0 , r . x , 0 , <nl> + 0 , vth , 0 , r . y , 0 , <nl> + 0 , 0 , vth , r . z , 0 , <nl> 0 , 0 , 0 , 0 , 1 <nl> } ; <nl> double domegadvar2 [ ] = <nl> { <nl> - theta , 0 , 0 , rx * vth , <nl> - 0 , theta , 0 , ry * vth , <nl> - 0 , 0 , theta , rz * vth <nl> + theta , 0 , 0 , r . x * vth , <nl> + 0 , theta , 0 , r . y * vth , <nl> + 0 , 0 , theta , r . z * vth <nl> } ; <nl> <nl> CvMat _dvardR = cvMat ( 5 , 9 , CV_64FC1 , dvardR ) ; <nl> CV_IMPL int cvRodrigues2 ( const CvMat * src , CvMat * dst , CvMat * jacobian ) <nl> } <nl> <nl> vth * = theta ; <nl> - rx * = vth ; ry * = vth ; rz * = vth ; <nl> + r * = vth ; <nl> } <nl> <nl> if ( depth = = CV_32F ) <nl> { <nl> - dst - > data . fl [ 0 ] = ( float ) rx ; <nl> - dst - > data . fl [ step ] = ( float ) ry ; <nl> - dst - > data . fl [ step * 2 ] = ( float ) rz ; <nl> + dst - > data . fl [ 0 ] = ( float ) r . x ; <nl> + dst - > data . fl [ step ] = ( float ) r . y ; <nl> + dst - > data . fl [ step * 2 ] = ( float ) r . z ; <nl> } <nl> else <nl> { <nl> - dst - > data . db [ 0 ] = rx ; <nl> - dst - > data . db [ step ] = ry ; <nl> - dst - > data . db [ step * 2 ] = rz ; <nl> + dst - > data . db [ 0 ] = r . x ; <nl> + dst - > data . db [ step ] = r . y ; <nl> + dst - > data . db [ step * 2 ] = r . z ; <nl> } <nl> } <nl> <nl>\n", "msg": "calib3d : port Rodrigues to cpp primitives\n"}
{"diff_id": 37389, "repo": "CRYTEK/CRYENGINE\n", "sha": "7cf8c4fe059ec9613841c6ca63b1479aa91e550d\n", "time": "2017-11-16T13:18:24Z\n", "diff": "mmm a / Code / CryEngine / CryAction / EntityContainers / FlowEntityContainerNodes . cpp <nl> ppp b / Code / CryEngine / CryAction / EntityContainers / FlowEntityContainerNodes . cpp <nl> class CFlowNode_EntityContainerContMgr_QueryIsInContainer : public CFlowBaseNode <nl> { <nl> static const SInputPortConfig inputs [ ] = <nl> { <nl> - InputPortConfig_AnyType ( \" DoQuery \" , _HELP ( \" Checks if the given Entity ID belonga to the selected container \" ) ) , <nl> - InputPortConfig < EntityId > ( \" EntityId \" , 0 , _HELP ( \" Entity ID to check \" ) ) , <nl> + InputPortConfig_AnyType ( \" DoQuery \" , _HELP ( \" Checks if the given Entity ID belongs to the selected container \" ) ) , <nl> + InputPortConfig < EntityId > ( \" Id \" , 0 , _HELP ( \" Entity ID to check \" ) ) , <nl> InputPortConfig < bool > ( \" AutomaticCheck \" , false , _HELP ( \" If True , the node will automatically fire its outputs if the selected entity is added / removed to the given container \" ) ) , <nl> { 0 } <nl> } ; <nl>\n", "msg": "! B ( CE - 13123 ) ( Flowgraph ) Multiple EntityInfo nodes cannot be attached to the QueryIsInContainer node\n", "score": 1}
{"diff_id": 37399, "repo": "facebook/hhvm\n", "sha": "d7feb777aca74ce3722ab858a5c2b766f647f9f4\n", "time": "2020-04-03T17:35:37Z\n", "diff": "mmm a / hphp / runtime / vm / unit . cpp <nl> ppp b / hphp / runtime / vm / unit . cpp <nl> static LineToOffsetRangeVecMap getLineToOffsetRangeVecMap ( const Unit * unit ) { <nl> } <nl> <nl> static const LineTable & loadLineTable ( const Unit * unit ) { <nl> - if ( unit - > repoID ( ) = = RepoIdInvalid ) { <nl> - LineTableStash : : accessor acc ; <nl> + assertx ( unit - > repoID ( ) ! = RepoIdInvalid ) ; <nl> + if ( ! RO : : RepoAuthoritative ) { <nl> + LineTableStash : : const_accessor acc ; <nl> if ( s_lineTables . find ( acc , unit ) ) { <nl> return acc - > second ; <nl> } <nl> - static LineTable empty ; <nl> - return empty ; <nl> } <nl> <nl> auto const hash = pointer_hash < Unit > { } ( unit ) % s_lineCache . size ( ) ; <nl> static const LineTable & loadLineTable ( const Unit * unit ) { <nl> auto & urp = Repo : : get ( ) . urp ( ) ; <nl> auto table = LineTable { } ; <nl> urp . getUnitLineTable [ unit - > repoID ( ) ] . get ( unit - > sn ( ) , table ) ; <nl> + <nl> + / / Loading line tables for each unseen line while coverage is enabled can <nl> + / / cause the treadmill to to carry an enormous number of discarded <nl> + / / LineTables , so instead cache the table permanently in s_lineTables . <nl> + if ( UNLIKELY ( g_context & & <nl> + ( unit - > isCoverageEnabled ( ) | | RID ( ) . getCoverage ( ) ) ) ) { <nl> + LineTableStash : : accessor acc ; <nl> + if ( s_lineTables . insert ( acc , unit ) ) { <nl> + acc - > second = std : : move ( table ) ; <nl> + } <nl> + return acc - > second ; <nl> + } <nl> + <nl> auto const p = new LineCacheEntry ( unit , std : : move ( table ) ) ; <nl> if ( auto const old = entry . exchange ( p , std : : memory_order_release ) ) { <nl> Treadmill : : enqueue ( [ old ] { delete old ; } ) ; <nl> int Unit : : getLineNumber ( Offset pc ) const { <nl> } <nl> return nullptr ; <nl> } ( ) ; <nl> - if ( lineTable ) return HPHP : : getLineNumber ( * lineTable , pc ) ; <nl> + return lineTable ? HPHP : : getLineNumber ( * lineTable , pc ) : - 1 ; <nl> } <nl> <nl> auto findLine = [ & ] { <nl> int Unit : : getLineNumber ( Offset pc ) const { <nl> auto line = findLine ( ) ; <nl> if ( line ! = INT_MIN ) return line ; <nl> <nl> + / / Updating m_lineMap while coverage is enabled can cause the treadmill to <nl> + / / fill with an enormous number of resized maps . <nl> + if ( UNLIKELY ( g_context & & ( isCoverageEnabled ( ) | | RID ( ) . getCoverage ( ) ) ) ) { <nl> + return HPHP : : getLineNumber ( loadLineTable ( this ) , pc ) ; <nl> + } <nl> + <nl> m_lineMap . lock_for_update ( ) ; <nl> try { <nl> line = findLine ( ) ; <nl>\n", "msg": "Avoid thrashing s_lineCache and m_lineMap in coverage mode\n"}
{"diff_id": 37822, "repo": "arangodb/arangodb\n", "sha": "a4541a83ad512799c97ccbc9bac39212af8d45f4\n", "time": "2016-04-28T15:32:56Z\n", "diff": "mmm a / arangod / RestHandler / RestVocbaseBaseHandler . cpp <nl> ppp b / arangod / RestHandler / RestVocbaseBaseHandler . cpp <nl> void RestVocbaseBaseHandler : : generateNotModified ( TRI_voc_rid_t rid ) { <nl> / / / @ brief generates next entry from a result set <nl> / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / <nl> <nl> - void RestVocbaseBaseHandler : : generateDocument ( VPackSlice const & document , <nl> + void RestVocbaseBaseHandler : : generateDocument ( VPackSlice const & input , <nl> bool generateBody , <nl> VPackOptions const * options ) { <nl> + VPackSlice document = input . resolveExternal ( ) ; <nl> std : : string rev ; <nl> if ( document . isObject ( ) ) { <nl> rev = VelocyPackHelper : : getStringValue ( document , TRI_VOC_ATTRIBUTE_REV , \" \" ) ; <nl>\n", "msg": "Generate document in rest handler now works with externals\n"}
{"diff_id": 38035, "msg": "Stop preview generator before reimporting resources with different type .\n", "msgGPT": "stop resource previews before reimporting and restarting the editor.", "METEOR Score": "23.47044917257683", "BLEU Score": "0.5944869199270039", "ROUGE-L Score": "0.3333333283333334", "score": 1, "repo": "godotengine/godot\n", "sha": "b0758b2d73eb4cd90dbe0a99b82f6ebdb96b7774\n", "time": "2019-01-25T20:27:50Z\n", "diff": "mmm a / editor / import_dock . cpp <nl> ppp b / editor / import_dock . cpp <nl> void ImportDock : : _reimport_attempt ( ) { <nl> void ImportDock : : _reimport_and_restart ( ) { <nl> <nl> EditorNode : : get_singleton ( ) - > save_all_scenes ( ) ; <nl> + EditorResourcePreview : : get_singleton ( ) - > stop ( ) ; / / dont try to re - create previews <nl> _reimport ( ) ; <nl> EditorNode : : get_singleton ( ) - > restart_editor ( ) ; <nl> } <nl>\n"}
{"diff_id": 38037, "repo": "esp8266/Arduino\n", "sha": "4684e44902f9fd8839029b7ee161324c5348606a\n", "time": "2016-04-08T08:26:11Z\n", "diff": "mmm a / libraries / ESP8266WiFi / src / ESP8266WiFiAP . cpp <nl> ppp b / libraries / ESP8266WiFi / src / ESP8266WiFiAP . cpp <nl> bool ESP8266WiFiAPClass : : softAP ( const char * ssid , const char * passphrase , int ch <nl> return false ; <nl> } <nl> <nl> - if ( ! ssid | | * ssid = = 0 | | strlen ( ssid ) > 31 ) { <nl> + if ( ! ssid | | strlen ( ssid ) = = 0 | | strlen ( ssid ) > 31 ) { <nl> / / fail SSID too long or missing ! <nl> DEBUG_WIFI ( \" [ AP ] SSID too long or missing ! \\ n \" ) ; <nl> return false ; <nl> } <nl> <nl> - if ( passphrase & & ( strlen ( passphrase ) > 63 | | strlen ( passphrase ) < 8 ) ) { <nl> + if ( passphrase & & strlen ( passphrase ) > 0 & & ( strlen ( passphrase ) > 63 | | strlen ( passphrase ) < 8 ) ) { <nl> / / fail passphrase to long or short ! <nl> DEBUG_WIFI ( \" [ AP ] fail passphrase to long or short ! \\ n \" ) ; <nl> return false ; <nl>\n", "msg": "Re - enable old behaviour if passphrase string is empty\n"}
{"diff_id": 38229, "msg": "fixed GetArtistDetails to return artist\n", "msgGPT": "refactor get artist details method to remove unnecessary parameter object usage.", "METEOR Score": "27.244000281406745", "BLEU Score": "0.3302359943348546", "ROUGE-L Score": "0.4705882307266437", "score": 1, "repo": "xbmc/xbmc\n", "sha": "ff4d993ee9cec703077431c8c52f0fec860bee24\n", "time": "2012-11-30T16:29:22Z\n", "diff": "mmm a / xbmc / interfaces / json - rpc / AudioLibrary . cpp <nl> ppp b / xbmc / interfaces / json - rpc / AudioLibrary . cpp <nl> JSONRPC_STATUS CAudioLibrary : : GetArtistDetails ( const CStdString & method , ITransp <nl> param [ \" properties \" ] = CVariant ( CVariant : : VariantTypeArray ) ; <nl> param [ \" properties \" ] . append ( \" artist \" ) ; <nl> <nl> - HandleFileItem ( \" artistid \" , false , \" artistdetails \" , items [ 0 ] , parameterObject , param [ \" properties \" ] , result , false ) ; <nl> + HandleFileItem ( \" artistid \" , false , \" artistdetails \" , items [ 0 ] , param , param [ \" properties \" ] , result , false ) ; <nl> return OK ; <nl> } <nl> <nl>\n"}
{"diff_id": 38290, "repo": "mongodb/mongo\n", "sha": "4e4a746769a899bbfb2daaf262dfb341da09e24b\n", "time": "2013-11-11T16:34:37Z\n", "diff": "mmm a / src / mongo / db / repl / rs_rollback . cpp <nl> ppp b / src / mongo / db / repl / rs_rollback . cpp <nl> <nl> <nl> # include \" mongo / pch . h \" <nl> <nl> + # include \" mongo / db / auth / authorization_manager . h \" <nl> + # include \" mongo / db / auth / authorization_manager_global . h \" <nl> # include \" mongo / db / client . h \" <nl> # include \" mongo / db / cloner . h \" <nl> # include \" mongo / db / ops / update . h \" <nl> namespace mongo { <nl> / / todo : fatal error if this throws ? <nl> oplogDetails - > cappedTruncateAfter ( rsoplog , h . commonPointOurDiskloc , false ) ; <nl> <nl> + Status status = getGlobalAuthorizationManager ( ) - > initialize ( ) ; <nl> + if ( ! status . isOK ( ) ) { <nl> + warning ( ) < < \" Failed to reinitialize auth data after rollback : \" < < status ; <nl> + warn = true ; <nl> + } <nl> + <nl> / * reset cached lastoptimewritten and h value * / <nl> loadLastOpTimeWritten ( ) ; <nl> <nl>\n", "msg": "SERVER - 9516 Reinitialize user and role data on replicaset rollback .\n"}
{"diff_id": 38292, "repo": "ClickHouse/ClickHouse\n", "sha": "49c4f2ffed3a8d8bac8e4887e3e50e9b757c3ee4\n", "time": "2019-06-16T20:11:30Z\n", "diff": "mmm a / dbms / src / Storages / MergeTree / MergeTreeReader . cpp <nl> ppp b / dbms / src / Storages / MergeTree / MergeTreeReader . cpp <nl> MergeTreeReader : : MergeTreeReader ( const String & path , <nl> { <nl> try <nl> { <nl> - if ( ! Poco : : File ( path ) . exists ( ) ) <nl> - throw Exception ( \" Part \" + path + \" is missing \" , ErrorCodes : : NOT_FOUND_EXPECTED_DATA_PART ) ; <nl> - <nl> for ( const NameAndTypePair & column : columns ) <nl> addStreams ( column . name , * column . type , profile_callback , clock_type ) ; <nl> } <nl> void MergeTreeReader : : addStreams ( const String & name , const IDataType & type , <nl> if ( streams . count ( stream_name ) ) <nl> return ; <nl> <nl> - bool data_file_exists = Poco : : File ( path + stream_name + DATA_FILE_EXTENSION ) . exists ( ) ; <nl> + bool data_file_exists = data_part - > checksums . files . count ( path + stream_name + DATA_FILE_EXTENSION ) ; <nl> <nl> / * * If data file is missing then we will not try to open it . <nl> * It is necessary since it allows to add new column to structure of the table without creating new files for old parts . <nl>\n", "msg": "Reduce number of \" stat \" syscalls for MergeTree data parts\n"}
{"diff_id": 38443, "repo": "xbmc/xbmc\n", "sha": "52068bca6bba8c61d5389220cbcb8296866d514a\n", "time": "2010-11-30T02:55:21Z\n", "diff": "mmm a / xbmc / GUIDialogAddonSettings . cpp <nl> ppp b / xbmc / GUIDialogAddonSettings . cpp <nl> <nl> # include \" Settings . h \" <nl> # include \" GUIInfoManager . h \" <nl> # include \" GUIDialogSelect . h \" <nl> + # include \" utils / log . h \" <nl> <nl> using namespace std ; <nl> using namespace ADDON ; <nl> void CGUIDialogAddonSettings : : CreateControls ( ) <nl> <nl> setting = setting - > NextSiblingElement ( \" setting \" ) ; <nl> controlId + + ; <nl> + if ( controlId > = CONTROL_START_SECTION ) <nl> + { <nl> + CLog : : Log ( LOGERROR , \" % s - cannot have more than % d controls per category - simplify your addon ! \" , __FUNCTION__ , CONTROL_START_SECTION - CONTROL_START_SETTING ) ; <nl> + break ; <nl> + } <nl> } <nl> EnableControls ( ) ; <nl> } <nl>\n", "msg": "fixed : - Disallow more than 100 settings per category from addons .\n"}
{"diff_id": 38619, "repo": "xbmc/xbmc\n", "sha": "f59b22cc3d5a3306871b4e8e780b9cec860813a4\n", "time": "2010-07-28T17:08:04Z\n", "diff": "mmm a / xbmc / FileSystem / FileDAAP . cpp <nl> ppp b / xbmc / FileSystem / FileDAAP . cpp <nl> int64_t CFileDAAP : : Seek ( int64_t iFilePosition , int iWhence ) <nl> CSingleLock lock ( g_DaapClient ) ; <nl> <nl> if ( iWhence = = SEEK_POSSIBLE ) <nl> - return m_curl . Seek ( iFilePosition , iWhence ) ; <nl> + return 1 ; / / m_curl . Seek ( iFilePosition , iWhence ) ; <nl> <nl> int requestid = + + m_thisHost - > request_id ; <nl> <nl>\n", "msg": "changed : assume daap is seekable , asfar as i know the servers always are .\n"}
{"diff_id": 38654, "repo": "apple/swift\n", "sha": "4d29236c754303028492d9f71e32a62d1e5b149d\n", "time": "2013-05-07T17:03:48Z\n", "diff": "mmm a / lib / Sema / TypeCheckConstraintsApply . cpp <nl> ppp b / lib / Sema / TypeCheckConstraintsApply . cpp <nl> using namespace constraints ; <nl> STATISTIC ( NumHandledCoercions , \" # of coercions handled directly \" ) ; <nl> STATISTIC ( NumCoercions , \" # of coercions \" ) ; <nl> <nl> + / / / \\ brief Coerce the given scalar value to the given tuple type . <nl> + / / / <nl> + / / / \\ param solution The solution in which the coercion is performed . <nl> + / / / \\ param tc The type checker . <nl> + / / / \\ param expr The expression to be coerced . <nl> + / / / \\ param toTuple The tuple type to which the expression will be coerced . <nl> + / / / \\ param toScalarIdx The index of the scalar field within the tuple type <nl> + / / / \\ c toType . <nl> + / / / <nl> + / / / \\ returns The coerced expression , whose type will be equivalent to <nl> + / / / \\ c toTuple . <nl> + static Expr * coerceScalarToTuple ( const Solution & solution , TypeChecker & tc , <nl> + Expr * expr , TupleType * toTuple , <nl> + int toScalarIdx ) { <nl> + / / If the destination type is variadic , compute the injection function to use . <nl> + Expr * injectionFn = nullptr ; <nl> + const auto & lastField = toTuple - > getFields ( ) . back ( ) ; <nl> + <nl> + if ( lastField . isVararg ( ) ) { <nl> + / / Find the appropriate injection function . <nl> + ArraySliceType * sliceType <nl> + = cast < ArraySliceType > ( lastField . getType ( ) . getPointer ( ) ) ; <nl> + Type boundType = BuiltinIntegerType : : get ( 64 , tc . Context ) ; <nl> + injectionFn = tc . buildArrayInjectionFnRef ( sliceType , boundType , <nl> + expr - > getStartLoc ( ) ) ; <nl> + if ( ! injectionFn ) <nl> + return nullptr ; <nl> + } <nl> + <nl> + / / If we ' re initializing the varargs list , use its base type . <nl> + const auto & field = toTuple - > getFields ( ) [ toScalarIdx ] ; <nl> + Type toScalarType ; <nl> + if ( field . isVararg ( ) ) <nl> + toScalarType = field . getVarargBaseTy ( ) ; <nl> + else <nl> + toScalarType = field . getType ( ) ; <nl> + <nl> + / / Coerce the expression to the type to the scalar type . <nl> + expr = solution . coerceToType ( tc , expr , toScalarType ) ; <nl> + if ( ! expr ) <nl> + return nullptr ; <nl> + <nl> + / / Preserve the sugar of the scalar field . <nl> + / / FIXME : This doesn ' t work if the type has default values because they fail <nl> + / / to canonicalize . <nl> + SmallVector < TupleTypeElt , 4 > sugarFields ; <nl> + bool hasInit = false ; <nl> + int i = 0 ; <nl> + for ( auto & field : toTuple - > getFields ( ) ) { <nl> + if ( field . hasInit ( ) ) { <nl> + hasInit = true ; <nl> + break ; <nl> + } <nl> + if ( i = = toScalarIdx ) { <nl> + if ( field . isVararg ( ) ) { <nl> + assert ( ( field . getVarargBaseTy ( ) - > isUnresolvedType ( ) | | <nl> + expr - > getType ( ) - > isEqual ( field . getVarargBaseTy ( ) ) ) & & <nl> + \" scalar field is not equivalent to dest vararg field ? ! \" ) ; <nl> + <nl> + sugarFields . push_back ( TupleTypeElt ( field . getType ( ) , <nl> + field . getName ( ) , <nl> + field . getInit ( ) , <nl> + expr - > getType ( ) ) ) ; <nl> + } <nl> + else { <nl> + assert ( ( field . getType ( ) - > isUnresolvedType ( ) | | <nl> + expr - > getType ( ) - > isEqual ( field . getType ( ) ) ) & & <nl> + \" scalar field is not equivalent to dest tuple field ? ! \" ) ; <nl> + sugarFields . push_back ( TupleTypeElt ( expr - > getType ( ) , <nl> + field . getName ( ) ) ) ; <nl> + } <nl> + } else { <nl> + sugarFields . push_back ( field ) ; <nl> + } <nl> + + + i ; <nl> + } <nl> + <nl> + Type destSugarTy = hasInit ? toTuple <nl> + : TupleType : : get ( sugarFields , tc . Context ) ; <nl> + <nl> + return new ( tc . Context ) ScalarToTupleExpr ( expr , destSugarTy , toScalarIdx , <nl> + injectionFn ) ; <nl> + } <nl> + <nl> Expr * Solution : : coerceToType ( TypeChecker & tc , Expr * expr , Type toType , <nl> bool isAssignment ) const { <nl> / / The type we ' re converting from . <nl> Expr * Solution : : coerceToType ( TypeChecker & tc , Expr * expr , Type toType , <nl> Expr * origExpr = expr ; <nl> + + NumCoercions ; <nl> <nl> + / / Coercions to tuple type . <nl> + if ( auto toTuple = toType - > getAs < TupleType > ( ) ) { <nl> + int toScalarIdx = toTuple - > getFieldForScalarInit ( ) ; <nl> + / / Coerce scalar to tuple . <nl> + / / FIXME : The is < TupleType > check is overly conservative , and misses <nl> + / / cases that matter ( e . g . , when the scalar field is itself a tuple ) . <nl> + if ( toScalarIdx ! = - 1 & & ! fromType - > is < TupleType > ( ) ) { <nl> + return coerceScalarToTuple ( * this , tc , expr , toTuple , toScalarIdx ) ; <nl> + } <nl> + <nl> + / / FIXME : Handle tuple - > tuple coercion . <nl> + } <nl> + <nl> / / Coercions from an lvalue : requalify and load . We perform these coercions <nl> / / first because they are often the first step in a multi - step coercion . <nl> if ( auto fromLValue = fromType - > getAs < LValueType > ( ) ) { <nl> namespace { <nl> } <nl> <nl> Expr * visitParenExpr ( ParenExpr * expr ) { <nl> - return simplifyExprType ( expr ) ; <nl> + expr - > setType ( expr - > getSubExpr ( ) - > getType ( ) ) ; <nl> + return expr ; <nl> } <nl> <nl> Expr * visitTupleExpr ( TupleExpr * expr ) { <nl>\n", "msg": "[ Constraint application ] Coerce scalars to tuples , conservatively .\n"}
{"diff_id": 38657, "repo": "apple/swift\n", "sha": "363ecaf71c129e19b106fcb6dc9a5a6177b8140f\n", "time": "2016-03-28T19:52:03Z\n", "diff": "mmm a / lib / SILOptimizer / IPO / EagerSpecializer . cpp <nl> ppp b / lib / SILOptimizer / IPO / EagerSpecializer . cpp <nl> static void addReturnValueImpl ( SILBasicBlock * RetBB , SILBasicBlock * NewRetBB , <nl> assert ( isa < ReturnInst > ( RetInst ) | | isa < ThrowInst > ( RetInst ) & & <nl> \" expected a properly terminated return or throw block \" ) ; <nl> assert ( RetInst - > getOperand ( 0 ) - > getType ( ) = = NewRetVal - > getType ( ) & & <nl> - \" Mistmatched return type \" ) ; <nl> + \" Mismatched return type \" ) ; <nl> SILBasicBlock * MergedBB = RetBB ; <nl> <nl> / / Split the return block if it is nontrivial . <nl>\n", "msg": "[ gardening ] Fix recently introduced typo : \" mistmatched \" → \" mismatched \"\n"}
{"diff_id": 38744, "repo": "CRYTEK/CRYENGINE\n", "sha": "9e8e76fb49cd465c470a0a2edf9c097a3dcafc0b\n", "time": "2018-10-23T12:46:17Z\n", "diff": "mmm a / Code / CryEngine / RenderDll / XRenderD3D9 / GraphicsPipeline / SceneForward . cpp <nl> ppp b / Code / CryEngine / RenderDll / XRenderD3D9 / GraphicsPipeline / SceneForward . cpp <nl> void CSceneForwardStage : : ExecuteSky ( CTexture * pColorTex , CTexture * pDepthTex ) <nl> <nl> PROFILE_LABEL_SCOPE ( \" SKY_PASS \" ) ; <nl> <nl> + CRenderView * pRenderView = RenderView ( ) ; <nl> + <nl> + const bool applyFog = pRenderView - > IsGlobalFogEnabled ( ) & & ! ( GetGraphicsPipeline ( ) . IsPipelineFlag ( CGraphicsPipeline : : EPipelineFlags : : NO_SHADER_FOG ) ) ; <nl> + bool isProcedualSky = false ; <nl> + bool hasSkyDomeTexture = false ; <nl> + <nl> / / Update sky dome texture if new data is available <nl> int timestamp = 0 ; <nl> + <nl> + m_pSkyDomeTextureMie = CRendererResources : : s_ptexBlack ; <nl> + m_pSkyDomeTextureRayleigh = CRendererResources : : s_ptexBlack ; <nl> + m_pSkyMoonTex = CRendererResources : : s_ptexBlack ; <nl> if ( m_pHDRSkyRE ) <nl> { <nl> if ( m_pHDRSkyRE - > m_skyDomeTextureLastTimeStamp ! = m_pHDRSkyRE - > m_pRenderParams - > m_skyDomeTextureTimeStamp ) <nl> void CSceneForwardStage : : ExecuteSky ( CTexture * pColorTex , CTexture * pDepthTex ) <nl> m_pHDRSkyRE - > m_skyDomeTextureLastTimeStamp = m_pHDRSkyRE - > m_pRenderParams - > m_skyDomeTextureTimeStamp ; <nl> } <nl> <nl> + m_pSkyDomeTextureMie = m_pHDRSkyRE - > m_pSkyDomeTextureMie ; <nl> + m_pSkyDomeTextureRayleigh = m_pHDRSkyRE - > m_pSkyDomeTextureRayleigh ; <nl> + if ( m_pHDRSkyRE - > m_moonTexId > 0 ) <nl> + m_pSkyMoonTex = CTexture : : GetByID ( m_pHDRSkyRE - > m_moonTexId ) ; <nl> + <nl> timestamp = m_pHDRSkyRE - > m_skyDomeTextureLastTimeStamp ; <nl> + isProcedualSky = true ; <nl> } <nl> <nl> CTexture * pSkyDomeTex = CRendererResources : : s_ptexBlack ; <nl> void CSceneForwardStage : : ExecuteSky ( CTexture * pColorTex , CTexture * pDepthTex ) <nl> auto * pResources = ( CShaderResources * ) skyMat - > GetShaderItem ( ) . m_pShaderResources ; <nl> <nl> if ( auto pSkyTexInfo = pResources - > m_Textures [ EFTT_DIFFUSE ] ) <nl> + { <nl> pSkyDomeTex = CTexture : : ForName ( pSkyTexInfo - > m_Name , 0 , eTF_Unknown ) ; <nl> + hasSkyDomeTexture = true ; <nl> + } <nl> } <nl> <nl> - CRenderView * pRenderView = RenderView ( ) ; <nl> - <nl> D3DViewPort viewport = RenderViewportToD3D11Viewport ( RenderView ( ) - > GetViewport ( ) ) ; <nl> if ( pRenderView - > IsRecursive ( ) ) <nl> { <nl> void CSceneForwardStage : : ExecuteSky ( CTexture * pColorTex , CTexture * pDepthTex ) <nl> } <nl> CRY_ASSERT ( pColorTex - > GetWidth ( ) = = viewport . Width & & pColorTex - > GetHeight ( ) = = viewport . Height ) ; <nl> <nl> - const bool bFog = pRenderView - > IsGlobalFogEnabled ( ) & & ! ( GetGraphicsPipeline ( ) . IsPipelineFlag ( CGraphicsPipeline : : EPipelineFlags : : NO_SHADER_FOG ) ) ; <nl> - <nl> - m_pSkyDomeTextureMie = CRendererResources : : s_ptexBlack ; <nl> - m_pSkyDomeTextureRayleigh = CRendererResources : : s_ptexBlack ; <nl> - m_pSkyMoonTex = CRendererResources : : s_ptexBlack ; <nl> - if ( m_pHDRSkyRE ) <nl> - { <nl> - m_pSkyDomeTextureMie = m_pHDRSkyRE - > m_pSkyDomeTextureMie ; <nl> - m_pSkyDomeTextureRayleigh = m_pHDRSkyRE - > m_pSkyDomeTextureRayleigh ; <nl> - if ( m_pHDRSkyRE - > m_moonTexId > 0 ) <nl> - m_pSkyMoonTex = CTexture : : GetByID ( m_pHDRSkyRE - > m_moonTexId ) ; <nl> - } <nl> - <nl> uint64 rtMask = 0 ; <nl> <nl> - rtMask | = ! ! m_pHDRSkyRE ? g_HWSR_MaskBit [ HWSR_SAMPLE0 ] : 0 ; <nl> - rtMask | = pSkyDomeTex ? g_HWSR_MaskBit [ HWSR_SAMPLE1 ] : 0 ; <nl> - rtMask | = bFog ? g_HWSR_MaskBit [ HWSR_FOG ] : 0 ; <nl> + rtMask | = isProcedualSky ? g_HWSR_MaskBit [ HWSR_SAMPLE0 ] : 0 ; <nl> + rtMask | = hasSkyDomeTexture ? g_HWSR_MaskBit [ HWSR_SAMPLE1 ] : 0 ; <nl> + rtMask | = applyFog ? g_HWSR_MaskBit [ HWSR_FOG ] : 0 ; <nl> <nl> if ( m_skyPass . IsDirty ( rtMask , timestamp , pSkyDomeTex - > GetTextureID ( ) , pDepthTex - > GetTextureID ( ) ) ) <nl> { <nl>\n", "msg": "! B ( CE - 18667 ) Fixed muting of procedual sky\n"}
{"diff_id": 38968, "repo": "mongodb/mongo\n", "sha": "b7660950c4888052f2c68a02f6667c114a72dfbd\n", "time": "2013-10-07T16:35:48Z\n", "diff": "mmm a / src / mongo / db / db . cpp <nl> ppp b / src / mongo / db / db . cpp <nl> namespace mongo { <nl> # ifdef __linux__ <nl> try <nl> { <nl> - const dev_t dev = getPartition ( dir ) ; <nl> - <nl> - / / This path handles the case where the filesystem uses the whole device ( including LVM ) <nl> - string path = str : : stream ( ) < < <nl> - \" / sys / dev / block / \" < < major ( dev ) < < ' : ' < < minor ( dev ) < < \" / queue / read_ahead_kb \" ; <nl> - <nl> - if ( ! boost : : filesystem : : exists ( path ) ) { <nl> - / / This path handles the case where the filesystem is on a partition . <nl> - path = str : : stream ( ) <nl> - < < \" / sys / dev / block / \" < < major ( dev ) < < ' : ' < < minor ( dev ) / / this is a symlink <nl> - < < \" / . . \" / / parent directory of a partition is for the whole device <nl> - < < \" / queue / read_ahead_kb \" ; <nl> - } <nl> + const dev_t dev = getPartition ( dir ) ; <nl> + <nl> + / / This path handles the case where the filesystem uses the whole device ( including LVM ) <nl> + string path = str : : stream ( ) < < <nl> + \" / sys / dev / block / \" < < major ( dev ) < < ' : ' < < minor ( dev ) < < \" / queue / read_ahead_kb \" ; <nl> + <nl> + if ( ! boost : : filesystem : : exists ( path ) ) { <nl> + / / This path handles the case where the filesystem is on a partition . <nl> + path = str : : stream ( ) <nl> + < < \" / sys / dev / block / \" < < major ( dev ) < < ' : ' < < minor ( dev ) / / this is a symlink <nl> + < < \" / . . \" / / parent directory of a partition is for the whole device <nl> + < < \" / queue / read_ahead_kb \" ; <nl> + } <nl> <nl> - if ( boost : : filesystem : : exists ( path ) ) { <nl> - ifstream file ( path . c_str ( ) ) ; <nl> - if ( file . is_open ( ) ) { <nl> - int kb ; <nl> - file > > kb ; <nl> - if ( kb > 256 ) { <nl> - log ( ) < < startupWarningsLog ; <nl> + if ( boost : : filesystem : : exists ( path ) ) { <nl> + ifstream file ( path . c_str ( ) ) ; <nl> + if ( file . is_open ( ) ) { <nl> + int kb ; <nl> + file > > kb ; <nl> + if ( kb > 256 ) { <nl> + log ( ) < < startupWarningsLog ; <nl> <nl> - log ( ) < < \" * * WARNING : Readahead for \" < < dir < < \" is set to \" < < kb < < \" KB \" <nl> - < < startupWarningsLog ; <nl> + log ( ) < < \" * * WARNING : Readahead for \" < < dir < < \" is set to \" < < kb < < \" KB \" <nl> + < < startupWarningsLog ; <nl> <nl> - log ( ) < < \" * * We suggest setting it to 256KB ( 512 sectors ) or less \" <nl> - < < startupWarningsLog ; <nl> + log ( ) < < \" * * We suggest setting it to 256KB ( 512 sectors ) or less \" <nl> + < < startupWarningsLog ; <nl> <nl> - log ( ) < < \" * * http : / / dochub . mongodb . org / core / readahead \" <nl> - < < startupWarningsLog ; <nl> + log ( ) < < \" * * http : / / dochub . mongodb . org / core / readahead \" <nl> + < < startupWarningsLog ; <nl> + } <nl> } <nl> } <nl> } <nl> - } <nl> catch ( const boost : : filesystem : : filesystem_error & ex ) <nl> { <nl> log ( ) < < ex . what ( ) < < endl ; <nl>\n", "msg": "adding try / catch around boost : : filesystem : : exists ( ) to handle inaccessible path ( fixed indent ) .\n"}
{"diff_id": 39004, "repo": "xbmc/xbmc\n", "sha": "b1f78773bf49bb8c347f60e9240078ad83234385\n", "time": "2010-03-16T16:17:14Z\n", "diff": "mmm a / xbmc / lib / libPython / xbmcmodule / xbmcmodule . cpp <nl> ppp b / xbmc / lib / libPython / xbmcmodule / xbmcmodule . cpp <nl> namespace PYXBMC <nl> return Py_BuildValue ( ( char * ) \" s \" , strPath . c_str ( ) ) ; <nl> } <nl> <nl> + / / getcleanmovietitle function <nl> + PyDoc_STRVAR ( getCleanMovieTitle__doc__ , <nl> + \" getCleanMovieTitle ( path ) - - Returns a clean movie title and year string if available . \\ n \" <nl> + \" \\ n \" <nl> + \" path : string or unicode - String to clean \\ n \" <nl> + \" \\ n \" <nl> + \" example : \\ n \" <nl> + \" - title , year = xbmc . getCleanMovieTitle ( ' / path / to / moviefolder / ' ) \\ n \" ) ; <nl> + <nl> + PyObject * XBMC_GetCleanMovieTitle ( PyObject * self , PyObject * args ) <nl> + { <nl> + PyObject * pObjectText ; <nl> + if ( ! PyArg_ParseTuple ( args , ( char * ) \" O \" , & pObjectText ) ) return NULL ; <nl> + <nl> + CStdString strPath ; <nl> + if ( ! PyXBMCGetUnicodeString ( strPath , pObjectText , 1 ) ) return NULL ; <nl> + <nl> + CFileItem item ( strPath , true ) ; <nl> + CStdString strName = item . GetMovieName ( true ) ; <nl> + <nl> + CStdString strTitle , strTitleAndYear , strYear ; <nl> + CUtil : : CleanString ( strName , strTitle , strTitleAndYear , strYear , true ) ; <nl> + <nl> + return Py_BuildValue ( ( char * ) \" s , s \" , strTitle . c_str ( ) , strYear . c_str ( ) ) ; <nl> + } <nl> + <nl> / / validatePath function <nl> PyDoc_STRVAR ( validatePath__doc__ , <nl> \" validatePath ( path ) - - Returns the validated path . \\ n \" <nl> namespace PYXBMC <nl> { ( char * ) \" getRegion \" , ( PyCFunction ) XBMC_GetRegion , METH_VARARGS | METH_KEYWORDS , getRegion__doc__ } , <nl> { ( char * ) \" getSupportedMedia \" , ( PyCFunction ) XBMC_GetSupportedMedia , METH_VARARGS | METH_KEYWORDS , getSupportedMedia__doc__ } , <nl> <nl> + { ( char * ) \" getCleanMovieTitle \" , ( PyCFunction ) XBMC_GetCleanMovieTitle , METH_VARARGS | METH_KEYWORDS , getCleanMovieTitle__doc__ } , <nl> + <nl> { ( char * ) \" skinHasImage \" , ( PyCFunction ) XBMC_SkinHasImage , METH_VARARGS | METH_KEYWORDS , skinHasImage__doc__ } , <nl> { NULL , NULL , 0 , NULL } <nl> } ; <nl>\n", "msg": "added : python function to return a cleaned movie title and year string if available\n", "score": 1}
{"diff_id": 39055, "msg": "Revert \" Truncate oversize ' tx ' messages before relaying / storing . \"\n", "msgGPT": "truncate oversized TX messages to the size of the tx in them.", "METEOR Score": "23.350473556175313", "BLEU Score": "0.44790086199661416", "ROUGE-L Score": "0.18181817681818196", "score": 1, "repo": "bitcoin/bitcoin\n", "sha": "8f6f92c72bc560ecf8d12fc7235a3e2222d7c033\n", "time": "2013-08-02T05:50:04Z\n", "diff": "mmm a / src / main . cpp <nl> ppp b / src / main . cpp <nl> bool static ProcessMessage ( CNode * pfrom , string strCommand , CDataStream & vRecv ) <nl> CInv inv ( MSG_TX , tx . GetHash ( ) ) ; <nl> pfrom - > AddInventoryKnown ( inv ) ; <nl> <nl> - / / Truncate messages to the size of the tx in them <nl> - unsigned int nSize = : : GetSerializeSize ( tx , SER_NETWORK , PROTOCOL_VERSION ) ; <nl> - unsigned int oldSize = vMsg . size ( ) ; <nl> - if ( nSize < oldSize ) { <nl> - vMsg . resize ( nSize ) ; <nl> - printf ( \" truncating oversized TX % s ( % u - > % u ) \\ n \" , <nl> - tx . GetHash ( ) . ToString ( ) . c_str ( ) , <nl> - oldSize , nSize ) ; <nl> - } <nl> - <nl> bool fMissingInputs = false ; <nl> CValidationState state ; <nl> if ( mempool . accept ( state , tx , true , & fMissingInputs ) ) <nl>\n"}
{"diff_id": 39097, "repo": "xbmc/xbmc\n", "sha": "cc5b821875b3f353b7eb5a04a354cba09efca223\n", "time": "2013-09-27T18:19:27Z\n", "diff": "mmm a / xbmc / cores / dvdplayer / DVDPlayer . cpp <nl> ppp b / xbmc / cores / dvdplayer / DVDPlayer . cpp <nl> bool CDVDPlayer : : GetCurrentSubtitle ( CStdString & strSubtitle ) <nl> { <nl> double pts = m_clock . GetClock ( ) + m_State . time_offset ; <nl> <nl> - if ( m_pInputStream & & m_pInputStream - > IsStreamType ( DVDSTREAM_TYPE_DVD ) & & m_CurrentSubtitle . source ! = STREAM_SOURCE_TEXT ) <nl> + if ( m_pInputStream & & m_pInputStream - > IsStreamType ( DVDSTREAM_TYPE_DVD ) & & m_CurrentSubtitle . source ! = STREAM_SOURCE_TEXT & & m_CurrentSubtitle . source ! = STREAM_SOURCE_DEMUX_SUB ) <nl> return false ; <nl> <nl> m_dvdPlayerSubtitle . GetCurrentSubtitle ( strSubtitle , pts - m_dvdPlayerVideo . GetSubtitleDelay ( ) ) ; <nl>\n", "msg": "allow external . sub subtitles next to text - based ones\n"}
{"diff_id": 39192, "repo": "xbmc/xbmc\n", "sha": "8633ee4255646fe9764da2ae575c7efec2cb93f2\n", "time": "2013-11-06T01:00:08Z\n", "diff": "mmm a / xbmc / utils / TuxBoxUtil . cpp <nl> ppp b / xbmc / utils / TuxBoxUtil . cpp <nl> bool CTuxBoxUtil : : GetHttpXML ( CURL url , CStdString strRequestType ) <nl> CXBMCTinyXML doc ; <nl> TiXmlElement * XMLRoot = NULL ; <nl> strTmp . Replace ( \" > < / \" , \" > - < / \" ) ; / / FILL EMPTY ELEMENTS WITH \" - \" ! <nl> - doc . Parse ( strTmp ) ; <nl> + doc . Parse ( strTmp , http . GetServerReportedCharset ( ) ) ; <nl> strTmp . Empty ( ) ; <nl> <nl> XMLRoot = doc . RootElement ( ) ; <nl>\n", "msg": "TuxBoxUtil : use charset reported by http server\n"}
{"diff_id": 39271, "repo": "godotengine/godot\n", "sha": "f48845428dcfe79edf381b1626e4ae7994fbdc96\n", "time": "2018-02-14T07:18:48Z\n", "diff": "mmm a / modules / bullet / space_bullet . cpp <nl> ppp b / modules / bullet / space_bullet . cpp <nl> bool SpaceBullet : : test_body_motion ( RigidBodyBullet * p_body , const Transform & p_f <nl> } else { <nl> if ( ! l_has_penetration ) <nl> break ; <nl> + else <nl> + has_penetration = true ; <nl> } <nl> } <nl> } <nl>\n", "msg": "Added return true o collide when no rusult is NULL\n"}
{"diff_id": 39316, "repo": "opencv/opencv\n", "sha": "5164c4ba313bb93a8b1ea3c4a6737922dbd34769\n", "time": "2016-04-13T07:10:24Z\n", "diff": "mmm a / apps / annotation / opencv_annotation . cpp <nl> ppp b / apps / annotation / opencv_annotation . cpp <nl> <nl> . / opencv_annotation - images < folder location > - annotations < ouput file > <nl> <nl> Created by : Puttemans Steven - February 2015 <nl> + Adapted by : Puttemans Steven - April 2016 - Vectorize the process to enable better processing <nl> + + early leave and store by pressing an ESC key <nl> + + enable delete ` d ` button , to remove last annotation <nl> * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / <nl> <nl> # include < opencv2 / core / core . hpp > <nl> using namespace cv ; <nl> <nl> / / Function prototypes <nl> void on_mouse ( int , int , int , int , void * ) ; <nl> - string int2string ( int ) ; <nl> - void get_annotations ( Mat , stringstream * ) ; <nl> + vector < Rect > get_annotations ( Mat ) ; <nl> <nl> / / Public parameters <nl> Mat image ; <nl> int roi_x0 = 0 , roi_y0 = 0 , roi_x1 = 0 , roi_y1 = 0 , num_of_rec = 0 ; <nl> - bool start_draw = false ; <nl> + bool start_draw = false , stop = false ; <nl> <nl> / / Window name for visualisation purposes <nl> - const string window_name = \" OpenCV Based Annotation Tool \" ; <nl> + const string window_name = \" OpenCV Based Annotation Tool \" ; <nl> <nl> / / FUNCTION : Mouse response for selecting objects in images <nl> / / If left button is clicked , start drawing a rectangle as long as mouse moves <nl> const string window_name = \" OpenCV Based Annotation Tool \" ; <nl> void on_mouse ( int event , int x , int y , int , void * ) <nl> { <nl> / / Action when left button is clicked <nl> - if ( event = = CV_EVENT_LBUTTONDOWN ) <nl> + if ( event = = EVENT_LBUTTONDOWN ) <nl> { <nl> if ( ! start_draw ) <nl> { <nl> void on_mouse ( int event , int x , int y , int , void * ) <nl> start_draw = false ; <nl> } <nl> } <nl> - / / Action when mouse is moving <nl> - if ( ( event = = CV_EVENT_MOUSEMOVE ) & & start_draw ) <nl> + <nl> + / / Action when mouse is moving and drawing is enabled <nl> + if ( ( event = = EVENT_MOUSEMOVE ) & & start_draw ) <nl> { <nl> / / Redraw bounding box for annotation <nl> Mat current_view ; <nl> void on_mouse ( int event , int x , int y , int , void * ) <nl> } <nl> } <nl> <nl> - / / FUNCTION : snippet to convert an integer value to a string using a clean function <nl> - / / instead of creating a stringstream each time inside the main code <nl> - string int2string ( int num ) <nl> + / / FUNCTION : returns a vector of Rect objects given an image containing positive object instances <nl> + vector < Rect > get_annotations ( Mat input_image ) <nl> { <nl> - stringstream temp_stream ; <nl> - temp_stream < < num ; <nl> - return temp_stream . str ( ) ; <nl> - } <nl> + vector < Rect > current_annotations ; <nl> <nl> - / / FUNCTION : given an image containing positive object instances , add all the object <nl> - / / annotations to a known stringstream <nl> - void get_annotations ( Mat input_image , stringstream * output_stream ) <nl> - { <nl> - / / Make it possible to exit the annotation <nl> - bool stop = false ; <nl> - <nl> - / / Reset the num_of_rec element at each iteration <nl> - / / Make sure the global image is set to the current image <nl> - num_of_rec = 0 ; <nl> - image = input_image ; <nl> + / / Make it possible to exit the annotation process <nl> + stop = false ; <nl> <nl> / / Init window interface and couple mouse actions <nl> namedWindow ( window_name , WINDOW_AUTOSIZE ) ; <nl> setMouseCallback ( window_name , on_mouse ) ; <nl> <nl> + image = input_image ; <nl> imshow ( window_name , image ) ; <nl> - stringstream temp_stream ; <nl> int key_pressed = 0 ; <nl> <nl> do <nl> { <nl> + / / Get a temporary image clone <nl> + Mat temp_image = input_image . clone ( ) ; <nl> + Rect currentRect ( 0 , 0 , 0 , 0 ) ; <nl> + <nl> / / Keys for processing <nl> / / You need to select one for confirming a selection and one to continue to the next image <nl> / / Based on the universal ASCII code of the keystroke : http : / / www . asciitable . com / <nl> - / / c = 99 add rectangle to current image <nl> - / / n = 110 save added rectangles and show next image <nl> - / / < ESC > = 27 exit program <nl> + / / < c > = 99 add rectangle to current image <nl> + / / < n > = 110 save added rectangles and show next image <nl> + / / < d > = 100 delete the last annotation made <nl> + / / < ESC > = 27 exit program <nl> key_pressed = 0xFF & waitKey ( 0 ) ; <nl> switch ( key_pressed ) <nl> { <nl> void get_annotations ( Mat input_image , stringstream * output_stream ) <nl> stop = true ; <nl> break ; <nl> case 99 : <nl> - / / Add a rectangle to the list <nl> - num_of_rec + + ; <nl> / / Draw initiated from top left corner <nl> if ( roi_x0 < roi_x1 & & roi_y0 < roi_y1 ) <nl> { <nl> - temp_stream < < \" \" < < int2string ( roi_x0 ) < < \" \" < < int2string ( roi_y0 ) < < \" \" < < int2string ( roi_x1 - roi_x0 ) < < \" \" < < int2string ( roi_y1 - roi_y0 ) ; <nl> + currentRect . x = roi_x0 ; <nl> + currentRect . y = roi_y0 ; <nl> + currentRect . width = roi_x1 - roi_x0 ; <nl> + currentRect . height = roi_y1 - roi_y0 ; <nl> } <nl> / / Draw initiated from bottom right corner <nl> if ( roi_x0 > roi_x1 & & roi_y0 > roi_y1 ) <nl> { <nl> - temp_stream < < \" \" < < int2string ( roi_x1 ) < < \" \" < < int2string ( roi_y1 ) < < \" \" < < int2string ( roi_x0 - roi_x1 ) < < \" \" < < int2string ( roi_y0 - roi_y1 ) ; <nl> + currentRect . x = roi_x1 ; <nl> + currentRect . y = roi_y1 ; <nl> + currentRect . width = roi_x0 - roi_x1 ; <nl> + currentRect . height = roi_y0 - roi_y1 ; <nl> } <nl> / / Draw initiated from top right corner <nl> if ( roi_x0 > roi_x1 & & roi_y0 < roi_y1 ) <nl> { <nl> - temp_stream < < \" \" < < int2string ( roi_x1 ) < < \" \" < < int2string ( roi_y0 ) < < \" \" < < int2string ( roi_x0 - roi_x1 ) < < \" \" < < int2string ( roi_y1 - roi_y0 ) ; <nl> + currentRect . x = roi_x1 ; <nl> + currentRect . y = roi_y0 ; <nl> + currentRect . width = roi_x0 - roi_x1 ; <nl> + currentRect . height = roi_y1 - roi_y0 ; <nl> } <nl> / / Draw initiated from bottom left corner <nl> if ( roi_x0 < roi_x1 & & roi_y0 > roi_y1 ) <nl> { <nl> - temp_stream < < \" \" < < int2string ( roi_x0 ) < < \" \" < < int2string ( roi_y1 ) < < \" \" < < int2string ( roi_x1 - roi_x0 ) < < \" \" < < int2string ( roi_y0 - roi_y1 ) ; <nl> + currentRect . x = roi_x0 ; <nl> + currentRect . y = roi_y1 ; <nl> + currentRect . width = roi_x1 - roi_x0 ; <nl> + currentRect . height = roi_y0 - roi_y1 ; <nl> } <nl> - <nl> - rectangle ( input_image , Point ( roi_x0 , roi_y0 ) , Point ( roi_x1 , roi_y1 ) , Scalar ( 0 , 255 , 0 ) , 1 ) ; <nl> - <nl> + / / Draw the rectangle on the canvas <nl> + / / Add the rectangle to the vector of annotations <nl> + current_annotations . push_back ( currentRect ) ; <nl> + break ; <nl> + case 100 : <nl> + / / Remove the last annotation <nl> + if ( current_annotations . size ( ) > 0 ) { <nl> + current_annotations . pop_back ( ) ; <nl> + } <nl> + break ; <nl> + default : <nl> + / / Default case - - > do nothing at all <nl> + / / Other keystrokes can simply be ignored <nl> break ; <nl> } <nl> <nl> void get_annotations ( Mat input_image , stringstream * output_stream ) <nl> { <nl> break ; <nl> } <nl> + <nl> + / / Draw all the current rectangles onto the top image and make sure that the global image is linked <nl> + for ( int i = 0 ; i < ( int ) current_annotations . size ( ) ; i + + ) { <nl> + rectangle ( temp_image , current_annotations [ i ] , Scalar ( 0 , 255 , 0 ) , 1 ) ; <nl> + } <nl> + image = temp_image ; <nl> + <nl> + / / Force an explicit redraw of the canvas - - > necessary to visualize delete correctly <nl> + imshow ( window_name , image ) ; <nl> } <nl> / / Continue as long as the next image key has not been pressed <nl> while ( key_pressed ! = 110 ) ; <nl> <nl> - / / If there are annotations AND the next image key is pressed <nl> - / / Write the image annotations to the file <nl> - if ( num_of_rec > 0 & & key_pressed = = 110 ) <nl> - { <nl> - * output_stream < < \" \" < < num_of_rec < < temp_stream . str ( ) < < endl ; <nl> - } <nl> - <nl> / / Close down the window <nl> destroyWindow ( window_name ) ; <nl> + <nl> + / / Return the data <nl> + return current_annotations ; <nl> } <nl> <nl> int main ( int argc , const char * * argv ) <nl> { <nl> / / If no arguments are given , then supply some information on how this tool works <nl> if ( argc = = 1 ) { <nl> - cout < < \" Usage : \" < < argv [ 0 ] < < endl ; <nl> - cout < < \" - images < folder_location > [ example - / data / testimages / ] \" < < endl ; <nl> - cout < < \" - annotations < ouput_file > [ example - / data / annotations . txt ] \" < < endl ; <nl> - <nl> - return - 1 ; <nl> + cout < < \" Usage : \" < < argv [ 0 ] < < endl ; <nl> + cout < < \" - images < folder_location > [ example - / data / testimages / ] \" < < endl ; <nl> + cout < < \" - annotations < ouput_file > [ example - / data / annotations . txt ] \" < < endl ; <nl> + cout < < \" TIP : Use absolute paths to avoid any problems with the software ! \" < < endl ; <nl> + return - 1 ; <nl> } <nl> <nl> / / Read in the input arguments <nl> string image_folder ; <nl> - string annotations ; <nl> + string annotations_file ; <nl> for ( int i = 1 ; i < argc ; + + i ) <nl> { <nl> if ( ! strcmp ( argv [ i ] , \" - images \" ) ) <nl> int main ( int argc , const char * * argv ) <nl> } <nl> else if ( ! strcmp ( argv [ i ] , \" - annotations \" ) ) <nl> { <nl> - annotations = argv [ + + i ] ; <nl> + annotations_file = argv [ + + i ] ; <nl> } <nl> } <nl> <nl> int main ( int argc , const char * * argv ) <nl> } <nl> # endif <nl> <nl> - / / Create the outputfilestream <nl> - ofstream output ( annotations . c_str ( ) ) ; <nl> - if ( ! output . is_open ( ) ) { <nl> - cerr < < \" The path for the output file contains an error and could not be opened . Please check again ! \" < < endl ; <nl> - return 0 ; <nl> - } <nl> - <nl> + / / Start by processing the data <nl> / / Return the image filenames inside the image folder <nl> + vector < vector < Rect > > annotations ; <nl> vector < String > filenames ; <nl> String folder ( image_folder ) ; <nl> glob ( folder , filenames ) ; <nl> int main ( int argc , const char * * argv ) <nl> continue ; <nl> } <nl> <nl> - / / Perform annotations & generate corresponding output <nl> - stringstream output_stream ; <nl> - get_annotations ( current_image , & output_stream ) ; <nl> + / / Perform annotations & store the result inside the vectorized structure <nl> + vector < Rect > current_annotations = get_annotations ( current_image ) ; <nl> + annotations . push_back ( current_annotations ) ; <nl> + <nl> + / / Check if the ESC key was hit , then exit earlier then expected <nl> + if ( stop ) { <nl> + break ; <nl> + } <nl> + } <nl> + <nl> + / / When all data is processed , store the data gathered inside the proper file <nl> + / / This now even gets called when the ESC button was hit to store preliminary results <nl> + ofstream output ( annotations_file . c_str ( ) ) ; <nl> + if ( ! output . is_open ( ) ) { <nl> + cerr < < \" The path for the output file contains an error and could not be opened . Please check again ! \" < < endl ; <nl> + return 0 ; <nl> + } <nl> <nl> - / / Store the annotations , write to the output file <nl> - if ( output_stream . str ( ) ! = \" \" ) { <nl> - output < < filenames [ i ] < < output_stream . str ( ) ; <nl> + / / Store the annotations , write to the output file <nl> + for ( int i = 0 ; i < ( int ) annotations . size ( ) ; i + + ) { <nl> + output < < filenames [ i ] < < \" \" < < annotations [ i ] . size ( ) ; <nl> + for ( int j = 0 ; j < ( int ) annotations [ i ] . size ( ) ; j + + ) { <nl> + Rect temp = annotations [ i ] [ j ] ; <nl> + output < < \" \" < < temp . x < < \" \" < < temp . y < < \" \" < < temp . width < < \" \" < < temp . height ; <nl> } <nl> + output < < endl ; <nl> } <nl> <nl> return 0 ; <nl>\n", "msg": "vectorize process + enable early quitting / storage + enable delete annotation option\n"}
{"diff_id": 39417, "repo": "facebook/hhvm\n", "sha": "4abd9b1396a17ff654c642feaf02af4e0f3b60e4\n", "time": "2018-03-02T14:11:24Z\n", "diff": "mmm a / hphp / runtime / vm / jit / fixup . cpp <nl> ppp b / hphp / runtime / vm / jit / fixup . cpp <nl> union FixupEntry { <nl> IndirectFixup indirect ; <nl> } ; <nl> <nl> - TreadHashMap < uint32_t , FixupEntry , std : : hash < uint32_t > > s_fixups { kInitCapac } ; <nl> + struct FixupHash { <nl> + size_t operator ( ) ( uint32_t k ) const { <nl> + return hash_int64 ( k ) ; <nl> + } <nl> + } ; <nl> + <nl> + TreadHashMap < uint32_t , FixupEntry , FixupHash > s_fixups { kInitCapac } ; <nl> <nl> PC pc ( const ActRec * / * ar * / , const Func * f , const Fixup & fixup ) { <nl> assertx ( f ) ; <nl>\n", "msg": "Use hash_int64 in the Fixup TreadHashMap\n"}
{"diff_id": 39418, "repo": "EOSIO/eos\n", "sha": "4a5aa34ab92aceede64153c1602cdafbbf60d8a8\n", "time": "2019-03-28T19:41:50Z\n", "diff": "mmm a / plugins / net_plugin / net_plugin . cpp <nl> ppp b / plugins / net_plugin / net_plugin . cpp <nl> namespace eosio { <nl> <nl> bool use_socket_read_watermark = false ; <nl> <nl> + channels : : transaction_ack : : channel_type : : handle incoming_transaction_ack_subscription ; <nl> + <nl> uint16_t thread_pool_size = 4 ; <nl> optional < boost : : asio : : thread_pool > thread_pool ; <nl> std : : shared_ptr < boost : : asio : : io_context > server_ioc ; <nl> namespace eosio { <nl> void send_transaction_to_all ( const std : : shared_ptr < std : : vector < char > > & send_buffer , VerifierFunc verify ) ; <nl> <nl> void accepted_block ( const block_state_ptr & ) ; <nl> + void transaction_ack ( const std : : pair < fc : : exception_ptr , transaction_metadata_ptr > & ) ; <nl> <nl> bool is_valid ( const handshake_message & msg ) ; <nl> <nl> namespace eosio { <nl> dispatcher - > bcast_block ( block ) ; <nl> } <nl> <nl> + void net_plugin_impl : : transaction_ack ( const std : : pair < fc : : exception_ptr , transaction_metadata_ptr > & results ) { <nl> + const auto & id = results . second - > id ; <nl> + if ( results . first ) { <nl> + fc_ilog ( logger , \" signaled NACK , trx - id = $ { id } : $ { why } \" , ( \" id \" , id ) ( \" why \" , results . first - > to_detail_string ( ) ) ) ; <nl> + dispatcher - > rejected_transaction ( id ) ; <nl> + } else { <nl> + fc_ilog ( logger , \" signaled ACK , trx - id = $ { id } \" , ( \" id \" , id ) ) ; <nl> + dispatcher - > bcast_transaction ( results . second ) ; <nl> + } <nl> + } <nl> + <nl> bool net_plugin_impl : : authenticate_peer ( const handshake_message & msg ) const { <nl> if ( allowed_connections = = None ) <nl> return false ; <nl> namespace eosio { <nl> cc . accepted_block . connect ( boost : : bind ( & net_plugin_impl : : accepted_block , my . get ( ) , _1 ) ) ; <nl> } <nl> <nl> + my - > incoming_transaction_ack_subscription = app ( ) . get_channel < channels : : transaction_ack > ( ) . subscribe ( boost : : bind ( & net_plugin_impl : : transaction_ack , my . get ( ) , _1 ) ) ; <nl> + <nl> my - > db_read_mode = cc . get_read_mode ( ) ; <nl> if ( my - > db_read_mode = = chain : : db_read_mode : : READ_ONLY ) { <nl> my - > max_nodes_per_host = 0 ; <nl>\n", "msg": "Revert \" Remove unneeded ack of transactions . Already processed by handle_message of packed_transaction_ptr \"\n"}
{"diff_id": 39616, "msg": "set _stream_creator to NULL after DestroyStreamCreator\n", "msgGPT": "set _stream_creator to NULL after destroying the stream creator to prevent potential issues.", "METEOR Score": "50.84444353633541", "BLEU Score": "0.5851582733665041", "ROUGE-L Score": "0.6999999952000001", "score": 1, "repo": "apache/incubator-brpc\n", "sha": "1425a87bd48a1e65466248149f989c65f9324585\n", "time": "2018-09-26T07:53:15Z\n", "diff": "mmm a / src / brpc / controller . cpp <nl> ppp b / src / brpc / controller . cpp <nl> void Controller : : EndRPC ( const CompletionInfo & info ) { <nl> } <nl> if ( _stream_creator ) { <nl> _stream_creator - > DestroyStreamCreator ( this ) ; <nl> + _stream_creator = NULL ; <nl> } <nl> / / Clear _error_text when the call succeeded , otherwise a successful <nl> / / call with non - empty ErrorText may confuse user . <nl>\n"}
{"diff_id": 39650, "repo": "bitcoin/bitcoin\n", "sha": "1e50d22ed2df9e87d1c33784d4274750546227fc\n", "time": "2016-11-07T12:19:42Z\n", "diff": "mmm a / src / main . cpp <nl> ppp b / src / main . cpp <nl> bool static ProcessMessage ( CNode * pfrom , string strCommand , CDataStream & vRecv , <nl> <nl> if ( ! ( pfrom - > GetLocalServices ( ) & NODE_BLOOM ) & & <nl> ( strCommand = = NetMsgType : : FILTERLOAD | | <nl> - strCommand = = NetMsgType : : FILTERADD | | <nl> - strCommand = = NetMsgType : : FILTERCLEAR ) ) <nl> + strCommand = = NetMsgType : : FILTERADD ) ) <nl> { <nl> if ( pfrom - > nVersion > = NO_BLOOM_VERSION ) { <nl> LOCK ( cs_main ) ; <nl> bool static ProcessMessage ( CNode * pfrom , string strCommand , CDataStream & vRecv , <nl> else if ( strCommand = = NetMsgType : : FILTERCLEAR ) <nl> { <nl> LOCK ( pfrom - > cs_filter ) ; <nl> - delete pfrom - > pfilter ; <nl> - pfrom - > pfilter = new CBloomFilter ( ) ; <nl> + if ( pfrom - > GetLocalServices ( ) & NODE_BLOOM ) { <nl> + delete pfrom - > pfilter ; <nl> + pfrom - > pfilter = new CBloomFilter ( ) ; <nl> + } <nl> pfrom - > fRelayTxes = true ; <nl> } <nl> <nl>\n", "msg": "Merge : Allow filterclear messages for enabling TX relay only .\n"}
{"diff_id": 39710, "repo": "apple/swift\n", "sha": "0df444920e3789f42253bef23f66e4384cd3dfa7\n", "time": "2020-04-10T17:16:06Z\n", "diff": "mmm a / lib / Sema / ConstraintGraph . cpp <nl> ppp b / lib / Sema / ConstraintGraph . cpp <nl> void ConstraintGraph : : unbindTypeVariable ( TypeVariableType * typeVar , Type fixed ) { <nl> } <nl> } <nl> <nl> + # pragma mark Algorithms <nl> + <nl> + / / / Perform a depth - first search . <nl> + / / / <nl> + / / / \\ param cg The constraint graph . <nl> + / / / \\ param typeVar The type variable we ' re searching from . <nl> + / / / \\ param preVisitNode Called before traversing a node . Must return \\ c <nl> + / / / false when the node has already been visited . <nl> + / / / \\ param visitConstraint Called before considering a constraint . If it <nl> + / / / returns \\ c false , that constraint will be skipped . <nl> + / / / \\ param visitedConstraints Set of already - visited constraints , used <nl> + / / / internally to avoid duplicated work . <nl> + static void depthFirstSearch ( <nl> + ConstraintGraph & cg , <nl> + TypeVariableType * typeVar , <nl> + llvm : : function_ref < bool ( TypeVariableType * ) > preVisitNode , <nl> + llvm : : function_ref < bool ( Constraint * ) > visitConstraint , <nl> + llvm : : SmallPtrSet < Constraint * , 8 > & visitedConstraints ) { <nl> + / / Visit this node . If we ' ve already seen it , bail out . <nl> + if ( ! preVisitNode ( typeVar ) ) <nl> + return ; <nl> + <nl> + / / Local function to visit adjacent type variables . <nl> + auto visitAdjacencies = [ & ] ( ArrayRef < TypeVariableType * > adjTypeVars ) { <nl> + for ( auto adj : adjTypeVars ) { <nl> + if ( adj = = typeVar ) <nl> + continue ; <nl> + <nl> + / / Recurse into this node . <nl> + depthFirstSearch ( cg , adj , preVisitNode , visitConstraint , <nl> + visitedConstraints ) ; <nl> + } <nl> + } ; <nl> + <nl> + / / Walk all of the constraints associated with this node to find related <nl> + / / nodes . <nl> + auto & node = cg [ typeVar ] ; <nl> + for ( auto constraint : node . getConstraints ( ) ) { <nl> + / / If we ' ve already seen this constraint , skip it . <nl> + if ( ! visitedConstraints . insert ( constraint ) . second ) <nl> + continue ; <nl> + <nl> + if ( visitConstraint ( constraint ) ) <nl> + visitAdjacencies ( constraint - > getTypeVariables ( ) ) ; <nl> + } <nl> + <nl> + / / Visit all of the other nodes in the equivalence class . <nl> + auto repTypeVar = cg . getConstraintSystem ( ) . getRepresentative ( typeVar ) ; <nl> + if ( typeVar = = repTypeVar ) { <nl> + / / We are the representative , so visit all of the other type variables <nl> + / / in this equivalence class . <nl> + visitAdjacencies ( node . getEquivalenceClass ( ) ) ; <nl> + } else { <nl> + / / We are not the representative ; visit the representative . <nl> + visitAdjacencies ( repTypeVar ) ; <nl> + } <nl> + <nl> + / / Walk any type variables related via fixed bindings . <nl> + visitAdjacencies ( node . getFixedBindings ( ) ) ; <nl> + } <nl> + <nl> llvm : : TinyPtrVector < Constraint * > ConstraintGraph : : gatherConstraints ( <nl> TypeVariableType * typeVar , GatheringKind kind , <nl> llvm : : function_ref < bool ( Constraint * ) > acceptConstraintFn ) { <nl> llvm : : TinyPtrVector < Constraint * > ConstraintGraph : : gatherConstraints ( <nl> return constraints ; <nl> } <nl> <nl> - # pragma mark Algorithms <nl> - <nl> - / / / Perform a depth - first search . <nl> - / / / <nl> - / / / \\ param cg The constraint graph . <nl> - / / / \\ param typeVar The type variable we ' re searching from . <nl> - / / / \\ param preVisitNode Called before traversing a node . Must return \\ c <nl> - / / / false when the node has already been visited . <nl> - / / / \\ param visitConstraint Called before considering a constraint . If it <nl> - / / / returns \\ c false , that constraint will be skipped . <nl> - / / / \\ param visitedConstraints Set of already - visited constraints , used <nl> - / / / internally to avoid duplicated work . <nl> - static void depthFirstSearch ( <nl> - ConstraintGraph & cg , <nl> - TypeVariableType * typeVar , <nl> - llvm : : function_ref < bool ( TypeVariableType * ) > preVisitNode , <nl> - llvm : : function_ref < bool ( Constraint * ) > visitConstraint , <nl> - llvm : : SmallPtrSet < Constraint * , 8 > & visitedConstraints ) { <nl> - / / Visit this node . If we ' ve already seen it , bail out . <nl> - if ( ! preVisitNode ( typeVar ) ) <nl> - return ; <nl> - <nl> - / / Local function to visit adjacent type variables . <nl> - auto visitAdjacencies = [ & ] ( ArrayRef < TypeVariableType * > adjTypeVars ) { <nl> - for ( auto adj : adjTypeVars ) { <nl> - if ( adj = = typeVar ) <nl> - continue ; <nl> - <nl> - / / Recurse into this node . <nl> - depthFirstSearch ( cg , adj , preVisitNode , visitConstraint , <nl> - visitedConstraints ) ; <nl> - } <nl> - } ; <nl> - <nl> - / / Walk all of the constraints associated with this node to find related <nl> - / / nodes . <nl> - auto & node = cg [ typeVar ] ; <nl> - for ( auto constraint : node . getConstraints ( ) ) { <nl> - / / If we ' ve already seen this constraint , skip it . <nl> - if ( ! visitedConstraints . insert ( constraint ) . second ) <nl> - continue ; <nl> - <nl> - if ( visitConstraint ( constraint ) ) <nl> - visitAdjacencies ( constraint - > getTypeVariables ( ) ) ; <nl> - } <nl> - <nl> - / / Visit all of the other nodes in the equivalence class . <nl> - auto repTypeVar = cg . getConstraintSystem ( ) . getRepresentative ( typeVar ) ; <nl> - if ( typeVar = = repTypeVar ) { <nl> - / / We are the representative , so visit all of the other type variables <nl> - / / in this equivalence class . <nl> - visitAdjacencies ( node . getEquivalenceClass ( ) ) ; <nl> - } else { <nl> - / / We are not the representative ; visit the representative . <nl> - visitAdjacencies ( repTypeVar ) ; <nl> - } <nl> - <nl> - / / Walk any type variables related via fixed bindings . <nl> - visitAdjacencies ( node . getFixedBindings ( ) ) ; <nl> - } <nl> - <nl> namespace { <nl> / / / A union - find connected components algorithm used to find the connected <nl> / / / components within a constraint graph . <nl>\n", "msg": "[ CS ] NFC : Move depthFirstSearch up slightly\n"}
{"diff_id": 39999, "repo": "arangodb/arangodb\n", "sha": "a7a556506932665e7455e27863dcc129eaeee85b\n", "time": "2016-04-11T12:22:22Z\n", "diff": "mmm a / arangod / Utils / Transaction . cpp <nl> ppp b / arangod / Utils / Transaction . cpp <nl> OperationResult Transaction : : modifyLocal ( <nl> <nl> VPackBuilder resultBuilder ; / / building the complete result <nl> <nl> - auto workForOneDocument = [ & ] ( VPackSlice const newVal ) - > int { <nl> + auto workForOneDocument = [ & ] ( VPackSlice const newVal , bool isBabies ) - > int { <nl> if ( ! newVal . isObject ( ) ) { <nl> return TRI_ERROR_ARANGO_DOCUMENT_TYPE_INVALID ; <nl> } <nl> OperationResult Transaction : : modifyLocal ( <nl> <nl> if ( res = = TRI_ERROR_ARANGO_CONFLICT ) { <nl> / / still return <nl> - if ( ! options . silent ) { <nl> + if ( ! options . silent & & ! isBabies ) { <nl> std : : string key = newVal . get ( TRI_VOC_ATTRIBUTE_KEY ) . copyString ( ) ; <nl> buildDocumentIdentity ( resultBuilder , cid , key , actualRevision , <nl> VPackSlice ( ) , <nl> OperationResult Transaction : : modifyLocal ( <nl> res = TRI_ERROR_NO_ERROR ; <nl> <nl> if ( newValue . isArray ( ) ) { <nl> - VPackArrayBuilder b ( & resultBuilder ) ; <nl> + std : : unordered_map < int , size_t > errorCounter ; <nl> + resultBuilder . openArray ( ) ; <nl> VPackArrayIterator it ( newValue ) ; <nl> while ( it . valid ( ) ) { <nl> - res = workForOneDocument ( it . value ( ) ) ; <nl> + res = workForOneDocument ( it . value ( ) , true ) ; <nl> if ( res ! = TRI_ERROR_NO_ERROR ) { <nl> - break ; <nl> + createBabiesError ( resultBuilder , errorCounter , res ) ; <nl> } <nl> + + it ; <nl> } <nl> + resultBuilder . close ( ) ; <nl> + return OperationResult ( resultBuilder . steal ( ) , nullptr , \" \" , TRI_ERROR_NO_ERROR , <nl> + options . waitForSync , errorCounter ) ; <nl> } else { <nl> - res = workForOneDocument ( newValue ) ; <nl> + res = workForOneDocument ( newValue , false ) ; <nl> + return OperationResult ( resultBuilder . steal ( ) , nullptr , \" \" , res , <nl> + options . waitForSync ) ; <nl> } <nl> - return OperationResult ( resultBuilder . steal ( ) , nullptr , \" \" , res , <nl> - options . waitForSync ) ; <nl> } <nl> <nl> / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / <nl> OperationResult Transaction : : removeLocal ( std : : string const & collectionName , <nl> <nl> VPackBuilder resultBuilder ; <nl> <nl> - auto workOnOneDocument = [ & ] ( VPackSlice value ) - > int { <nl> + auto workOnOneDocument = [ & ] ( VPackSlice value , bool isBabies ) - > int { <nl> VPackSlice actualRevision ; <nl> TRI_doc_mptr_t previous ; <nl> std : : string key ; <nl> OperationResult Transaction : : removeLocal ( std : : string const & collectionName , <nl> actualRevision , previous ) ; <nl> <nl> if ( res ! = TRI_ERROR_NO_ERROR ) { <nl> - if ( res = = TRI_ERROR_ARANGO_CONFLICT & & ! options . silent ) { <nl> + if ( res = = TRI_ERROR_ARANGO_CONFLICT & & ! options . silent & & ! isBabies ) { <nl> buildDocumentIdentity ( resultBuilder , cid , key , <nl> actualRevision , VPackSlice ( ) , <nl> options . returnOld ? & previous : nullptr , nullptr ) ; <nl> OperationResult Transaction : : removeLocal ( std : : string const & collectionName , <nl> if ( value . isArray ( ) ) { <nl> VPackArrayBuilder guard ( & resultBuilder ) ; <nl> for ( auto const & s : VPackArrayIterator ( value ) ) { <nl> - res = workOnOneDocument ( s ) ; <nl> + res = workOnOneDocument ( s , true ) ; <nl> if ( res ! = TRI_ERROR_NO_ERROR ) { <nl> createBabiesError ( resultBuilder , countErrorCodes , res ) ; <nl> } <nl> OperationResult Transaction : : removeLocal ( std : : string const & collectionName , <nl> / / With babies the reporting is handled somewhere else . <nl> res = TRI_ERROR_NO_ERROR ; <nl> } else { <nl> - res = workOnOneDocument ( value ) ; <nl> + res = workOnOneDocument ( value , false ) ; <nl> } <nl> return OperationResult ( resultBuilder . steal ( ) , nullptr , \" \" , res , <nl> options . waitForSync , countErrorCodes ) ; <nl>\n", "msg": "Further improved baby - api implementation in transaction .\n", "score": 1}
{"diff_id": 40002, "repo": "godotengine/godot\n", "sha": "7577252b1bd3e38a0aa6da1e5e6beee333af5e6f\n", "time": "2018-01-27T14:11:39Z\n", "diff": "mmm a / core / dictionary . cpp <nl> ppp b / core / dictionary . cpp <nl> <nl> # include \" safe_refcount . h \" <nl> # include \" variant . h \" <nl> <nl> - struct _DictionaryVariantHash { <nl> - <nl> - static _FORCE_INLINE_ uint32_t hash ( const Variant & p_variant ) { return p_variant . hash ( ) ; } <nl> - } ; <nl> - <nl> struct DictionaryPrivate { <nl> <nl> SafeRefCount refcount ; <nl> - OrderedHashMap < Variant , Variant , _DictionaryVariantHash > variant_map ; <nl> + OrderedHashMap < Variant , Variant , VariantHasher , VariantComparator > variant_map ; <nl> } ; <nl> <nl> void Dictionary : : get_key_list ( List < Variant > * p_keys ) const { <nl> void Dictionary : : get_key_list ( List < Variant > * p_keys ) const { <nl> if ( _p - > variant_map . empty ( ) ) <nl> return ; <nl> <nl> - for ( OrderedHashMap < Variant , Variant , _DictionaryVariantHash > : : Element E = _p - > variant_map . front ( ) ; E ; E = E . next ( ) ) { <nl> + for ( OrderedHashMap < Variant , Variant , VariantHasher , VariantComparator > : : Element E = _p - > variant_map . front ( ) ; E ; E = E . next ( ) ) { <nl> p_keys - > push_back ( E . key ( ) ) ; <nl> } <nl> } <nl> const Variant & Dictionary : : operator [ ] ( const Variant & p_key ) const { <nl> } <nl> const Variant * Dictionary : : getptr ( const Variant & p_key ) const { <nl> <nl> - OrderedHashMap < Variant , Variant , _DictionaryVariantHash > : : ConstElement E = ( ( const OrderedHashMap < Variant , Variant , _DictionaryVariantHash > * ) & _p - > variant_map ) - > find ( p_key ) ; <nl> + OrderedHashMap < Variant , Variant , VariantHasher , VariantComparator > : : ConstElement E = ( ( const OrderedHashMap < Variant , Variant , VariantHasher , VariantComparator > * ) & _p - > variant_map ) - > find ( p_key ) ; <nl> <nl> if ( ! E ) <nl> return NULL ; <nl> const Variant * Dictionary : : getptr ( const Variant & p_key ) const { <nl> <nl> Variant * Dictionary : : getptr ( const Variant & p_key ) { <nl> <nl> - OrderedHashMap < Variant , Variant , _DictionaryVariantHash > : : Element E = _p - > variant_map . find ( p_key ) ; <nl> + OrderedHashMap < Variant , Variant , VariantHasher , VariantComparator > : : Element E = _p - > variant_map . find ( p_key ) ; <nl> <nl> if ( ! E ) <nl> return NULL ; <nl> Variant * Dictionary : : getptr ( const Variant & p_key ) { <nl> <nl> Variant Dictionary : : get_valid ( const Variant & p_key ) const { <nl> <nl> - OrderedHashMap < Variant , Variant , _DictionaryVariantHash > : : ConstElement E = ( ( const OrderedHashMap < Variant , Variant , _DictionaryVariantHash > * ) & _p - > variant_map ) - > find ( p_key ) ; <nl> + OrderedHashMap < Variant , Variant , VariantHasher , VariantComparator > : : ConstElement E = ( ( const OrderedHashMap < Variant , Variant , VariantHasher , VariantComparator > * ) & _p - > variant_map ) - > find ( p_key ) ; <nl> <nl> if ( ! E ) <nl> return Variant ( ) ; <nl> Array Dictionary : : keys ( ) const { <nl> return varr ; <nl> <nl> int i = 0 ; <nl> - for ( OrderedHashMap < Variant , Variant , _DictionaryVariantHash > : : Element E = _p - > variant_map . front ( ) ; E ; E = E . next ( ) ) { <nl> + for ( OrderedHashMap < Variant , Variant , VariantHasher , VariantComparator > : : Element E = _p - > variant_map . front ( ) ; E ; E = E . next ( ) ) { <nl> varr [ i ] = E . key ( ) ; <nl> i + + ; <nl> } <nl> Array Dictionary : : values ( ) const { <nl> return varr ; <nl> <nl> int i = 0 ; <nl> - for ( OrderedHashMap < Variant , Variant , _DictionaryVariantHash > : : Element E = _p - > variant_map . front ( ) ; E ; E = E . next ( ) ) { <nl> + for ( OrderedHashMap < Variant , Variant , VariantHasher , VariantComparator > : : Element E = _p - > variant_map . front ( ) ; E ; E = E . next ( ) ) { <nl> varr [ i ] = E . get ( ) ; <nl> i + + ; <nl> } <nl> const Variant * Dictionary : : next ( const Variant * p_key ) const { <nl> return & _p - > variant_map . front ( ) . key ( ) ; <nl> return NULL ; <nl> } <nl> - OrderedHashMap < Variant , Variant , _DictionaryVariantHash > : : Element E = _p - > variant_map . find ( * p_key ) ; <nl> + OrderedHashMap < Variant , Variant , VariantHasher , VariantComparator > : : Element E = _p - > variant_map . find ( * p_key ) ; <nl> <nl> if ( E & & E . next ( ) ) <nl> return & E . next ( ) . key ( ) ; <nl>\n", "msg": "Use the appropriate Variant hash and compare functions for Dictionaries\n"}
{"diff_id": 40188, "repo": "bitcoin/bitcoin\n", "sha": "e58985c916fda39b8ccf08d0db00426af939749a\n", "time": "2018-08-08T11:22:13Z\n", "diff": "mmm a / src / validation . cpp <nl> ppp b / src / validation . cpp <nl> bool CVerifyDB : : VerifyDB ( const CChainParams & chainparams , CCoinsView * coinsview , <nl> LogPrintf ( \" [ 0 % % ] . . . \" ) ; / * Continued * / <nl> for ( pindex = chainActive . Tip ( ) ; pindex & & pindex - > pprev ; pindex = pindex - > pprev ) { <nl> boost : : this_thread : : interruption_point ( ) ; <nl> - int percentageDone = std : : max ( 1 , std : : min ( 99 , ( int ) ( ( ( double ) ( chainActive . Height ( ) - pindex - > nHeight ) ) / ( double ) nCheckDepth * ( nCheckLevel > = 4 ? 50 : 100 ) ) ) ) ; <nl> + const int percentageDone = std : : max ( 1 , std : : min ( 99 , ( int ) ( ( ( double ) ( chainActive . Height ( ) - pindex - > nHeight ) ) / ( double ) nCheckDepth * ( nCheckLevel > = 4 ? 50 : 100 ) ) ) ) ; <nl> if ( reportDone < percentageDone / 10 ) { <nl> / / report every 10 % step <nl> LogPrintf ( \" [ % d % % ] . . . \" , percentageDone ) ; / * Continued * / <nl> bool CVerifyDB : : VerifyDB ( const CChainParams & chainparams , CCoinsView * coinsview , <nl> if ( nCheckLevel > = 4 ) { <nl> while ( pindex ! = chainActive . Tip ( ) ) { <nl> boost : : this_thread : : interruption_point ( ) ; <nl> - uiInterface . ShowProgress ( _ ( \" Verifying blocks . . . \" ) , std : : max ( 1 , std : : min ( 99 , 100 - ( int ) ( ( ( double ) ( chainActive . Height ( ) - pindex - > nHeight ) ) / ( double ) nCheckDepth * 50 ) ) ) , false ) ; <nl> + const int percentageDone = std : : max ( 1 , std : : min ( 99 , 100 - ( int ) ( ( ( double ) ( chainActive . Height ( ) - pindex - > nHeight ) ) / ( double ) nCheckDepth * 50 ) ) ) ; <nl> + if ( reportDone < percentageDone / 10 ) { <nl> + / / report every 10 % step <nl> + LogPrintf ( \" [ % d % % ] . . . \" , percentageDone ) ; / * Continued * / <nl> + reportDone = percentageDone / 10 ; <nl> + } <nl> + uiInterface . ShowProgress ( _ ( \" Verifying blocks . . . \" ) , percentageDone , false ) ; <nl> pindex = chainActive . Next ( pindex ) ; <nl> CBlock block ; <nl> if ( ! ReadBlockFromDisk ( block , pindex , chainparams . GetConsensus ( ) ) ) <nl>\n", "msg": "Log progress while verifying blocks at level 4 .\n"}
{"diff_id": 40254, "repo": "xbmc/xbmc\n", "sha": "e67d9bad2ebe1c149ee7d6175be660ee0b8b5502\n", "time": "2020-05-18T09:26:03Z\n", "diff": "mmm a / xbmc / music / Album . cpp <nl> ppp b / xbmc / music / Album . cpp <nl> void CAlbum : : MergeScrapedAlbum ( const CAlbum & source , bool override / * = true * / ) <nl> } <nl> <nl> / * <nl> - Scraping can return different album artists from the originals derived from tags , even when doing <nl> - a lookup on name . <nl> + Scraping can return different album artists from the originals derived from tags , even when <nl> + doing a lookup on artist name . <nl> <nl> When overwritting the data derived from tags , AND the original and scraped album have the same <nl> Musicbrainz album ID , then merging an album replaces both the album artsts and the song artists <nl> - with those scraped . <nl> + with those scraped ( providing they are not empty ) . <nl> <nl> When not doing that kind of merge , for any matching artist names the Musicbrainz artist id <nl> returned by the scraper can be used to populate any previously missing Musicbrainz artist id values . <nl> * / <nl> - if ( bArtistSongMerge ) <nl> + if ( bArtistSongMerge & & ! source . artistCredits . empty ( ) ) <nl> { <nl> artistCredits = source . artistCredits ; / / Replace artists and store mbid returned by scraper <nl> strArtistDesc . clear ( ) ; / / @ todo : set artist display string e . g . \" artist1 & artist2 \" when scraped <nl>\n", "msg": "Prevent album artists being left blank when merging scraped album results and preferring scraper results enabled .\n"}
{"diff_id": 40493, "repo": "apple/foundationdb\n", "sha": "b242760adf1449c96fb6642958d788879da3b89b\n", "time": "2019-07-19T16:58:40Z\n", "diff": "mmm a / fdbclient / ManagementAPI . actor . cpp <nl> ppp b / fdbclient / ManagementAPI . actor . cpp <nl> std : : map < std : : string , std : : string > configForToken ( std : : string const & mode ) { <nl> <nl> if ( storeType . present ( ) ) { <nl> out [ p + \" log_engine \" ] = format ( \" % d \" , logType . get ( ) . operator KeyValueStoreType : : StoreType ( ) ) ; <nl> - out [ p + \" storage_engine \" ] = format ( \" % d \" , storeType . get ( ) . operator KeyValueStoreType : : StoreType ( ) ) ; <nl> + out [ p + \" storage_engine \" ] = format ( \" % d \" , KeyValueStoreType : : StoreType ( storeType . get ( ) ) ) ; <nl> return out ; <nl> } <nl> <nl>\n", "msg": "Use functional cast instead of explicit operator call\n"}
{"diff_id": 40499, "repo": "godotengine/godot\n", "sha": "fa2fda324476d9384f86773d1e4bc17ff4f8b05e\n", "time": "2020-01-30T02:09:00Z\n", "diff": "mmm a / editor / editor_profiler . cpp <nl> ppp b / editor / editor_profiler . cpp <nl> void EditorProfiler : : _item_edited ( ) { <nl> <nl> void EditorProfiler : : _update_plot ( ) { <nl> <nl> - int w = graph - > get_size ( ) . width ; <nl> - int h = graph - > get_size ( ) . height ; <nl> - <nl> + const int w = graph - > get_size ( ) . width ; <nl> + const int h = graph - > get_size ( ) . height ; <nl> bool reset_texture = false ; <nl> - <nl> - int desired_len = w * h * 4 ; <nl> + const int desired_len = w * h * 4 ; <nl> <nl> if ( graph_image . size ( ) ! = desired_len ) { <nl> reset_texture = true ; <nl> void EditorProfiler : : _update_plot ( ) { <nl> } <nl> <nl> PoolVector < uint8_t > : : Write wr = graph_image . write ( ) ; <nl> + const Color background_color = get_color ( \" dark_color_2 \" , \" Editor \" ) ; <nl> <nl> - / / clear <nl> + / / Clear the previous frame and set the background color . <nl> for ( int i = 0 ; i < desired_len ; i + = 4 ) { <nl> - wr [ i + 0 ] = 0 ; <nl> - wr [ i + 1 ] = 0 ; <nl> - wr [ i + 2 ] = 0 ; <nl> + wr [ i + 0 ] = Math : : fast_ftoi ( background_color . r * 255 ) ; <nl> + wr [ i + 1 ] = Math : : fast_ftoi ( background_color . g * 255 ) ; <nl> + wr [ i + 2 ] = Math : : fast_ftoi ( background_color . b * 255 ) ; <nl> wr [ i + 3 ] = 255 ; <nl> } <nl> <nl> / / find highest value <nl> <nl> - bool use_self = display_time - > get_selected ( ) = = DISPLAY_SELF_TIME ; <nl> + const bool use_self = display_time - > get_selected ( ) = = DISPLAY_SELF_TIME ; <nl> float highest = 0 ; <nl> <nl> for ( int i = 0 ; i < frame_metrics . size ( ) ; i + + ) { <nl> void EditorProfiler : : _update_plot ( ) { <nl> <nl> for ( int j = 0 ; j < h * 4 ; j + = 4 ) { <nl> <nl> - int a = column [ j + 3 ] ; <nl> + const int a = column [ j + 3 ] ; <nl> if ( a > 0 ) { <nl> column [ j + 0 ] / = a ; <nl> column [ j + 1 ] / = a ; <nl> column [ j + 2 ] / = a ; <nl> } <nl> <nl> - uint8_t r = uint8_t ( column [ j + 0 ] ) ; <nl> - uint8_t g = uint8_t ( column [ j + 1 ] ) ; <nl> - uint8_t b = uint8_t ( column [ j + 2 ] ) ; <nl> + const uint8_t red = uint8_t ( column [ j + 0 ] ) ; <nl> + const uint8_t green = uint8_t ( column [ j + 1 ] ) ; <nl> + const uint8_t blue = uint8_t ( column [ j + 2 ] ) ; <nl> + const bool is_filled = red > = 1 | | green > = 1 | | blue > = 1 ; <nl> + const int widx = ( ( j > > 2 ) * w + i ) * 4 ; <nl> <nl> - int widx = ( ( j > > 2 ) * w + i ) * 4 ; <nl> - wr [ widx + 0 ] = r ; <nl> - wr [ widx + 1 ] = g ; <nl> - wr [ widx + 2 ] = b ; <nl> + / / If the pixel isn ' t filled by any profiler line , apply the background color instead . <nl> + wr [ widx + 0 ] = is_filled ? red : Math : : fast_ftoi ( background_color . r * 255 ) ; <nl> + wr [ widx + 1 ] = is_filled ? green : Math : : fast_ftoi ( background_color . g * 255 ) ; <nl> + wr [ widx + 2 ] = is_filled ? blue : Math : : fast_ftoi ( background_color . b * 255 ) ; <nl> wr [ widx + 3 ] = 255 ; <nl> } <nl> } <nl>\n", "msg": "Use the editor background color for the profiler graph\n"}
{"diff_id": 40581, "repo": "mongodb/mongo\n", "sha": "934614f0dc21653c8f49a1eb7120af029f7b8091\n", "time": "2011-09-19T19:31:46Z\n", "diff": "mmm a / s / strategy_shard . cpp <nl> ppp b / s / strategy_shard . cpp <nl> namespace mongo { <nl> } <nl> <nl> void _insert ( Request & r , DbMessage & d , ChunkManagerPtr manager ) { <nl> - const int flags = d . reservedField ( ) ; <nl> + const int flags = d . reservedField ( ) | InsertOption_ContinueOnError ; / / ContinueOnError is always on when using sharding . <nl> map < ChunkPtr , vector < BSONObj > > insertsForChunk ; / / Group bulk insert for appropriate shards <nl> try { <nl> while ( d . moreJSObjs ( ) ) { <nl>\n", "msg": "Send ContinueOnError flag for all bulk inserts when using sharding .\n"}
{"diff_id": 40593, "repo": "nlohmann/json\n", "sha": "63ecbfd36be3087d24bca385370413869900ff35\n", "time": "2017-07-07T21:38:04Z\n", "diff": "mmm a / test / src / unit - pointer_access . cpp <nl> ppp b / test / src / unit - pointer_access . cpp <nl> TEST_CASE ( \" pointer access \" ) <nl> <nl> const test_type * p2 = value . get_ptr < const test_type * > ( ) ; <nl> CHECK ( p1 = = value . get_ptr < const test_type * > ( ) ) ; <nl> - / / CHECK ( * p2 = = value . get < test_type > ( ) ) ; <nl> + CHECK ( * p2 = = value . get < test_type > ( ) ) ; <nl> <nl> const test_type * const p3 = value . get_ptr < const test_type * const > ( ) ; <nl> CHECK ( p1 = = value . get_ptr < const test_type * const > ( ) ) ; <nl> - / / CHECK ( * p3 = = value . get < test_type > ( ) ) ; <nl> + CHECK ( * p3 = = value . get < test_type > ( ) ) ; <nl> <nl> / / check if null pointers are returned correctly <nl> CHECK ( value . get_ptr < const json : : object_t * > ( ) = = nullptr ) ; <nl>\n", "msg": ": white_check_mark : re - added test\n"}
{"diff_id": 40610, "repo": "sqlitebrowser/sqlitebrowser\n", "sha": "d6533ba5f7ec7bef2595d69a9c2d131a1d5588d8\n", "time": "2015-04-23T20:44:23Z\n", "diff": "mmm a / src / MainWindow . cpp <nl> ppp b / src / MainWindow . cpp <nl> void MainWindow : : switchToBrowseDataTab ( ) <nl> QString tableToBrowse = ui - > dbTreeWidget - > model ( ) - > data ( ui - > dbTreeWidget - > currentIndex ( ) . sibling ( ui - > dbTreeWidget - > currentIndex ( ) . row ( ) , 0 ) ) . toString ( ) ; <nl> <nl> ui - > mainTab - > setCurrentIndex ( 1 ) ; <nl> - ui - > comboBrowseTable - > setCurrentText ( tableToBrowse ) ; <nl> - ui - > comboBrowseTable - > activated ( tableToBrowse ) ; <nl> + ui - > comboBrowseTable - > setCurrentIndex ( ui - > comboBrowseTable - > findText ( tableToBrowse ) ) ; <nl> + populateTable ( tableToBrowse ) ; <nl> } <nl>\n", "msg": "Fix Qt4 build broken in dd8dd4852d97a92d6f9772dc788aaf1591d0ff19\n"}
{"diff_id": 40614, "repo": "godotengine/godot\n", "sha": "882838579238a4fe6d3371ce76042306d5fabd17\n", "time": "2019-04-06T15:40:15Z\n", "diff": "mmm a / core / variant_call . cpp <nl> ppp b / core / variant_call . cpp <nl> void register_variant_methods ( ) { <nl> _VariantCall : : add_variant_constant ( Variant : : TRANSFORM , \" IDENTITY \" , identity_transform ) ; <nl> transform_x . set ( - 1 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 1 , 0 , 0 , 0 ) ; <nl> _VariantCall : : add_variant_constant ( Variant : : TRANSFORM , \" FLIP_X \" , transform_x ) ; <nl> - transform_x . set ( 1 , 0 , 0 , 0 , - 1 , 0 , 0 , 0 , 1 , 0 , 0 , 0 ) ; <nl> + transform_y . set ( 1 , 0 , 0 , 0 , - 1 , 0 , 0 , 0 , 1 , 0 , 0 , 0 ) ; <nl> _VariantCall : : add_variant_constant ( Variant : : TRANSFORM , \" FLIP_Y \" , transform_y ) ; <nl> - transform_x . set ( 1 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , - 1 , 0 , 0 , 0 ) ; <nl> + transform_z . set ( 1 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , - 1 , 0 , 0 , 0 ) ; <nl> _VariantCall : : add_variant_constant ( Variant : : TRANSFORM , \" FLIP_Z \" , transform_z ) ; <nl> <nl> _VariantCall : : add_variant_constant ( Variant : : PLANE , \" PLANE_YZ \" , Plane ( Vector3 ( 1 , 0 , 0 ) , 0 ) ) ; <nl>\n", "msg": "Fixed Transform FLIP_Y and FLIP_Z set as identity transform\n", "score": 1}
{"diff_id": 40731, "repo": "apple/swift\n", "sha": "14f5fb86e28368dab194a77b24dafd3701ba8c00\n", "time": "2015-03-25T09:37:20Z\n", "diff": "mmm a / lib / SILPasses / SimplifyCFG . cpp <nl> ppp b / lib / SILPasses / SimplifyCFG . cpp <nl> static void simplifyCondBranchInst ( CondBranchInst * BI , bool BranchTaken ) { <nl> BI - > eraseFromParent ( ) ; <nl> } <nl> <nl> - static SILValue skipExpect ( SILValue V ) { <nl> + static SILValue getUnderlyingCondition ( SILValue V ) { <nl> + if ( auto * SEI = dyn_cast < SelectEnumInst > ( V ) ) <nl> + V = SEI - > getEnumOperand ( ) . stripCasts ( ) ; <nl> + <nl> if ( auto * BI = dyn_cast < BuiltinInst > ( V ) ) { <nl> + / / Expect - intrinsics have no effect , so we can see through them . <nl> if ( BI - > getIntrinsicInfo ( ) . ID = = llvm : : Intrinsic : : expect ) <nl> return BI - > getArguments ( ) [ 0 ] ; <nl> } <nl> static SILValue skipExpect ( SILValue V ) { <nl> / / / Returns true if C1 , C2 represent equivalent conditions in the <nl> / / / sense that each is eventually based on the same value . <nl> static bool areEquivalentConditions ( SILValue C1 , SILValue C2 ) { <nl> - if ( auto * SEI = dyn_cast < SelectEnumInst > ( C1 ) ) <nl> - C1 = SEI - > getEnumOperand ( ) . stripCasts ( ) ; <nl> - <nl> - if ( auto * SEI = dyn_cast < SelectEnumInst > ( C2 ) ) <nl> - C2 = SEI - > getEnumOperand ( ) . stripCasts ( ) ; <nl> - <nl> - / / Expect - intrinsics have no effect , so we can see through them . <nl> - return skipExpect ( C1 ) = = skipExpect ( C2 ) ; <nl> + return getUnderlyingCondition ( C1 ) = = getUnderlyingCondition ( C2 ) ; <nl> } <nl> <nl> static bool trySimplifyConditional ( TermInst * Term , DominanceInfo * DT ) { <nl>\n", "msg": "SimplifyCFG : small refactoring , NFC\n"}
{"diff_id": 41009, "repo": "godotengine/godot\n", "sha": "a38b59b656e6834d466df37379266c29d6364490\n", "time": "2018-02-22T12:39:52Z\n", "diff": "mmm a / editor / editor_export . cpp <nl> ppp b / editor / editor_export . cpp <nl> void EditorExportPlatform : : gen_debug_flags ( Vector < String > & r_flags , int p_flags ) <nl> } <nl> <nl> Error EditorExportPlatform : : _save_pack_file ( void * p_userdata , const String & p_path , const Vector < uint8_t > & p_data , int p_file , int p_total ) { <nl> - if ( p_path . ends_with ( \" . so \" ) | | p_path . ends_with ( \" . dylib \" ) | | p_path . ends_with ( \" . dll \" ) ) <nl> - return OK ; <nl> <nl> PackData * pd = ( PackData * ) p_userdata ; <nl> <nl>\n", "msg": "EditorExport : Allow export plugins to add shared libraries\n"}
{"diff_id": 41031, "repo": "apple/swift\n", "sha": "dcc37c3340fed7a4b86640593da01fa2059df22b\n", "time": "2017-12-04T18:46:03Z\n", "diff": "mmm a / lib / Parse / Lexer . cpp <nl> ppp b / lib / Parse / Lexer . cpp <nl> Optional < syntax : : TriviaPiece > Lexer : : lexWhitespace ( bool StopAtFirstNewline ) { <nl> case ' \\ n ' : <nl> case ' \\ r ' : <nl> NextToken . setAtStartOfLine ( true ) ; <nl> - return syntax : : TriviaPiece { <nl> - syntax : : TriviaKind : : Newline , <nl> - Length , <nl> - OwnedString ( Start , Length ) , <nl> - } ; <nl> + return syntax : : TriviaPiece { syntax : : TriviaKind : : Newline , Length , { } } ; <nl> case ' ' : <nl> - return syntax : : TriviaPiece { <nl> - syntax : : TriviaKind : : Space , <nl> - Length , <nl> - OwnedString ( Start , Length ) , <nl> - } ; <nl> + return syntax : : TriviaPiece { syntax : : TriviaKind : : Space , Length , { } } ; <nl> case ' \\ t ' : <nl> - return syntax : : TriviaPiece { <nl> - syntax : : TriviaKind : : Tab , <nl> - Length , <nl> - OwnedString ( Start , Length ) , <nl> - } ; <nl> + return syntax : : TriviaPiece { syntax : : TriviaKind : : Tab , Length , { } } ; <nl> default : <nl> return None ; <nl> } <nl> Optional < syntax : : TriviaPiece > Lexer : : lexSingleLineComment ( syntax : : TriviaKind Kin <nl> if ( Length = = 0 ) <nl> return None ; <nl> <nl> - return Optional < syntax : : TriviaPiece > ( { <nl> - Kind , <nl> - Length , <nl> - OwnedString ( Start , Length ) <nl> - } ) ; <nl> + return Optional < syntax : : TriviaPiece > ( { Kind , 1 , OwnedString ( Start , Length ) } ) ; <nl> } <nl> <nl> Optional < syntax : : TriviaPiece > <nl> Lexer : : lexBlockComment ( syntax : : TriviaKind Kind ) { <nl> if ( Length = = 0 ) <nl> return None ; <nl> <nl> - return Optional < syntax : : TriviaPiece > ( { <nl> - Kind , <nl> - Length , <nl> - OwnedString ( Start , Length ) <nl> - } ) ; <nl> + return Optional < syntax : : TriviaPiece > ( { Kind , 1 , OwnedString ( Start , Length ) } ) ; <nl> } <nl> <nl> Optional < syntax : : TriviaPiece > Lexer : : lexComment ( ) { <nl>\n", "msg": "[ Syntax ] Normalize TriviaPiece internal value .\n"}
{"diff_id": 41077, "repo": "xbmc/xbmc\n", "sha": "54137428f9894379246581ee1779b21d4dc3f123\n", "time": "2018-04-02T14:02:28Z\n", "diff": "mmm a / xbmc / filesystem / Directory . cpp <nl> ppp b / xbmc / filesystem / Directory . cpp <nl> bool CDirectory : : GetDirectory ( const CURL & url , CFileItemList & items , const CHint <nl> { <nl> if ( g_application . IsCurrentThread ( ) & & pDirectory - > ProcessRequirements ( ) ) <nl> { <nl> + authUrl . SetDomain ( \" \" ) ; <nl> authUrl . SetUserName ( \" \" ) ; <nl> authUrl . SetPassword ( \" \" ) ; <nl> continue ; <nl> bool CDirectory : : GetDirectory ( const CURL & url , CFileItemList & items , const CHint <nl> / / hide credentials if necessary <nl> if ( CPasswordManager : : GetInstance ( ) . IsURLSupported ( realURL ) ) <nl> { <nl> - for ( int i = 0 ; i < items . Size ( ) ; + + i ) <nl> + bool hide = false ; <nl> + / / for explicitly credetials <nl> + if ( ! realURL . GetUserName ( ) . empty ( ) ) <nl> { <nl> - CFileItemPtr item = items [ i ] ; <nl> - CURL itemUrl = item - > GetURL ( ) ; <nl> - / / for explicitly credetials <nl> - if ( ! realURL . GetUserName ( ) . empty ( ) ) <nl> + / / credentials was changed i . e . were stored in the password <nl> + / / manager , in this case we can hide them from an item URL , <nl> + / / otherwise we have to keep cretendials in an item URL <nl> + if ( realURL . GetUserName ( ) ! = authUrl . GetUserName ( ) <nl> + | | realURL . GetPassWord ( ) ! = authUrl . GetPassWord ( ) <nl> + | | realURL . GetDomain ( ) ! = authUrl . GetDomain ( ) ) <nl> { <nl> - / / credentials was changed i . e . were stored in the password <nl> - / / manager , in this case we can hide them from an item URL , <nl> - / / otherwise we have to keep cretendials in an item URL <nl> - if ( realURL . GetUserName ( ) ! = authUrl . GetUserName ( ) <nl> - | | realURL . GetPassWord ( ) ! = authUrl . GetPassWord ( ) ) <nl> - { <nl> - / / hide credentials <nl> - itemUrl . SetUserName ( \" \" ) ; <nl> - itemUrl . SetPassword ( \" \" ) ; <nl> - } <nl> + hide = true ; <nl> } <nl> - else <nl> + } <nl> + else <nl> + { <nl> + / / hide credentials in any other cases <nl> + hide = true ; <nl> + } <nl> + <nl> + if ( hide ) <nl> + { <nl> + for ( int i = 0 ; i < items . Size ( ) ; + + i ) <nl> { <nl> - / / hide credentials in any other cases <nl> + CFileItemPtr item = items [ i ] ; <nl> + CURL itemUrl = item - > GetURL ( ) ; <nl> + itemUrl . SetDomain ( \" \" ) ; <nl> itemUrl . SetUserName ( \" \" ) ; <nl> itemUrl . SetPassword ( \" \" ) ; <nl> + item - > SetPath ( itemUrl . Get ( ) ) ; <nl> } <nl> - item - > SetPath ( itemUrl . Get ( ) ) ; <nl> } <nl> } <nl> <nl>\n", "msg": "[ filesystem ] Directory : cut domain name from an URL\n"}
{"diff_id": 41128, "repo": "apple/swift\n", "sha": "f9400be21b2e8ed5ada8b8c5acd6ab345e4a4cb0\n", "time": "2019-04-25T15:52:46Z\n", "diff": "mmm a / lib / Sema / CSSolver . cpp <nl> ppp b / lib / Sema / CSSolver . cpp <nl> ConstraintSystem : : solveImpl ( Expr * & expr , <nl> if ( convertType ) { <nl> auto constraintKind = ConstraintKind : : Conversion ; <nl> <nl> - if ( getContextualTypePurpose ( ) = = CTP_ReturnStmt <nl> + if ( ( getContextualTypePurpose ( ) = = CTP_ReturnStmt | | <nl> + getContextualTypePurpose ( ) = = CTP_ReturnSingleExpr ) <nl> & & Options . contains ( ConstraintSystemFlags : : UnderlyingTypeForOpaqueReturnType ) ) <nl> constraintKind = ConstraintKind : : OpaqueUnderlyingType ; <nl> <nl>\n", "msg": "Create opaque type constraint for single expr return . [ 49581931 ]\n"}
{"diff_id": 41173, "repo": "telegramdesktop/tdesktop\n", "sha": "2c0b852dadfff98857114c097da8270de630c68d\n", "time": "2020-03-27T16:36:05Z\n", "diff": "mmm a / Telegram / SourceFiles / app . cpp <nl> ppp b / Telegram / SourceFiles / app . cpp <nl> For license and copyright information please follow this link : <nl> # endif / / OS_MAC_OLD <nl> <nl> namespace { <nl> - App : : LaunchState _launchState = App : : Launched ; <nl> <nl> - HistoryView : : Element * hoveredItem = nullptr , <nl> - * pressedItem = nullptr , <nl> - * hoveredLinkItem = nullptr , <nl> - * pressedLinkItem = nullptr , <nl> - * mousedItem = nullptr ; <nl> + constexpr auto kImageAreaLimit = 6 ' 016 * 3 ' 384 ; <nl> <nl> - struct CornersPixmaps { <nl> - QPixmap p [ 4 ] ; <nl> - } ; <nl> - QVector < CornersPixmaps > corners ; <nl> - using CornersMap = QMap < uint32 , CornersPixmaps > ; <nl> - CornersMap cornersMap ; <nl> - QImage cornersMaskLarge [ 4 ] , cornersMaskSmall [ 4 ] ; <nl> + App : : LaunchState _launchState = App : : Launched ; <nl> <nl> - int32 serviceImageCacheSize = 0 ; <nl> + HistoryView : : Element * hoveredItem = nullptr , <nl> + * pressedItem = nullptr , <nl> + * hoveredLinkItem = nullptr , <nl> + * pressedLinkItem = nullptr , <nl> + * mousedItem = nullptr ; <nl> + <nl> + struct CornersPixmaps { <nl> + QPixmap p [ 4 ] ; <nl> + } ; <nl> + QVector < CornersPixmaps > corners ; <nl> + using CornersMap = QMap < uint32 , CornersPixmaps > ; <nl> + CornersMap cornersMap ; <nl> + QImage cornersMaskLarge [ 4 ] , cornersMaskSmall [ 4 ] ; <nl> + <nl> + int32 serviceImageCacheSize = 0 ; <nl> <nl> } / / namespace <nl> <nl> namespace App { <nl> reader . setAutoTransform ( true ) ; <nl> # endif / / OS_MAC_OLD <nl> if ( animated ) * animated = reader . supportsAnimation ( ) & & reader . imageCount ( ) > 1 ; <nl> + if ( ! reader . canRead ( ) ) { <nl> + return QImage ( ) ; <nl> + } <nl> + const auto imageSize = reader . size ( ) ; <nl> + if ( imageSize . width ( ) * imageSize . height ( ) > kImageAreaLimit ) { <nl> + return QImage ( ) ; <nl> + } <nl> QByteArray fmt = reader . format ( ) ; <nl> if ( ! fmt . isEmpty ( ) ) * format = fmt ; <nl> if ( ! reader . read ( & result ) ) { <nl>\n", "msg": "Limit image size the app tries to read .\n"}
{"diff_id": 41180, "repo": "osquery/osquery\n", "sha": "fe3766796c68a46cbbb3502a85cdc7aecd1c5af7\n", "time": "2016-02-03T16:31:57Z\n", "diff": "mmm a / osquery / tables / system / darwin / smbios_tables . cpp <nl> ppp b / osquery / tables / system / darwin / smbios_tables . cpp <nl> QueryData genSMBIOSTables ( QueryContext & context ) { <nl> } <nl> <nl> QueryData genPlatformInfo ( QueryContext & context ) { <nl> - auto root = IORegistryEntryFromPath ( kIOMasterPortDefault , \" IODeviceTree : / \" ) ; <nl> - if ( root = = 0 ) { <nl> + auto rom = IORegistryEntryFromPath ( kIOMasterPortDefault , \" IODeviceTree : / rom \" ) ; <nl> + if ( rom = = 0 ) { <nl> return { } ; <nl> } <nl> <nl> - io_iterator_t it = 0 ; <nl> - auto kr = IORegistryEntryGetChildIterator ( root , kIODeviceTreePlane , & it ) ; <nl> - if ( kr ! = KERN_SUCCESS | | it = = 0 ) { <nl> - IOObjectRelease ( root ) ; <nl> - return { } ; <nl> - } <nl> - <nl> - io_service_t entry = 0 ; <nl> CFMutableDictionaryRef details = nullptr ; <nl> - while ( ( entry = IOIteratorNext ( it ) ) ) { <nl> - io_name_t name ; <nl> - if ( IORegistryEntryGetName ( entry , name ) = = KERN_SUCCESS ) { <nl> - / / Assume the ROM entry begins with a canonicalized ' rom ' string . <nl> - if ( std : : string ( name ) . find ( \" rom \" ) = = 0 ) { <nl> - IORegistryEntryCreateCFProperties ( <nl> - entry , & details , kCFAllocatorDefault , kNilOptions ) ; <nl> - IOObjectRelease ( entry ) ; <nl> - break ; <nl> - } <nl> - } <nl> - IOObjectRelease ( entry ) ; <nl> - } <nl> + IORegistryEntryCreateCFProperties ( <nl> + rom , & details , kCFAllocatorDefault , kNilOptions ) ; <nl> + IOObjectRelease ( rom ) ; <nl> <nl> / / Success is determined by the details dictionary existence . <nl> - IOObjectRelease ( it ) ; <nl> - IOObjectRelease ( root ) ; <nl> if ( details = = nullptr ) { <nl> return { } ; <nl> } <nl>\n", "msg": "Use ' / rom ' path for OS X platform_info\n"}
{"diff_id": 41230, "repo": "mongodb/mongo\n", "sha": "bbf7a013d20e784bb5eff38b549c84712c819827\n", "time": "2017-09-25T18:25:10Z\n", "diff": "mmm a / src / mongo / db / startup_warnings_mongod . cpp <nl> ppp b / src / mongo / db / startup_warnings_mongod . cpp <nl> void logMongodStartupWarnings ( const StorageGlobalParams & storageParams , <nl> warned = true ; <nl> } <nl> <nl> + / / Check if - - nojournal <nl> + bool isReplSet = replCoord - > getReplicationMode ( ) = = repl : : ReplicationCoordinator : : modeReplSet ; <nl> + if ( isReplSet & & storageParams . engine = = \" wiredTiger \" & & ! storageParams . dur ) { <nl> + log ( ) < < startupWarningsLog ; <nl> + log ( ) < < \" * * WARNING : Running wiredTiger with the - - nojournal option in a replica set \" <nl> + < < startupWarningsLog ; <nl> + log ( ) < < \" * * is deprecated and subject to be removed in a future version . \" <nl> + < < startupWarningsLog ; <nl> + warned = true ; <nl> + } <nl> + <nl> if ( warned ) { <nl> log ( ) < < startupWarningsLog ; <nl> } <nl>\n", "msg": "SERVER - 30760 Add startupWarning for WiredTiger - - nojournal\n"}
{"diff_id": 41245, "repo": "ariya/phantomjs\n", "sha": "23515550d5ebb4b11882ec9b12b42d85672d3045\n", "time": "2013-04-30T21:57:58Z\n", "diff": "mmm a / src / networkaccessmanager . cpp <nl> ppp b / src / networkaccessmanager . cpp <nl> NetworkAccessManager : : NetworkAccessManager ( QObject * parent , const Config * config <nl> , m_ignoreSslErrors ( config - > ignoreSslErrors ( ) ) <nl> , m_authAttempts ( 0 ) <nl> , m_maxAuthAttempts ( 3 ) <nl> + , m_resourceTimeout ( 0 ) <nl> , m_idCounter ( 0 ) <nl> , m_networkDiskCache ( 0 ) <nl> , m_sslConfiguration ( QSslConfiguration : : defaultConfiguration ( ) ) <nl> - , m_resourceTimeout ( 0 ) <nl> { <nl> setCookieJar ( CookieJar : : instance ( ) ) ; <nl> <nl>\n", "msg": "MINOR : Reorder initialisation order in NAM constr .\n"}
{"diff_id": 41296, "repo": "apple/swift\n", "sha": "3c9fa1627cf66ec94778e8b62e2ec4a7d0af09c6\n", "time": "2018-01-21T21:18:34Z\n", "diff": "mmm a / lib / SILOptimizer / Transforms / AllocBoxToStack . cpp <nl> ppp b / lib / SILOptimizer / Transforms / AllocBoxToStack . cpp <nl> static bool rewriteAllocBoxAsAllocStack ( AllocBoxInst * ABI ) { <nl> <nl> / / Promote this alloc_box to an alloc_stack . Insert the alloc_stack <nl> / / at the beginning of the function . <nl> - SILBuilder Builder ( ABI ) ; <nl> - Builder . setCurrentDebugScope ( ABI - > getDebugScope ( ) ) ; <nl> + SILBuilderWithScope Builder ( ABI ) ; <nl> assert ( ABI - > getBoxType ( ) - > getLayout ( ) - > getFields ( ) . size ( ) = = 1 <nl> & & \" rewriting multi - field box not implemented \" ) ; <nl> auto * ASI = Builder . createAllocStack ( <nl>\n", "msg": "[ AllocBoxToStack ] Use ` SILBUilderWithScope ` instead of ` SILBuilder ` .\n"}
{"diff_id": 41304, "repo": "EOSIO/eos\n", "sha": "9826e640dca4154e97e1d9bdf6bd5e1f975b845f\n", "time": "2019-04-23T17:51:38Z\n", "diff": "mmm a / libraries / chain / block_log . cpp <nl> ppp b / libraries / chain / block_log . cpp <nl> <nl> <nl> # define LOG_READ ( std : : ios : : in | std : : ios : : binary ) <nl> # define LOG_WRITE ( std : : ios : : out | std : : ios : : binary | std : : ios : : app ) <nl> + # define LOG_RW ( std : : ios : : in | std : : ios : : out | std : : ios : : binary ) <nl> <nl> namespace eosio { namespace chain { <nl> <nl> namespace eosio { namespace chain { <nl> std : : fstream index_stream ; <nl> fc : : path block_file ; <nl> fc : : path index_file ; <nl> - bool block_write ; <nl> - bool index_write ; <nl> + bool open_files = false ; <nl> bool genesis_written_to_block_log = false ; <nl> uint32_t version = 0 ; <nl> uint32_t first_block_num = 0 ; <nl> <nl> - inline void check_block_read ( ) { <nl> - if ( block_write ) { <nl> - block_stream . close ( ) ; <nl> - block_stream . open ( block_file . generic_string ( ) . c_str ( ) , LOG_READ ) ; <nl> - block_write = false ; <nl> + inline void check_open_files ( ) { <nl> + if ( ! open_files ) { <nl> + reopen ( ) ; <nl> } <nl> } <nl> + void reopen ( ) ; <nl> <nl> - inline void check_block_write ( ) { <nl> - if ( ! block_write ) { <nl> + void close ( ) { <nl> + if ( block_stream . is_open ( ) ) <nl> block_stream . close ( ) ; <nl> - block_stream . open ( block_file . generic_string ( ) . c_str ( ) , LOG_WRITE ) ; <nl> - block_write = true ; <nl> - } <nl> - } <nl> - <nl> - inline void check_index_read ( ) { <nl> - try { <nl> - if ( index_write ) { <nl> - index_stream . close ( ) ; <nl> - index_stream . open ( index_file . generic_string ( ) . c_str ( ) , LOG_READ ) ; <nl> - index_write = false ; <nl> - } <nl> - } <nl> - FC_LOG_AND_RETHROW ( ) <nl> - } <nl> - <nl> - inline void check_index_write ( ) { <nl> - if ( ! index_write ) { <nl> + if ( index_stream . is_open ( ) ) <nl> index_stream . close ( ) ; <nl> - index_stream . open ( index_file . generic_string ( ) . c_str ( ) , LOG_WRITE ) ; <nl> - index_write = true ; <nl> - } <nl> + open_files = false ; <nl> } <nl> } ; <nl> + <nl> + void block_log_impl : : reopen ( ) { <nl> + close ( ) ; <nl> + <nl> + / / open to create files if they don ' t exist <nl> + / / ilog ( \" Opening block log at $ { path } \" , ( \" path \" , my - > block_file . generic_string ( ) ) ) ; <nl> + block_stream . open ( block_file . generic_string ( ) . c_str ( ) , LOG_WRITE ) ; <nl> + index_stream . open ( index_file . generic_string ( ) . c_str ( ) , LOG_WRITE ) ; <nl> + <nl> + close ( ) ; <nl> + <nl> + block_stream . open ( block_file . generic_string ( ) . c_str ( ) , LOG_RW ) ; <nl> + index_stream . open ( index_file . generic_string ( ) . c_str ( ) , LOG_RW ) ; <nl> + <nl> + open_files = true ; <nl> + } <nl> } <nl> <nl> block_log : : block_log ( const fc : : path & data_dir ) <nl> namespace eosio { namespace chain { <nl> block_log : : ~ block_log ( ) { <nl> if ( my ) { <nl> flush ( ) ; <nl> + my - > close ( ) ; <nl> my . reset ( ) ; <nl> } <nl> } <nl> <nl> void block_log : : open ( const fc : : path & data_dir ) { <nl> - if ( my - > block_stream . is_open ( ) ) <nl> - my - > block_stream . close ( ) ; <nl> - if ( my - > index_stream . is_open ( ) ) <nl> - my - > index_stream . close ( ) ; <nl> + my - > close ( ) ; <nl> <nl> if ( ! fc : : is_directory ( data_dir ) ) <nl> fc : : create_directories ( data_dir ) ; <nl> + <nl> my - > block_file = data_dir / \" blocks . log \" ; <nl> my - > index_file = data_dir / \" blocks . index \" ; <nl> <nl> - / / ilog ( \" Opening block log at $ { path } \" , ( \" path \" , my - > block_file . generic_string ( ) ) ) ; <nl> - my - > block_stream . open ( my - > block_file . generic_string ( ) . c_str ( ) , LOG_WRITE ) ; <nl> - my - > index_stream . open ( my - > index_file . generic_string ( ) . c_str ( ) , LOG_WRITE ) ; <nl> - my - > block_write = true ; <nl> - my - > index_write = true ; <nl> + my - > reopen ( ) ; <nl> <nl> / * On startup of the block log , there are several states the log file and the index file can be <nl> * in relation to each other . <nl> namespace eosio { namespace chain { <nl> <nl> if ( log_size ) { <nl> ilog ( \" Log is nonempty \" ) ; <nl> - my - > check_block_read ( ) ; <nl> my - > block_stream . seekg ( 0 ) ; <nl> my - > version = 0 ; <nl> my - > block_stream . read ( ( char * ) & my - > version , sizeof ( my - > version ) ) ; <nl> namespace eosio { namespace chain { <nl> my - > head_id = my - > head - > id ( ) ; <nl> <nl> if ( index_size ) { <nl> - my - > check_block_read ( ) ; <nl> - my - > check_index_read ( ) ; <nl> - <nl> ilog ( \" Index is nonempty \" ) ; <nl> uint64_t block_pos ; <nl> my - > block_stream . seekg ( - sizeof ( uint64_t ) , std : : ios : : end ) ; <nl> namespace eosio { namespace chain { <nl> } <nl> } else if ( index_size ) { <nl> ilog ( \" Index is nonempty , remove and recreate it \" ) ; <nl> - my - > index_stream . close ( ) ; <nl> + my - > close ( ) ; <nl> fc : : remove_all ( my - > index_file ) ; <nl> - my - > index_stream . open ( my - > index_file . generic_string ( ) . c_str ( ) , LOG_WRITE ) ; <nl> - my - > index_write = true ; <nl> + my - > reopen ( ) ; <nl> } <nl> } <nl> <nl> namespace eosio { namespace chain { <nl> try { <nl> EOS_ASSERT ( my - > genesis_written_to_block_log , block_log_append_fail , \" Cannot append to block log until the genesis is first written \" ) ; <nl> <nl> - my - > check_block_write ( ) ; <nl> - my - > check_index_write ( ) ; <nl> + my - > check_open_files ( ) ; <nl> <nl> + my - > block_stream . seekp ( 0 , std : : ios : : end ) ; <nl> + my - > index_stream . seekp ( 0 , std : : ios : : end ) ; <nl> uint64_t pos = my - > block_stream . tellp ( ) ; <nl> EOS_ASSERT ( my - > index_stream . tellp ( ) = = sizeof ( uint64_t ) * ( b - > block_num ( ) - my - > first_block_num ) , <nl> block_log_append_fail , <nl> namespace eosio { namespace chain { <nl> } <nl> <nl> void block_log : : reset ( const genesis_state & gs , const signed_block_ptr & first_block , uint32_t first_block_num ) { <nl> - if ( my - > block_stream . is_open ( ) ) <nl> - my - > block_stream . close ( ) ; <nl> - if ( my - > index_stream . is_open ( ) ) <nl> - my - > index_stream . close ( ) ; <nl> + my - > close ( ) ; <nl> <nl> fc : : remove_all ( my - > block_file ) ; <nl> fc : : remove_all ( my - > index_file ) ; <nl> <nl> - my - > block_stream . open ( my - > block_file . generic_string ( ) . c_str ( ) , LOG_WRITE ) ; <nl> - my - > index_stream . open ( my - > index_file . generic_string ( ) . c_str ( ) , LOG_WRITE ) ; <nl> - my - > block_write = true ; <nl> - my - > index_write = true ; <nl> + my - > reopen ( ) ; <nl> <nl> auto data = fc : : raw : : pack ( gs ) ; <nl> my - > version = 0 ; / / version of 0 is invalid ; it indicates that the genesis was not properly written to the block log <nl> my - > first_block_num = first_block_num ; <nl> + my - > block_stream . seekp ( 0 , std : : ios : : end ) ; <nl> my - > block_stream . write ( ( char * ) & my - > version , sizeof ( my - > version ) ) ; <nl> my - > block_stream . write ( ( char * ) & my - > first_block_num , sizeof ( my - > first_block_num ) ) ; <nl> my - > block_stream . write ( data . data ( ) , data . size ( ) ) ; <nl> namespace eosio { namespace chain { <nl> <nl> auto pos = my - > block_stream . tellp ( ) ; <nl> <nl> - my - > block_stream . close ( ) ; <nl> - my - > block_stream . open ( my - > block_file . generic_string ( ) . c_str ( ) , std : : ios : : in | std : : ios : : out | std : : ios : : binary ) ; / / Bypass append - only writing just once <nl> - <nl> static_assert ( block_log : : max_supported_version > 0 , \" a version number of zero is not supported \" ) ; <nl> my - > version = block_log : : max_supported_version ; <nl> my - > block_stream . seekp ( 0 ) ; <nl> my - > block_stream . write ( ( char * ) & my - > version , sizeof ( my - > version ) ) ; <nl> my - > block_stream . seekp ( pos ) ; <nl> flush ( ) ; <nl> - <nl> - my - > block_write = false ; <nl> - my - > check_block_write ( ) ; / / Reset to append - only writing . <nl> } <nl> <nl> std : : pair < signed_block_ptr , uint64_t > block_log : : read_block ( uint64_t pos ) const { <nl> - my - > check_block_read ( ) ; <nl> + my - > check_open_files ( ) ; <nl> <nl> my - > block_stream . seekg ( pos ) ; <nl> std : : pair < signed_block_ptr , uint64_t > result ; <nl> namespace eosio { namespace chain { <nl> } <nl> <nl> uint64_t block_log : : get_block_pos ( uint32_t block_num ) const { <nl> - my - > check_index_read ( ) ; <nl> + my - > check_open_files ( ) ; <nl> if ( ! ( my - > head & & block_num < = block_header : : num_from_id ( my - > head_id ) & & block_num > = my - > first_block_num ) ) <nl> return npos ; <nl> my - > index_stream . seekg ( sizeof ( uint64_t ) * ( block_num - my - > first_block_num ) ) ; <nl> namespace eosio { namespace chain { <nl> } <nl> <nl> signed_block_ptr block_log : : read_head ( ) const { <nl> - my - > check_block_read ( ) ; <nl> + my - > check_open_files ( ) ; <nl> <nl> uint64_t pos ; <nl> <nl> namespace eosio { namespace chain { <nl> <nl> void block_log : : construct_index ( ) { <nl> ilog ( \" Reconstructing Block Log Index . . . \" ) ; <nl> - my - > index_stream . close ( ) ; <nl> + my - > close ( ) ; <nl> + <nl> fc : : remove_all ( my - > index_file ) ; <nl> - my - > index_stream . open ( my - > index_file . generic_string ( ) . c_str ( ) , LOG_WRITE ) ; <nl> - my - > index_write = true ; <nl> + <nl> + my - > reopen ( ) ; <nl> <nl> uint64_t end_pos ; <nl> - my - > check_block_read ( ) ; <nl> <nl> my - > block_stream . seekg ( - sizeof ( uint64_t ) , std : : ios : : end ) ; <nl> my - > block_stream . read ( ( char * ) & end_pos , sizeof ( end_pos ) ) ; <nl> namespace eosio { namespace chain { <nl> my - > block_stream . read ( ( char * ) & totem , sizeof ( totem ) ) ; <nl> } <nl> <nl> + my - > index_stream . seekp ( 0 , std : : ios : : end ) ; <nl> while ( pos < end_pos ) { <nl> fc : : raw : : unpack ( my - > block_stream , tmp ) ; <nl> my - > block_stream . read ( ( char * ) & pos , sizeof ( pos ) ) ; <nl>\n", "msg": "Keep block log open to minimize open / close of file\n"}
{"diff_id": 41307, "repo": "mongodb/mongo\n", "sha": "741d9f7a19b569beefd6156517df2cc13eed92c9\n", "time": "2010-06-01T19:48:02Z\n", "diff": "mmm a / db / queryoptimizer . cpp <nl> ppp b / db / queryoptimizer . cpp <nl> namespace mongo { <nl> ss < < \" best guess plan requested , but scan and order required : \" ; <nl> ss < < \" query : \" < < query_ ; <nl> ss < < \" order : \" < < order_ ; <nl> - <nl> + ss < < \" choices : \" ; <nl> + for ( unsigned i = 0 ; i < plans_ . size ( ) ; i + + ) { <nl> + ss < < plans_ [ i ] - > indexKey ( ) < < \" \" ; <nl> + } <nl> + <nl> string s = ss . str ( ) ; <nl> msgassertedNoTrace ( 13284 , s . c_str ( ) ) ; <nl> } <nl>\n", "msg": "more debugging for SERVER - 1179\n"}
{"diff_id": 41365, "repo": "xbmc/xbmc\n", "sha": "5659162c54d4753bb610c8bd8f3aa78f182e1973\n", "time": "2012-03-30T22:31:14Z\n", "diff": "mmm a / xbmc / video / VideoDatabase . cpp <nl> ppp b / xbmc / video / VideoDatabase . cpp <nl> void CVideoDatabase : : CreateViews ( ) <nl> { <nl> CLog : : Log ( LOGINFO , \" create episodeview \" ) ; <nl> m_pDS - > exec ( \" DROP VIEW IF EXISTS episodeview \" ) ; <nl> - CStdString episodeview = PrepareSQL ( \" create view episodeview as select episode . * , files . strFileName as strFileName , \" <nl> - \" path . strPath as strPath , files . playCount as playCount , files . lastPlayed as lastPlayed , files . dateAdded as dateAdded , tvshow . c % 02d as strTitle , tvshow . c % 02d as strStudio , tvshow . idShow as idShow , \" <nl> - \" tvshow . c % 02d as premiered , tvshow . c % 02d as mpaa , tvshow . c % 02d as strShowPath from episode \" <nl> - \" join files on files . idFile = episode . idFile \" <nl> - \" join tvshowlinkepisode on episode . idEpisode = tvshowlinkepisode . idEpisode \" <nl> - \" join tvshow on tvshow . idShow = tvshowlinkepisode . idShow \" <nl> - \" join path on files . idPath = path . idPath \" , VIDEODB_ID_TV_TITLE , VIDEODB_ID_TV_STUDIOS , VIDEODB_ID_TV_PREMIERED , VIDEODB_ID_TV_MPAA , VIDEODB_ID_TV_BASEPATH ) ; <nl> + CStdString episodeview = PrepareSQL ( \" CREATE VIEW episodeview AS SELECT \" <nl> + \" episode . * , \" <nl> + \" files . strFileName AS strFileName , \" <nl> + \" path . strPath AS strPath , \" <nl> + \" files . playCount AS playCount , \" <nl> + \" files . lastPlayed AS lastPlayed , \" <nl> + \" files . dateAdded AS dateAdded , \" <nl> + \" tvshow . c % 02d AS strTitle , \" <nl> + \" tvshow . c % 02d AS strStudio , \" <nl> + \" tvshow . idShow AS idShow , \" <nl> + \" tvshow . c % 02d AS premiered , \" <nl> + \" tvshow . c % 02d AS mpaa , \" <nl> + \" tvshow . c % 02d AS strShowPath \" <nl> + \" FROM episode \" <nl> + \" JOIN files ON \" <nl> + \" files . idFile = episode . idFile \" <nl> + \" JOIN tvshowlinkepisode ON \" <nl> + \" episode . idEpisode = tvshowlinkepisode . idEpisode \" <nl> + \" JOIN tvshow ON \" <nl> + \" tvshow . idShow = tvshowlinkepisode . idShow \" <nl> + \" JOIN path ON \" <nl> + \" files . idPath = path . idPath \" , VIDEODB_ID_TV_TITLE , VIDEODB_ID_TV_STUDIOS , VIDEODB_ID_TV_PREMIERED , VIDEODB_ID_TV_MPAA , VIDEODB_ID_TV_BASEPATH ) ; <nl> m_pDS - > exec ( episodeview . c_str ( ) ) ; <nl> <nl> CLog : : Log ( LOGINFO , \" create tvshowview \" ) ; <nl> m_pDS - > exec ( \" DROP VIEW IF EXISTS tvshowview \" ) ; <nl> CStdString tvshowview = PrepareSQL ( \" CREATE VIEW tvshowview AS SELECT \" <nl> - \" tvshow . * , \" <nl> - \" path . strPath AS strPath , \" <nl> - \" path . dateAdded AS dateAdded , \" <nl> + \" tvshow . * , \" <nl> + \" path . strPath AS strPath , \" <nl> + \" path . dateAdded AS dateAdded , \" <nl> \" NULLIF ( COUNT ( episode . c12 ) , 0 ) AS totalCount , \" <nl> \" COUNT ( files . playCount ) AS watchedcount , \" <nl> \" NULLIF ( COUNT ( DISTINCT ( episode . c12 ) ) , 0 ) AS totalSeasons \" <nl> void CVideoDatabase : : CreateViews ( ) <nl> <nl> CLog : : Log ( LOGINFO , \" create musicvideoview \" ) ; <nl> m_pDS - > exec ( \" DROP VIEW IF EXISTS musicvideoview \" ) ; <nl> - m_pDS - > exec ( \" create view musicvideoview as select musicvideo . * , files . strFileName as strFileName , path . strPath as strPath , files . playCount as playCount , files . lastPlayed as lastPlayed , files . dateAdded as dateAdded \" <nl> - \" from musicvideo join files on files . idFile = musicvideo . idFile join path on path . idPath = files . idPath \" ) ; <nl> + m_pDS - > exec ( \" CREATE VIEW musicvideoview AS SELECT \" <nl> + \" musicvideo . * , \" <nl> + \" files . strFileName as strFileName , \" <nl> + \" path . strPath as strPath , \" <nl> + \" files . playCount as playCount , \" <nl> + \" files . lastPlayed as lastPlayed , \" <nl> + \" files . dateAdded as dateAdded \" <nl> + \" FROM musicvideo \" <nl> + \" JOIN files ON \" <nl> + \" files . idFile = musicvideo . idFile \" <nl> + \" JOIN path ON \" <nl> + \" path . idPath = files . idPath \" ) ; <nl> <nl> CLog : : Log ( LOGINFO , \" create movieview \" ) ; <nl> m_pDS - > exec ( \" DROP VIEW IF EXISTS movieview \" ) ; <nl> - m_pDS - > exec ( \" create view movieview as select movie . * , files . strFileName as strFileName , path . strPath as strPath , files . playCount as playCount , files . lastPlayed as lastPlayed , files . dateAdded as dateAdded \" <nl> - \" from movie join files on files . idFile = movie . idFile join path on path . idPath = files . idPath \" ) ; <nl> + m_pDS - > exec ( \" CREATE VIEW movieview AS SELECT \" <nl> + \" movie . * , \" <nl> + \" files . strFileName AS strFileName , \" <nl> + \" path . strPath AS strPath , \" <nl> + \" files . playCount AS playCount , \" <nl> + \" files . lastPlayed AS lastPlayed , \" <nl> + \" files . dateAdded AS dateAdded \" <nl> + \" FROM movie \" <nl> + \" JOIN files ON \" <nl> + \" files . idFile = movie . idFile \" <nl> + \" JOIN path ON \" <nl> + \" path . idPath = files . idPath \" ) ; <nl> } <nl> <nl> / / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * <nl>\n", "msg": "cosmetic - improve layout of view creation\n"}
{"diff_id": 41553, "repo": "xbmc/xbmc\n", "sha": "201b80b9eaa24ac67795e102ccffd57f8bf377f5\n", "time": "2019-10-11T19:46:08Z\n", "diff": "mmm a / xbmc / interfaces / python / PythonInvoker . cpp <nl> ppp b / xbmc / interfaces / python / PythonInvoker . cpp <nl> extern \" C \" FILE * fopen_utf8 ( const char * _Filename , const char * _Mode ) ; <nl> using namespace XFILE ; <nl> using namespace KODI : : MESSAGING ; <nl> <nl> - extern \" C \" <nl> - { <nl> - int xbp_chdir ( const char * dirname ) ; <nl> - char * dll_getenv ( const char * szKey ) ; <nl> - } <nl> - <nl> # define PythonModulesSize sizeof ( PythonModules ) / sizeof ( PythonModule ) <nl> <nl> CCriticalSection CPythonInvoker : : s_critical ; <nl>\n", "msg": "[ cleanup ] remove unused functions\n"}
{"diff_id": 41715, "repo": "ClickHouse/ClickHouse\n", "sha": "36a9ac86b813fbbcd977ef43420471d413e0735f\n", "time": "2019-11-05T14:02:38Z\n", "diff": "mmm a / dbms / src / Common / Macros . cpp <nl> ppp b / dbms / src / Common / Macros . cpp <nl> <nl> # include < Poco / Util / AbstractConfiguration . h > <nl> # include < Common / Macros . h > <nl> # include < Common / Exception . h > <nl> + # include < IO / WriteHelpers . h > <nl> <nl> <nl> namespace DB <nl> String Macros : : expand ( const String & s , size_t level , const String & database_na <nl> else if ( macro_name = = \" table \" & & ! table_name . empty ( ) ) <nl> res + = table_name ; <nl> else <nl> - throw Exception ( \" No macro \" + macro_name + \" in config \" , ErrorCodes : : SYNTAX_ERROR ) ; <nl> + throw Exception ( \" No macro ' \" + macro_name + <nl> + \" ' in config while processing substitutions in ' \" + s + \" ' at \" <nl> + + toString ( begin ) , ErrorCodes : : SYNTAX_ERROR ) ; <nl> <nl> pos = end + 1 ; <nl> } <nl>\n", "msg": "More verbose error message in macros .\n"}
{"diff_id": 41785, "repo": "arangodb/arangodb\n", "sha": "74b147bb20bc5b9bdc54c72bbe33b14588aa7f81\n", "time": "2015-12-15T17:09:55Z\n", "diff": "mmm a / arangod / Cluster / ClusterComm . cpp <nl> ppp b / arangod / Cluster / ClusterComm . cpp <nl> bool ClusterComm : : moveFromSendToReceived ( OperationID operationID ) { <nl> TRI_ASSERT ( i ! = toSendByOpID . end ( ) ) ; <nl> <nl> QueueIterator q = i - > second ; <nl> - ClusterCommOperation * op = * q ; <nl> + ClusterCommOperation op = * q ; <nl> TRI_ASSERT ( op - > result . operationID = = operationID ) ; <nl> toSendByOpID . erase ( i ) ; <nl> toSend . erase ( q ) ; <nl> + std : : unique_ptr < ClusterCommOperation > opPtr ( op ) ; <nl> if ( op - > result . dropped ) { <nl> return false ; <nl> } <nl> bool ClusterComm : : moveFromSendToReceived ( OperationID operationID ) { <nl> op - > result . status = CL_COMM_SENT ; <nl> } <nl> received . push_back ( op ) ; <nl> + opPtr . release ( ) ; <nl> q = received . end ( ) ; <nl> q - - ; <nl> receivedByOpID [ operationID ] = q ; <nl> void ClusterCommThread : : run ( ) { <nl> } <nl> } <nl> <nl> - if ( ! cc - > moveFromSendToReceived ( op - > result . operationID ) ) { <nl> - / / It was dropped in the meantime , so forget about it : <nl> - delete op ; <nl> - } <nl> + cc - > moveFromSendToReceived ( op - > result . operationID ) ; <nl> + / / Potentially it was dropped in the meantime , then we forget about it . <nl> } <nl> <nl> / / Now the send queue is empty ( at least was empty , when we looked <nl>\n", "msg": "Improve memory management in ClusterComm library .\n"}
{"diff_id": 41830, "repo": "mongodb/mongo\n", "sha": "2d0674bad139cf408403a61fcc6b246a3f8fdc32\n", "time": "2013-07-10T00:02:50Z\n", "diff": "mmm a / src / mongo / bson / mutable / document . cpp <nl> ppp b / src / mongo / bson / mutable / document . cpp <nl> namespace mutablebson { <nl> \" Attempt to add a sibling to an element without a parent \" ) ; <nl> <nl> ElementRep & parentRep = impl . getElementRep ( thisRep . parent ) ; <nl> - if ( impl . isLeaf ( parentRep ) ) <nl> - return Status ( <nl> - ErrorCodes : : IllegalOperation , <nl> - \" Attempt to add a sibling element under a non - object element \" ) ; <nl> + dassert ( ! impl . isLeaf ( parentRep ) ) ; <nl> <nl> impl . disableInPlaceUpdates ( ) ; <nl> <nl> namespace mutablebson { <nl> \" Attempt to add a sibling to an element without a parent \" ) ; <nl> <nl> ElementRep * parentRep = & impl . getElementRep ( thisRep - > parent ) ; <nl> - if ( impl . isLeaf ( * parentRep ) ) <nl> - return Status ( <nl> - ErrorCodes : : IllegalOperation , <nl> - \" Attempt to add a sibling element under a non - object element \" ) ; <nl> + dassert ( ! impl . isLeaf ( * parentRep ) ) ; <nl> <nl> impl . disableInPlaceUpdates ( ) ; <nl> <nl>\n", "msg": "SERVER - 8046 Remove some impossible error condition checks\n"}
{"diff_id": 41861, "repo": "mongodb/mongo\n", "sha": "291be8e769616761080d51c7edf694851e373216\n", "time": "2012-02-14T17:48:40Z\n", "diff": "mmm a / src / third_party / murmurhash3 / MurmurHash3 . cpp <nl> ppp b / src / third_party / murmurhash3 / MurmurHash3 . cpp <nl> inline uint64_t rotl64 ( uint64_t x , int8_t r ) <nl> / / Block read - if your platform needs to do endian - swapping or can only <nl> / / handle aligned reads , do the conversion here <nl> <nl> - FORCE_INLINE uint32_t getblock ( const uint32_t * p , int i ) <nl> + FORCE_INLINE inline uint32_t getblock ( const uint32_t * p , int i ) <nl> { <nl> return p [ i ] ; <nl> } <nl> <nl> - FORCE_INLINE uint64_t getblock ( const uint64_t * p , int i ) <nl> + FORCE_INLINE inline uint64_t getblock ( const uint64_t * p , int i ) <nl> { <nl> return p [ i ] ; <nl> } <nl> FORCE_INLINE uint64_t getblock ( const uint64_t * p , int i ) <nl> / / mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm - - <nl> / / Finalization mix - force all bits of a hash block to avalanche <nl> <nl> - FORCE_INLINE uint32_t fmix ( uint32_t h ) <nl> + FORCE_INLINE inline uint32_t fmix ( uint32_t h ) <nl> { <nl> h ^ = h > > 16 ; <nl> h * = 0x85ebca6b ; <nl> FORCE_INLINE uint32_t fmix ( uint32_t h ) <nl> <nl> / / mmmmmmmmm - <nl> <nl> - FORCE_INLINE uint64_t fmix ( uint64_t k ) <nl> + FORCE_INLINE inline uint64_t fmix ( uint64_t k ) <nl> { <nl> k ^ = k > > 33 ; <nl> k * = BIG_CONSTANT ( 0xff51afd7ed558ccd ) ; <nl>\n", "msg": "added inlines for compiling with older gcc\n"}
{"diff_id": 41968, "repo": "tensorflow/tensorflow\n", "sha": "4b1e0f8d4060ea3b6a7f6ffb5ee6bab2778dc40c\n", "time": "2019-10-09T19:17:59Z\n", "diff": "mmm a / third_party / mlir / lib / Transforms / LoopFusion . cpp <nl> ppp b / third_party / mlir / lib / Transforms / LoopFusion . cpp <nl> struct MemRefDependenceGraph { <nl> return false ; <nl> } <nl> <nl> + / / Returns the unique AffineStoreOp in ` node ` that meets all the following : <nl> + / / * ) store is the only one that writes to a function - local memref live out <nl> + / / of ` node ` , <nl> + / / * ) store is not the source of a self - dependence on ` node ` . <nl> + / / Otherwise , returns a null AffineStoreOp . <nl> + AffineStoreOp getUniqueOutgoingStore ( Node * node ) { <nl> + AffineStoreOp uniqueStore ; <nl> + <nl> + / / Return null if ` node ` doesn ' t have any outgoing edges . <nl> + auto outEdgeIt = outEdges . find ( node - > id ) ; <nl> + if ( outEdgeIt = = outEdges . end ( ) ) <nl> + return nullptr ; <nl> + <nl> + const auto & nodeOutEdges = outEdgeIt - > second ; <nl> + for ( auto * op : node - > stores ) { <nl> + auto storeOp = cast < AffineStoreOp > ( op ) ; <nl> + auto * memref = storeOp . getMemRef ( ) ; <nl> + / / Skip this store if there are no dependences on its memref . This means <nl> + / / that store either : <nl> + / / * ) writes to a memref that is only read within the same loop nest <nl> + / / ( self - dependence edges are not represented in graph at the moment ) , <nl> + / / * ) writes to a function live out memref ( function parameter ) , or <nl> + / / * ) is dead . <nl> + if ( llvm : : all_of ( nodeOutEdges , [ = ] ( const Edge & edge ) { <nl> + return ( edge . value ! = memref ) ; <nl> + } ) ) <nl> + continue ; <nl> + <nl> + if ( uniqueStore ) <nl> + / / Found multiple stores to function - local live - out memrefs . <nl> + return nullptr ; <nl> + / / Found first store to function - local live - out memref . <nl> + uniqueStore = storeOp ; <nl> + } <nl> + <nl> + return uniqueStore ; <nl> + } <nl> + <nl> / / Returns true if node ' id ' can be removed from the graph . Returns false <nl> / / otherwise . A node can be removed from the graph iff the following <nl> / / conditions are met : <nl> static Value * createPrivateMemRef ( AffineForOp forOp , Operation * srcStoreOpInst , <nl> return newMemRef ; <nl> } <nl> <nl> - / / Checks if node ' srcId ' ( which writes to a live out memref ) , can be safely <nl> - / / fused into node ' dstId ' . Returns true if the following conditions are met : <nl> - / / * ) ' srcNode ' only writes to live out ' memref ' . <nl> - / / * ) ' srcNode ' has exactly one output edge on ' memref ' ( which is to ' dstId ' ) . <nl> - / / * ) ' dstNode ' s read / write region to ' memref ' is a super set of ' srcNode ' s <nl> - / / write region to ' memref ' . <nl> + / / Checks if node ' srcId ' can be safely fused into node ' dstId ' . Node ' srcId ' <nl> + / / may write to multiple memrefs but it is required that only one of them , <nl> + / / ' srcLiveOutStoreOp ' , have an output edge . <nl> + / / Returns true if ' dstNode ' s read / write region to ' memref ' is a super set of <nl> + / / ' srcNode ' s write region to ' memref ' . <nl> / / TODO ( andydavis ) Generalize this to handle more live in / out cases . <nl> static bool canFuseSrcWhichWritesToLiveOut ( unsigned srcId , unsigned dstId , <nl> - Value * memref , <nl> + AffineStoreOp srcLiveOutStoreOp , <nl> MemRefDependenceGraph * mdg ) { <nl> - auto * srcNode = mdg - > getNode ( srcId ) ; <nl> + assert ( srcLiveOutStoreOp & & \" Expected a valid store op \" ) ; <nl> + assert ( mdg - > getOutEdgeCount ( srcId ) = = 1 & & \" Expected only one output edge \" ) ; <nl> auto * dstNode = mdg - > getNode ( dstId ) ; <nl> + Value * memref = srcLiveOutStoreOp . getMemRef ( ) ; <nl> <nl> - / / Gather all memrefs from ' srcNode ' store ops . <nl> - DenseSet < Value * > storeMemrefs ; <nl> - for ( auto * storeOpInst : srcNode - > stores ) { <nl> - storeMemrefs . insert ( cast < AffineStoreOp > ( storeOpInst ) . getMemRef ( ) ) ; <nl> - } <nl> - / / Return false if any of the following are true : <nl> - / / * ) ' srcNode ' writes to a live in / out memref other than ' memref ' . <nl> - / / * ) ' srcNode ' has more than one output edge on ' memref ' . <nl> - / / Check that all stores are to the same memref . <nl> - if ( storeMemrefs . size ( ) ! = 1 | | <nl> - mdg - > getOutEdgeCount ( srcNode - > id , memref ) ! = 1 ) <nl> - return false ; <nl> - / / Compute MemRefRegion ' srcWriteRegion ' for ' srcStoreOpInst ' on ' memref ' . <nl> - auto * srcStoreOpInst = srcNode - > stores . front ( ) ; <nl> - MemRefRegion srcWriteRegion ( srcStoreOpInst - > getLoc ( ) ) ; <nl> - if ( failed ( srcWriteRegion . compute ( srcStoreOpInst , / * loopDepth = * / 0 ) ) ) { <nl> + / / Compute MemRefRegion ' srcWriteRegion ' for ' srcStoreOp ' on ' memref ' . <nl> + MemRefRegion srcWriteRegion ( srcLiveOutStoreOp . getLoc ( ) ) ; <nl> + if ( failed ( srcWriteRegion . compute ( srcLiveOutStoreOp , / * loopDepth = * / 0 ) ) ) { <nl> LLVM_DEBUG ( llvm : : dbgs ( ) <nl> < < \" Unable to compute MemRefRegion for source operation \\ n . \" ) ; <nl> return false ; <nl> } <nl> SmallVector < int64_t , 4 > srcShape ; <nl> / / Query ' srcWriteRegion ' for ' srcShape ' and ' srcNumElements ' . <nl> - / / by ' srcStoreOpInst ' at depth ' dstLoopDepth ' . <nl> + / / by ' srcStoreOp ' at depth ' dstLoopDepth ' . <nl> Optional < int64_t > srcNumElements = <nl> srcWriteRegion . getConstantBoundingSizeAndShape ( & srcShape ) ; <nl> if ( ! srcNumElements . hasValue ( ) ) <nl> struct GreedyFusion { <nl> / / Skip if ' srcNode ' is not a loop nest . <nl> if ( ! isa < AffineForOp > ( srcNode - > op ) ) <nl> continue ; <nl> - / / Skip if ' srcNode ' has more than one store to any memref . <nl> - / / TODO ( andydavis ) Support fusing multi - output src loop nests . <nl> - if ( srcNode - > stores . size ( ) ! = 1 ) <nl> + / / Skip if ' srcNode ' has more than one live - out store to a <nl> + / / function - local memref . <nl> + / / TODO ( andydavis ) Support more generic multi - output src loop nests <nl> + / / fusion . <nl> + auto srcStoreOp = mdg - > getUniqueOutgoingStore ( srcNode ) ; <nl> + if ( ! srcStoreOp ) <nl> continue ; <nl> + / / Unique outgoing store found must write to ' memref ' since ' memref ' <nl> + / / is the one that established the producer - consumer relationship <nl> + / / between ' srcNode ' and ' dstNode ' . <nl> + assert ( srcStoreOp . getMemRef ( ) = = memref & & <nl> + \" Found store to unexpected memref \" ) ; <nl> <nl> / / Skip if ' srcNode ' writes to any live in or escaping memrefs , <nl> / / and cannot be fused . <nl> bool writesToLiveInOrOut = <nl> mdg - > writesToLiveInOrEscapingMemrefs ( srcNode - > id ) ; <nl> if ( writesToLiveInOrOut & & <nl> - ! canFuseSrcWhichWritesToLiveOut ( srcId , dstId , memref , mdg ) ) <nl> + ! canFuseSrcWhichWritesToLiveOut ( srcId , dstId , srcStoreOp , mdg ) ) <nl> continue ; <nl> <nl> / / Skip if ' srcNode ' out edge count on ' memref ' > ' maxSrcUserCount ' . <nl> struct GreedyFusion { <nl> if ( insertPointInst = = nullptr ) <nl> continue ; <nl> <nl> - / / Get unique ' srcNode ' store op . <nl> - auto * srcStoreOpInst = srcNode - > stores . front ( ) ; <nl> / / Gather ' dstNode ' store ops to ' memref ' . <nl> SmallVector < Operation * , 2 > dstStoreOpInsts ; <nl> for ( auto * storeOpInst : dstNode - > stores ) <nl> struct GreedyFusion { <nl> unsigned bestDstLoopDepth ; <nl> mlir : : ComputationSliceState sliceState ; <nl> / / Check if fusion would be profitable . <nl> - if ( ! isFusionProfitable ( srcStoreOpInst , srcStoreOpInst , <nl> - dstLoadOpInsts , dstStoreOpInsts , & sliceState , <nl> + if ( ! isFusionProfitable ( srcStoreOp , srcStoreOp , dstLoadOpInsts , <nl> + dstStoreOpInsts , & sliceState , <nl> & bestDstLoopDepth , maximalFusion ) ) <nl> continue ; <nl> / / TODO ( andydavis ) Remove the following test code when canFuseLoops <nl> struct GreedyFusion { <nl> } <nl> / / Fuse computation slice of ' srcLoopNest ' into ' dstLoopNest ' . <nl> auto sliceLoopNest = mlir : : insertBackwardComputationSlice ( <nl> - srcStoreOpInst , dstLoadOpInsts [ 0 ] , bestDstLoopDepth , & sliceState ) ; <nl> + srcStoreOp , dstLoadOpInsts [ 0 ] , bestDstLoopDepth , & sliceState ) ; <nl> if ( sliceLoopNest ) { <nl> LLVM_DEBUG ( llvm : : dbgs ( ) < < \" \\ tslice loop nest : \\ n \" <nl> < < * sliceLoopNest . getOperation ( ) < < \" \\ n \" ) ; <nl>\n", "msg": "Add support for some multi - store cases in affine fusion\n"}
{"diff_id": 42105, "msg": "added simple GSP GPU ReadHWRegs function to support returning the framebuffer address\n", "msgGPT": "add GSP GPU register read functionality and fix a bug in copying framebuffer 2 addresses.", "METEOR Score": "26.088606631395034", "BLEU Score": "0.5409644462681136", "ROUGE-L Score": "0.27586206397146257", "score": 1, "repo": "yuzu-emu/yuzu\n", "sha": "9e047e32d4973cb01f96116027e80639aa9f4280\n", "time": "2014-04-26T05:48:24Z\n", "diff": "mmm a / src / core / hle / service / gsp . cpp <nl> ppp b / src / core / hle / service / gsp . cpp <nl> <nl> <nl> # include \" common / log . h \" <nl> <nl> + # include \" core / mem_map . h \" <nl> # include \" core / hle / hle . h \" <nl> # include \" core / hle / service / gsp . h \" <nl> <nl> + # include \" core / hw / lcd . h \" <nl> + <nl> / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / <nl> / / Namespace GSP_GPU <nl> <nl> namespace GSP_GPU { <nl> <nl> + enum { <nl> + REG_FRAMEBUFFER_1 = 0x00400468 , <nl> + REG_FRAMEBUFFER_2 = 0x00400494 , <nl> + } ; <nl> + <nl> + / / / Read a GSP GPU hardware register <nl> + void ReadHWRegs ( Service : : Interface * self ) { <nl> + static const u32 framebuffer_1 [ ] = { LCD : : VRAM_TOP_LEFT_FRAME1 , LCD : : VRAM_TOP_RIGHT_FRAME1 } ; <nl> + static const u32 framebuffer_2 [ ] = { LCD : : VRAM_TOP_LEFT_FRAME2 , LCD : : VRAM_TOP_RIGHT_FRAME2 } ; <nl> + <nl> + u32 * cmd_buff = ( u32 * ) HLE : : GetPointer ( HLE : : CMD_BUFFER_ADDR + Service : : kCommandHeaderOffset ) ; <nl> + u32 reg_addr = cmd_buff [ 1 ] ; <nl> + u32 size = cmd_buff [ 2 ] ; <nl> + u32 * dst = ( u32 * ) Memory : : GetPointer ( cmd_buff [ 0x41 ] ) ; <nl> + <nl> + switch ( reg_addr ) { <nl> + <nl> + / / Top framebuffer 1 addresses <nl> + case REG_FRAMEBUFFER_1 : <nl> + memcpy ( dst , framebuffer_1 , size ) ; <nl> + break ; <nl> + <nl> + / / Top framebuffer 2 addresses <nl> + case REG_FRAMEBUFFER_2 : <nl> + memcpy ( dst , framebuffer_1 , size ) ; <nl> + break ; <nl> + <nl> + default : <nl> + ERROR_LOG ( OSHLE , \" GSP_GPU : : ReadHWRegs unknown register read at address % 08X \" , reg_addr ) ; <nl> + } <nl> + <nl> + } <nl> + <nl> void RegisterInterruptRelayQueue ( Service : : Interface * self ) { <nl> u32 * cmd_buff = ( u32 * ) HLE : : GetPointer ( HLE : : CMD_BUFFER_ADDR + Service : : kCommandHeaderOffset ) ; <nl> u32 flags = cmd_buff [ 1 ] ; <nl> const Interface : : FunctionInfo FunctionTable [ ] = { <nl> { 0x00010082 , NULL , \" WriteHWRegs \" } , <nl> { 0x00020084 , NULL , \" WriteHWRegsWithMask \" } , <nl> { 0x00030082 , NULL , \" WriteHWRegRepeat \" } , <nl> - { 0x00040080 , NULL , \" ReadHWRegs \" } , <nl> + { 0x00040080 , ReadHWRegs , \" ReadHWRegs \" } , <nl> { 0x00050200 , NULL , \" SetBufferSwap \" } , <nl> { 0x00060082 , NULL , \" SetCommandList \" } , <nl> { 0x000700C2 , NULL , \" RequestDma \" } , <nl>\n"}
{"diff_id": 42110, "repo": "xbmc/xbmc\n", "sha": "5ddaccc6e0407f96e1b20fb79e0b457e407c2241\n", "time": "2010-11-23T01:43:09Z\n", "diff": "mmm a / xbmc / lib / libjsonrpc / JSONRPC . cpp <nl> ppp b / xbmc / lib / libjsonrpc / JSONRPC . cpp <nl> JSON_STATUS CJSONRPC : : Permission ( const CStdString & method , ITransportLayer * tran <nl> int flags = client - > GetPermissionFlags ( ) ; <nl> <nl> for ( int i = 1 ; i < = OPERATION_PERMISSION_ALL ; i * = 2 ) <nl> - { <nl> - if ( flags & i ) <nl> - result [ \" permission \" ] . append ( PermissionToString ( ( OperationPermission ) ( flags & i ) ) ) ; <nl> - } <nl> + result [ PermissionToString ( ( OperationPermission ) i ) ] = ( flags & i ) > 0 ; <nl> <nl> return OK ; <nl> } <nl>\n", "msg": "Made Permission return an object to be consistant with announcementflags\n", "score": 1}
{"diff_id": 42134, "msg": "Switch from deprecated RSocketClientChannel to RocketClientChannel\n", "msgGPT": "update thrift client to use rocket client channel instead of r socket client channel for the new thrift streaming protocol.", "METEOR Score": "58.086079032157606", "BLEU Score": "0.431369217329377", "ROUGE-L Score": "0.319999995392", "score": 1, "repo": "facebook/watchman\n", "sha": "ce5e1ee74bef97fec905610aafd5653b4c92860a\n", "time": "2019-07-11T16:37:36Z\n", "diff": "mmm a / watcher / eden . cpp <nl> ppp b / watcher / eden . cpp <nl> <nl> # include < folly / io / async / EventBaseManager . h > <nl> # include < thrift / lib / cpp / async / TAsyncSocket . h > <nl> # include < thrift / lib / cpp2 / async / HeaderClientChannel . h > <nl> - # include < thrift / lib / cpp2 / async / RSocketClientChannel . h > <nl> + # include < thrift / lib / cpp2 / async / RocketClientChannel . h > <nl> # include < algorithm > <nl> # include < chrono > <nl> # include < iterator > <nl> std : : unique_ptr < StreamingEdenServiceAsyncClient > getEdenClient ( <nl> <nl> / * * Create a thrift client that will connect to the eden server associated <nl> * with the current user . <nl> - * This particular client uses the RSocketClientChannel channel that <nl> + * This particular client uses the RocketClientChannel channel that <nl> * is required to use the new thrift streaming protocol . * / <nl> - std : : unique_ptr < StreamingEdenServiceAsyncClient > getRSocketEdenClient ( <nl> + std : : unique_ptr < StreamingEdenServiceAsyncClient > getRocketEdenClient ( <nl> w_string_piece rootPath , <nl> folly : : EventBase * eb = folly : : EventBaseManager : : get ( ) - > getEventBase ( ) ) { <nl> return retryEStale ( [ & ] { <nl> auto addr = getEdenSocketAddress ( rootPath ) ; <nl> <nl> return make_unique < StreamingEdenServiceAsyncClient > ( <nl> - apache : : thrift : : RSocketClientChannel : : newChannel ( <nl> + apache : : thrift : : RocketClientChannel : : newChannel ( <nl> TAsyncSocket : : UniquePtr ( new TAsyncSocket ( eb , addr ) ) ) ) ; <nl> } ) ; <nl> } <nl> class EdenView : public QueryableView { <nl> } <nl> } <nl> <nl> - std : : unique_ptr < StreamingEdenServiceAsyncClient > rSocketSubscribe ( <nl> + std : : unique_ptr < StreamingEdenServiceAsyncClient > rocketSubscribe ( <nl> std : : shared_ptr < w_root_t > root , <nl> SettleCallback & settleCallback , <nl> std : : chrono : : milliseconds & settleTimeout ) { <nl> - auto client = getRSocketEdenClient ( root - > root_path , & subscriberEventBase_ ) ; <nl> + auto client = getRocketEdenClient ( root - > root_path , & subscriberEventBase_ ) ; <nl> auto stream = client - > sync_subscribeStreamTemporary ( <nl> std : : string ( root - > root_path . data ( ) , root - > root_path . size ( ) ) ) ; <nl> auto streamFuture = <nl> class EdenView : public QueryableView { <nl> std : : chrono : : milliseconds settleTimeout ( root - > trigger_settle ) ; <nl> std : : unique_ptr < StreamingEdenServiceAsyncClient > client ; <nl> <nl> - client = rSocketSubscribe ( root , settleCallback , settleTimeout ) ; <nl> + client = rocketSubscribe ( root , settleCallback , settleTimeout ) ; <nl> <nl> / / This will run until the stream ends <nl> watchman : : log ( watchman : : DBG , \" Started subscription thread loop \\ n \" ) ; <nl>\n"}
{"diff_id": 42263, "repo": "xbmc/xbmc\n", "sha": "e7cb48d870485094cd1181ce9636fa321b88fab0\n", "time": "2011-03-01T12:00:36Z\n", "diff": "mmm a / xbmc / cores / dvdplayer / DVDPlayer . cpp <nl> ppp b / xbmc / cores / dvdplayer / DVDPlayer . cpp <nl> bool CDVDPlayer : : OpenInputStream ( ) <nl> <nl> for ( unsigned int i = 0 ; i < filenames . size ( ) ; i + + ) <nl> { <nl> - CLog : : Log ( LOGERROR , \" test subs Amet [ % s ] \" , filenames [ i ] . c_str ( ) ) ; <nl> / / if vobsub subtitle : <nl> if ( URIUtils : : GetExtension ( filenames [ i ] ) = = \" . idx \" ) <nl> { <nl>\n", "msg": "cosmetics , remove some debug logging\n"}
{"diff_id": 42693, "repo": "facebook/hhvm\n", "sha": "3da6f82fd4d04021e3683aa022f1da20955cd17b\n", "time": "2013-12-18T19:41:47Z\n", "diff": "mmm a / hphp / compiler / expression / simple_function_call . cpp <nl> ppp b / hphp / compiler / expression / simple_function_call . cpp <nl> void SimpleFunctionCall : : analyzeProgram ( AnalysisResultPtr ar ) { <nl> } <nl> } <nl> if ( ! ok ) { <nl> - Compiler : : Error ( Compiler : : UnknownFunction , shared_from_this ( ) ) ; <nl> + if ( m_classScope | | ! Unit : : lookupFunc ( String ( m_name ) . get ( ) ) ) { <nl> + Compiler : : Error ( Compiler : : UnknownFunction , shared_from_this ( ) ) ; <nl> + } <nl> } <nl> } <nl> } <nl> ExpressionPtr hphp_opt_is_callable ( CodeGenerator * cg , <nl> } <nl> <nl> } <nl> - <nl>\n", "msg": "Don ' t warn for system functions that aren ' t known at static analysis time\n"}
{"diff_id": 42764, "repo": "microsoft/vcpkg\n", "sha": "62d67d3bf8eeff1afa8009041fd08b8822676b7b\n", "time": "2019-06-19T23:39:04Z\n", "diff": "mmm a / toolsrc / src / vcpkg / export . chocolatey . cpp <nl> ppp b / toolsrc / src / vcpkg / export . chocolatey . cpp <nl> if ( Test - Path $ installedDir ) <nl> const std : : string nuspec_file_content = <nl> create_nuspec_file_contents ( per_package_dir_path . string ( ) , binary_paragraph , packages_version , chocolatey_options ) ; <nl> const fs : : path nuspec_file_path = per_package_dir_path / Strings : : concat ( binary_paragraph . spec . name ( ) , \" . nuspec \" ) ; <nl> - fs . write_contents ( nuspec_file_path , nuspec_file_content ) ; <nl> + fs . write_contents ( nuspec_file_path , nuspec_file_content , VCPKG_LINE_INFO ) ; <nl> <nl> fs . create_directory ( per_package_dir_path / \" tools \" , ec ) ; <nl> <nl> const std : : string chocolatey_install_content = create_chocolatey_install_contents ( ) ; <nl> const fs : : path chocolatey_install_file_path = per_package_dir_path / \" tools \" / \" chocolateyInstall . ps1 \" ; <nl> - fs . write_contents ( chocolatey_install_file_path , chocolatey_install_content ) ; <nl> + fs . write_contents ( chocolatey_install_file_path , chocolatey_install_content , VCPKG_LINE_INFO ) ; <nl> <nl> const std : : string chocolatey_uninstall_content = create_chocolatey_uninstall_contents ( binary_paragraph ) ; <nl> const fs : : path chocolatey_uninstall_file_path = per_package_dir_path / \" tools \" / \" chocolateyUninstall . ps1 \" ; <nl> - fs . write_contents ( chocolatey_uninstall_file_path , chocolatey_uninstall_content ) ; <nl> + fs . write_contents ( chocolatey_uninstall_file_path , chocolatey_uninstall_content , VCPKG_LINE_INFO ) ; <nl> <nl> const auto cmd_line = Strings : : format ( R \" ( \" % s \" pack - OutputDirectory \" % s \" \" % s \" - NoDefaultExcludes > nul ) \" , <nl> nuget_exe . u8string ( ) , <nl>\n", "msg": "rebase and fix build breaks .\n"}
{"diff_id": 42768, "repo": "facebook/hhvm\n", "sha": "a1446f8b468965fc8617af8e8c61227c384aec4a\n", "time": "2019-09-23T22:39:10Z\n", "diff": "mmm a / hphp / runtime / base / program - functions . cpp <nl> ppp b / hphp / runtime / base / program - functions . cpp <nl> hugifyText ( char * from , char * to ) { <nl> } <nl> size_t sz = to - from ; <nl> <nl> + # ifdef FACEBOOK <nl> if ( RuntimeOption : : EvalNewTHPHotText ) { <nl> auto const hasKernelSupport = [ ] ( ) - > bool { <nl> KernelVersion version ; <nl> if ( version . m_major < 5 ) return false ; <nl> if ( version . m_major > 5 ) return true ; <nl> if ( version . m_minor > 2 ) return true ; <nl> - # ifdef FACEBOOK <nl> - if ( ( version . m_minor = = 2 ) & & ( version . m_minor > = 9 ) ) return true ; <nl> - # endif <nl> + if ( ( version . m_minor = = 2 ) & & ( version . m_fbk > = 1 ) ) return true ; <nl> return false ; <nl> } ; <nl> if ( hasKernelSupport ( ) ) { <nl> hugifyText ( char * from , char * to ) { <nl> return ; <nl> } <nl> } <nl> + # endif <nl> <nl> void * mem = malloc ( sz ) ; <nl> memcpy ( mem , from , sz ) ; <nl>\n", "msg": "use new hugify method only in fb builds\n"}
{"diff_id": 42825, "repo": "esp8266/Arduino\n", "sha": "d891704c1e041e556267744e99213cc7b80550fd\n", "time": "2016-02-26T15:41:27Z\n", "diff": "mmm a / cores / esp8266 / Print . cpp <nl> ppp b / cores / esp8266 / Print . cpp <nl> size_t ICACHE_FLASH_ATTR Print : : write ( const uint8_t * buffer , size_t size ) { <nl> } <nl> <nl> size_t Print : : printf ( const char * format , . . . ) { <nl> - va_list arg ; <nl> - va_start ( arg , format ) ; <nl> - char temp [ 1460 ] ; <nl> - size_t len = ets_vsnprintf ( temp , 1460 , format , arg ) ; <nl> - len = print ( temp ) ; <nl> - va_end ( arg ) ; <nl> - return len ; <nl> + va_list arg ; <nl> + va_start ( arg , format ) ; <nl> + char temp [ 64 ] ; <nl> + char * buffer = temp ; <nl> + size_t len = vsnprintf ( temp , sizeof ( temp ) , format , arg ) ; <nl> + va_end ( arg ) ; <nl> + if ( len > sizeof ( temp ) - 1 ) { <nl> + buffer = new char [ len + 1 ] ; <nl> + if ( ! buffer ) { <nl> + return 0 ; <nl> + } <nl> + va_start ( arg , format ) ; <nl> + vsnprintf ( buffer , len + 1 , format , arg ) ; <nl> + va_end ( arg ) ; <nl> + } <nl> + len = write ( ( const uint8_t * ) buffer , len ) ; <nl> + if ( buffer ! = temp ) { <nl> + delete [ ] buffer ; <nl> + } <nl> + return len ; <nl> } <nl> <nl> size_t ICACHE_FLASH_ATTR Print : : print ( const __FlashStringHelper * ifsh ) { <nl>\n", "msg": "Reduce stack usage by Print : : printf\n"}
{"diff_id": 42915, "repo": "apple/foundationdb\n", "sha": "084afbd22d6d108b646ee41637d40207a06f529f\n", "time": "2020-05-18T22:22:44Z\n", "diff": "mmm a / fdbserver / BackupProgress . actor . cpp <nl> ppp b / fdbserver / BackupProgress . actor . cpp <nl> std : : map < std : : tuple < LogEpoch , Version , int > , std : : map < Tag , Version > > BackupProgr <nl> <nl> auto progressIt = progress . lower_bound ( epoch ) ; <nl> if ( progressIt ! = progress . end ( ) & & progressIt - > first = = epoch ) { <nl> - if ( progressIt ! = progress . begin ( ) ) { <nl> - / / Previous epoch is gone , consolidate the progress . <nl> + std : : set < Tag > toCheck = tags ; <nl> + for ( auto current = progressIt ; current ! = progress . begin ( ) & & ! toCheck . empty ( ) ; ) { <nl> auto prev = std : : prev ( progressIt ) ; <nl> + / / Previous epoch is gone , consolidate the progress . <nl> for ( auto [ tag , version ] : prev - > second ) { <nl> - if ( tags . count ( tag ) > 0 ) { <nl> + if ( toCheck . count ( tag ) > 0 ) { <nl> progressIt - > second [ tag ] = std : : max ( version , progressIt - > second [ tag ] ) ; <nl> + toCheck . erase ( tag ) ; <nl> } <nl> } <nl> + current = prev ; <nl> } <nl> updateTagVersions ( & tagVersions , & tags , progressIt - > second , info . epochEnd , adjustedBeginVersion , epoch ) ; <nl> } else { <nl> auto rit = std : : find_if ( <nl> progress . rbegin ( ) , progress . rend ( ) , <nl> [ epoch = epoch ] ( const std : : pair < LogEpoch , std : : map < Tag , Version > > & p ) { return p . first < epoch ; } ) ; <nl> - if ( ! ( rit = = progress . rend ( ) ) ) { <nl> + while ( ! ( rit = = progress . rend ( ) ) ) { <nl> / / A partial recovery can result in empty epoch that copies previous <nl> / / epoch ' s version range . In this case , we should check previous <nl> / / epoch ' s savedVersion . <nl> std : : map < std : : tuple < LogEpoch , Version , int > , std : : map < Tag , Version > > BackupProgr <nl> / / ASSERT ( info . logRouterTags = = epochTags [ rit - > first ] ) ; <nl> <nl> updateTagVersions ( & tagVersions , & tags , rit - > second , info . epochEnd , adjustedBeginVersion , epoch ) ; <nl> + break ; <nl> } <nl> + rit + + ; <nl> } <nl> } <nl> <nl>\n", "msg": "True - up backup progress may go back multiple epochs\n"}
{"diff_id": 42979, "msg": "Disable Project Export button after deleting preset\n", "msgGPT": "disable export button and remove export preset when deleting a preset in project export dialog.", "METEOR Score": "48.13412376209137", "BLEU Score": "0.4597391261750378", "ROUGE-L Score": "0.5263157848199447", "score": 1, "repo": "godotengine/godot\n", "sha": "2fc2d824650ad1fa4fa3a2a09fe3d5d878a80712\n", "time": "2019-04-23T15:49:15Z\n", "diff": "mmm a / editor / project_export . cpp <nl> ppp b / editor / project_export . cpp <nl> void ProjectExportDialog : : _delete_preset_confirm ( ) { <nl> <nl> int idx = presets - > get_current ( ) ; <nl> _edit_preset ( - 1 ) ; <nl> + export_button - > set_disabled ( true ) ; <nl> EditorExport : : get_singleton ( ) - > remove_export_preset ( idx ) ; <nl> _update_presets ( ) ; <nl> } <nl>\n"}
{"diff_id": 43071, "repo": "telegramdesktop/tdesktop\n", "sha": "b09aa49749da36dc13a55ecc399764205c0132a1\n", "time": "2016-03-13T13:25:19Z\n", "diff": "mmm a / Telegram / SourceFiles / historywidget . cpp <nl> ppp b / Telegram / SourceFiles / historywidget . cpp <nl> void HistoryWidget : : cancelEdit ( ) { <nl> updateMouseTracking ( ) ; <nl> } <nl> <nl> + int32 old = _textUpdateEventsFlags ; <nl> + _textUpdateEventsFlags = 0 ; <nl> onTextChange ( ) ; <nl> + _textUpdateEventsFlags = old ; <nl> + <nl> updateBotKeyboard ( ) ; <nl> updateFieldPlaceholder ( ) ; <nl> <nl>\n", "msg": "not sending typing when edit post is finished\n"}
{"diff_id": 43348, "repo": "xbmc/xbmc\n", "sha": "6102167e9a9882fe83976582268d0d403a442667\n", "time": "2012-03-26T02:53:05Z\n", "diff": "mmm a / xbmc / interfaces / python / xbmcmodule / window . cpp <nl> ppp b / xbmc / interfaces / python / xbmcmodule / window . cpp <nl> namespace PYXBMC <nl> Control * pControl = ( Control * ) object ; <nl> <nl> { <nl> - GilSafeSingleLock lock ( g_graphicsContext ) ; <nl> + CPyThreadState state ; <nl> + CSingleLock lock ( g_graphicsContext ) ; <nl> if ( ! self - > pWindow - > GetControl ( pControl - > iControlId ) ) <nl> { <nl> + lock . Leave ( ) ; <nl> + state . Restore ( ) ; <nl> PyErr_SetString ( PyExc_RuntimeError , \" Control does not exist in window \" ) ; <nl> return false ; <nl> } <nl>\n", "msg": "correct usage of CPyThreadState and g_graphicsContext locking in Window_RemoveSingleControl ( ensure we release both before accessing other python functions )\n"}
{"diff_id": 43447, "repo": "apple/swift\n", "sha": "188d218886a9d9ccccbfa727c42d7c24c2cb04dc\n", "time": "2016-12-01T19:11:45Z\n", "diff": "mmm a / lib / AST / ArchetypeBuilder . cpp <nl> ppp b / lib / AST / ArchetypeBuilder . cpp <nl> bool ArchetypeBuilder : : addSuperclassRequirement ( PotentialArchetype * T , <nl> RequirementSource Source ) { <nl> T = T - > getRepresentative ( ) ; <nl> <nl> - if ( Superclass - > hasArchetype ( ) ) { <nl> - / / Map contextual type to interface type . <nl> - / / FIXME : There might be a better way to do this . <nl> - Superclass = Superclass . transform ( <nl> - [ & ] ( Type t ) - > Type { <nl> - if ( t - > is < ArchetypeType > ( ) ) { <nl> - auto * pa = resolveArchetype ( t ) ; <nl> - / / Why does this happen ? <nl> - if ( ! pa ) <nl> - return ErrorType : : get ( t ) ; <nl> - return pa - > getDependentType ( / * FIXME : * / { } , <nl> - / * allowUnresolved = * / false ) ; <nl> - } <nl> - return t ; <nl> - } ) ; <nl> - } <nl> - <nl> / / Make sure the concrete type fulfills the superclass requirement <nl> / / of the archetype . <nl> if ( T - > isConcreteType ( ) ) { <nl>\n", "msg": "[ Archetype builder ] Remove some dead code . NFC\n"}
{"diff_id": 43460, "repo": "xbmc/xbmc\n", "sha": "2c1e2f6c27da2aac32c90282071f786175c87b9b\n", "time": "2014-01-05T13:56:48Z\n", "diff": "mmm a / xbmc / video / VideoDatabase . cpp <nl> ppp b / xbmc / video / VideoDatabase . cpp <nl> void CVideoDatabase : : CleanDatabase ( CGUIDialogProgressBarHandle * handle , const se <nl> { <nl> std : : map < int , bool > : : const_iterator pathsDeleteDecision = pathsDeleteDecisions . find ( m_pDS - > fv ( 0 ) . get_asInt ( ) ) ; <nl> if ( ( pathsDeleteDecision ! = pathsDeleteDecisions . end ( ) & & pathsDeleteDecision - > second ) | | <nl> - ( pathsDeleteDecision = = pathsDeleteDecisions . end ( ) & & ! CDirectory : : Exists ( m_pDS - > fv ( 1 ) . get_asString ( ) ) ) ) <nl> + ( pathsDeleteDecision = = pathsDeleteDecisions . end ( ) & & ! CDirectory : : Exists ( m_pDS - > fv ( 1 ) . get_asString ( ) , false ) ) ) <nl> strIds + = m_pDS - > fv ( 0 ) . get_asString ( ) + \" , \" ; <nl> <nl> m_pDS - > next ( ) ; <nl>\n", "msg": "videodb : never use cached lookups during database cleaning\n"}
{"diff_id": 43465, "msg": "change WrapperForTiming to WrapperForQLock\n", "msgGPT": "rename wrapper for timing class to wrapper for q lock class in mongo namespace.", "METEOR Score": "42.93482147587903", "BLEU Score": "0.527304964820815", "ROUGE-L Score": "0.6666666619135801", "score": 1, "repo": "mongodb/mongo\n", "sha": "ea480461f0ba0af13d0849f9a3427a0150e57082\n", "time": "2012-05-07T14:35:36Z\n", "diff": "mmm a / src / mongo / db / d_concurrency . cpp <nl> ppp b / src / mongo / db / d_concurrency . cpp <nl> namespace mongo { <nl> static void unlocking_w ( ) ; <nl> static void unlocking_W ( ) ; <nl> <nl> - class WrapperForTiming { <nl> + class WrapperForQLock { <nl> QLock q ; <nl> public : <nl> LockStat stats ; <nl> namespace mongo { <nl> bool R_to_W ( ) { return q . R_to_W ( ) ; } <nl> } ; <nl> <nl> - static WrapperForTiming & q = * new WrapperForTiming ( ) ; <nl> + static WrapperForQLock & q = * new WrapperForQLock ( ) ; <nl> <nl> void reportLockStats ( BSONObjBuilder & result ) { <nl> BSONObjBuilder b ; <nl>\n"}
{"diff_id": 43526, "repo": "arangodb/arangodb\n", "sha": "dc74a0b68123a3620dd46e1942b8d5e4f942aa67\n", "time": "2016-08-18T12:52:45Z\n", "diff": "mmm a / arangod / Cluster / ClusterComm . cpp <nl> ppp b / arangod / Cluster / ClusterComm . cpp <nl> size_t ClusterComm : : performSingleRequest ( <nl> * ( req . headerFields ) , timeout ) ; <nl> } <nl> <nl> - / / mop : obviously an error happened <nl> - const char * body = \" \" ; <nl> - int64_t bodyLen = 0 ; <nl> + std : : unordered_map < std : : string , std : : string > headers ; <nl> / / mop : helpless attempt to fix segfaulting due to body buffer empty <nl> - if ( req . result . status ! = CL_COMM_BACKEND_UNAVAILABLE ) { <nl> - / / Add correct recognition of content type later . <nl> - basics : : StringBuffer & buffer = req . result . result - > getBody ( ) ; <nl> - body = buffer . c_str ( ) ; <nl> - bodyLen = static_cast < int64_t > ( buffer . length ( ) ) ; <nl> - <nl> - req . result . status = CL_COMM_RECEIVED ; / / a fake , but a good one <nl> - req . done = true ; <nl> + if ( req . result . status = = CL_COMM_BACKEND_UNAVAILABLE ) { <nl> + THROW_ARANGO_EXCEPTION ( TRI_ERROR_CLUSTER_BACKEND_UNAVAILABLE ) ; <nl> } <nl> + <nl> + / / Add correct recognition of content type later . <nl> + basics : : StringBuffer & buffer = req . result . result - > getBody ( ) ; <nl> + const char * body = buffer . c_str ( ) ; <nl> + <nl> + int64_t bodyLen = static_cast < int64_t > ( buffer . length ( ) ) ; <nl> + <nl> + req . result . status = CL_COMM_RECEIVED ; / / a fake , but a good one <nl> + req . done = true ; <nl> + headers = req . result . result - > getHeaderFields ( ) ; <nl> nrDone = 1 ; <nl> / / This was it , except for a small problem : syncRequest reports back in <nl> / / req . result . result of type httpclient : : SimpleHttpResult rather than <nl> size_t ClusterComm : : performSingleRequest ( <nl> GeneralRequest : : ContentType type = GeneralRequest : : ContentType : : JSON ; <nl> <nl> auto answer = new FakeRequest ( type , body , bodyLen ) ; <nl> - answer - > setHeaders ( req . result . result - > getHeaderFields ( ) ) ; <nl> + answer - > setHeaders ( headers ) ; <nl> req . result . answer . reset ( static_cast < GeneralRequest * > ( answer ) ) ; <nl> req . result . answer_code = static_cast < GeneralResponse : : ResponseCode > ( <nl> req . result . result - > getHttpReturnCode ( ) ) ; <nl>\n", "msg": "Throw exceptions to avoid any circus behaviour\n"}
{"diff_id": 43531, "repo": "xbmc/xbmc\n", "sha": "6bd5eb0e589d92688466011a9108fe1de6376df1\n", "time": "2013-09-27T11:39:48Z\n", "diff": "mmm a / xbmc / cores / dvdplayer / DVDPlayer . cpp <nl> ppp b / xbmc / cores / dvdplayer / DVDPlayer . cpp <nl> bool CDVDPlayer : : HasMenu ( ) <nl> <nl> bool CDVDPlayer : : GetCurrentSubtitle ( CStdString & strSubtitle ) <nl> { <nl> - double pts = m_clock . GetClock ( ) ; <nl> + double pts = m_clock . GetClock ( ) + m_State . time_offset ; <nl> <nl> - if ( m_pInputStream & & m_pInputStream - > IsStreamType ( DVDSTREAM_TYPE_DVD ) ) <nl> + if ( m_pInputStream & & m_pInputStream - > IsStreamType ( DVDSTREAM_TYPE_DVD ) & & m_CurrentSubtitle . source ! = STREAM_SOURCE_TEXT ) <nl> return false ; <nl> <nl> m_dvdPlayerSubtitle . GetCurrentSubtitle ( strSubtitle , pts - m_dvdPlayerVideo . GetSubtitleDelay ( ) ) ; <nl>\n", "msg": "[ fix ] Allow the use of external subtitles for DVDs\n"}
{"diff_id": 43561, "repo": "apple/swift\n", "sha": "38bfcc655f3e1c1e4c05fb2dccf21f7542d7df84\n", "time": "2016-10-21T16:22:56Z\n", "diff": "mmm a / tools / sil - opt / SILOpt . cpp <nl> ppp b / tools / sil - opt / SILOpt . cpp <nl> EnableResilience ( \" enable - resilience \" , <nl> \" interfaces for all public declarations by \" <nl> \" default \" ) ) ; <nl> <nl> + static llvm : : cl : : opt < bool > <nl> + EnableSILOwnershipOpt ( \" enable - sil - ownership \" , <nl> + llvm : : cl : : desc ( \" Compile the module with sil - ownership initially enabled for all functions \" ) ) ; <nl> + <nl> static llvm : : cl : : opt < std : : string > <nl> ResourceDir ( \" resource - dir \" , <nl> llvm : : cl : : desc ( \" The directory that holds the compiler resource files \" ) ) ; <nl> int main ( int argc , char * * argv ) { <nl> SILOpts . AssertConfig = AssertConfId ; <nl> if ( OptimizationGroup ! = OptGroup : : Diagnostics ) <nl> SILOpts . Optimization = SILOptions : : SILOptMode : : Optimize ; <nl> - <nl> + SILOpts . EnableSILOwnership = EnableSILOwnershipOpt ; <nl> <nl> / / Load the input file . <nl> llvm : : ErrorOr < std : : unique_ptr < llvm : : MemoryBuffer > > FileBufOrErr = <nl>\n", "msg": "[ semantic - arc ] Add an option to SILOpt to set the EnableSILOwnership flag .\n", "score": 1}
{"diff_id": 43570, "repo": "xbmc/xbmc\n", "sha": "55b47a50459503e14ae33ed3a4b6fbef2513d112\n", "time": "2011-08-17T06:29:45Z\n", "diff": "mmm a / xbmc / video / VideoDatabase . cpp <nl> ppp b / xbmc / video / VideoDatabase . cpp <nl> bool CVideoDatabase : : GetItemsForPath ( const CStdString & content , const CStdString <nl> GetMusicVideosByWhere ( \" \" , where , items ) ; <nl> } <nl> for ( int i = 0 ; i < items . Size ( ) ; i + + ) <nl> - items [ i ] - > SetPath ( items [ i ] - > GetVideoInfoTag ( ) - > m_strFileNameAndPath ) ; <nl> + items [ i ] - > SetPath ( items [ i ] - > GetVideoInfoTag ( ) - > m_basePath ) ; <nl> return items . Size ( ) > 0 ; <nl> } <nl>\n", "msg": "Revert \" fixed : Better fix for bccb52dd1fb708959a4cf93e14761178b337182a - Video metadata would not show in the video files node for stacked files ( thanks Jonathan for all the pointers ) \"\n", "score": 1}
{"diff_id": 43597, "repo": "CRYTEK/CRYENGINE\n", "sha": "4a22edf0b127161ac68671ab0ea6ce883101121c\n", "time": "2018-09-04T06:56:18Z\n", "diff": "mmm a / Code / CryPlugins / CryDefaultEntities / Module / DefaultComponents / Physics / RigidBodyComponent . cpp <nl> ppp b / Code / CryPlugins / CryDefaultEntities / Module / DefaultComponents / Physics / RigidBodyComponent . cpp <nl> void CRigidBodyComponent : : Physicalize ( ) <nl> { <nl> SEntityPhysicalizeParams physParams ; <nl> physParams . type = ( int ) m_type ; <nl> + <nl> + Enable ( m_isEnabledByDefault ) ; <nl> <nl> / / Don ' t physicalize a slot by default <nl> physParams . nSlot = std : : numeric_limits < int > : : max ( ) ; <nl> void CRigidBodyComponent : : Physicalize ( ) <nl> buoyancyParams . waterDamping = m_buoyancyParameters . damping ; <nl> m_pEntity - > GetPhysicalEntity ( ) - > SetParams ( & buoyancyParams ) ; <nl> <nl> - Enable ( m_isEnabledByDefault ) ; <nl> } <nl> <nl> void CRigidBodyComponent : : ProcessEvent ( const SEntityEvent & event ) <nl>\n", "msg": "! I 1843114 / / ce / main_stabilisation - > / / ce / main ! B ( CE - 18107 ) ( CryDefaultEntities ) Rigidbody component ' s \" Enabled by Default \" property can ' t be re - enabled\n"}
{"diff_id": 43650, "repo": "arangodb/arangodb\n", "sha": "d1051f13cdb4ff4600a8010bcffa0ad6d7b0c808\n", "time": "2017-04-26T09:01:03Z\n", "diff": "mmm a / arangosh / Dump / DumpFeature . cpp <nl> ppp b / arangosh / Dump / DumpFeature . cpp <nl> int DumpFeature : : dumpCollection ( int fd , std : : string const & cid , <nl> uint64_t chunkSize = _chunkSize ; <nl> <nl> std : : string const baseUrl = <nl> - \" / _api / replication / dump ? collection = \" + cid + \" & ticks = false & flush = false \" ; <nl> + \" / _api / replication / dump ? collection = \" + cid + <nl> + \" & batchId = \" + StringUtils : : itoa ( _batchId ) + <nl> + \" & ticks = false & flush = false \" ; <nl> <nl> uint64_t fromTick = _tickStart ; <nl> <nl> while ( true ) { <nl> std : : string url = baseUrl + \" & from = \" + StringUtils : : itoa ( fromTick ) + <nl> - \" & chunkSize = \" + StringUtils : : itoa ( chunkSize ) + <nl> - \" & batchId = \" + StringUtils : : itoa ( _batchId ) ; <nl> + \" & chunkSize = \" + StringUtils : : itoa ( chunkSize ) ; <nl> <nl> if ( maxTick > 0 ) { <nl> url + = \" & to = \" + StringUtils : : itoa ( maxTick ) ; <nl> int DumpFeature : : runDump ( std : : string & dbName , std : : string & errorMsg ) { <nl> int DumpFeature : : dumpShard ( int fd , std : : string const & DBserver , <nl> std : : string const & name , std : : string & errorMsg ) { <nl> std : : string const baseUrl = \" / _api / replication / dump ? DBserver = \" + DBserver + <nl> + \" & batchId = \" + StringUtils : : itoa ( _batchId ) + <nl> \" & collection = \" + name + \" & chunkSize = \" + <nl> StringUtils : : itoa ( _chunkSize ) + \" & ticks = false \" ; <nl> <nl>\n", "msg": "add batchId to dump for for shards\n"}
{"diff_id": 43666, "repo": "sqlitebrowser/sqlitebrowser\n", "sha": "f05e3a211c393bb21686aaf41b680176e608a8ea\n", "time": "2016-05-17T16:59:23Z\n", "diff": "mmm a / src / ExportCsvDialog . cpp <nl> ppp b / src / ExportCsvDialog . cpp <nl> bool ExportCsvDialog : : exportQuery ( const QString & sQuery , const QString & sFilenam <nl> QChar quoteChar = currentQuoteChar ( ) ; <nl> QString quotequoteChar = QString ( quoteChar ) + quoteChar ; <nl> QChar sepChar = currentSeparatorChar ( ) ; <nl> + <nl> + / / Choose appropriate newline character for the platform <nl> + # ifdef Q_OS_WIN <nl> QString newlineChar = \" \\ r \\ n \" ; <nl> + # else <nl> + QString newlineChar = \" \\ n \" ; <nl> + # endif <nl> <nl> / / chars that require escaping <nl> std : : string special_chars = newlineChar . toStdString ( ) + sepChar . toLatin1 ( ) + quoteChar . toLatin1 ( ) ; <nl>\n", "msg": "Change the newline character for CSV export depending upon the platform\n", "score": 1}
{"diff_id": 43762, "repo": "EOSIO/eos\n", "sha": "621fae83e29ae41d82c436effa0cbfbebc5e0295\n", "time": "2019-09-20T11:48:11Z\n", "diff": "mmm a / unittests / forked_tests . cpp <nl> ppp b / unittests / forked_tests . cpp <nl> BOOST_AUTO_TEST_CASE ( push_block_returns_forked_transactions ) try { <nl> push_blocks ( c , c2 ) ; <nl> <nl> wlog ( \" c1 blocks : \" ) ; <nl> + signed_block_ptr cb ; <nl> c . produce_blocks ( 3 ) ; <nl> signed_block_ptr b ; <nl> - b = c . produce_block ( ) ; <nl> + cb = b = c . produce_block ( ) ; <nl> account_name expected_producer = N ( dan ) ; <nl> BOOST_REQUIRE_EQUAL ( b - > producer . to_string ( ) , expected_producer . to_string ( ) ) ; <nl> <nl> BOOST_AUTO_TEST_CASE ( push_block_returns_forked_transactions ) try { <nl> BOOST_REQUIRE_EQUAL ( b - > producer . to_string ( ) , expected_producer . to_string ( ) ) ; <nl> / / create accounts on c1 which will be forked out <nl> c . produce_block ( ) ; <nl> - auto trace1 = c . create_account ( N ( test1 ) ) ; <nl> + <nl> + transaction_trace_ptr trace1 , trace2 , trace3 ; <nl> + { / / create account the hard way so we can set reference block and expiration <nl> + signed_transaction trx ; <nl> + authority active_auth ( get_public_key ( N ( test1 ) , \" active \" ) ) ; <nl> + authority owner_auth ( get_public_key ( N ( test1 ) , \" owner \" ) ) ; <nl> + trx . actions . emplace_back ( vector < permission_level > { { config : : system_account_name , config : : active_name } } , <nl> + newaccount { <nl> + . creator = config : : system_account_name , <nl> + . name = N ( test1 ) , <nl> + . owner = owner_auth , <nl> + . active = active_auth , <nl> + } ) ; <nl> + trx . expiration = c . control - > head_block_time ( ) + fc : : seconds ( 60 ) ; <nl> + trx . set_reference_block ( cb - > id ( ) ) ; <nl> + trx . sign ( get_private_key ( config : : system_account_name , \" active \" ) , c . control - > get_chain_id ( ) ) ; <nl> + trace1 = c . push_transaction ( trx ) ; <nl> + } <nl> c . produce_block ( ) ; <nl> - auto trace2 = c . create_account ( N ( test2 ) ) ; <nl> - auto trace3 = c . create_account ( N ( test3 ) ) ; <nl> + { <nl> + signed_transaction trx ; <nl> + authority active_auth ( get_public_key ( N ( test2 ) , \" active \" ) ) ; <nl> + authority owner_auth ( get_public_key ( N ( test2 ) , \" owner \" ) ) ; <nl> + trx . actions . emplace_back ( vector < permission_level > { { config : : system_account_name , config : : active_name } } , <nl> + newaccount { <nl> + . creator = config : : system_account_name , <nl> + . name = N ( test2 ) , <nl> + . owner = owner_auth , <nl> + . active = active_auth , <nl> + } ) ; <nl> + trx . expiration = c . control - > head_block_time ( ) + fc : : seconds ( 60 ) ; <nl> + trx . set_reference_block ( cb - > id ( ) ) ; <nl> + trx . sign ( get_private_key ( config : : system_account_name , \" active \" ) , c . control - > get_chain_id ( ) ) ; <nl> + trace2 = c . push_transaction ( trx ) ; <nl> + } <nl> + { <nl> + signed_transaction trx ; <nl> + authority active_auth ( get_public_key ( N ( test3 ) , \" active \" ) ) ; <nl> + authority owner_auth ( get_public_key ( N ( test3 ) , \" owner \" ) ) ; <nl> + trx . actions . emplace_back ( vector < permission_level > { { config : : system_account_name , config : : active_name } } , <nl> + newaccount { <nl> + . creator = config : : system_account_name , <nl> + . name = N ( test3 ) , <nl> + . owner = owner_auth , <nl> + . active = active_auth , <nl> + } ) ; <nl> + trx . expiration = c . control - > head_block_time ( ) + fc : : seconds ( 60 ) ; <nl> + trx . set_reference_block ( cb - > id ( ) ) ; <nl> + trx . sign ( get_private_key ( config : : system_account_name , \" active \" ) , c . control - > get_chain_id ( ) ) ; <nl> + trace3 = c . push_transaction ( trx ) ; <nl> + } <nl> c . produce_block ( ) ; <nl> c . produce_blocks ( 9 ) ; <nl> <nl> BOOST_AUTO_TEST_CASE ( push_block_returns_forked_transactions ) try { <nl> / / verify transaction on fork is reported by push_block in order <nl> BOOST_REQUIRE_EQUAL ( 3 , c . get_unapplied_transaction_queue ( ) . size ( ) ) ; <nl> BOOST_REQUIRE_EQUAL ( trace1 - > id , c . get_unapplied_transaction_queue ( ) . begin ( ) - > id ( ) ) ; <nl> - c . get_unapplied_transaction_queue ( ) . erase ( c . get_unapplied_transaction_queue ( ) . begin ( ) ) ; <nl> - BOOST_REQUIRE_EQUAL ( trace2 - > id , c . get_unapplied_transaction_queue ( ) . begin ( ) - > id ( ) ) ; <nl> - c . get_unapplied_transaction_queue ( ) . erase ( c . get_unapplied_transaction_queue ( ) . begin ( ) ) ; <nl> - BOOST_REQUIRE_EQUAL ( trace3 - > id , c . get_unapplied_transaction_queue ( ) . begin ( ) - > id ( ) ) ; <nl> + BOOST_REQUIRE_EQUAL ( trace2 - > id , ( + + c . get_unapplied_transaction_queue ( ) . begin ( ) ) - > id ( ) ) ; <nl> + BOOST_REQUIRE_EQUAL ( trace3 - > id , ( + + ( + + c . get_unapplied_transaction_queue ( ) . begin ( ) ) ) - > id ( ) ) ; <nl> + <nl> + BOOST_REQUIRE_EXCEPTION ( c . control - > get_account ( N ( test1 ) ) , fc : : exception , <nl> + [ a = N ( test1 ) ] ( const fc : : exception & e ) - > bool { <nl> + return std : : string ( e . what ( ) ) . find ( a . to_string ( ) ) ! = std : : string : : npos ; <nl> + } ) ; <nl> + BOOST_REQUIRE_EXCEPTION ( c . control - > get_account ( N ( test2 ) ) , fc : : exception , <nl> + [ a = N ( test2 ) ] ( const fc : : exception & e ) - > bool { <nl> + return std : : string ( e . what ( ) ) . find ( a . to_string ( ) ) ! = std : : string : : npos ; <nl> + } ) ; <nl> + BOOST_REQUIRE_EXCEPTION ( c . control - > get_account ( N ( test3 ) ) , fc : : exception , <nl> + [ a = N ( test3 ) ] ( const fc : : exception & e ) - > bool { <nl> + return std : : string ( e . what ( ) ) . find ( a . to_string ( ) ) ! = std : : string : : npos ; <nl> + } ) ; <nl> + <nl> + / / produce block which will apply the unapplied transactions <nl> + c . produce_block ( ) ; <nl> + <nl> + / / verify unapplied transactions ran <nl> + BOOST_REQUIRE_EQUAL ( c . control - > get_account ( N ( test1 ) ) . name , N ( test1 ) ) ; <nl> + BOOST_REQUIRE_EQUAL ( c . control - > get_account ( N ( test2 ) ) . name , N ( test2 ) ) ; <nl> + BOOST_REQUIRE_EQUAL ( c . control - > get_account ( N ( test3 ) ) . name , N ( test3 ) ) ; <nl> <nl> } FC_LOG_AND_RETHROW ( ) <nl> <nl>\n", "msg": "Enhance push_block_returns_forked_transactions test to verify forked unapplied transactions are applied .\n"}
{"diff_id": 43904, "msg": "issue : Using 800x450 as design resolution for TestJavascript .\n", "msgGPT": "set design resolution size for js- test in HTML5 to 800x450 pixels.", "METEOR Score": "31.497174990904778", "BLEU Score": "0.5572977793184941", "ROUGE-L Score": "0.36363635867768596", "score": 1, "repo": "cocos2d/cocos2d-x\n", "sha": "89ccd9240eeea8ed8f1b2a90a3856a318294aea1\n", "time": "2013-06-27T08:10:42Z\n", "diff": "mmm a / samples / Javascript / TestJavascript / Classes / AppDelegate . cpp <nl> ppp b / samples / Javascript / TestJavascript / Classes / AppDelegate . cpp <nl> bool AppDelegate : : applicationDidFinishLaunching ( ) <nl> Director * pDirector = Director : : sharedDirector ( ) ; <nl> pDirector - > setOpenGLView ( EGLView : : sharedOpenGLView ( ) ) ; <nl> <nl> + / / JS - Test in Html5 uses 800x450 as design resolution <nl> + EGLView : : sharedOpenGLView ( ) - > setDesignResolutionSize ( 800 , 450 , kResolutionFixedHeight ) ; <nl> / / turn on display FPS <nl> pDirector - > setDisplayStats ( true ) ; <nl> <nl>\n"}
{"diff_id": 43983, "repo": "ClickHouse/ClickHouse\n", "sha": "df87bead2e6b8746c521f5f9feacb8db4701ef81\n", "time": "2016-05-16T18:46:19Z\n", "diff": "mmm a / dbms / src / Parsers / ASTAlterQuery . cpp <nl> ppp b / dbms / src / Parsers / ASTAlterQuery . cpp <nl> void ASTAlterQuery : : addParameters ( const Parameters & params ) <nl> children . push_back ( params . sharding_key_expr ) ; <nl> if ( params . coordinator ) <nl> children . push_back ( params . coordinator ) ; <nl> + if ( params . primary_key ) <nl> + children . push_back ( params . primary_key ) ; <nl> } <nl> <nl> ASTAlterQuery : : ASTAlterQuery ( StringRange range_ ) : IAST ( range_ ) <nl>\n", "msg": "Alter primary key : development [ # METR - 21119 ] .\n", "score": 1}
{"diff_id": 44334, "repo": "EOSIO/eos\n", "sha": "0530e1ec5e0b8838b611c52241d735fc8b73500a\n", "time": "2018-09-14T19:46:34Z\n", "diff": "mmm a / libraries / chain / authorization_manager . cpp <nl> ppp b / libraries / chain / authorization_manager . cpp <nl> namespace eosio { namespace chain { <nl> EOS_ASSERT ( checker . satisfied ( p . first , p . second ) , unsatisfied_authorization , <nl> \" transaction declares authority ' $ { auth } ' , \" <nl> \" but does not have signatures for it under a provided delay of $ { provided_delay } ms , \" <nl> - \" provided permissions $ { provided_permissions } , and provided keys $ { provided_keys } \" , <nl> + \" provided permissions $ { provided_permissions } , provided keys $ { provided_keys } , \" <nl> + \" and a delay max limit of $ { delay_max_limit_ms } ms \" , <nl> ( \" auth \" , p . first ) <nl> ( \" provided_delay \" , provided_delay . count ( ) / 1000 ) <nl> ( \" provided_permissions \" , provided_permissions ) <nl> namespace eosio { namespace chain { <nl> <nl> EOS_ASSERT ( checker . satisfied ( { account , permission } ) , unsatisfied_authorization , <nl> \" permission ' $ { auth } ' was not satisfied under a provided delay of $ { provided_delay } ms , \" <nl> - \" provided permissions $ { provided_permissions } , and provided keys $ { provided_keys } \" , <nl> + \" provided permissions $ { provided_permissions } , provided keys $ { provided_keys } , \" <nl> + \" and a delay max limit of $ { delay_max_limit_ms } ms \" , <nl> ( \" auth \" , permission_level { account , permission } ) <nl> ( \" provided_delay \" , provided_delay . count ( ) / 1000 ) <nl> ( \" provided_permissions \" , provided_permissions ) <nl>\n", "msg": "Correct assert message by including delay_max_limit_ms\n"}
{"diff_id": 44635, "repo": "godotengine/godot\n", "sha": "9e57c359b769bef1a5659079b7c4fdccee08d4cb\n", "time": "2018-11-24T14:03:54Z\n", "diff": "mmm a / scene / gui / scroll_bar . cpp <nl> ppp b / scene / gui / scroll_bar . cpp <nl> void ScrollBar : : _notification ( int p_what ) { <nl> <nl> if ( Math : : abs ( vel ) > = dist ) { <nl> set_value ( target_scroll ) ; <nl> + scrolling = false ; <nl> + set_physics_process_internal ( false ) ; <nl> } else { <nl> set_value ( get_value ( ) + vel ) ; <nl> } <nl>\n", "msg": "Fix scroll bar lock when smooth scroll enabled , issue 23314\n"}
{"diff_id": 44875, "repo": "xbmc/xbmc\n", "sha": "ca1ccae57d8d5b4b7e8c6db55c2c148a202a5023\n", "time": "2020-06-08T17:56:51Z\n", "diff": "mmm a / xbmc / video / windows / GUIWindowVideoNav . cpp <nl> ppp b / xbmc / video / windows / GUIWindowVideoNav . cpp <nl> void CGUIWindowVideoNav : : LoadVideoInfo ( CFileItemList & items , CVideoDatabase & dat <nl> CFileItemPtr pItem = items [ i ] ; <nl> CFileItemPtr match ; <nl> <nl> - if ( ! content . empty ( ) & & pItem - > m_bIsFolder & & ! pItem - > IsParentFolder ( ) ) <nl> + if ( pItem - > m_bIsFolder & & ! pItem - > IsParentFolder ( ) ) <nl> { <nl> / / we need this for enabling the right context menu entries , like mark watched / unwatched <nl> pItem - > SetProperty ( \" IsVideoFolder \" , true ) ; <nl>\n", "msg": "[ video ] Re - add ' Mark watched / unwatched ' context menu items to content - less video sources .\n"}
